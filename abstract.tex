\documentclass[ILAS2025-program.tex]{subfiles}

\begin{document}

\parindent=0pt
\parskip=5pt

\section{Abstracts of Plenary Talks}


\hypertarget{down0009}{}\begin{ilasabstract}
\talktitle{Tubal tensor algebra: mathematical foundations and applications
}
    
\textbf{Haim Avron}, \info{11:00\textrm{--}12:00 @ SYS Hall (June 27, Friday)} \hfill \hyperlink{up0009}{$\Uparrow$}
    
    
\mtskip
    Developed in a series of seminal papers in the early 2010s, the tubal tensor framework provides a clean and effective algebraic setting for tensor computations, supporting matrix-mimetic features such as a tensor Singular Value Decomposition and Eckart–Young-like optimality results. It has proven to be a powerful tool for analyzing inherently multilinear data arising in hyperspectral imaging, medical imaging, neural dynamics, scientific simulations, and more.

At the heart of tubal tensor algebra lies a special tensor-tensor product: originally the t-product, later generalized into a full family of products via the *M-product. Though initially defined through the multiplication of a block-circulant unfolding of one tensor by a matricization of another, it was soon observed that the t-product can be interpreted as standard matrix multiplication where the scalars are tubes—i.e., real vectors twisted ``inward.'' Yet, a fundamental question remains: Why is this the ``right'' way to define a tensor-tensor product in the tubal setting?

In the talk, I will discuss the mathematical foundations of the tubal tensor framework, and discuss applications and extensions. In particular, I will show that the t-product and its *M generalization arises naturally when viewing third-order tensors as matrices of tubes, together with a small set of desired natural algebraic properties. Furthermore,*M-product is, in fact, the unique way to define a tubal product satisfying these properties, and these desired properties are required for the tubal SVD and Eckart–Young-like optimality results.


\end{ilasabstract}
    

\hypertarget{down0005}{}\begin{ilasabstract}
\talktitle{Matrix structures in queueing and network models: An overview}
    
\textbf{Dario Andrea Bini}, \info{09:00\textrm{--}10:00 @ SYS Hall (June 25, Wednesday)} \hfill \hyperlink{up0005}{$\Uparrow$}
    
    
\mtskip
    We provide an overview of some results concerning classes of matrices involved in queueing and network models. We show specific examples where the analysis of matrix structures, besides providing a better understanding of the original problem, is a fundamental step in designing effective ad hoc solution algorithms.

Two specific issues are considered:  the analysis of random walks on a regular grid in the quarter plane, and the assessment of the centrality of the edges in a graph. Both issues derive from the analysis of relevant real-world problems and are modeled by Markov chains describing random walks on a graph. 

In the first topic, the graph is a regular grid, and the specific features of the problem lead to semi-infinite transition probability matrices with a two-level tridiagonal and almost Toeplitz structure. We show that these matrices live in a suitable infinite-dimensional structured matrix algebra which is also a Banach space with respect to the infinity norm. This fact will be crucial to designing effective fast algorithms for computing the steady-state vector of the associated Markov chain.

In the second topic, the graph is typically a road map of a city or region. Thus, the Toeplitz structure of the associated transition probability matrix is lost. However, the sparsity and band structure of this matrix will allow us to easily compute a centrality measure of the edges defined in terms of Kemeny's constant of the associated Markov chain. The effectiveness of the model and the solution algorithms is tested on the road maps of Pisa and Tuscany.

\end{ilasabstract}
    

\hypertarget{down0006}{}\begin{ilasabstract}
\talktitle{Clustering in graphs with high clustering coefficients}
    
\textbf{Fan Chung}, \info{08:00\textrm{--}09:00 @ SYS Hall (June 26, Thursday)} \hfill \hyperlink{up0006}{$\Uparrow$}
    
    
\mtskip
    Many real world networks possess the so-called small world phenomenon where every node is relatively close to every other node and have a large clustering coefficient, i.e., friends of friends are likely friends. The task of learning an adequate similarity measure on various feature spaces often involves  graphs with high clustering coefficients.
We investigate the clustering effect in sparse  clustering graphs by examining the structural and spectral  properties as well as the enumeration  of patterns. In addition, we consider random graph models for clustering graphs that can be use to analyze the behavior of complex networks.
\end{ilasabstract}
    

\hypertarget{down0003}{}\begin{ilasabstract}
\talktitle{The canonical form for congruence: some history and applications}
    
\textbf{Fernando De Terán}, \info{09:00\textrm{--}10:00 @ SYS Hall (June 24, Tuesday)} \hfill \hyperlink{up0003}{$\Uparrow$}
    
    
\mtskip
    A square matrix $A$ can be either seen as a linear map or as a bilinear form. When considered as a linear map, it is natural to introduce the relation of ``similarity'', $P^{-1}AP$ (with $P$ invertible), which is a change of basis that allows us to represent the linear map in a simpler form, in particular in the well-known ``Jordan canonical form''. When considering the matrix $A$ as a bilinear form, the natural relation instead is the one of ``congruence'', $P^\top AP$ (with $P$ invertible), which is the suitable change of basis for bilinear forms. Is there a canonical form for such a relation? The answer is yes, and actually some different canonical forms for congruence have been introduced over the years since the 1930's. In this talk I will introduce the most recent one (by Horn and Sergeichuk, 2006), review the history of this and the other canonical forms, and show some applications in the context of my past and current research, including:
\begin{itemize}
    \item The solution of the equation $AX+X^\top A=0$ and its connection to $\top$-palindromic pencils.
    \item The consistency of the equation $X^\top AX=B$ when $B$ is either symmetric or skew-symmetric.
\end{itemize}
\end{ilasabstract}
    

\hypertarget{down0001}{}\begin{ilasabstract}
\talktitle{Various inequalities for quasi-arithmetic mean and quasi-geometric type means of matrices}
    
\textbf{Fumio Hiai}, \info{09:30\textrm{--}10:30 @ SYS Hall (June 23, Monday)} \hfill \hyperlink{up0001}{$\Uparrow$}
    
    
\mtskip
    Our targets in this talk are the quasi extensions of the weighted arithmetic mean and of the weighted geometric type means, including the weighted geometric mean, the weighted spectral geometric mean, the R\'enyi mean, and the Log-Euclidean mean, for positive (semi)definite matrices. For example,
\begin{align*}
&\mathcal{A}_{\alpha,p}(A,B):=(\alpha A^p+(1-\alpha)B^p)^{1/p},
\ \mbox{the quasi-weighted arithmetic mean}, \\
&G_{\alpha,p}(A,B):=(A^p\#_\alpha B^p)^{1/p},
\ \mbox{the quasi-weighted geometric mean}, \\
&R_{\alpha,p}(A,B):=\bigl(B^{{\frac{1-\alpha}{2}}p}A^{\alpha p}B^{{\frac{1-\alpha}{2}}p}\bigr)^{1/p},
\ \mbox{the R\'enyi mean}, \\
&LE_\alpha(A,B):=\exp(\alpha\log A+(1-\alpha)\log B),
\ \mbox{the weighted Log-Euclidean mean},
\end{align*}
where $\alpha\in(0,1)$ (or all $\alpha>0$) is the weight parameter and $p>0$ is the parameter of the quasi extension.
For the quasi versions of these weighted matrix means we consider inequalities in different types of orders such as the Loewner order $\le$, the chaotic $\le_{\mathrm{ch}}$ (i.e., $\log X\le \log Y$), the near order $\le_{\mathrm{ne}}$ (i.e., $X\#Y^{-1}\le I$), the entrywise eigenvalue order $\le_\lambda$, the log-majorization $\prec_{\log}$, the weak majorization $\prec_w$, and the order under trace (i.e., $\mathrm{Tr}\,X\le\mathrm{Tr}\,Y$), whose order relations weaken in this writing order.
Our objective is to pursue under which condition of the parameters $\alpha,p,q$ the inequality $\mathcal{M}_{\alpha,p}(A,B)\triangleleft\mathcal{N}_{\alpha,q}(A,B)$ holds for all positive (semi)definite matrices $A,B$, for any pair $(\mathcal{M}_{\alpha,p},\mathcal{N}_{\alpha,q})$ from the above quasi-weighted means and for any order $\triangleleft$ mentioned above.
For instance, it is shown that $\mathcal{A}_{\alpha,p}(A,B)\le\mathcal{A}_{\alpha,q}(A,B)$ holds for all $A,B\ge0$ if and only if $p=q$ or $1\le p<q$ or $1/2\le p<1\le q$, whereas, for any other weaker order $\triangleleft$, $\mathcal{A}_{\alpha,p}(A,B)\triangleleft\mathcal{A}_{\alpha,q}(A,B)$ holds for all $A,B\ge0$ if and only if $p\le q$. When $(\mathcal{M}_{\alpha,p},\mathcal{N}_{\alpha,q})$ is a pair from the quasi-weighted geometric type means, we are mostly interested in the condition of $\alpha,p,q$ under which the log-majorization $\mathcal{M}_{\alpha,p}(A,B)\prec_{\log}\mathcal{N}_{\alpha,q}(A,B)$ holds and whether $AB=BA$ follows from the equality case $\mathrm{Tr}\,\mathcal{M}_{\alpha,p}(A,B)=\mathrm{Tr}\,\mathcal{N}_{\alpha,q}(A,B)$ in this situation.
\end{ilasabstract}
    

\hypertarget{down0004}{}\begin{ilasabstract}
\talktitle{Adaptive randomized pivoting}
    
\textbf{Daniel Kressner}, \info{08:00\textrm{--}09:00 @ SYS Hall (June 25, Wednesday)} \hfill \hyperlink{up0004}{$\Uparrow$}
    
    
\mtskip
    Finding good subsets of row and column indices, often called pivots, is a ubiquitous task in applied and numerical linear algebra. One of its most famous appearances is arguably in Gaussian elimination for solving linear systems, where a good choice of pivots is crucial for numerical stability. This talk will focus on pivoting in the context of low-dimensional approximation, including column subset selection, discrete empirical interpolation, and various interpolative decompositions, such as the CUR and Cholesky/Nystrom approximations. In all of these cases, a greedy choice of pivots usually works well but there are well-known counterexamples where such a choice leads to poor results. We present a new randomized pivot selection strategy that avoids such unfavorable worst-case performance by using adaptivity in two senses: It adapts to information on the range / co-range of a matrix, and the sampling distribution is updated after each pivot selection. Adaptive randomized pivoting enjoys error guarantees that match, in expectation, the best known existence results. At the same time, it is   simpler and usually cheaper than volume-based techniques, which achieve similar guarantees through volume sampling or iterative local volume maximization. We will illustrate several applications of adaptive randomized pivoting and discuss derandomized variants. This talk is based on joint work with Alice Cortinovis, University of Pisa.
\end{ilasabstract}
    

\hypertarget{down0008}{}\begin{ilasabstract}
\talktitle{Principal joint block diagonalization    }
    
\textbf{Ren-Cang Li}, \info{10:00\textrm{--}11:00 @ SYS Hall (June 27, Friday)} \hfill \hyperlink{up0008}{$\Uparrow$}
    
    
\mtskip
    Matrix joint block-diagonalization frequently arises from diverse applications such as
independent component analysis, blind source separation, and common principal component analysis (CPCA),
among others. CPCA, a special case, is about joint diagonalization, i.e.,
each blocksize being 1-by-1. In the last fifteen years or so, CPCA has attracted a great deal of attention because
of its applications to, e.g., multivariate data analysis and multiview  clustering.
Generically three or more matrices cannot be jointly block-diagonalized, but practically,
a reasonably good approximate joint block-diagonalization suffices  for
real-world applications. This talk is concerned with fast  {\em Principal Joint Block Diagonalization\/}, in which
our focus is on dominant and partial common block-diagonal structure among the 
matrices of interest, in contrast to most existing methods, such as the popular ones based on Givens' rotation,
which by nature have to go for full joint diagonalization and can be too time-consuming to be practical for a group of modest sized matrices
that are not sufficiently close to being jointly diagonalizable.
An NPDo approach is proposed for maximizing the common dominant block-diagonal parts.
It is shown the NPDo approach is globally convergent to a stationary point
while the objective function increases monotonically. Along similar lines,
joint principal SVD-type block-diagonalization is also investigated.
Numerical experiments will be presented to illustrate the use of the NPDo approach and demonstrate its superiority
to existing methods for matrices of dimension 200 or larger.

\end{ilasabstract}
    

\hypertarget{down0007}{}\begin{ilasabstract}
\talktitle{Using algebra to prove Erd\H{o}s-Ko-Rado type theorems
}
    
\textbf{Karen Meagher}, \info{09:00\textrm{--}10:00 @ SYS Hall (June 26, Thursday)} \hfill \hyperlink{up0007}{$\Uparrow$}
    
    
\mtskip
    My research focuses on variations of the Erd\H{o}s-Ko-Rado (EKR) theorem. The question was to determine the largest set of subsets of size $k$ from $\{1,2,\dots,n\}$, with the property that any two of the $k$-subsets have non-empty intersection. The Erd\H{o}s-Ko-Rado (EKR) theorem states that a largest such set can only be formed by taking all $k$-subsets that contain a common fixed point.

More generally, for any object for which ``intersection'' can be defined, we can ask the same question: what is the largest set of objects with the property that any two objects in the set have non-empty intersection? For many objects the answer to this question is a result analogous to EKR theorem for $k$-subsets. When this holds, it can be considered to be an \textbf{EKR-type theorem}.

Typically, these questions are considered to be problems from design theory and there are many different proof approaches that can applied. In my work (and in my opinion) the best results come from using tools from linear algebra. 

In this talk, I will give an overview of how to use linear algebra to prove EKR-type theorems. My focus will be on results for intersecting sets of permutations from transitive groups. For these objects (the permutations) we define a graph, called \textbf{the derangement graph}. The eigenvalues of the this graph can be determined from the group, and the using the \textbf{ratio bound} the eigenvalues give a bound on the size of the largest intersecting set of permutations. This graph has lovely algebraic properties, in particular it is a graph in an association scheme, which means that strong tools from linear algebra are available.

\end{ilasabstract}
    

\hypertarget{down0002}{}\begin{ilasabstract}
\talktitle{Extremal eigenvalue multiplicities of matrices of a given pattern
}
    
\textbf{Polona Oblak}, \info{08:00\textrm{--}09:00 @ SYS Hall (June 24, Tuesday)} \hfill \hyperlink{up0002}{$\Uparrow$}
    
    
\mtskip
    We explore the family ${\mathcal S}(G)$ of real symmetric matrices whose off-diagonal zero-nonzero pattern matches the one of the adjacency matrix of a given simple graph $G$. Our focus is on the eigenvalue multiplicities that such matrices can attain, which is a subproblem of the well-studied Inverse Eigenvalue Problem for a Graph (IEP-$G$).



While every ${\mathcal S}(G)$ contains a matrix with all eigenvalues simple, understanding constraints on high multiplicities remains a significant challenge. 
Interpreting multiplicity lists as partitions, we will examine the following key parameters: the maximum achievable multiplicity of any eigenvalue, the largest possible minimal multiplicity, and the minimal number of distinct eigenvalues attainable by matrices in ${\mathcal S}(G)$.
We will also discuss constraints on matrices that realise the extreme values of the relevant parameter.

\end{ilasabstract}
    

\hypertarget{down0000}{}\begin{ilasabstract}
\talktitle{A ramble through mathematics relevant for quantum theory:  A personal perspective
}
    
\textbf{Karol Życzkowski}, \info{08:30\textrm{--}09:30 @ SYS Hall (June 23, Monday)} \hfill \hyperlink{up0000}{$\Uparrow$}
    
    
\mtskip
    Which branches of mathematics are the most important for a physicist working in quantum theory? 
How to foster an interdisciplinary collaboration of a theoretical physicists and a mathematician?
Which problems motivated by quantum theory can be inspiring for the mathematical community?  
Basing on personal experience concerning research related to linear algebra, operator theory, matrix analysis, random matrices, geometry of convex sets, group theory and combinatorics, I will argue that such a collaboration is possible and can be fruitful.

\end{ilasabstract}
    \newpage

\section{Abstracts of Mini-symposium Talks}


\hypertarget{down0179}{}\begin{ilasabstract}
\talktitle{Recent developments of switching methods for the construction of cospectral graphs}
    
\textbf{Aida Abiad}, \info{14:30\textrm{--}15:00 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0179}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    Switching is an operation on a graph that does not change the spectrum of the adjacency matrix, thus producing cospectral graphs. An important activity in the field of spectral graph theory is the characterization of graphs by their spectrum. Hence, switching provides a tool for disproving the existence of such a characterization. 

In this talk we will overview recent progress on switching methods for the construction of cospectral graphs. Work by Wang and Xu (2010) suggests that most cospectral graphs with cospectral complements can be constructed using regular orthogonal matrices of level 2, which has relevance for Haemers' conjecture. In this direction, we will present two new switching methods based on regular orthogonal matrices of level 2. We will also show a general framework for counting the number of graphs that have a non-isomorphic cospectral graph through any of the existing switching methods for the adjacency matrix, expanding on the work by Haemers and Spence (2004).  

This is joint work with Nils van de Berg and Robin Simoens.

\end{ilasabstract}
    

\hypertarget{down0391}{}\begin{ilasabstract}
\talktitle{Block cross-interactive residual smoothing for block Lanczos-type iterative solvers}
    
\textbf{Kensuke Aihara}, \info{16:00\textrm{--}16:30 @ SC4011 (June 26, Thursday)} \hfill \hyperlink{up0391}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    Block Lanczos-type iterative solvers are effective for large sparse nonsymmetric linear systems with multiple right-hand sides. However, the methods often exhibit large oscillations in the residual and approximation norms. The large oscillations are known to lead to a large increase in the residual gap (the difference between the recursively updated residual and the explicitly computed residual) due to rounding errors. The cross-interactive residual smoothing (CIRS) is a useful scheme to improve convergence behavior and the residual gap for a single right-hand side case. This approach ensures that the primary and smoothed sequences of residuals influence one another, thereby avoiding the severe propagation of rounding errors. In our previous study, we have extended CIRS to the global version that can be applicable to linear matrix equations. In this study, we propose another extension to the multiple right-hand sides case; that is, a block version of CIRS (Bl-CIRS). Subsequently, we demonstrate its effectiveness through a rounding error analysis and numerical experiments. We show that orthonormalizing the columns of direction matrices in Bl-CIRS is crucial to reduce the residual gap. This talk is based on our recent preprint [arXiv:2412.19488] jointly worked on Dr. Akira Imakura and Dr. Keiichi Morikuni. 

\end{ilasabstract}
    

\hypertarget{down0059}{}\begin{ilasabstract}
\talktitle{A low-complexity LSTM network to realize multibeam beamforming
}
    
\textbf{Hansaka Aluvihare}, \info{14:30\textrm{--}15:00 @ SC1003 (June 23, Monday)} \hfill \hyperlink{up0059}{$\Uparrow$}
    
    
(in {\color{mstitle}MS26: Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics})
        
\mtskip
    Even large amounts of data can be efficiently realized by imposing structures into neural networks through structured weight matrices. These structured weight matrices could be trained to realize phase shifts for specific beams in multi-beam beamforming, along with input and output vectors made up of time-domain signals. In our previous research, we showed that wideband multi-beam beamformers using true-time-delays (TTDs) can be represented by delay Vandermonde matrices (DVM). We use a frequency-domain transformation to explicitly express the TTD-based time delay data in terms of the elements of the DVM-structured weight matrices. Building upon these weight matrices, we introduce a novel low-complexity neural network LSTM architecture for realizing wideband multi-beam beamformers. The proposed structured LSTM network reduces the computational complexity for realizing wideband multi-beam beamformers from $\mathcal{O}(N^2L)$ to $\mathcal{O}(N^sL)$, where $1 < s < 2$ and $L$ is the number of layers.

\end{ilasabstract}
    

\hypertarget{down0170}{}\begin{ilasabstract}
\talktitle{Doubly stochastic matrices and graphs}
    
\textbf{Enide Andrade}, \info{14:00\textrm{--}14:30 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0170}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    In this talk we present a study about inverses of modified Laplacian matrices; the modification is by adding the
identity matrix which gives a positive definite matrix. We investigate the relationship between
the underlying graph and the properties of this inverse. 
\end{ilasabstract}
    

\hypertarget{down0338}{}\begin{ilasabstract}
\talktitle{Laplacian eigenvalues of weighted threshold graphs}
    
\textbf{Milica Anđelić}, \info{15:00\textrm{--}15:30 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0338}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    We provide a closed  formula to compute the Laplacian spectrum of weighted threshold graphs. We also  show that their Laplacian eigenvalues are the parts of the conjugate partition of the associated   weighted Ferrers diagrams. \\

({\it This is a joint work with Zoran Stani\'c, Faculty of Mathematics, University of Belgrade, Serbia.})
\end{ilasabstract}
    

\hypertarget{down0168}{}\begin{ilasabstract}
\talktitle{Identifying and estimating dynamical covariance matrices with hierarchical rank structure}
    
\textbf{Robin Armstrong}, \info{15:00\textrm{--}15:30 @ SC0014 (June 24, Tuesday)} \hfill \hyperlink{up0168}{$\Uparrow$}
    
    
(in {\color{mstitle}MS6: Model reduction})
        
\mtskip
    Many algorithms in data assimilation and model reduction rely on sample-based estimates for covariance matrices associated with the trajectory of a high-dimensional dynamical system. The number of available samples is often far less than the dimension of the underlying state space, making it necessary to impose a regularizing structural assumption such as spatial localization. This talk will examine the use of hierarchical rank structure as a regularizing assumption for high-dimensional covariance estimation. Whereas spatial localization assumes that long-range correlations are near-zero, hierarchical rank structure corresponds to the situation where long-range correlations vary more smoothly than short-range ones. We will first examine, from theoretical and empirical circumstances, the conditions under which this assumption is appropriate. We will then present algorithms and experiments which show how to estimate a high-dimensional covariance matrix from limited samples by imposing hierarchical rank structure. Covariance matrices associated with turbulent fluid dynamics, numerical weather prediction models, and Lorenz-type systems will serve as illustrative examples throughout.

\end{ilasabstract}
    

\hypertarget{down0158}{}\begin{ilasabstract}
\talktitle{Composition operators and convexity of their Berezin range on functional Hilbert spaces}
    
\textbf{Athul Augustine}, \info{14:00\textrm{--}14:30 @ SC0009 (June 24, Tuesday)} \hfill \hyperlink{up0158}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    We discuss the convexity of the range of the Berezin transform. Berezin range of a bounded linear operator $T$ acting on a reproducing kernel Hilbert space $\mathcal{H}$ is the set $B(T)$ := $\{\langle T\hat{k}_{x},\hat{k}_{x} \rangle_{\mathcal{H}} : x \in X\}$, where $\hat{k}_{x}$ is the normalized reproducing kernel for $\mathcal{H}$ at $x \in X$. The \textit{numerical range} of a bounded linear operator $T$ on a Hilbert space $\mathcal{H}$ is defined as $W(A):= \{\langle Tu,u\rangle : \|u\| = 1 \}.$ By Toeplitz-Hausdorff theorem, the numerical range of a linear operator on a Hilbert space is always convex.  It is easy to observe that the Berezin range of an operator $T$ is always a subset of the numerical range of $T$. In general, the Berezin range of an operator is not convex. Primarily, we focus on characterizing 
convexity of the Berezin range for classes of composition operators acting on some functional Hilbert spaces.

\end{ilasabstract}
    

\hypertarget{down0344}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Oleg Balabanov}, \info{14:00\textrm{--}14:30 @ SC3001 (June 26, Thursday)} \hfill \hyperlink{up0344}{$\Uparrow$}
    
    
(in {\color{mstitle}MS16: Approximations and errors in Krylov-based solvers})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0382}{}\begin{ilasabstract}
\talktitle{Structural symmetries in hypergraphs and their spectra}
    
\textbf{Anirban Banerjee}, \info{17:30\textrm{--}18:00 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0382}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    We investigate how certain connectivity matrices capture the structural symmetries in hypergraphs. We encode hypergraph symmetries through two frameworks: (1) equivalence relations on the vertex set and (2) hypergraph automorphisms. We demonstrate how these two formulations of symmetry manifest in the spectral properties of those hypergraph matrices. This study further identifies intriguing structural features, we term building blocks. Moreover, the spectral patterns induced by hypergraph symmetries provide insight into various dynamical processes, including dynamics on networks and random walks on graphs.

\end{ilasabstract}
    

\hypertarget{down0336}{}\begin{ilasabstract}
\talktitle{Limit points of the smallest positive eigenvalues of graphs
}
    
\textbf{Sasmita Barik}, \info{14:00\textrm{--}14:30 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0336}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    Hoffman initiated the study of limit points of eigenvalues of nonnegative symmetric integer matrices and posed the question of finding all limit points of the set of spectral radii of all nonnegative symmetric integer matrices. In the same article, the author showed that it is enough to consider the adjacency matrices of simple graphs to study the limit points of spectral radii. Since then, many researchers have worked on similar problems, considering various specific eigenvalues such as the least eigenvalue, the $k$-th largest eigenvalue, and the $k$-th smallest eigenvalue, among others. Motivated by this, we ask the question, ``which real numbers are the limit points of the set of the smallest positive eigenvalues (respectively, the largest negative eigenvalues) of graphs?'' In this talk, we provide a complete answer to this question by proving that any nonnegative (respectively, nonpositive) real number is a limit point of the set of all smallest positive eigenvalues (respectively, largest negative eigenvalues) of graphs. We also show that the union of the sets of limit points of the smallest positive eigenvalues and the largest negative eigenvalues of graphs is dense in $\mathbb{R}$.

\end{ilasabstract}
    

\hypertarget{down0209}{}\begin{ilasabstract}
\talktitle{Gaussian process regression for the identification of model dynamics}
    
\textbf{Christopher Beattie}, \info{16:00\textrm{--}16:30 @ SC0014 (June 24, Tuesday)} \hfill \hyperlink{up0209}{$\Uparrow$}
    
    
(in {\color{mstitle}MS6: Model reduction})
        
\mtskip
    Standard approximation strategies for Gaussian Process Regression may be linked with optimal spline approximation within the framework of a reproducing kernel Hilbert space determined by a given covariance function associated with a Bayesian prior.   We extend this framework to obtain optimal rational approximants (modeling rational transfer functions) utilizing intrinsic Gaussian processes and Bayesian priors that allow for data-driven modeling of dynamical systems with the management of nonstationary temporal dependence, drift, and observation errors.  I will review elements of a basic framework for Gaussian Process Regression and a version of ``rational kriging'' recently introduced by V. R. Joseph,  connecting this to optimal approximation in reproducing kernel Hilbert spaces with rational kernels, paralleling traditional Gaussian Process Regression approaches.

\end{ilasabstract}
    

\hypertarget{down0060}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Natalia Bebiano}, \info{15:00\textrm{--}15:30 @ SC1003 (June 23, Monday)} \hfill \hyperlink{up0060}{$\Uparrow$}
    
    
(in {\color{mstitle}MS26: Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0365}{}\begin{ilasabstract}
\talktitle{Computation of an exact and approximate GCRD of several polynomial matrices using generalized Sylvester matrices}
    
\textbf{Anjali Beniwal}, \info{17:00\textrm{--}17:30 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0365}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    The computation of an exact and approximate Greatest Common Right Divisor (GCRD) of polynomial matrices is a fundamental problem in control theory and signal processing. While extensive research has been conducted on the Greatest Common Divisors (GCDs) of scalar polynomials, the study of GCRDs in polynomial matrices remains relatively limited. It is important to develop fast and reliable ways to compute both exact and approximate GCRD, especially when dealing with approximate cases where the data is corrupted by noise.\\
We address the problem of computing both exact and approximate GCRDs for a given set of univariate polynomial matrices $B_1(s), \dots, B_t(s)$. We establish a key theoretical result—proving that the rank deficiency of a particular generalized Sylvester matrix associated with $P(s)$, where $P(s)$ is obtained by stacking $B_1(s), \dots, B_t(s)$ one below the other, corresponds to the degree of the determinant of their GCRD. This equivalence enables us to develop efficient algorithms for computing an exact GCRD using \textit{Effectively Eliminating QR} (EEQR) decomposition and $SVD$ of that particular generalized Sylvester matrix. $SVD$ can handle noise-corrupted data, making it particularly effective for computing an approximate GCRD. This approach leverages the numerical rank of that particular generalized Sylvester matrix to estimate the degree of an approximate GCRD. Both algorithms are simple to develop, easy to understand, and convenient to implement, ensuring scalability.\\
We validate our results through various numerical examples, demonstrating their effectiveness. These findings have significant implications for applications requiring polynomial matrix factorizations and simplifications in the presence of noise and uncertainty.
\end{ilasabstract}
    

\hypertarget{down0380}{}\begin{ilasabstract}
\talktitle{On the trace norm of $A_{\alpha}$ matrix of directed graphs}
    
\textbf{Mushtaq A. Bhat}, \info{16:30\textrm{--}17:00 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0380}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
     Let $D$ be a directed graph (or briefly digraph) of order $n$ with adjacency matrix $A(D)$. For $\alpha\in[0,1)$, the $A_{\alpha}$ matrix of $D$ is defined as $A_{\alpha}(D)=\alpha {\Delta}^{+}(D)+(1-\alpha)A(D)$, where ${\Delta}^{+}(D)=\mbox{diag}~(d_1^{+},d_2^{+},\dots,d_n^{+})$ is the diagonal matrix of vertex out degrees of $D$. Let $\sigma_{1\alpha}(D),\sigma_{2\alpha}(D),\\ \dots,\sigma_{n\alpha}(D)$ be the singular values of $A_{\alpha}(D)$. Then the trace norm of $A_{\alpha}(D)$, which we call the $\alpha$ trace norm of $D$, is defined as $\|A_{\alpha}(D)\|_*=\sum_{i=1}^{n}\sigma_{i\alpha}(D)$. In this talk, we discuss the singular values of some basic digraphs and present a characterization of the digraphs $D$ with $\mbox{Rank}~(A_{\alpha}(D))=1$. As an application of these results, we obtain a lower bound for the trace norm of $A_{\alpha}$ matrix of digraphs and determine the extremal digraphs. In particular, we determine the oriented trees for which the trace norm of $A_{\alpha}$ matrix attains minimum. We obtain a lower bound for the $\alpha$ spectral norm $\sigma_{1\alpha}(D)$ of digraphs and characterize the extremal digraphs. As an application of this result, we obtain an upper bound for the $\alpha$ trace norm of digraphs and characterize the extremal digraphs. 
\end{ilasabstract}
    

\hypertarget{down0207}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Saptak Bhattacharya}, \info{17:00\textrm{--}17:30 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0207}{$\Uparrow$}
    
    
(in {\color{mstitle}MS7: Linear algebra and quantum information science})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0201}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Davide Bianchi}, \info{16:00\textrm{--}16:30 @ SC0009 (June 24, Tuesday)} \hfill \hyperlink{up0201}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0025}{}\begin{ilasabstract}
\talktitle{Decay bounds for inverses of banded matrices via quasiseparable structure}
    
\textbf{Paola Boito}, \info{11:00\textrm{--}11:30 @ SC1003 (June 23, Monday)} \hfill \hyperlink{up0025}{$\Uparrow$}
    
    
(in {\color{mstitle}MS26: Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics})
        
\mtskip
    \begin{bibunit}
        A well-known result in matrix theory states that, under suitable hypotheses, the inverse of a banded matrix $A$ exhibits an exponential off-diagonal decay behavior. In other words, there exist constants $K>0$ and $0<\xi<1$, independent of matrix size, such that 
$$
[A^{-1}]_{ij}\leq K \xi^{|i-j|}.
$$
Several versions of such bounds are available in the literature. Most of them rely on polynomial approximation of the function $x\rightarrow 1/x$ on a convex subset of $\mathbb{C}$ containing the spectrum of $A$; see for instance the seminal work by Demko, Moss and Smith \cite{DMS84}.

Here we take a different approach, which exploits the quasiseparable structure of $A$ and $A^{-1}$. Based on recently proposed inversion algorithms for banded matrices \cite{BE23}, we develop new decay bounds for inverses of one-sided and two-sided banded matrices, under a hypothesis of strong diagonal dominance. Our bounds are easily computable, do not require spectral information on $A$ and can be advantageous for symmetric indefinite or nonsymmetric matrices.

This is joint work with Yuli Eidelman (Tel-Aviv University). 


\begin{thebibliography}{99}
\bibitem{BE23}
P.~Boito and Y.~Eidelman, Computation of quasiseparable representations of Green matrices. Linear Algebra and its Applications, in press (available online 6 May 2024).
\bibitem{DMS84}
S.~Demko, W.~F.~Moss, and P.~W.~Smith,
Decay rates for inverses of band matrices. Mathematics of Computation 43.168 (1984), 491-499.
\end{thebibliography}


        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0372}{}\begin{ilasabstract}
\talktitle{The distance to bounded realness revisited}
    
\textbf{Shreemayee Bora}, \info{16:30\textrm{--}17:00 @ SC1003 (June 26, Thursday)} \hfill \hyperlink{up0372}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    The spectrum of a Hamiltonian matrix is symmetric with respect to the imaginary axis. Hence its eigenvalues occur in pairs $(\lambda, -\bar{\lambda})$ if the matrix is complex and in quadruples, $(\lambda, \bar{\lambda}, -\bar{\lambda},-\lambda)$ if the matrix is real. This pairing breaks down when the eigenvalues are purely imaginary and this can lead to numerical challenges in computational methods used in optimal control.  The distance from a given Hamiltonian matrix $H$ to a nearest Hamiltonian matrix $H + \Delta H$ such that any further arbitrarily small Hamiltonian perturbation to $H + \Delta H$ generically removes all its purely imaginary eigenvalues is called the \emph{distance to bounded realness}. Algorithms for finding an upper bound of this distance have been obtained in the literature. In this talk we will present upper and lower bounds on the distance to \emph{bounded realness} which are often seen to be tight in numerical experiments. In fact in many cases the bounds are seen to be equal. We identify conditions under which the equality holds. In particular, we show that our algorithm computes the distance if the Hamiltonian matrix $H$ has only purely imaginary eigenvalues with the ones of positive type being separated from those of negative type. The key to obtaining the results is to convert the Hamiltonian matrix eigenvalue problem into that of an eigenvalue problem associated with a closely related Hermitian matrix pencil.

This is joint work with Kannan R. of the Department of Mathematics, IIT Guwahati. 

\end{ilasabstract}
    

\hypertarget{down0222}{}\begin{ilasabstract}
\talktitle{On the tree cover number and the positive semidefinite maximum nullity of a graph}
    
\textbf{Chassidy Bozeman}, \info{16:30\textrm{--}17:00 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0222}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    Let $G=(V,E)$ be  a simple graph. A tree cover of $G$ is a collection of  vertex-disjoint simple trees occurring as induced subgraphs of $G$ that together cover all the vertices of $G$. The tree cover number of $G$, denoted $T(G)$, is the minimum cardinality of a tree cover. We give a characterization of connected outerplanar graphs whose tree cover number equals the upper bound of $\lceil \frac{n}{2} \rceil$.  We also present results on tree cover number of graph with girth at least 5. In 2011, [Barioli et al., Minimum semidefinite rank of outerplanar graphs and the tree cover number, {\em Elec. J. Lin. Alg.,} 2011] introduced the tree cover number as a tool for studying the maximum nullity of a family of matrices associated with a graph:  Let $\mathcal{S}_+(G)$ denote the set of real positive semidefinite matrices $A=(a_{ij})$ such that for $i\neq j$, $a_{ij}\neq 0$ if $\{i,j\}\in E$ and $a_{ij}=0$ if $\{i,j\}\notin E$. The positive semidefinite maximum  nullity of $G$, denoted $M_+(G),$ is $\max\{\text{null}(A)|A\in \mathcal{S}_+(G)\}.$ It was conjectured in 2011 that $T(G) \le \mathrm{M}_+(G)$ holds for all graphs, and shown that equality holds when $G$ is outerplanar.  Therefore our bounds on $T(G)$ give bounds on $M_+(G)$ for outerplanar graphs. We show that the conjecture $T(G)\leq M_+(G)$ is true for certain other graph families.

\end{ilasabstract}
    

\hypertarget{down0032}{}\begin{ilasabstract}
\talktitle{Measuring the impact of a single transition on Kemeny's constant
}
    
\textbf{Jane Breen}, \info{11:30\textrm{--}12:00 @ SC2001 (June 23, Monday)} \hfill \hyperlink{up0032}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    Kemeny's constant is a measure of the expected length of a random trip between states of a Markov chain, and is a useful quantifier of the mixing properties of the Markov chain. By examining how the value of Kemeny's constant changes when the probability transition matrix is perturbed, one can determine the transitions which have the greatest impact on the connectivity of the Markov chain. This has been shown to be useful in a wide range of applications, including road network dynamics and social network decomposition. In this talk, we give an overview of several methods to determine the importance of a single transition to the value of Kemeny's constant and discuss some applications.

\end{ilasabstract}
    

\hypertarget{down0332}{}\begin{ilasabstract}
\talktitle{Incorporating data science applications into standard linear algebra courses
}
    
\textbf{Jane Breen}, \info{14:00\textrm{--}14:30 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0332}{$\Uparrow$}
    
    
(in {\color{mstitle}MS27: Linear algebra education})
        
\mtskip
    Linear algebra plays a central role in data science, but it can be hard for students to see that connection in a traditional course, and instructors do not always have the flexibility in the curriculum to spend time on these ideas. In this talk, I’ll share practical ways that I have introduced data science-inspired problems and applications into standard linear algebra classes in the past. 

\end{ilasabstract}
    

\hypertarget{down0203}{}\begin{ilasabstract}
\talktitle{Matrix-free stochastic calculation of operator norms without using adjoint---on the way to compute the adjoint mismatch}
    
\textbf{Jonas Bresch}, \info{17:00\textrm{--}17:30 @ SC0009 (June 24, Tuesday)} \hfill \hyperlink{up0203}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    Linear inverse problems are of great interest in the last years.
In this talk, we investigate linear inverse problems where the adjoint of the forward operator is not know exactly.
Therefore, we focus on the problem of computing the norm of an operator (between finite dimensional Hilbert spaces),
more precisely $\|A\|$ respectively $\|A - V\|$,
where only evaluations of the linear map $x \mapsto A x$, 
respectively and $y \mapsto V^*y$ are available 
with restrictive storage assumptions for the proposed algorithm.
We propose stochastic methods of random search type for the maximization of the Rayleigh quotient
respectively Rayleigh-like quotient
and employ exact line search in the random search directions.
Moreover, 
we can show that the proposed algorithms converge to the global maximum 
(the operator norm) almost surely 
and illustrate the performance of the method with numerical experiments.
Furthermore, 
for the latter problem we can prove a convergence rate.

\end{ilasabstract}
    

\hypertarget{down0031}{}\begin{ilasabstract}
\talktitle{(Reverse-)Grassmannian permutation matrices}
    
\textbf{Richard A. Brualdi}, \info{11:00\textrm{--}11:30 @ SC2001 (June 23, Monday)} \hfill \hyperlink{up0031}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    A {\it Grassmannian permutation} $i_1i_2\cdots i_n$  is a permutation of $\{1,2,\ldots,n\}$  with at most one descent $i_{k+1}<i_k$; a {\it reverse-Grassmannian} has at most one ascent $i_{k+1}>i_k$. We consider reverse-Grassmannians ({revG}'s) and their corresponding permutation matrices.The number of such revG's is $2^n-n$ which includes the only permutation $n(n-1)\cdots 1$ without any ascents (the reverse-diagonal matrix or Hankel diagonal matrix $L_n$). An $n\times n$ $(0,1)$-matrix $A$  with total support  (every 1 of $A$ belongs to a permutationn matrix $P\le A$) is a {\it revG-blocker} provided that there does not exist a revG permutation matrix $P\le A$. Such a revG-blocker must contain at least $n$ 0's.
We determine a Frobenius-K\"onig-type theorem for revG-blockers with exactly $n$ 0's. Just as the convex polytope $\Omega_n$ of $n\times n$ doubly stochastic matrices gives continuous analogues of permutation matrices, the convex hull $\Omega_n(\mbox{revG})$ of the $n\times n$ revG's gives continuous analogues of revGs. $\Omega_n(\mbox{revG})$ has the same dimension as $\Omega_n$ since there is a basis of the $n\times n$ permutation matrices consisting of revGs. (This talk is based on ongoing work with Lei Cao.)
\end{ilasabstract}
    

\hypertarget{down0360}{}\begin{ilasabstract}
\talktitle{On entanglement-breaking quantum channels}
    
\textbf{Ngoc Muoi Bui}, \info{16:30\textrm{--}17:00 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0360}{$\Uparrow$}
    
    
(in {\color{mstitle}MS7: Linear algebra and quantum information science})
        
\mtskip
    Entanglement breaking (EB) channel is a completely positive and trace-preserving linear operator that disrupts the entanglement between the input system with any system. Examples of EB channels include depolarizing channels, quantum-classical channels, etc. We will discuss some characterizations of the class of EB channels for finite- and infinite-dimensional quantum systems. In particular, we show some sufficient conditions for channels to be EB.
\end{ilasabstract}
    

\hypertarget{down0311}{}\begin{ilasabstract}
\talktitle{The linear algebra of space-time regularization for time-dependent distributed inverse problems}
    
\textbf{Daniela Calvetti}, \info{13:30\textrm{--}14:00 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0311}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    In Bayesian dynamic ill-posed inverse problem, the a priori belief about the solution may have different characteristics in the spatial and temporal directions.  This is the case, for example, for a  promoting sparsity in space  and  smoothness in the temporal direction. In this talk we will consider dynamic inverse problems where the prior should promote group sparsity  in the spatial direction and some degree of time continuity in time, and we will show how linear algebraic techniques can be used to design robust and computationally efficient algorithms. 

\end{ilasabstract}
    

\hypertarget{down0320}{}\begin{ilasabstract}
\talktitle{The matrix equation $X^*AX=I_n$, or how much of sesquilinear form is positive definite
}
    
\textbf{Roberto Canogar}, \info{14:00\textrm{--}14:30 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0320}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    We will report on our progress to provide necessary and sufficient conditions for the matrix equation $X^*AX=I_n$ to be consistent where $A$ is any complex $m\times m$ matrix ($m, n$ might be different). Note that $X\in C^{m\times n}$ is an unknown matrix, and $X^*$ denotes its conjugate transpose. In other words, given any sesquilinear form over $C^m$, we want to determine a subspace of the maximum attainable dimension with the property that the restriction of the sesquilinear form to this subspace is positive definite. As we will see this project is near completion.

\end{ilasabstract}
    

\hypertarget{down0369}{}\begin{ilasabstract}
\talktitle{Pattern avoiding and pattern forcing $(0,1)$-matrices for some permutation patterns
}
    
\textbf{Lei Cao}, \info{17:00\textrm{--}17:30 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0369}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    Let $A = [a_{ij}]$ be an $n \times n$ $(0,1)$-matrix, $P = [p_{ij}]$ an $n \times n$ permutation matrix, and $Q$ a $k \times k$ permutation matrix with $k \leq n$. We write $P \leq A$ if $p_{ij} \leq a_{ij}$ for all $i, j = 1, 2, \ldots, n$.

\begin{itemize}
    \item $A$ is \emph{$Q$-avoiding} if and only if there does not exist a $k \times k$ submatrix $A_k$ of $A$ such that $Q \leq A_k$ entrywise.

    \item $A$ is \emph{$Q$-permutation avoiding} if and only if there does not exist an $n \times n$ permutation matrix $P \leq A$ such that $Q$ is a $k \times k$ submatrix of $P$.

    \item $A$ is \emph{$Q$-forcing} if and only if every $n \times n$ permutation matrix $P \leq A$ contains $Q$ as a $k \times k$ submatrix.
\end{itemize}



In this presentation, I will discuss recent results on $Q$-avoiding, $Q$-permutation avoiding, and $Q$-forcing $(0,1)$-matrices for certain special permutation patterns $Q$. Specifically, we investigate the minimum number of zeros in $(0,1)$-matrices that avoid or force particular permutation patterns. Additionally, we examine the polytope of 123-avoiding doubly stochastic matrices—that is, the convex hull of all 123-avoiding permutation matrices.

\end{ilasabstract}
    

\hypertarget{down0195}{}\begin{ilasabstract}
\talktitle{Low-rank exponential integrators leveraged by rational Krylov techniques
}
    
\textbf{Benjamin Carrel}, \info{14:30\textrm{--}15:00 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0195}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    The numerical integration of stiff equations is a challenging problem that needs to be approached by specialized numerical methods. Exponential integrators form a popular class of such methods since they are provably robust to stiffness and have been successfully applied to a variety of problems. On the other hand, the dynamical low-rank approximation is a recent technique for solving high-dimensional differential equations by means of low-rank approximations. However, the domain is lacking numerical methods for stiff equations since existing methods are either not robust-to-stiffness or have unreasonably large hidden constants. \newline
In this talk, we focus on solving large-scale stiff matrix differential equations with a Sylvester-like structure,
$$\dot{X}(t) = AX(t) + X(t)B + G(t,X(t)), \qquad X_0=X(0),$$
that admit good low-rank approximations. We propose two new methods that have good convergence properties, small memory footprints and that are fast to compute. The theoretical analysis shows that the new methods have order one and two, respectively. The efficient implementation of the methods relies on the low-rank structure of the scheme leveraged by rational Krylov techniques. The approximation error is analyzed, leading to a priori error bounds and, therefore, a mean for choosing the size of the Krylov space. Numerical experiments are performed on several examples, confirming the theory and showing good speedup in comparison to existing techniques.

\end{ilasabstract}
    

\hypertarget{down0198}{}\begin{ilasabstract}
\talktitle{Refined inertias of nonnegative patterns with positive off-diagonal entries}
    
\textbf{Minnie Catral}, \info{16:30\textrm{--}17:00 @ SC0008 (June 24, Tuesday)} \hfill \hyperlink{up0198}{$\Uparrow$}
    
    
(in {\color{mstitle}MS24: Nonnegative and related families of matrices})
        
\mtskip
    \newcommand{\ri}{\operatorname{ri}}
The  {\em refined inertia} of  an $n\times n$ matrix $A$  is the 4-tuple $\ri(A)=(n_+,n_-,n_z,2n_p)$ where $n_+,n_-$ equal the number of eigenvalues of $A$ with positive, negative (respectively) real parts, $n_z$ is the number of eigenvalues of $A$  equal to zero and $2n_p$ is the number of nonzero pure imaginary eigenvalues of $A$ (note that $n_+ + n_-+ n_z+2n_p = n$).  
We investigate refined inertias of nonnegative patterns with  all off-diagonal entries positive,  $k \in\{0, \dots, n\}$ diagonal entries positive and the remaining $n-k$ diagonal entries $0$. The case $k=n$ correspond to the positive pattern and the case $k=0$ correspond to the hollow positive pattern. For the positive sign pattern, every refined inertia  $(n_+, n_-, n_z, 2n_p)$ with $n_+ \geq 1$  can be realized; for the hollow positive  pattern, every refined inertia with $n_+ \geq 1$ and $n_- \geq 2$ can be realized. For the intermediate nonnegative patterns, that is, for  $k \in\{1, \dots, n-1\}$, we show that for $k \geq 2$,  there is no restriction on $n_-$ for the refined inertia set, but  $n_- \geq 1$ for $k=1$. 

This talk is based on joint work with Adam Berliner, Dale Olesky and Pauline van den Driessche.
\end{ilasabstract}
    

\hypertarget{down0231}{}\begin{ilasabstract}
\talktitle{A Divide-and-Conquer Framework for Efficient Algebraic Linearizations of Matrix Polynomials
}
    
\textbf{Eunice Chan}, \info{17:00\textrm{--}17:30 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0231}{$\Uparrow$}
    
    
(in {\color{mstitle}MS30: Bohemian matrices: Theory, applications, and explorations})
        
\mtskip
    In this talk, we explore the integration of the divide-and-conquer (dc) technique into the computation of eigenvalues for matrix polynomials using algebraic linearizations. Algebraic linearizations reduce a matrix polynomial $\mathbf{P}(z) \in \mathbb{C}[z]^{r \times r}$ of degree $s$ into a generalized eigenvalue problem of the form
\begin{equation*}
    (z\mathbf{D_L} - \mathbf{L})\mathbf{v} = \mathbf{0} \>,
\end{equation*}
where $\mathbf{D_L}$ is block diagonal, $\mathbf{L}$ is block upper Hessenberg, and $\mathbf{P}(z)$ is reconstructed through a resolvent representation:
\begin{equation*}
    \mathbf{P}(z)^{-1} = \mathbf{X_L}(z\mathbf{D_L} - \mathbf{L})^{-1}\mathbf{Y_L} \>.
\end{equation*}
While algebraic linearizations offer a structured and efficient way to solve polynomial eigenvalue problems, the resulting linearized systems can become computationally demanding for large-scale problems. To overcome this challenge, we incorporate the divide-and-conquer technique, as outlined by Bini and Pan (1992), leveraging its ability to break down eigenvalue computation into smaller, independent subproblems.

We demonstrate how this integration facilitates the efficient computation of eigenvalues for systems such as
\begin{equation*}
    \mathbf{h}(z) = z\mathbf{a}(z)\mathbf{d}_0\mathbf{b}(z) + \mathbf{c}_0 \>,
\end{equation*}
where $\mathbf{a}(z)$ and $\mathbf{b}(z)$ are matrix polynomials with their own linearizations. This combined approach reduces computational complexity while maintaining numerical stability, making it a scalable and practical solution for large-scale polynomial eigenvalue problems. This talk will highlight the theoretical framework and discuss how this integration enhances the efficiency and robustness of algebraic linearizations.


\end{ilasabstract}
    

\hypertarget{down0145}{}\begin{ilasabstract}
\talktitle{Integral inequalities of Kantorovich and Fiedler types for Hadamard products of matrices}
    
\textbf{Pattrawut Chansangiam}, \info{11:00\textrm{--}11:30 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0145}{$\Uparrow$}
    
    
(in {\color{mstitle}MS3: Matrix inequalities with applications})
        
\mtskip
    The scalar Kantorovich inequality is a reverse weighted arithmetic-harmonic mean
inequality. In matrix case, this inequality is also a reverse version of Fiedler’s inequality. In
this talk, we discuss several Kantorovich and Fiedler types integral inequalities involving
Hadamard products of continuous fields of Hilbert space operators. Kantorovich type inequality
in which the product is replaced by an operator mean is also investigated. Such inequalities
include discrete inequalities as special cases. Moreover, we obtain the monotonicity of certain
maps involving Hadamard products of operators. As special cases, we get some operator versions of Fiedler matrix inequality.

\end{ilasabstract}
    

\hypertarget{down0129}{}\begin{ilasabstract}
\talktitle{Nonlinear model reduction using machine learning on Grassmann Manifol}
    
\textbf{Saifon Chaturantabut}, \info{10:30\textrm{--}11:00 @ SC0014 (June 24, Tuesday)} \hfill \hyperlink{up0129}{$\Uparrow$}
    
    
(in {\color{mstitle}MS6: Model reduction})
        
\mtskip
    This work explores a parametric model order reduction approach for nonlinear dynamical systems, integrating machine learning methods on a Grassmann manifold. Distances between parameters are first calculated using a metric defined on the Grassmann manifold of solution subspaces. Then, the K-medoids clustering algorithm is used with these Grassmann distances to categorize the parameters into classes and form a dictionary of local bases. Machine learning techniques based on support vector machines (SVM) and artificial neural networks (ANN) are finally employed to create classifiers that can automatically determine the most appropriate local basis for constructing reduced-order models. Numerical experiments are conducted on nonlinear differential equations, including the parametrized Burger's equation, the Sine-Gordon equation, and a nonlinear flow.

\end{ilasabstract}
    

\hypertarget{down0073}{}\begin{ilasabstract}
\talktitle{On parameter tuning for spectral clustering: two simple, fast, and effective criteria}
    
\textbf{Guangliang Chen}, \info{14:00\textrm{--}14:30 @ SC4011 (June 23, Monday)} \hfill \hyperlink{up0073}{$\Uparrow$}
    
    
(in {\color{mstitle}MS20: Manifold learning and statistical applications})
        
\mtskip
    Spectral clustering is a modern, powerful clustering approach with many successful applications. However, it has faced two major challenges -- high computational complexity and parameter tuning. Since its introduction, much effort has been devoted to improving the scalability of spectral clustering, while little research has been conducted on parameter tuning. In this talk, we address the parameter tuning challenge of spectral clustering in a general context. Specifically, we propose two new criteria for tuning the scale parameter used in similarity functions such as Gaussian and cosine. Experiments demonstrate the effectiveness of these tuning techniques. 
\end{ilasabstract}
    

\hypertarget{down0139}{}\begin{ilasabstract}
\talktitle{Curvature on graphs via distance matrix}
    
\textbf{Wei-Chia Chen}, \info{11:00\textrm{--}11:30 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0139}{$\Uparrow$}
    
    
(in {\color{mstitle}MS15: Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham})
        
\mtskip
    Recently, Steinerberger introduced a notion of curvature on graphs based on solutions to the linear system $Dx=\mathbf{1},$ where $D$ is the graph distance matrix and $\mathbf{1}$ is the all-one vector. 
They also observed in the Mathematica database that graphs so that $Dx=\mathbf{1}$ has no solutions seem to be rare. 
In this talk, we will focus on how nonnegative solutions to $Dx=\mathbf{1}$ behave when certain graph operations are performed, such as adding an edge between two graphs. We also provide a way to create an infinite family of graphs so that $Dx=\mathbf{1}$ has no solutions. This is joint work with Mao-Pei Tsui.

\end{ilasabstract}
    

\hypertarget{down0152}{}\begin{ilasabstract}
\talktitle{Convergence of Hessian estimator from random samples on a manifold with boundary}
    
\textbf{Chih-Wei Chen}, \info{11:30\textrm{--}12:00 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0152}{$\Uparrow$}
    
    
(in {\color{mstitle}MS20: Manifold learning and statistical applications})
        
\mtskip
    A common method for estimating the Hessian operator from random samples on a submanifold involves locally fitting a quadratic polynomial. Although widely used, it is unclear if this estimator introduces bias, especially in manifolds with boundaries and nonuniform sampling. We show that this estimator asymptotically converges to the Hessian operator, with nonuniform sampling and curvature effects proving negligible, even near boundaries. Our analysis framework simplifies the intensive computations required for direct analysis. This is join work with Hau-Tieng Wu. 

\end{ilasabstract}
    

\hypertarget{down0306}{}\begin{ilasabstract}
\talktitle{One-bit diffraction tomography}
    
\textbf{Pengwen Chen}, \info{11:30\textrm{--}12:00 @ SC4011 (June 26, Thursday)} \hfill \hyperlink{up0306}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    A few years ago, we proposed a null initialization as one initialization scheme for phase retrieval
reconstruction. The null initialization can be regarded as one reconstruction from  one-bit measurements. In this talk, we shall
present a noise-robust framework for 1-bit diffraction tomography, a novel imaging approach that
relies on intensity-only binary measurements obtained through coded apertures. The proposed
reconstruction scheme leverages the shifted inverse power iteration, to
effectively recover 3D object structures under high-noise conditions. We develop one accurate 3D
reconstruction scheme for tomographic phase retrieval. The inverse X-ray transform is implemented via 
solving a Toeplitz system, where FFT based preconditioners can be employed to improve the
convergence speed. A few simulations are reveal the correlation of dose fractionation.

\end{ilasabstract}
    

\hypertarget{down0333}{}\begin{ilasabstract}
\talktitle{New challenges in teaching elementary linear algebra}
    
\textbf{Mei Q Chen}, \info{14:30\textrm{--}15:00 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0333}{$\Uparrow$}
    
    
(in {\color{mstitle}MS27: Linear algebra education})
        
\mtskip
    Linear Algebra is a required course for the BS degree program in mathematics
and is a major program elective for majors in finance, computer science,
engineering, and physics at The Citadel. To provide students with
opportunities to explore advanced topics in linear algebra, to gain research
experience and to solve open problems in linear algebra (posted in MAA
publications), or to work on real-world applications in their major fields
using linear algebra, we add project assignments to the course curriculum.
In this talk, we will share our experience in developing course projects,
working with students with different majors to complete their projects and
to inspire them for further studies in linear algebra, and to prepare
mathematics majors for advanced linear algebra.

\end{ilasabstract}
    

\hypertarget{down0228}{}\begin{ilasabstract}
\talktitle{On the maximal spectral radius of digraphs with a prescribed number of arcs
}
    
\textbf{Yen-Jen Cheng}, \info{17:30\textrm{--}18:00 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0228}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    The spectral radius of a matrix is the largest magnitude of its eigenvalues. The spectral radius of a graph is the spectral radius of its adjacency matrix. It captures important structural information about the graph and plays a key role in spectral graph theory. In this talk, I will introduce a new approach to find upper bounds of the spectral radius of a nonnegative matrix, and use it to
identify the unique digraph whose spectral radius is
maximum among all digraphs with a prescribed number
of arcs. This result resolves a problem 
independently posed by R. Brualdi and A. Hoffman, as well as F.
Friedland, back in 1985.

\end{ilasabstract}
    

\hypertarget{down0268}{}\begin{ilasabstract}
\talktitle{Ten Hermitian solutions of anti-Riccati matrix equation arising in anti-LQR problem
}
    
\textbf{Chun-Yueh Chiang}, \info{10:30\textrm{--}11:00 @ SC3001 (June 25, Wednesday)} \hfill \hyperlink{up0268}{$\Uparrow$}
    
    
(in {\color{mstitle}MS11: Structured matrix computations and its applications})
        
\mtskip
    In this talk, we consider a class of conjugate discrete-time Riccati equations (CDARE), arising originally
from the linear quadratic regulation problem for discrete-time antilinear systems. Recently, we have proven
the existence of the maximal solution to the CDARE with a nonsingular control weighting matrix within
the framework of a constructive method. Our contribution to the work is to find another meaningful
Hermitian solution, which has received little attention in the existing literature. Moreover, we show that
certain extremal solutions cannot be attained simultaneously, and almost (anti-)stabilizing solutions coincide
with some extremal solutions. We expect that our theoretical results presented in this paper will play an
important role in optimal control problems for discrete-time antilinear systems.

\end{ilasabstract}
    

\hypertarget{down0024}{}\begin{ilasabstract}
\talktitle{Geometric mean of T-positive definite tensors}
    
\textbf{Hayoung Choi}, \info{12:00\textrm{--}12:30 @ SC1001 (June 23, Monday)} \hfill \hyperlink{up0024}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    In this talk, we generalize the geometric mean of two positive definite matrices to that of third-order tensors using the notion of T-product. Specifically, we define the geometric mean of two T-positive definite tensors and verify several properties that ``mean'' should satisfy including the idempotence and the commutative property, and so on. Moreover, it is shown that the geometric mean is a unique T-positive definite solution of an algebraic Riccati tensor equation and can be expressed as solutions of algebraic Riccati matrix equations. 

\end{ilasabstract}
    

\hypertarget{down0034}{}\begin{ilasabstract}
\talktitle{Density-equalizing map with applications}
    
\textbf{Gary Choi}, \info{11:00\textrm{--}11:30 @ SC2006 (June 23, Monday)} \hfill \hyperlink{up0034}{$\Uparrow$}
    
    
(in {\color{mstitle}MS22: Linear algebra applications in computational geometry})
        
\mtskip
    We present surface and volumetric mapping methods based on a natural principle of density diffusion. Specifically, we start with a prescribed density distribution in a surface or volumetric domain and then create shape deformations with different regions enlarged or shrunk based on the density gradient. Using the proposed methods, we can easily achieve different mapping effects with controllable area change. Applications to shape registration, morphing, remeshing, medical shape analysis, and data visualization will be presented. 

\end{ilasabstract}
    

\hypertarget{down0205}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Man-Duen Choi}, \info{16:00\textrm{--}16:30 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0205}{$\Uparrow$}
    
    
(in {\color{mstitle}MS7: Linear algebra and quantum information science})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0171}{}\begin{ilasabstract}
\talktitle{Two invariants of distance matrices of trees, in a unified framework}
    
\textbf{Projesh Nath Choudhury}, \info{14:30\textrm{--}15:00 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0171}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    In 1971, Graham and Pollak showed that if $D_T$ is the distance matrix of a tree $T$ on $n$ nodes, then $\det(D_T)$ depends only on $n$, not $T$. This independence from the tree structure has been verified for many different variants of weighted bi-directed trees. In my talk (over an arbitrary commutative ring):
\begin{enumerate}
 \item I will present a general setting which strictly subsumes every known variant, and where we show that $\det(D_T)$ - as well as another graph invariant, the cofactor-sum - depends only on the edge-data, not the tree-structure.
 \item More generally - even in the original unweighted setting - we strengthen the state-of-the-art, by computing the minors of $D_T$ where one removes rows and columns indexed by equal-sized sets of pendant nodes. (In fact, we go beyond pendant nodes.)
 \item We explain why our result is the ``most general possible'', in that allowing greater freedom in the parameters leads to dependence on the tree-structure.
\end{enumerate}
We will discuss related results for arbitrary strongly connected graphs, including a third, novel invariant. If time permits, a formula for  $D_T^{-1}$ will be presented for trees $T$, whose special case answers an open problem of Bapat-Lal-Pati (Linear Alg. Appl. 2006), and which extends to our general setting a result of Graham-Lovasz (Advances in Math. 1978). (Joint with Apoorva Khare.)
\end{ilasabstract}
    

\hypertarget{down0232}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Geeta Chowdhry}, \info{17:30\textrm{--}18:00 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0232}{$\Uparrow$}
    
    
(in {\color{mstitle}MS30: Bohemian matrices: Theory, applications, and explorations})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0304}{}\begin{ilasabstract}
\talktitle{Inverse Iteration for Sylvester Operators
}
    
\textbf{Eric King-wah Chu}, \info{10:30\textrm{--}11:00 @ SC4011 (June 26, Thursday)} \hfill \hyperlink{up0304}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    We generalize the inverse iteration for matrices  to the (generalized) Sylvester operator $\mathcal{S}(X) \equiv AXB^\top - CXD^\top$, computing the null space or the homogeneous solution to $\mathcal{S}(X)=0$, or the eigen-spaces for the intersecting subspectrum $\Lambda (A, C) \cap \Lambda (D,B)$. Cases with two small matrix pencils in $(A,C)$ and $(D,B)$, a large and a small pencils, and two large pencils, as well as the special cases for the Sylvester and Lyapunov equations, and the linear equation with tensor structures, are  considered. When the solution process for the corresponding Sylvester equation is robust and efficient, the generalized inverse iteration converges in one or two iterations, especially for cases of small dimensions or with semi-simple intersecting eigenvalues. For large examples, especially with derogatory intersecting eigenvalues, the approach performs less well. Illustrative numerical experiments are presented.

\end{ilasabstract}
    

\hypertarget{down0042}{}\begin{ilasabstract}
\talktitle{A framework for exploring the conformational landscape of cryo-EM using energy-aware pathfinding algorithm}
    
\textbf{Szu-Chi Chung}, \info{12:00\textrm{--}12:30 @ SC4011 (June 23, Monday)} \hfill \hyperlink{up0042}{$\Uparrow$}
    
    
(in {\color{mstitle}MS20: Manifold learning and statistical applications})
        
\mtskip
    Cryo-electron microscopy (cryo-EM) is a powerful technique for investigating macromolecular structures and holds great promise for uncovering kinetically preferred transition sequences between conformational states. While such transitions are often explored using two-dimensional energy landscapes, the intrinsic complexity of biomolecular conformations frequently renders low-dimensional representations insufficient. Recent advances in reconstruction models have enabled the characterization of structural heterogeneity from cryo-EM images through high-dimensional latent spaces. However, constructing conformational landscapes in these spaces and identifying preferred transition pathways remain major challenges. 

In this study, we propose a novel framework for identifying preferred trajectories within high-dimensional conformational landscapes. Our method formulates the problem as a graph-based search for minimum energy paths, where edge weights are computed from local energy estimates derived from density in high-dimensional space. We demonstrate the effectiveness of this approach by accurately identifying transition states in both synthetic and experimental datasets exhibiting continuous conformational changes. To facilitate future research and reproducibility, we provide a modular implementation of our framework at https://github.com/tengyulin/energy\_aware\_pathfinding/.

\end{ilasabstract}
    

\hypertarget{down0202}{}\begin{ilasabstract}
\talktitle{Data-driven inverse problems via autoencoder
}
    
\textbf{Matthias Chung}, \info{16:30\textrm{--}17:00 @ SC0009 (June 24, Tuesday)} \hfill \hyperlink{up0202}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    Emerging disciplines such as data analytics, machine learning, and uncertainty quantification increasingly depend on efficient computational techniques to address inverse problems. As models grow in complexity and data volumes expand, existing state-of-the-art inference methods are reaching their limitations, highlighting the urgent need for novel approaches.
Inverse problems in science and engineering remain inherently challenging. While likelihood-free methods offer promising alternatives to traditional inversion techniques, they often face limitations in generalization and accuracy. In this work, we propose a novel paired autoencoder framework as a likelihood-free estimator. Our approach enables efficient solution generation, quality evaluation, and iterative refinement. We demonstrate the effectiveness of the method through applications to full waveform inversion and inverse electromagnetic imaging.

\end{ilasabstract}
    

\hypertarget{down0312}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Julianne Chung}, \info{14:00\textrm{--}14:30 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0312}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0217}{}\begin{ilasabstract}
\talktitle{Signal processing of spherical data. From real life to mathematical challenges}
    
\textbf{Antonio Cicone}, \info{16:00\textrm{--}16:30 @ SC1003 (June 24, Tuesday)} \hfill \hyperlink{up0217}{$\Uparrow$}
    
    
(in {\color{mstitle}MS19: Explicit and hidden asymptotic structures, GLT Analysis, and applications})
        
\mtskip
    In signal processing the time-frequency analysis of nonlinear and non-stationary processes, as well as the determination of the unknown number of active sub-signals of a blind-source composite signal are, in general, challenging inverse problem tasks. If we consider data sampled on a sphere, things get even more complicated. This is the reason why just a few techniques have been developed so far to study this kind of data. However, many real-life data are of this nature, like in Geophysics and Physics.

The idea is to extend the Iterative Filtering (IF) algorithm to work on the sphere. IF is a non-stationary signal decomposition method proposed a decade ago [1] to address the problem of extracting time-varying oscillatory components from a non-stationary multicomponent signal. This method proved to be really valuable in many applications, see [2] and references therein, and it was accelerated in what is known as Fast Iterative Filtering (FIF) [3] by leveraging the Toeplitz matrix theory.

In this talk, we introduce the generalization of IF to handle spherical data and show how we can address the question about its convergence [4]. We conclude with some examples of application to geophysical data.

This is joint work with {\em Giovanni Barbarino}, {\em Roberto Cavassi}, {\em Wing S. Li}, {\em Edward J. Timko}, {\em Haomin Zhou}.

[1] L. Lin, Y. Wang, and H. Zhou. ``Iterative filtering as an alternative algorithm for empirical mode decomposition''. Adv. in Adap. Data An., 2009, 1.04, 543-560.

[2] G. Barbarino, A. Cicone. ``Conjectures on spectral properties of ALIF algorithm''. Linear Algebra and its Applications, 2022, 647, 127--152.

[3] A. Cicone, H. Zhou. ``Numerical Analysis for Iterative Filtering with New Efficient Implementations Based on FFT''. Num. Math., 2021, 147 (1), 1--28.

[4] G. Barbarino, R. Cavassi, A. Cicone. Extension and convergence analysis of Iterative Filtering to spherical data. Linear Algebra and its Applications, 2024.


\end{ilasabstract}
    

\hypertarget{down0029}{}\begin{ilasabstract}
\talktitle{Principal eigenvectors and principal ratios in hypergraph Tur\'{a}n problems}
    
\textbf{Joshua Cooper}, \info{11:30\textrm{--}12:00 @ SC1005 (June 23, Monday)} \hfill \hyperlink{up0029}{$\Uparrow$}
    
    
(in {\color{mstitle}MS15: Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham})
        
\mtskip
    For a general class of hypergraph Tur\'{a}n problems with uniformity $r$, we investigate the principal eigenvector for the $p$-spectral radius of its extremal graphs, showing in a strong sense that these eigenvectors have equal weight on each vertex (equivalently, showing that the principal ratio is close to $1$). Our result is sharp for the conjectural extremizers of the Tur\'{a}n tetrahedron problem, and for some other problems in which the extremizers are well understood; it is unclear whether it always sharp. We establish a result which may have also have independent interest, proving a lower bound on the spectral radius depending on the degrees of the graph. The case $1 < p < r$ of our results leads to some subtleties connected to Nikiforov's notion of $k$-tightness. We raise a conjecture about these issues, and provide some preliminary evidence for our conjecture.

\end{ilasabstract}
    

\hypertarget{down0379}{}\begin{ilasabstract}
\talktitle{Determinants of Steiner distance hypermatrices}
    
\textbf{Joshua Cooper}, \info{16:00\textrm{--}16:30 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0379}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    Generalizing work from the 1970s on the determinants of distance hypermatrices of trees, we consider the hyperdeterminants of order-$k$ Steiner distance hypermatrices of trees $T$ on $n$ vertices.  We show that this hypermatrix has the same diagonalization as a $k$-form for any $T$ on $n$ vertices, generalizing of a result of Graham-Lov\'{a}sz, implying a tensor version of ``conditional negative definiteness'', providing new proofs of previous results of the authors and Tauscheck, and resolving the conjecture that these hyperdeterminants depend only on $k$ and $n$ -- as Graham-Pollak showed for $k=2$.

\end{ilasabstract}
    

\hypertarget{down0204}{}\begin{ilasabstract}
\talktitle{Tensor-train methods for sequential state and parameter estimation in state-space models
}
    
\textbf{Tiangang Cui}, \info{17:30\textrm{--}18:00 @ SC0009 (June 24, Tuesday)} \hfill \hyperlink{up0204}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    Numerous real-world applications require the estimation, forecasting, and control of dynamic systems using incomplete and indirect observations. These problems can be formulated as state-space models, where the challenge lies in learning the model states and parameters from observed data. We present new tensor-based sequential Bayesian learning methods that jointly estimate parameters and states. Our methods provide manageable error analysis and potentially mitigate the particle degeneracy encountered in many particle-based approaches. Besides offering new insights into algorithmic design, our methods naturally incorporate conditional transports, enabling filtering, smoothing, and parameter estimation within a unified framework.

\end{ilasabstract}
    

\hypertarget{down0245}{}\begin{ilasabstract}
\talktitle{Similarities between the numerical range of an operator and of certain generalized inverses}
    
\textbf{Dragana Cvetkovic Ilic}, \info{11:00\textrm{--}11:30 @ SC0009 (June 25, Wednesday)} \hfill \hyperlink{up0245}{$\Uparrow$}
    
    
(in {\color{mstitle}MS33: Norms of matrices, numerical range, applications of functional analysis to matrix theory})
        
\mtskip
    In this talk we will consider the different properties of the numerical range for a bounded linear operator from the point of view of its similarities  to the numerical range  of certain generalized inverses such as the Moore-Penrose inverse, Drazin inverse, DMP-inverse, MDP-inverse and CMP-inverse.  We will discuss  the question whether the numerical ranges of an operator and its certain generalized inverse simultaneously contain the origin as well as whether this is true in the case of the closure, boundary, extreme points and sharp points of the corresponding numerical ranges.  To illustrate our results we will exhibit some numerical examples.
\end{ilasabstract}
    

\hypertarget{down0200}{}\begin{ilasabstract}
\talktitle{Near-derangements and polytopes}
    
\textbf{Geir Dahl}, \info{17:30\textrm{--}18:00 @ SC0008 (June 24, Tuesday)} \hfill \hyperlink{up0200}{$\Uparrow$}
    
    
(in {\color{mstitle}MS24: Nonnegative and related families of matrices})
        
\mtskip
    A derangement is a permutation with no fixed point. This talk deals with  {\em near-derangements}, defined as permutations with at most one fixed point. We present some properties of  the corresponding set of permutation matrices $\mathcal{P}^{(\le 1)}_n$. 
  Also, we briefly discuss  the polytope determined by $\mathcal{P}^{(\le 1)}_n$ and the related polytope $\mathcal{P}^*$ of  all $n\times n$  doubly stochastic matrices with trace at most 1.
  In particular, all its  extreme points of $\mathcal{P}^*$ are determined. 
This is joint work with Richard A. Brualdi.

\end{ilasabstract}
    

\hypertarget{down0121}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Sujit Sakharam Damase}, \info{11:00\textrm{--}11:30 @ SC0008 (June 24, Tuesday)} \hfill \hyperlink{up0121}{$\Uparrow$}
    
    
(in {\color{mstitle}MS9: Total positivity})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0259}{}\begin{ilasabstract}
\talktitle{A linear algebra online course experience at UC3M: development and teaching}
    
\textbf{Fernando De Terán}, \info{10:30\textrm{--}11:00 @ SC1005 (June 25, Wednesday)} \hfill \hyperlink{up0259}{$\Uparrow$}
    
    
(in {\color{mstitle}MS27: Linear algebra education})
        
\mtskip
    I will review my experience with a SPOC (Small Private Online Course) with flipped classroom that we developed to teach basic Linear Algebra at UC3M. We used this course for 6 academic years in a first-year Linear Algebra course for engineers.
\end{ilasabstract}
    

\hypertarget{down0319}{}\begin{ilasabstract}
\talktitle{The uniqueness of solution of systems of generalized Sylvester and $\star$-Sylvester equations}
    
\textbf{Fernando De Terán}, \info{13:30\textrm{--}14:00 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0319}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    The {\em generalized Sylvester equation}
$$
AXB-CXD=E
$$
has been a subject of interest since, at least, the early 20th century. More recently, the {\em$\star$-generalized Sylvester equation}
$$
AXB-CX^\star D=E,
$$
with $\star$ being either the transpose or the conjugate transpose, has attracted some attention within the linear algebra community.

In this talk, we provide necessary and sufficient conditions for the uniqueness of solution of homogeneous systems of generalized Sylvester and $\star$-Sylvester equations, namely
$$
A_iX_{\alpha_i}^{s_i}B_i-C_iX_{\beta_i}^{t_i}D_i=0,\qquad i=1,\hdots,r,
$$
with $s_i,t_i\in\{1,\star\}$. 

We focus on the case where the system has the same number of equations and unknowns (namely, $r$), and where all coefficient matrices (and unknowns) are square and with the same size.
\end{ilasabstract}
    

\hypertarget{down0177}{}\begin{ilasabstract}
\talktitle{I love the triangle number!}
    
\textbf{Louis Deaett}, \info{13:30\textrm{--}14:00 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0177}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    A \emph{zero-nonzero pattern} is a matrix with entries from the set $\{0,*\}$.  The \emph{triangle number} of the pattern is the largest $k$ such that some $k\times k$ submatrix is (up to permutation) triangular with only $*$ entries on its diagonal.


A \emph{realization} of the pattern over some field is a matrix that can be obtained by replacing each $*$ entry of the pattern with a nonzero value from that field.
The smallest rank of such a realization is the \emph{minimum rank} of the pattern (over that field).  The triangle number provides a natural and simple lower bound on this value.

This talk explores some different combinatorial angles on the triangle number.  For example, we review how the triangle number is connected with the zero forcing number, both for simple graphs and directed graphs.  In fact, the bound it provides on the minimum rank of a pattern is closely related to the bound given by the zero forcing number on the maximum nullity of a graph; we see how, in certain special cases, the relationship is especially strong.  This also motivates the question of Nordhaus-Gaddum type bounds for the triangle number, and we present some recent results on this front.  We also examine the triangle number through the lens of lattice theory and matroid theory, where it provides a lower bound on a related class of minimum rank problems for matroids, one which can provide insights into the original minimum rank problem for matrix patterns.

\end{ilasabstract}
    

\hypertarget{down0279}{}\begin{ilasabstract}
\talktitle{Zero-dilation indices and numerical ranges}
    
\textbf{Kennett Dela Rosa}, \info{11:30\textrm{--}12:00 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0279}{$\Uparrow$}
    
    
(in {\color{mstitle}MS33: Norms of matrices, numerical range, applications of functional analysis to matrix theory})
        
\mtskip
    The zero-dilation index $d(A) $ of a matrix $A$ is the largest integer $k$ for which $\begin{bmatrix}0_k& *\\ * & *\end{bmatrix}$ is unitarily similar to $A$. In this study, the zero-dilation indices of certain block matrices are considered, namely, the block matrix analogues of companion matrices and upper triangular KMS matrices, respectively shown as \[\mathcal{C}=\begin{bmatrix} 0& \bigoplus_{j=1}^{m-1}A_j \\ B_0& [B_j]_{j=1}^{m-1}\end{bmatrix}\ \textup{and}\ \mathcal{K}=\begin{bmatrix}0& A& A^2&\cdots& A^{m-1}\\ 0 & 0& A& \ddots& \vdots\\ 0& 0 &0 &\ddots& A^2\\ \vdots& \vdots &\vdots & \ddots& A\\ 0& 0 & 0& \cdots &0\end{bmatrix}\]
where $\mathcal{C}$ and $\mathcal{K}$ are $mn$-by-$mn$ and $A_j,B_j,A$ are $n$-by-$n$. Provided $\bigoplus_{j=1}^{m-1}A_j$ is nonsingular, it is proved that $d(\mathcal{C})$ satisfies the following: if $m\geq 3$ is odd (respectively, $m\geq 2$ is even), then $\frac{(m-1)n}{2}\leq d(\mathcal{C})\leq \frac{(m+1)n}{2}$ (respectively, $ d(\mathcal{C})= \frac{mn}{2}$). In the odd $m$ case, examples are given showing that it is possible to get as zero-dilation index each integer value between $\frac{(m-1)n}{2} $ and $\frac{(m+1)n}{2}$. On the other hand, $d(\mathcal{K})$ is proved to be equal to the number of nonnegative eigenvalues of $(\mathcal{K}+\mathcal{K}^*)/2$. Alternative characterizations of $d(\mathcal{K})$ are given. The circularity of the numerical range of $\mathcal{K} $ is also considered.

\end{ilasabstract}
    

\hypertarget{down0043}{}\begin{ilasabstract}
\talktitle{Computations with high relative accuracy for the collocation matrices of q-Jacobi polynomials}
    
\textbf{Jorge Delgado}, \info{14:00\textrm{--}14:30 @ SC0008 (June 23, Monday)} \hfill \hyperlink{up0043}{$\Uparrow$}
    
    
(in {\color{mstitle}MS9: Total positivity})
        
\mtskip
    In this talk the bidiagonal decomposition of the Collocation Matrices of q-Jacobi Polynomials will be presented.
In addition, it will be shown that this bidiagonal decomposition can be constructed with high relative accuracy (HRA)
in many cases.
Then, for these cases, the bidiagonal decomposition will be used to solve with HRA the following linear algebra
problems: computation of the inverse, the eigenvalues and the singular values of those collocation matices, and
the solution of some related linear systems of equations.

This is a joint work with Jorge Delgado, Héctor Orera and Juan Manuel Peña.
\end{ilasabstract}
    

\hypertarget{down0357}{}\begin{ilasabstract}
\talktitle{Preconditioning for uncertainty quantification of high-dimensional inverse problems}
    
\textbf{Philip Dinenis}, \info{17:00\textrm{--}17:30 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0357}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    In variational inverse problems, the Laplace approximation of the posterior distribution can be estimated by minimizing an objective function and computing its inverse Hessian at the minimizer. In high-dimensional problems, computing and storing this inverse Hessian may be intractable while low-rank approximations may be poor in ill-conditioned settings. We show that in 4DVar problems, we can construct effective preconditioners using what we know about the scales of different sources of uncertainty – such as such as model, background, and measurement errors. When this is used in combination with the quasi-Newton method l-BFGS, we can greatly speed up the optimization and improve the approximation of posterior covariance. Moreover, the form of this approximation in terms of the symmetric low-rank updates, gives a way to factorize the covariance matrix and efficiently sample from the posterior distribution.

\end{ilasabstract}
    

\hypertarget{down0254}{}\begin{ilasabstract}
\talktitle{Operator means and quantum divergences}
    
\textbf{Trung Hoa Dinh}, \info{11:00\textrm{--}11:30 @ SC1001 (June 25, Wednesday)} \hfill \hyperlink{up0254}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    In this talk, we will explore the use of operator means to construct new quantum divergences. We will also examine the least squares problem in the context of various quantum divergences. Additionally, we will discuss some applications and highlight open questions in this area.

\end{ilasabstract}
    

\hypertarget{down0216}{}\begin{ilasabstract}
\talktitle{Minimal indices through perturbation behavior}
    
\textbf{Andrii Dmytryshyn}, \info{17:30\textrm{--}18:00 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0216}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    Computing the complete eigenstructure of matrix pencils is a challenging problem. Small perturbations can change both the eigenvalues with their multiplicities, as well as the minimal indices of a given pencil. Recently, however, perturbation theory was used to compute eigenvalues of singular matrix pencils. In this talk, we investigate how the behavior of a general matrix pencil under small perturbations can help determine its minimal indices.

\end{ilasabstract}
    

\hypertarget{down0330}{}\begin{ilasabstract}
\talktitle{Polynomial and rational matrices with the invariant rational functions and the four sequences of minimal indices prescribed}
    
\textbf{Froilan M. Dopico}, \info{15:00\textrm{--}15:30 @ SC1003 (June 26, Thursday)} \hfill \hyperlink{up0330}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    The complete eigenstructure, or structural data, of a rational matrix
$R(s)$ is comprised by its invariant rational functions, both finite
and at infinity, which determine its finite and infinite pole and zero
structures, and by the minimal indices of its left and right null spaces.
These quantities arise in many applications and have been thoroughly
studied in numerous references. However, $R(s)$ has other two fundamental
subspaces which, in contrast, have received much less attention
in the literature. They are its column and row spaces, which also have
their associated minimal indices. This work solves the problems of
finding necessary and sufficient conditions for the existence of rational
matrices in two scenarios: (a) when the invariant rational functions and the minimal indices of the column and row spaces are prescribed,
and (b) when the complete eigenstructure together with the minimal
indices of the column and row spaces are prescribed. The particular,
but extremely important, cases of these problems for polynomial matrices
are solved first and are the main tool for solving the general
problems. The results in this work complete and extend non-trivially
the necessary and sufficient conditions recently developed in the literature
for the existence of polynomial and rational matrices when only
the complete eigenstructure is prescribed.

This is joint work with Itziar Baraga\~na and Silvia Marcaida (Universidad del Pa\'is Vasco UPV/EHU, Spain) and Alicia Roca (Universitat Polit\`ecnica de Val\`encia, Spain).
\end{ilasabstract}
    

\hypertarget{down0131}{}\begin{ilasabstract}
\talktitle{Koopman mode decomposition for nonlinear model reduction}
    
\textbf{Zlatko Drmac}, \info{11:30\textrm{--}12:00 @ SC0014 (June 24, Tuesday)} \hfill \hyperlink{up0131}{$\Uparrow$}
    
    
(in {\color{mstitle}MS6: Model reduction})
        
\mtskip
    The Dynamic Mode Decomposition (DMD) is a popular numerical method
for data driven analysis of nonlinear dynamical systems, with a wide spectrum 
of applications. It can be used for model order reduction, analysis of
latent structures in the dynamics, and e.g. for forecasting and control.  The
theoretical bedrock upon which the more general Extended DMD framework 
is built is the Koopman composition operator.
%
DMD can be described as a data driven Rayleigh-Ritz extraction of spectral information
of a Koopman operator associated with the underlying dynamical system. 
The nonlinear data snapshots are represented using the eigenvectors of the
operator resulting in a modal decomposition KMD (Koopman Mode Decomposition).
This becomes a model order reduction tool that represents the nonlinear dynamics
using selected eigenpairs. It can be used to reveal coherent states and for forecasting. \\
In some cases, a numerically computed compression of the Koopman operator exhibits 
high non-normality, and, as a result, the eigenvectors are highly ill-conditioned and the
KMD becomes numerically unstable.
%
We address this problem and introduce a new theoretical and computational framework for
data driven Koopman mode analysis of nonlinear dynamics. The 
problem of ill-conditioned eigenvectors  is solved using a Koopman-Schur 
decomposition that is entirely 
based on unitary transformations. The analysis in terms of the eigenvectors as 
modes of a Koopman operator  is replaced with a modal decomposition 
in terms of a flag of invariant subspaces that correspond to selected eigenvalues. 
  \\
%
The main computational tool from the numerical linear algebra is the partial 
ordered Schur decomposition that provides convenient orthonormal bases for these 
subspaces. \\
%
This is a joint work with Igor Mezi\'{c}, University of California at Santa Barbara.
%

Reference:\\
Zlatko Drma\v{c}, Igor Mezi\'{c} A data driven Koopman-Schur decomposition for 
computational analysis of nonlinear dynamics, SIAM J. Sci. Comp. (in review)\\
https://doi.org/10.48550/arXiv.2312.15837




\end{ilasabstract}
    

\hypertarget{down0239}{}\begin{ilasabstract}
\talktitle{Krylov: better, faster, parallel}
    
\textbf{Fabio Durastante}, \info{17:00\textrm{--}17:30 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0239}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    Krylov subspace methods are indispensable for addressing a wide array of challenges in sparse and large-scale linear algebra. They are pivotal in solving large, sparse linear systems \( A \mathbf{x} = \mathbf{b} \), computing select eigenvalues and eigenvectors of expansive sparse matrices \( A \mathbf{v} = \lambda \mathbf{v} \), evaluating matrix-function vector products \( \mathbf{y} = f(A) \mathbf{x} \), and resolving linear matrix equations with low-rank right-hand sides \( A X + X B^T = UV^T \).
In contemporary computational science, ``large-scale'' denotes problems involving sparse matrices with millions to billions of unknowns. Addressing such complexities necessitates leveraging supercomputers and implementing distributed-memory versions of Krylov-based algorithms. The Parallel Sparse Computation Toolkit (PSCToolkit) is a comprehensive software framework designed to tackle these challenges. It offers modular components for managing distributed sparse matrices and executing sparse matrix computations across various hybrid architectures, from small servers to high-end supercomputers equipped with multicore CPUs and NVIDIA GPUs. PSCToolkit's design emphasizes node-level efficiency, flexibility, and usability, supporting integration with both Fortran and C/C++ applications. In this presentation, I will delve into the implementation nuances of Krylov subspace methods within distributed computing environments, focusing on the capabilities and structure of PSCToolkit. Furthermore, I will showcase scalability results and performance benchmarks achieved on supercomputers that integrate multicore processors and GPU accelerators, demonstrating PSCToolkit's efficacy in harnessing the computational power of modern heterogeneous systems.

\end{ilasabstract}
    

\hypertarget{down0052}{}\begin{ilasabstract}
\talktitle{Max-type quasidistances probability simplices}
    
\textbf{Michal Eckstein}, \info{14:00\textrm{--}14:30 @ SC0014 (June 23, Monday)} \hfill \hyperlink{up0052}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    A quasidistance is a function on a set, which is non-negative, non-degenerate and satisfies the triangle inequality. Despite the lack of symmetry, quasidistances lead to a rich theory involving geometric structures, such as geodesics. 

We introduce a new family of max-type quasimetrics on probability simplices $\Delta_N$ defined by
\[
D_f(P,Q) = \max_i \big( f(q_i) - f(p_i) \big),
\]
where \(f\colon [0,1]\to [0,1]\) is a continuous, strictly increasing function with \(f(0)=0\) and \(f(1)=1\). Under mild regularity assumptions on \(f\), the quasimetric space $(\Delta_N,D_f)$ has a Finslerian structure and admits geodesics (both forward and backward) between any two points. Moreover, the function \(D_f\) is monotone under bistochastic maps.

\end{ilasabstract}
    

\hypertarget{down0258}{}\begin{ilasabstract}
\talktitle{The spectrum of Toeplitz matrices with two off-diagonals}
    
\textbf{Sven-Erik Ekström}, \info{11:30\textrm{--}12:00 @ SC1003 (June 25, Wednesday)} \hfill \hyperlink{up0258}{$\Uparrow$}
    
    
(in {\color{mstitle}MS19: Explicit and hidden asymptotic structures, GLT Analysis, and applications})
        
\mtskip
    Consider the Toplitz matrix $T_n(g_{r,s})$ generated by the symbol $g_{r,s}(\theta)=e^{r\mathbf{i}\theta}+e^{-s\mathbf{i}\theta}$ where $0<r<n$ and $0<s<n$.
The eigenvalues of $T_n(g_{r,s})$ (and eigenvectors) for the case $r=s=1$ (tridiagonal Toeplitz) has been know explicitly for about 100 years. In 2018 the eigenvalues (and eigenvectors) were given also for the case $r=s>1$ by Ekström and Serra-Capizzano.
In the current presentation we discuss the case $1\leq r<s$, and the eigenvalues of $T_n(g_{r,s})$.  
We present an algorithm to construct matrices, smaller than the original matrix, that given their eigenvalues we can exactly reconstruct the full spectrum of $T_n(g_{r,s})$. A brief discussion on the ideas behind the algorithm will be given as well as some still unresolved questions. 

\end{ilasabstract}
    

\hypertarget{down0197}{}\begin{ilasabstract}
\talktitle{Connecting the Hermite-Biehler theorem to the nonnegative inverse eigenvalue problem}
    
\textbf{Richard Ellard}, \info{16:00\textrm{--}16:30 @ SC0008 (June 24, Tuesday)} \hfill \hyperlink{up0197}{$\Uparrow$}
    
    
(in {\color{mstitle}MS24: Nonnegative and related families of matrices})
        
\mtskip
    The famous Hermite-Biehler Theorem (Hermite, 1856; Biehler, 1879) states that a real polynomial $f(x)=p(x^2)+xq(x^2)$ is Hurwitz stable (all of the roots of $f$ lie in the open left half-plane) if and only if the leading coefficients of $p$ and $q$ have the same sign and all the roots of $p(-x^2)$ and $xq(-x^2)$ are real and interlace. More generally, the number and relative positions of the nonnegative roots of $p(-x)$ and $q(-x)$ determine the number of roots of $f$ which lie in the left (or right) half-plane. The \emph{Nonnegative Inverse Eigenvalue Problem} (NIEP) asks for a characterisation of those lists of complex numbers which are \emph{realisable} as the spectrum of some (entrywise) nonnegative matrix. An important special case arises when the Perron eigenvalue is the only root of the characteristic polynomial $f$ in the right half-plane, and, in this special case, a complete characterisation was given by Laffey and \v{S}migoc (2006) which employed a rather long and technical argument. By examining the relationship between the roots of $f$ and those of $p$ and $q$ from a simple algorithmic perspective, we give a new---and perhaps more elegant---proof of the Laffey-\v{S}migoc characterisation which provides a deeper insight into the result.

\end{ilasabstract}
    

\hypertarget{down0355}{}\begin{ilasabstract}
\talktitle{Exchange algorithms for Optimal Experimental Design
}
    
\textbf{Srinivas Eswar}, \info{16:00\textrm{--}16:30 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0355}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    We tackle optimal sensor placement for Bayesian linear inverse problems by establishing connections to the Column Subset Selection Problem (CSSP). We build on the Golub-Klema-Stewart (GKS) approach which involves computing the truncated Singular Value Decomposition (SVD) followed by a pivoted QR factorization on the right singular vectors. We study the effects of using the Federov exchange rule, greedily swapping sensors while improving the objective, after a GKS-style initialization. Theoretical guarantees on the number of swaps are established. Numerical experiments on model inverse problems demonstrate the performance of our approaches.

\end{ilasabstract}
    

\hypertarget{down0393}{}\begin{ilasabstract}
\talktitle{Krylov subspaces and Sobolev functions}
    
\textbf{Amin Faghih}, \info{17:00\textrm{--}17:30 @ SC4011 (June 26, Thursday)} \hfill \hyperlink{up0393}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    In this talk, we will discuss how to generate Sobolev rational functions that are orthonormal with respect to a discrete Sobolev inner product through a long recurrence relation. The recurrence coefficients of this relation can be stored in a Hessenberg pencil. Two important numerical methods are those based on Krylov subspace methods and those based on restoring matrix structures. The methods are based on the connection between Sobolev orthonormal rational functions and the orthonormal bases for rational Krylov subspaces generated by a Jordan-like matrix.
\end{ilasabstract}
    

\hypertarget{down0010}{}\begin{ilasabstract}
\talktitle{Preservers of totally positive and totally nonnegative matrices}
    
\textbf{Shaun Fallat}, \info{11:00\textrm{--}11:30 @ SC0008 (June 23, Monday)} \hfill \hyperlink{up0010}{$\Uparrow$}
    
    
(in {\color{mstitle}MS9: Total positivity})
        
\mtskip
    A matrix is called totally nonnegative (positive) if all its minors are nonnegative (positive). In this talk we consider functions that preserve that class of totally nonnegative (positive) matrices. This subject has rightfully received significant attention over the years, including previous studies on characterizing surjective linear preservers and more recent interesting inquiries into various types of entry-wise preservers for this class of matrices. Building upon the basic fact that the class of totally nonnegative (positive) matrices forms a semigroup we highlight some existing work and investigate and report on some recent progress concerning multiplicative maps that preserve this semigroup of positive matrices.

\end{ilasabstract}
    

\hypertarget{down0376}{}\begin{ilasabstract}
\talktitle{Leslie's enduring influence on the IEP-G and zero forcing}
    
\textbf{Shaun Fallat}, \info{16:30\textrm{--}17:00 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0376}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    When I think about Leslie's contributions to the IEP-G and Zero forcing, it is easy to conjure her impact via: Handbook(s) of LA, AIM workshops, AIM Squares, AIM ARC, BIRS FRGs, Sessions at ILAS, AMS, and the ``Boca'' conferences, not to mention, the very recent IEP-G/Zero forcing book with Shader and Lin…But Leslie has done SO much more to steer many recent advances in this area, including her numerous research team members from students, to postdocs, to collaborators. It is safe to say, the Leslie has personally opened the door to the IEP-G and Zero forcing to more people than anyone else (and it is not even close).  Her devotion to this topic and her steadfast support and encouragement to engage with so many researchers is astonishing…I hope to highlight several instances of Leslie's leadership and guidance that has shaped the direction of both the IEP-G and topics related to Zero forcing. When you look at the past 25 years her stamp is nearly everywhere on the IEP-G and Zero forcing. Personally, she was instrumental in supporting my research and I am truly blessed to have published 15 papers with my friend Dr. Leslie Hogben!
\end{ilasabstract}
    

\hypertarget{down0270}{}\begin{ilasabstract}
\talktitle{Inheritance properties of conjugate discrete-time algebraic Riccati equations}
    
\textbf{Hung-Yuan Fan}, \info{11:30\textrm{--}12:00 @ SC3001 (June 25, Wednesday)} \hfill \hyperlink{up0270}{$\Uparrow$}
    
    
(in {\color{mstitle}MS11: Structured matrix computations and its applications})
        
\mtskip
    In this talk we consider a class of conjugate discrete-time Riccati equations, arising originally from the linear quadratic regulator problem for discrete-time antilinear systems. Under mild and reasonable assumptions, the existence of the maximal solution to the conjugate discrete-time Riccati equation, in which the control weighting matrix is nonsingular and its constant term is Hermitian, will be inherited to a transformed discrete-time algebraic Riccati equation. Based on this inheritance property, an accelerated fixed-point iteration is proposed for finding the maximal solution via the transformed Riccati equation. Numerical examples are shown to illustrate the correctness of our theoretical results and the feasibility of the proposed algorithm.
\end{ilasabstract}
    

\hypertarget{down0066}{}\begin{ilasabstract}
\talktitle{Mixed-precision algorithms for the Sylvester matrix equation}
    
\textbf{Massimiliano Fasi}, \info{15:00\textrm{--}15:30 @ SC2001 (June 23, Monday)} \hfill \hyperlink{up0066}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    Modern supercomputers achieve their remarkable speeds by leveraging machine-learning hardware accelerators.
These accelerators deliver extraordinary throughput by trading off some degree of accuracy, and, to fully utilise their potential, we must rely on low-precision floating-point formats such as binary16, bfloat16, or binary8.
These reduced-precision formats can have a throughput up to two orders of magnitude higher than binary64, but they lack the precision needed for traditional scientific simulations, which require higher accuracy to yield meaningful results.
To integrate GPUs effectively into scientific computing, we must reimagine high-precision computations by strategically applying lower precision whenever feasible.

We consider techniques to solve the general Sylvester equation $AX + XB = C$ in mixed precision.
By revisiting a stationary iteration for linear systems, we derive a new iterative refinement scheme for the quasi-triangular Sylvester equation.
We then leverage this iterative scheme to solve the general Sylvester equation in mixed precision.
The new algorithms compute the Schur decomposition of the matrix coefficients in low precision, use the low-precision Schur factors to obtain an approximate solution to the quasi-triangular equation, and iteratively refine it to obtain a working-precision solution to the quasi-triangular equation.
However, being only orthonormal to low precision, the unitary Schur factors of A and B cannot be used to recover the solution to the original equation.
We propose two effective approaches to address this issue: one is based on re-orthonormalization in the working precision, and the other on explicit inversion of the almost-unitary factors.

This is joint work with Andrii Dmytryshyn, Nicholas J.~Higham, and Xiaobo Liu.
 
\end{ilasabstract}
    

\hypertarget{down0375}{}\begin{ilasabstract}
\talktitle{Reconfiguring a community}
    
\textbf{Mary Flagg}, \info{16:00\textrm{--}16:30 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0375}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    Reconfiguration is a process of transforming one feasible solution to a problem into another feasible solution in small incremental steps while maintaining the property of being a solution at each step. In the case of graph theory, solutions to problems are often subsets of the vertex set with a specific property. We refer to these as vertex set parameters. In this talk I will share a universal approach to vertex set parameter reconfiguration developed with Leslie Hogben and Bryan Curtis that is applied to zero forcing variants as well as other common graph parameters. Zero forcing was developed in this community to be an upper bound to the nullity of any real symmetric matrix with off-diagonal zero pattern determined by the adjacency matrix of a given graph. Understanding zero forcing sets has applications to understanding eigenvalues and eigenvectors of these matrices. 
Reconfiguration is also a description of how Leslie Hogben has helped to change our community for the better, one step at a time by facilitating community and research opportunity to graduate students, new researchers and faculty at undergraduate institutions. I will share my perspective on her reconfiguration efforts.

\end{ilasabstract}
    

\hypertarget{down0314}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Colin Fox}, \info{15:00\textrm{--}15:30 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0314}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0021}{}\begin{ilasabstract}
\talktitle{On entaglement, separability and their computability}
    
\textbf{Shmuel Friedland}, \info{12:00\textrm{--}12:30 @ SC0014 (June 23, Monday)} \hfill \hyperlink{up0021}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    \begin{bibunit}
        In this talk we survey some results on entanglement and separablity of general, symmetric (bosons),  skew-symmetric (fermions) tensors, and their computability.  We will survey briefly some results that I coauthored.
\begin{thebibliography}{99}
\bibitem{AF21} M. Aliabadi and S. Friedland, On the complexity of finding tensor ranks, \emph{Commun. Appl. Math. Comput.}, Vol. 3 (2) (2021),  281-289
\bibitem{BFZ} W. Bruzda, S. Friedland, K. {\.Z}yczkowski, Tensor rank and entanglement of pure quantum states,  {\it Linear and Multilinear Algebra} 72 (2024), no. 11, 1796-1859. 
\bibitem{DFLW17}  H. Derksen,  S. Friedland, L.-H. Lim, and L. Wang, Theoretical and computational aspects of entanglement,  arXiv:1705.07160.
\bibitem{FLd16} S. Friedland and  L.-H. Lim,The computational complexity of duality, jointly with,  \emph{SIAM Journal on Optimization}, 26, No. 4 (2016), 2378--2393.
\bibitem{FLn16} S. Friedland and  L.-H. Lim, Nuclear norm of higher-order tensors,  \emph{Mathematics of Computation}, 87 (2018), 1255--1281.
\bibitem{FK} S. Friedand and T. Kemp, Most Boson quantum states are almost maximally entangled,  \emph{Proceedings of Amer. Math. Soc.} 146, No.12, (2018), 5035--5049.
\bibitem{FW20} S. Friedland and L. Wang, Spectral norm of a symmetric tensor and its computation, ,  \emph{Mathematics of Computation}, 89 (2020), 2175--2215.
\end{thebibliography}
        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0340}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Takeshi Fukaya}, \info{14:00\textrm{--}14:30 @ SC2006 (June 26, Thursday)} \hfill \hyperlink{up0340}{$\Uparrow$}
    
    
(in {\color{mstitle}MS13: Advances in QR factorizations})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0169}{}\begin{ilasabstract}
\talktitle{Approximation of reciprocal matrices by consistent matrices}
    
\textbf{Susana Furtado}, \info{13:30\textrm{--}14:00 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0169}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    An $n$-by-$n$ matrix $A=[a_{ij}]$ is said to be a pairwise comparison matrix (PC matrix)
or a reciprocal matrix if it is positive and $a_{ij}=\frac{1}{%
a_{ji}},$ for all $i,j=1,\ldots ,n.$ If, in addition, $a_{ik}a_{kj}=a_{ij}$ for
all $i,j,k,$ the matrix is said to be consistent. Such a matrix is of the
form $ww^{(-T)}$ for some positive vector $w$, in which $w^{(-T)}$ is the transpose of the entrywise
inverse of $w$.

PC matrices play an important role in decision making, namely in models for ranking
alternatives, as the Analytic Hierarchy Process,  proposed by Saaty (1977). 
In these models, a PC matrix represents independent, pairwise, ratio
comparisons among $n$ alternatives and a cardinal ranking vector should be
obtained from it. The consistent matrix constructed from this vector should
be a good approximation of the PC matrix. So, it is desirable to choose a
ranking vector from the set of efficient vectors, as, otherwise, there would
be a positive vector such that the consistent matrix constructed from it
better approximates the PC matrix in at least one entry and is not worse in
all other entries. 

It is known that a positive vector $w$ is efficient for a PC matrix $A$ if
and only if a certain directed graph associated with $A$ and $w$ is strongly
connected. Based on this result, here we give a description of the set of
efficient vectors for a PC matrix as a union of a finite number of
convex sets and discuss some of its consequences. In particular, tight lower
and upper bound matrices for the consistent matrix constructed from an
efficient vector are given. 

(This is a joint work with Charles~Johnson.) 

\end{ilasabstract}
    

\hypertarget{down0144}{}\begin{ilasabstract}
\talktitle{Inequalities on spectral geometric mean and application for relative entropy}
    
\textbf{Shigeru Furuichi}, \info{10:30\textrm{--}11:00 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0144}{$\Uparrow$}
    
    
(in {\color{mstitle}MS3: Matrix inequalities with applications})
        
\mtskip
    \begin{bibunit}
        The weighted geometric mean is defined by $A\sharp_t B:=A^{\frac{1}{2}}\left(A^{-\frac{1}{2}}BA^{-\frac{1}{2}}\right)^t A^{\frac{1}{2}}$ for positive invertible operators $A,B$ and $0\leq t\leq 1.$ 
The weighted spectral geometric mean was defined in \cite{Lee1} by
\[A{{{\rm sp}}_{t}}B={{\left( {{A}^{-1}}\sharp B \right)}^{t}}A{{\left( {{A}^{-1}}\sharp B \right)}^{t}},\quad (0\leq t\leq 1).\]
Operator inequalities between the weighted spectral geometric mean $A{\rm sp}_t B$ and the weighted geometric mean $A\sharp_tB$ have compared in \cite{MFS2023} with the generalized Kantorovich constant for $0<m<M$ and $t\in \mathbb{R}$:
\[K\left( m,M,t \right)=\frac{\left(m{{M}^{t}}-M{{m}^{t}}\right)}{\left( t-1 \right)\left( M-m \right)}{{\left( \frac{t-1}{t}\frac{{{M}^{t}}-{{m}^{t}}}{m{{M}^{t}}-M{{m}^{t}}} \right)}^{t}}.\]
	
In this talk, we consider the case $t\notin (0,1)$. We firstly state the relations of $A\hat\sharp_t B$ and $A{{\hat{\rm sp}}_{t}}B$ for $t\notin (0,1)$ in L\"{o}wner order with the generalized Kantorovich constant. Norm inequalities are also shown for them.
We also give log--majorization and the bounds for the Tsallis relative entropy as its application.
Our talk is based on the results in \cite{FS2024}.


\begin{thebibliography}{5}

\bibitem{Lee1}
 H. Lee and Y. Lim, {\it Metric and spectral geometric means on symmetric cones}, Kyungpook Math. J., {\bf47}(1) (2007), 133--150.

\bibitem{MFS2023}
H. R. Moradi, S. Furuichi and M. Sababheh, {\it Operator spectral geometric versus geometric mean}, 	Linear Multilinear Algebra, {\bf 72}(2024), 997--1016.


\bibitem{FS2024} S. Furuichi and Y. Seo, {\it Some inequalities for spectral geometric mean
with applications}, Linear Multilinear Algebra, \url{doi.org/10.1080/03081087.2024.2433512}.
\end{thebibliography}
        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0274}{}\begin{ilasabstract}
\talktitle{Reversibility problem for real quaternion matrices}
    
\textbf{Angelo Galimba}, \info{10:30\textrm{--}11:00 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0274}{$\Uparrow$}
    
    
(in {\color{mstitle}MS31: Matrix decompositions and applications})
        
\mtskip
    In a group $G$, we say that $g \in G$ is \emph{reversible} if there exists $s \in G$ such that $s^{-1}gs = g^{-1}$. Moreover, such $g$ is \emph{strongly reversible} if $s$ is an involution, i.e., $s^2 = e$ where $e$ is the identity of the group $G$. In this talk, we study the reversibility problem in the group of invertible matrices over real quaternions $\mathbb{H}$, $GL(n, \mathbb{H})$. We completely classify up to standard Jordan form all real quaternion matrices in $GL(n,\mathbb{H})$ that are strongly reversible.
\end{ilasabstract}
    

\hypertarget{down0341}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Mark Gates}, \info{14:30\textrm{--}15:00 @ SC2006 (June 26, Thursday)} \hfill \hyperlink{up0341}{$\Uparrow$}
    
    
(in {\color{mstitle}MS13: Advances in QR factorizations})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0026}{}\begin{ilasabstract}
\talktitle{On the numerical solution of nonLocal boundary value problems by matrix function computations}
    
\textbf{Luca Gemignani}, \info{11:30\textrm{--}12:00 @ SC1003 (June 23, Monday)} \hfill \hyperlink{up0026}{$\Uparrow$}
    
    
(in {\color{mstitle}MS26: Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics})
        
\mtskip
    Given a matrix $A\in \mathbb R^{s\times s}$ and a  vector $\mathbf {f} \in \mathbb{ R } ^s,$ under mild assumptions the non-local boundary value problem 
\begin{eqnarray*}
    &&\odv{\mathbf{u}}{\tau} = A \mathbf{u}, \quad 0<\tau<1,   \label{l1} \\
  &&\displaystyle \int_0^1 \mathbf{u}(\tau) \,\mathrm{d}\tau = \mathbf {f}, \label{l2}
\end{eqnarray*}
admits as unique solution
\[
 \mathbf{u}(\tau)= q(\tau,A) \mathbf {f}, \quad q(\tau,w)= \frac{w e^{w\tau}}{e^w -1}.
 \]
This talk  deals with efficient numerical methods for computing the action
of $q(\tau,A)$ on a vector,  when $A$ is a large and
  sparse matrix.  Methods based on the Fourier expansion of $q(\tau,w)$
are considered. First, we place
these methods in the classical framework of Krylov-Lanczos
(polynomial-rational) techniques for accelerating Fourier series.
This allows us to apply the convergence results developed in this
context to our function. Second, we design some  new acceleration schemes for computing $q(\tau,A) \mathbf {f}$. Numerical results are presented to show the effectiveness of
the proposed algorithms.


\emph{This is joint work with Lidia Aceto.}
\end{ilasabstract}
    

\hypertarget{down0256}{}\begin{ilasabstract}
\talktitle{Banded block Toeplitz matrices with real asymptotic spectrum
}
    
\textbf{Dario Giandinoto}, \info{10:30\textrm{--}11:00 @ SC1003 (June 25, Wednesday)} \hfill \hyperlink{up0256}{$\Uparrow$}
    
    
(in {\color{mstitle}MS19: Explicit and hidden asymptotic structures, GLT Analysis, and applications})
        
\mtskip
    k-Toeplitz matrices or block Toeplitz matrices are matrices with periodic entries on their diagonals. In this sense, they constitute a generalization of Toeplitz matrices, which have constant (or 1-periodic) entries on their diagonals. In this talk, we will go over a result by Shapiro and Štampach which gives a condition for the reality of the asymptotic spectrum. Then, we will illustrate how to generalize this result to the block Toeplitz setting. Finally we will formulate a conjecture which completely characterizes block Toeplitz matrices with real asymptotic spectrum.

\end{ilasabstract}
    

\hypertarget{down0272}{}\begin{ilasabstract}
\talktitle{Spectral properties of stochastic block model}
    
\textbf{Van Su Giap}, \info{11:00\textrm{--}11:30 @ SC4011 (June 25, Wednesday)} \hfill \hyperlink{up0272}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    The stochastic block model (SBM) is an extension of the Erd\H{o}s-R\'{e}nyi graph and has applications in numerous fields, such as data analysis, recovering community structure in graph data and social networks. In this paper, we consider the normal central SBM adjacency matrix with $K$ communities of arbitrary sizes. We derive an explicit formula for the limiting empirical spectral density function when the size of the matrix tends to infinity. We also obtain an upper bound for the operator norm of such random matrices by means of the Stieltjes transform and random matrix theory.

\end{ilasabstract}
    

\hypertarget{down0373}{}\begin{ilasabstract}
\talktitle{Stable extraction of eigenpairs from a subspace for generalized eigenvalue problems}
    
\textbf{Miryam Gnazzo}, \info{17:00\textrm{--}17:30 @ SC1003 (June 26, Thursday)} \hfill \hyperlink{up0373}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    In this talk, we consider generalized eigenvalue problems associated with pencils in the form $A v = \lambda B v$, with $A,B \in \mathbb{R}^{m \times m}$. In several frameworks, we may be interested in the numerical approximation of a prescribed subset of eigenvectors, possibly coming from a good approximation of part of the eigenspace. This extraction of eigenpairs from a subspace can be done employing a class of methods often called oblique projectors. They consist in solving a different generalized eigenvalue problem $P^TAQv = \lambda P^T B Qv$, for suitable $P,Q\in \mathbb{R}^{m \times n}$ and $n<m$. A popular example of oblique projectors is Rayleigh-Ritz. However, it can be observed that this method is not backward stable. The goal of this talk consists in proposing alternative methods within the family of oblique projectors, with the additional property of being backward stable. Moreover, in settings where $m \gg n$, we present a randomized version of this technique, obtained via the solution a sketched version of the generalized eigenvalue problem.

\end{ilasabstract}
    

\hypertarget{down0230}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Laureano Gonzalez-Vega}, \info{16:30\textrm{--}17:00 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0230}{$\Uparrow$}
    
    
(in {\color{mstitle}MS30: Bohemian matrices: Theory, applications, and explorations})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0053}{}\begin{ilasabstract}
\talktitle{Tensors structures in single-shot quantum information: from convex splits to induced divergences}
    
\textbf{Gilad Gour}, \info{14:30\textrm{--}15:00 @ SC0014 (June 23, Monday)} \hfill \hyperlink{up0053}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    Recent advances in quantum information theory reveal the power of tensor structures in communication and coding tasks. In this talk, I present two results that reformulate key protocols using tools from matrix analysis: an equality-based version of the convex split lemma, relying on collision mutual information derived from the sandwiched R\'enyi relative entropy of order $2$, and the induced divergence, a new family of smoothed quantum divergences. These developments yield sharper achievability bounds for state merging, splitting, and communication over quantum channels, while highlighting the central role of the collision relative entropy in quantum information.
\end{ilasabstract}
    

\hypertarget{down0384}{}\begin{ilasabstract}
\talktitle{Commutativity concepts relative to transformation/matrix groups and semi-FTvN systems}
    
\textbf{Muddappa Gowda}, \info{16:30\textrm{--}17:00 @ SC2006 (June 26, Thursday)} \hfill \hyperlink{up0384}{$\Uparrow$}
    
    
(in {\color{mstitle}MS28: From matrix theory to Euclidean Jordan algebras, FTvN systems, and beyond})
        
\mtskip
    We introduce the concepts of {\it commutativity} relative to a transformation/matrix group and {\it strong commutativity} in the setting of a semi-FTvN system and show their appearance as optimality conditions in certain optimization problems. In the setting of a semi-FTvN system (in particular, in an FTvN system), we show that strong commutativity implies commutativity and observe that in the special case of Euclidean Jordan algebra, commutativity and strong commutativity concepts reduce, respectively, to those of operator and strong operator commutativity. We demonstrate that every complete hyperbolic polynomial induces a semi-FTvN system. By way of an application, we describe several commutation principles. 


\end{ilasabstract}
    

\hypertarget{down0310}{}\begin{ilasabstract}
\talktitle{Some factorizations in the complex symplectic group}
    
\textbf{Daryl Granario}, \info{15:00\textrm{--}15:30 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0310}{$\Uparrow$}
    
    
(in {\color{mstitle}MS31: Matrix decompositions and applications})
        
\mtskip
    As one of the classical Lie groups, the complex symplectic group is fundamental not only in mathematics but also in various related fields. We look at some important matrix decompositions when restricted to the complex symplectic group. In particular, we look at how we can use symplectic versions of canonical forms to derive decompositions such as the one given by Ballantine concerning products of positive definite matrices, and the one given by Sourour concerning the spectra of factors in a product of matrices.

\end{ilasabstract}
    

\hypertarget{down0063}{}\begin{ilasabstract}
\talktitle{On the eigenvalues of the graphs $D(5, q)$}
    
\textbf{Himanshu Gupta}, \info{15:00\textrm{--}15:30 @ SC1005 (June 23, Monday)} \hfill \hyperlink{up0063}{$\Uparrow$}
    
    
(in {\color{mstitle}MS15: Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham})
        
\mtskip
    In 1995, Lazebnik and Ustimenko introduced the family of $q$-regular graphs $D(k, q)$, which is defined for any positive integer $k$ and prime power $q$. The connected components of the graph $D(k, q)$ have provided the best-known general lower bound on the size of a graph for any given order and girth to this day. Furthermore, Ustimenko conjectured that the second largest eigenvalue of $D(k, q)$ is always less than or equal to $2\sqrt{q}$, indicating that the graphs $D(k, q)$ are almost Ramanujan graphs. In this talk, we will discuss some recent progress on this conjecture. This includes the result that the second largest eigenvalue of $D(5, q)$ is less than or equal to $2\sqrt{q}$ when $q$ is an odd prime power. This is joint work with Vladislav Taranchuk.

\end{ilasabstract}
    

\hypertarget{down0264}{}\begin{ilasabstract}
\talktitle{Minimum number of distinct eigenvalues of Johnson and Hamming graphs}
    
\textbf{Himanshu Gupta}, \info{11:30\textrm{--}12:00 @ SC2001 (June 25, Wednesday)} \hfill \hyperlink{up0264}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    This talk focuses on the inverse eigenvalue problem for graphs (IEPG), which seeks to determine the possible spectra of symmetric matrices associated with a given graph $G$. These matrices have off-diagonal non-zero entries corresponding to the edges of $G$, while diagonal entries are unrestricted. A key parameter in IEPG is $q(G)$, the minimum number of distinct eigenvalues among such matrices. The Johnson and Hamming graphs are well-studied families of graphs with many interesting combinatorial and algebraic properties. We prove that every Johnson graph admits a signed adjacency matrix with exactly two distinct eigenvalues, establishing that its $q$-value is two. Additionally, we explore the behavior of $q(G)$ for Hamming graphs. This is a joint work with Shaun Fallat, Allen Herman, and Johnna Parenteau. 

\end{ilasabstract}
    

\hypertarget{down0377}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Tracy Hall}, \info{17:00\textrm{--}17:30 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0377}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0329}{}\begin{ilasabstract}
\talktitle{A Ritz method for solution of parametric generalized EVPs}
    
\textbf{Antti Hannukainen}, \info{14:30\textrm{--}15:00 @ SC1003 (June 26, Thursday)} \hfill \hyperlink{up0329}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    This talk deals with approximate solution of generalized eigenvalue problem with coefficient matrix that is an affine function of $d$-parameters. The coefficient matrix is assumed to be symmetric positive definite and spectrally equivalent to an average matrix for all parameters in a given set. We develop a Ritz method for rapidly approximating the eigenvalues on the spectral interval of interest $(0,\Lambda)$ for given parameter value. The Ritz subspace is the same for all parameters and it is designed based on the observation that any eigenvector can be split into two components. The first component belongs to a subspace spanned by some eigenvectors of the average matrix. The second component is defined by a correction operator that is a $d+1$ dimensional analytic function. We use this structure and build our Ritz subspace from eigenvectors of the average matrix and samples of the correction operator. The samples are evaluated at interpolation points related to a sparse polynomial interpolation method. We show that the resulting Ritz subspace can approximate eigenvectors of the original problem related to the spectral interval of interest with the same accuracy as the sparse polynomial interpolation approximates the correction operator. Bound for Ritz eigenvalue error follows from this and known results. Theoretical results are illustrated by numerical examples. The advantage of our approach is that the analysis treats multiple eigenvalues and eigenvalue crossings that typically have posed technical challenges in similar works.

\end{ilasabstract}
    

\hypertarget{down0128}{}\begin{ilasabstract}
\talktitle{Isometries on groups of invertible elements in Fourier-Stieltjes algebras}
    
\textbf{Osamu Hatori}, \info{11:30\textrm{--}12:00 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0128}{$\Uparrow$}
    
    
(in {\color{mstitle}MS12: Preserver problems, I})
        
\mtskip
    If open subgroups of the groups of invertible elements in two Fourier-Stieltjes algebras are isometric as metric spaces, then the underlying locally compact groups are topologically isomorphic.

\end{ilasabstract}
    

\hypertarget{down0183}{}\begin{ilasabstract}
\talktitle{High-order eulerian numbers and matrices}
    
\textbf{Tian-Xiao He}, \info{14:30\textrm{--}15:00 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0183}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    We study the properties of the higher-order Eulerian numbers and the higher-order Eulerian matrices. The row generating functions and the row sums of the higher-order Eulerian matrices are given. We also define higher-order Eulerian fractions and their alternative forms. Some properties of higher-order Eulerian fractions are expressed using differentials and integrals. The inversion relationships between second-order Eulerian numbers and Stirling numbers of the second and first kinds are given. We also give exact expressions for the entries of higher-order Eulerian matrices.
\end{ilasabstract}
    

\hypertarget{down0062}{}\begin{ilasabstract}
\talktitle{Degenerate eigenvalues for the non-backtracking matrix}
    
\textbf{Kristin Heysse}, \info{14:30\textrm{--}15:00 @ SC1005 (June 23, Monday)} \hfill \hyperlink{up0062}{$\Uparrow$}
    
    
(in {\color{mstitle}MS15: Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham})
        
\mtskip
    The non-backtracking matrix is the transition matrix for a walk in a graph which cannot traverse an edge twice in immediate succession. The spectral information of this matrix has seen great interest, notably in applications of network analysis. The non-symmetric nature of this matrix allows for graphs without a full basis of eigenvectors, which results in nontrivial Jordan chains. In this talk, we will consider the Jordan form of this matrix and construct infinite families of graphs with nontrivial Jordan chains. 

\end{ilasabstract}
    

\hypertarget{down0013}{}\begin{ilasabstract}
\talktitle{Joint concavity/convexity of matrix trace functions for geometric type means}
    
\textbf{Fumio Hiai}, \info{11:00\textrm{--}11:30 @ SC0009 (June 23, Monday)} \hfill \hyperlink{up0013}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    In this talk we consider the quasi extensions of the weighted geometric type means, including
\begin{align*}
&G_{\alpha,p}(A,B):=(A^p\#_\alpha B^p)^{1/p},
\ \mbox{the quasi-weighted geometric mean}, \\
&SG_{\alpha,p}(A,B):=(A^p\#_\alpha B^p)^{1/p},
\ \mbox{the quasi-weighted spectral geometric mean}, \\
&R_{\alpha,p}(A,B):=\bigl(B^{{\frac{1-\alpha}{2}}p}A^{\alpha p}B^{{\frac{1-\alpha}{2}}p}\bigr)^{1/p},
\ \mbox{the R\'enyi mean}, \\
&LE_\alpha(A,B):=\exp(\alpha\log A+(1-\alpha)\log B),
\ \mbox{the weighted Log-Euclidean mean},
\end{align*}
where $\alpha>0$ is the weight parameter and $p>0$ is the parameter of the quasi extension. We aim at determining the range of the parameters $\alpha,p$ under which the trace function $\mathrm{Tr}\,\mathcal{M}_{\alpha,p}(A,B)$ is jointly concave (also jointly convex) for each $\mathcal{M}_{\alpha,p}$ from the above quasi-weighted geometric type means. Our discussions are in strong relation to the monotonicity property (or date-processing inequality) of quantum divergences in quantum information.

\end{ilasabstract}
    

\hypertarget{down0248}{}\begin{ilasabstract}
\talktitle{Tingley's problem concerning the direct sum of extremely C-regular subspaces with the $\ell^p$-norm.}
    
\textbf{Daisuke Hirota}, \info{11:00\textrm{--}11:30 @ SC0012 (June 25, Wednesday)} \hfill \hyperlink{up0248}{$\Uparrow$}
    
    
(in {\color{mstitle}MS35: Preserver Problems, II})
        
\mtskip
    Tingley's problem asks whether every surjective isometry between the unit spheres of two Banach spaces can be 
extended to a surjective real-linear \nobreak{isometry} between the whole spaces. 
Let $\{A_{\lambda}\}_{\lambda\in\Lambda}$ be a family of uniformly closed, extremely C-regular subspaces,  
and 
let $p$ be a real number such that $1<p<\infty$ with $p\neq 2$. 
We denote by $A_{\Lambda}^{p}$ the Banach space of formed by the direct sum of $\{A_{\lambda}\}_{\lambda\in \Lambda}$ 
equipped with the norm $\|{\bm{f}}\|_{p}=\left(\sum_{\lambda\in \Lambda}\|{\bm{f}}_{\lambda}\|_{\infty}^{p}\right)^{1/p}$ for ${\bm{f}}\in A_{\Lambda}^{p}$. \\
\quad In this presentation, I will speak on the fact that
 if $\Delta$ is a surjective isometry between two unit spheres $S(A_{M}^{p})$ and $S(A_{N}^{p})$ of the Banach spaces 
 $A_{M}^{p}$ and $A_{N}^{p}$, 
 then $\Delta$ admits an extension to a surjective real-linear isometry between the whole spaces.
\end{ilasabstract}
    

\hypertarget{down0174}{}\begin{ilasabstract}
\talktitle{An optimal preconditioned MINRES method for nonsymmetric multilevel block Toeplitz systems with applications}
    
\textbf{Sean Hon}, \info{14:00\textrm{--}14:30 @ SC1003 (June 24, Tuesday)} \hfill \hyperlink{up0174}{$\Uparrow$}
    
    
(in {\color{mstitle}MS19: Explicit and hidden asymptotic structures, GLT Analysis, and applications})
        
\mtskip
    In this talk, we introduce a novel preconditioning strategy for solving multilevel block Toeplitz systems, with applications to nonlocal evolutionary fractional diffusion equations. We show that the Hermitian part of certain nonsymmetric systems serves as an ideal preconditioner. By transforming the nonsymmetric block Toeplitz system into a symmetric block Hankel system using a symmetrization technique, we propose a symmetric positive definite block Tau preconditioner that is efficiently implemented using the discrete sine transform. We prove that this approach enables mesh-size-independent convergence with eigenvalues of the preconditioned matrices contained in specific intervals around $\pm 1$. Numerical results will be presented to demonstrate the method's efficiency in terms of iterations and computation time. This is joint work with Grigorios Tachyridis.
\end{ilasabstract}
    

\hypertarget{down0296}{}\begin{ilasabstract}
\talktitle{Spectral community detection in geometric random graphs}
    
\textbf{Carlos Hoppen}, \info{11:00\textrm{--}11:30 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0296}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    This talk is about community detection in graphs defined by the Soft Geometric Block Model (SGBM). Suppose that $n=k \ell$ points are classified into $k \geq 2$ communities with $\ell$ points in each community. These $n$ points are embedded independently and with uniform probability as points $X_1,\ldots,X_n$ of the $d$-dimensional flat unit torus $\mathbf{T^d}$. A random graph $G$ is generated so that the edge $\{i,j\}$ appears with probability $F_{in}(||X_i-X_j||)$ if $i$ and $j$ belong to the same community, and with probability $F_{out}(||X_i-X_j||)$  if $i$ and $j$ belong to different communities. Under some technical conditions about $F_{in}$ and $F_{out}$, we shall prove that asymptotically almost surely there is a set of $k-1$ eigenvalues of the adjacency matrix $A(G)$ whose eigenspaces allow us to correctly identify the members of each community. This strategy gives a spectral algorithm for community detection in random geometric graphs. The talk is based on joint work with Konstantin Avrachenkov (INRIA-Sophia Antipolis), Luiz Emilio Allem (UFRGS), Hariprasad Manjunath (Chanakya University), and Lucas Siviero Sibemberg (UFRGS), and generalizes a result of Avrachenkov, Bobu and Dreveton [Avrachenkov, K., Bobu, A., Dreveton, M., \emph{Higher-Order Spectral Clustering for Geometric Graphs}, Journal of Fourier Analysis and Applications {\bf 27} (2021), article 22.], which deals with the case of $k=2$ communities. 

\end{ilasabstract}
    

\hypertarget{down0187}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Di Hou}, \info{14:30\textrm{--}15:00 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0187}{$\Uparrow$}
    
    
(in {\color{mstitle}MS32: Advances in matrix manifold optimization})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0238}{}\begin{ilasabstract}
\talktitle{Lanczos with compression for symmetric Lyapunov equations}
    
\textbf{Francesco Hrobat}, \info{16:30\textrm{--}17:00 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0238}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    In this work, we present a low-memory variant of the Lanczos algorithm for the solution of the Lyapunov equation
\begin{equation}\label{eqn:lyap}
AX + XA = \boldsymbol{c}\boldsymbol{c}^T,    
\end{equation}
where $A$ is a large-scale symmetric positive-definite matrix and $\boldsymbol{c}$ is a vector. 

The classical Lanczos method consists in building an orthonormal basis $\mathbf{Q}_M$ for the polynomial Krylov subspace
\[ \mathcal{K}_M(A,\boldsymbol{c}) = span(\boldsymbol{c},A\boldsymbol{c}, \dots, A^{M-1}\boldsymbol{c}) \]
and in approximating the solution $X$ with $\mathbf{Q}_MX_M\mathbf{Q}_M^T$, where $X_M$ solves the projected equation
\[ \mathbf{Q}_M^TA\mathbf{Q}_M X_M + X_M\mathbf{Q}_M^TA\mathbf{Q}_M = \| \boldsymbol{c} \|_F^2\boldsymbol{e}_1\boldsymbol{e}_1^T.\]
The Lanczos algorithm often requires a relatively large $M$ to obtain a good approximation of the solution, which can lead to memory issues due to the storage demands of $\mathbf{Q}_M$. Furthermore, the solution $X$ can be well approximated by a low-rank matrix, whose rank is significantly smaller than $M$, i.e. the dimension of the polynomial Krylov subspace. 

An alternative approach is to use a rational Krylov subspace instead of a polynomial one. Using the Zolotarev poles as the poles of the rational Krylov subspace, it is possible to approximate the solution $X$ by a low-rank matrix with the guarantee that the residual has norm smaller than a prescribed quantity [$2$]. The rank of the computed approximate solution is usually close to the numerical rank of the real solution. The main drawback is that this method requires solving multiple shifted linear systems involving the matrix $A$, which is prohibitive if $A$ is large. 

Mimicking the approach in [$3$], our method employs a polynomial Krylov subspace to approximate the solution of \eqref{eqn:lyap} while leveraging rational Krylov subspaces associated with small matrices to compress the Lanczos basis. This method accesses $A$ only through matrix-vector products and requires the storage of only a few vectors from the polynomial Krylov subspace instead of the entire Lanczos basis, producing an approximate solution whose rank is independent of the dimension of the involved polynomial Krylov subspace.

The computational cost of the proposed algorithm is dominated by the construction of the Lanczos basis, and the compression steps do not require additional matrix-vector products involving $A$. Furthermore, theoretical results demonstrate that the algorithm achieves an approximation error comparable to that of the standard Lanczos algorithm, with an additional error term that can be bounded a priori using Zolotarev numbers. In practice, this additional error is negligible compared to the Lanczos error.

Numerical experiments show that the behavior of the proposed algorithm is comparable to that of the Lanczos algorithm without reorthogonalization, both in terms of matrix-vector products and quality of the approximated solution. Comparisons with existing low-memory variants of the Lanczos method demonstrate competitive performance in terms of accuracy, computational cost, and runtime.


\begin{itemize}
\item[1] A. A. Casulli, F. H., D. Kressner, Lanczos with Rational Krylov compression for symmetric Lyapunov equations, In preparation.
\item[2] B. Beckermann, An error analysis for rational Galerkin projection applied to the Sylvester
equation, SIAM J. Numer. Anal., 49 (2011), pp. 2430--2450. 
\item[3] A. A. Casulli and I. Simunec. A low-memory Lanczos method with rational
Krylov compression for matrix functions, arXiv, 2024.
\end{itemize} 

\end{ilasabstract}
    

\hypertarget{down0359}{}\begin{ilasabstract}
\talktitle{Quantum complementarity: A novel resource for exclusion}
    
\textbf{Chung-Yun Hsieh}, \info{16:00\textrm{--}16:30 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0359}{$\Uparrow$}
    
    
(in {\color{mstitle}MS7: Linear algebra and quantum information science})
        
\mtskip
    Complementarity is a phenomenon explaining several core features of quantum theory, such as the well-known uncertainty principle. Roughly speaking, two objects are said to be {\em complementary} if being certain about one of them necessarily forbids useful knowledge about the other. Two quantum measurements that do not commute form an example of complementary measurements, and this phenomenon can also be defined for ensembles of states. Although a key quantum feature, it is unclear whether complementarity can be understood more operationally, as a necessary resource in some quantum information task. Here we show this is the case, and relates to a novel task which we term {\em $\eta$-unambiguous exclusion}. As well as giving complementarity a clear operational definition, this also uncovers the foundational underpinning of unambiguous exclusion tasks for the first time. \\\\
Reference: C.-Y. Hsieh, R. Uola, P. Skrzypczyk, {\em Quantum complementarity: A novel resource for unambiguous exclusion and encryption}, arXiv:2309.11968.

\end{ilasabstract}
    

\hypertarget{down0361}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Hsien-Yi Hsieh}, \info{17:00\textrm{--}17:30 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0361}{$\Uparrow$}
    
    
(in {\color{mstitle}MS7: Linear algebra and quantum information science})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0208}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Shao-Hua Hu}, \info{17:30\textrm{--}18:00 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0208}{$\Uparrow$}
    
    
(in {\color{mstitle}MS7: Linear algebra and quantum information science})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0040}{}\begin{ilasabstract}
\talktitle{Coordinate testing for general sufficient dimension reduction methods}
    
\textbf{Shih-Hao Huang}, \info{11:00\textrm{--}11:30 @ SC4011 (June 23, Monday)} \hfill \hyperlink{up0040}{$\Uparrow$}
    
    
(in {\color{mstitle}MS20: Manifold learning and statistical applications})
        
\mtskip
    In modern data analysis, the number of covariates is often large, and the relationship between covariates and response is often complex. Parametric regression risks model misspecification, while nonparametric regression suffers from the curse of dimensionality. Sufficient dimension reduction (SDR) regression provides a flexible alternative, summarizing covariate effects through a few linear combinations without imposing a specific functional form. While SDR methods have been extensively studied, coordinate testing, which assesses the contribution of a set of linear combinations of covariates, has been largely overlooked. To address this gap, we propose a novel method that transforms the coordinate testing problem into a dimension testing problem by applying appropriate residualization. Since dimension tests are well-established, this method allows practitioners to leverage existing inference tools within the SDR framework.

\end{ilasabstract}
    

\hypertarget{down0133}{}\begin{ilasabstract}
\talktitle{Progress on orders of matrix means}
    
\textbf{Huajun Huang}, \info{11:00\textrm{--}11:30 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0133}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    On the set  of positive definite matrices, 
the L\"owner order \(\le\), the chaotic order \(\ll\), the near order \(\preceq\), the eigenvalue entrywise order, and the weak log-majorization order \(\prec_{w \log}\) satisfy:
\[
A \le B \Longrightarrow A \ll B  \Longrightarrow  A \preceq B  \Longrightarrow A \le_{\lambda} B \Longrightarrow A \prec_{w \log} B.
\]
The spectral geometric mean \(\natural_t\) and the Bures–Wasserstein mean \(\diamond_t\) satisfy that for \(t \in [0,1]\):
\begin{align*}
	A \natural_t B &\preceq A \diamond_t B, \\
	(A^{-1} \diamond_t B^{-1})^{-1} &\preceq A \natural_t B = (A^{-1} \natural_t B^{-1})^{-1}, \\
	(A^{-1} \diamond_t B^{-1})^{-1} &\preceq A \diamond_t B.
\end{align*}
Moreover, the Alpha Procrustes mean is closely related to the Bures–Wasserstein mean. 
I will present some recent results on the order relations among these matrix means. A few affirmative order relations and a few counterexamples will be explored.
\end{ilasabstract}
    

\hypertarget{down0151}{}\begin{ilasabstract}
\talktitle{Application of VoxelMorph and SynthMorph for multitype 3D medical image registration}
    
\textbf{Yu-Jie Huang}, \info{11:00\textrm{--}11:30 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0151}{$\Uparrow$}
    
    
(in {\color{mstitle}MS20: Manifold learning and statistical applications})
        
\mtskip
    In this work, we explore the application of VoxelMorph and SynthMorph for 3D medical image registration. VoxelMorph provides a deep learning-based framework that utilizes deformable pairwise registration, enabling the alignment of complex anatomical structures through continuous deformation fields. By modeling transformations as smooth manifolds, VoxelMorph facilitates precise, non-rigid alignment, making it well-suited for capturing intricate deformations in medical images. SynthMorph further extends this approach, offering a robust method for image registration across diverse MRI contrasts, effectively handling variations in image intensities without relying on acquired imaging data. We investigate how these deformable models can be integrated into existing medical imaging workflows to enhance multi-type image registration, improving the alignment of images with varying anatomical and contrast properties.
\end{ilasabstract}
    

\hypertarget{down0191}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Longxiu Huang}, \info{14:30\textrm{--}15:00 @ SC3001 (June 24, Tuesday)} \hfill \hyperlink{up0191}{$\Uparrow$}
    
    
(in {\color{mstitle}MS18: New methods in numerical multilinear algebra})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0015}{}\begin{ilasabstract}
\talktitle{Near-order relation of power means}
    
\textbf{Jinmi Hwang}, \info{12:00\textrm{--}12:30 @ SC0009 (June 23, Monday)} \hfill \hyperlink{up0015}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    On the setting of positive definite operators we study the near-order properties of power means such as the quasi-arithmetic mean (H\"{o}lder mean) and R\'{e}nyi power mean. We see the monotonicity of spectral geometric mean and Wasserstein mean on parameters with respect to the near-order and the near-order relationship between the spectral geometric mean and Wasserstein mean. Furthermore, the monotonicity of quasi-arithmetic mean on parameters and the convergence of R\'{e}nyi power mean to the log-Euclidean mean with respect to the near-order have been established.
\end{ilasabstract}
    

\hypertarget{down0065}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Bruno Iannazzo}, \info{14:30\textrm{--}15:00 @ SC2001 (June 23, Monday)} \hfill \hyperlink{up0065}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0176}{}\begin{ilasabstract}
\talktitle{Quasi-boundary regularization for space-time fractional diffusion equations with variable coefficients}
    
\textbf{Asim Ilyas}, \info{15:00\textrm{--}15:30 @ SC1003 (June 24, Tuesday)} \hfill \hyperlink{up0176}{$\Uparrow$}
    
    
(in {\color{mstitle}MS19: Explicit and hidden asymptotic structures, GLT Analysis, and applications})
        
\mtskip
    This work addresses the inverse problem of reconstructing a source term in a space-time fractional diffusion equation with variable coefficients, using final time observations and a quasi-boundary value regularization method. The equation under consideration incorporates a Caputo fractional derivative in space and a tempered fractional derivative in time, both of order between 0 and 1. These types of equations are particularly relevant in various applied fields. To numerically approximate the regularized problem, we employ a finite difference scheme, which results in a large-scale two-by-two block linear system. The study presents theoretical insights into the spectral properties of both non-preconditioned and preconditioned matrix sequences, using tools from Toeplitz and Generalized Locally Toeplitz (GLT) theory. Notably, the preconditioner, derived from the GLT framework, is introduced and analyzed here for the first time in this context. Numerical experiments are conducted to validate the theoretical findings, followed by concluding remarks.
\end{ilasabstract}
    

\hypertarget{down0349}{}\begin{ilasabstract}
\talktitle{Deflation techniques for matrix function calculations based on double exponential-type numerical integral formula}
    
\textbf{Akira Imakura}, \info{14:30\textrm{--}15:00 @ SC4011 (June 26, Thursday)} \hfill \hyperlink{up0349}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    This talk focuses on efficient methods for computing matrix functions, such as matrix exponential and matrix square roots.
Recently, methods based on double exponential (DE)-type numerical integral formula have been proposed and have attracted much attention.
In this talk, we propose a convergence improvement based on a deflation technique of splitting eigen-components that adversely affect convergence.
\end{ilasabstract}
    

\hypertarget{down0046}{}\begin{ilasabstract}
\talktitle{The weighted power difference mean and its generalization}
    
\textbf{Masatoshi Ito}, \info{14:00\textrm{--}14:30 @ SC0009 (June 23, Monday)} \hfill \hyperlink{up0046}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    Pal, Singh, Moslehian and Aujla (2016) introduced the weighted logarithmic mean for two positive numbers
 or operators on a complex Hilbert space, which is based on an extension of the Hermite-Hadamard inequality.
Furuichi and Minculete (2020) obtained a refinement of the inequality by Pal et al.
On the other hand, we discussed relations among some weighted operator means
 by considering the notion of a transpose symmetric path of weighted means,
 and we introduced the weighted Heinz mean.
In this talk, based on these arguments,
 we  newly introduce the weighted power difference mean and get relations
 among the weighted power, power difference and arithmetic means.
Moreover, we generalize these results from the viewpoint of a transpose symmetric path.


\end{ilasabstract}
    

\hypertarget{down0122}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Tanvi Jain}, \info{11:30\textrm{--}12:00 @ SC0008 (June 24, Tuesday)} \hfill \hyperlink{up0122}{$\Uparrow$}
    
    
(in {\color{mstitle}MS9: Total positivity})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0123}{}\begin{ilasabstract}
\talktitle{New weighted spectral geometric mean and quantum divergence}
    
\textbf{Miran Jeong}, \info{10:30\textrm{--}11:00 @ SC0009 (June 24, Tuesday)} \hfill \hyperlink{up0123}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    A new class of weighted spectral geometric means has recently been introduced. In this talk, we present its inequalities in terms of the L\"{o}wner order, operator
norm, and trace.
Moreover, we establish a log-majorization relationship between the new spectral geometric mean, and the R\'{e}nyi relative operator entropy.
We also give the quantum divergence of the quantity, given by the difference of trace values between the
arithmetic mean and new spectral geometric mean.
Finally, we study the barycenter that minimizes the weighted sum of quantum divergences for given variables.

\end{ilasabstract}
    

\hypertarget{down0383}{}\begin{ilasabstract}
\talktitle{Generalized convexity for spectral functions on Euclidean Jordan algebras
}
    
\textbf{Juyoung Jeong}, \info{16:00\textrm{--}16:30 @ SC2006 (June 26, Thursday)} \hfill \hyperlink{up0383}{$\Uparrow$}
    
    
(in {\color{mstitle}MS28: From matrix theory to Euclidean Jordan algebras, FTvN systems, and beyond})
        
\mtskip
    In a Euclidean Jordan algebra $\mathcal{V}$, a spectral function $G : \mathcal{V} \to \mathbb{R}$ is defined as a function that depends solely on the eigenvalues of its argument. Formally, such a function takes the form $G = f \circ \lambda$, where $f : \mathbb{R}^n \to \mathbb{R}$ is a (symmetric) function and $\lambda : \mathcal{V} \to \mathbb{R}^n$ denotes the eigenvalue mapping. It turns out that spectral functions are invariant under algebra automorphisms of $\mathcal{V}$.
Due to their simple yet elegant structure and wide applicability, spectral functions play a crucial role not only in matrix theory but also in convex analysis, optimization, and beyond. It has been observed that $G$ is (strictly) convex if and only if so is the associated function $f$, which we call a transfer principle for (strict) convexity. In this talk, we will explore analogous transfer principle for generalized notions of convexity, including strong convexity, quasi-convexity, pseudo-convexity, and related concepts. 

\end{ilasabstract}
    

\hypertarget{down0033}{}\begin{ilasabstract}
\talktitle{Median eigenvalues of subcubic graphs}
    
\textbf{Zilin Jiang}, \info{12:00\textrm{--}12:30 @ SC2001 (June 23, Monday)} \hfill \hyperlink{up0033}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    We present a resolution to conjectures by Fowler, Pisanski, and Mohar regarding the median eigenvalues of subcubic (chemical) graphs. Specifically, we prove that the median eigenvalues of every connected graph with maximum degree at most three, except for the Heawood graph, lie within the interval $[-1, 1]$. This result has significant implications in mathematical chemistry, particularly in the analysis of molecular orbital models, and extends prior work on bipartite chemical graphs.

\end{ilasabstract}
    

\hypertarget{down0308}{}\begin{ilasabstract}
\talktitle{Product of skew-involutions}
    
\textbf{Jesus Paolo Joven}, \info{14:00\textrm{--}14:30 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0308}{$\Uparrow$}
    
    
(in {\color{mstitle}MS31: Matrix decompositions and applications})
        
\mtskip
    We show that every $2n$-by-$2n$ matrix over a field $\mathbb{F}$ with determinant 1 is a product of (i) four or fewer skew-involutions ($A^2 = -I$) provided $\mathbb{F} \neq \mathbb{Z}_3$, and (ii) eight or fewer skew-involutions if $\mathbb{F} = \mathbb{Z}_3$ and $n > 1$. We also show that every real symplectic matrix is a product of six real symplectic skew-involutions. 

\end{ilasabstract}
    

\hypertarget{down0353}{}\begin{ilasabstract}
\talktitle{Inverse $Z$-matrices with the bi-diagonal south-west structure
}
    
\textbf{Sivakumar K.C.}, \info{17:00\textrm{--}17:30 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0353}{$\Uparrow$}
    
    
(in {\color{mstitle}MS24: Nonnegative and related families of matrices})
        
\mtskip
    Two new matrix classes are introduced; inverse cyclic matrices and bi-diagonal south-west matrices. An interesting relation is established between these classes. Applications to two classes of inverse $Z$-matrices are provided.

\end{ilasabstract}
    

\hypertarget{down0364}{}\begin{ilasabstract}
\talktitle{Simultaneous symplectic normalisation of quadratic forms
}
    
\textbf{Rudra Kamat}, \info{16:30\textrm{--}17:00 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0364}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    A fundamental result in symplectic linear algebra states that for a given positive semi-definite quadratic form on a symplectic space there exists a symplectic basis in which the quadratic form reduces to a normal form. The special case of the aforementioned result for positive definite quadratic forms is known as Williamson's theorem. In this work, we establish necessary and sufficient conditions on positive semi-definite quadratic forms on a symplectic space to be simultaneously reduced to their normal forms in a common symplectic basis. In particular, we establish conditions on \(2n\times 2n\) real symmetric positive-definite matrices to be simultaneously diagonalisable by a symplectic matrix in the sense of Williamson's theorem. We also discuss some applications of the main result in quantum information theory and statistical thermodynamics.

\end{ilasabstract}
    

\hypertarget{down0348}{}\begin{ilasabstract}
\talktitle{A semi-definite optimization method for maximizing the shared band gap of topologicalpPhotonic crystals}
    
\textbf{Chiu-Yen Kao}, \info{14:00\textrm{--}14:30 @ SC4011 (June 26, Thursday)} \hfill \hyperlink{up0348}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    Topological photonic crystals (PCs) can support robust edge modes to transport electromagnetic energy in an efficient manner. Such edge modes are the eigenmodes of the PDE operator for a joint optical structure formed by connecting together two photonic crystals with distinct topological invariants, and the corresponding eigenfrequencies are located in the shared band gap of two individual photonic crystals. This work is concerned with maximizing the shared band gap of two photonic crystals with different topological features in order to increase the bandwidth of the edge modes. We develop a semi-definite optimization framework for the underlying optimal design problem, which enables efficient update of dielectric functions at each time step while respecting symmetry constraints and, when necessary, the constraints on topological invariants. At each iteration, we perform sensitivity analysis 
of the band gap function and the topological invariant constraint function to linearize the optimization problem and solve a convex semi-definite programming (SDP) problem efficiently. Numerical examples show that the proposed algorithm is superior in generating optimized optical structures with robust edge modes. (This is joint work with Junshan Lin at Auburn University and Braxton Osting at University of Utah)
\end{ilasabstract}
    

\hypertarget{down0044}{}\begin{ilasabstract}
\talktitle{Unimodality preservation by ratios of functional series and integral transforms}
    
\textbf{Dmitrii Karp}, \info{14:30\textrm{--}15:00 @ SC0008 (June 23, Monday)} \hfill \hyperlink{up0044}{$\Uparrow$}
    
    
(in {\color{mstitle}MS9: Total positivity})
        
\mtskip
    Elementary, but very useful lemma due to Biernacki and Krzy\.{z} (1955) asserts that the ratio of two power series inherits monotonicity from that of the sequence of ratios of their respective  coefficients. Over the last two decades it has been realized that, under some additional assumptions, similar claims hold for more general ratios of series and integral
transforms as well as for unimodality in place of monotonicity. In the talk, we discuss conditions on the functional sequence and the kernel of an integral transform ensuring the preservation property. Numerous series and integral transforms appearing in applications satisfy our sufficient conditions, including Dirichlet, factorial (and $q$-factorial) series, inverse factorial series, Laplace, Mellin and generalized Stieltjes transforms, among many others.  We illustrate our results by ratios of generalized hypergeometric functions and Nuttall's $Q$ functions.  The key role in our considerations is played by the notion of sign regularity.

The talk is based on the the joint work with Anna Vishnyakova and Yi Zhang. 

\end{ilasabstract}
    

\hypertarget{down0120}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Olga Katkova}, \info{10:30\textrm{--}11:00 @ SC0008 (June 24, Tuesday)} \hfill \hyperlink{up0120}{$\Uparrow$}
    
    
(in {\color{mstitle}MS9: Total positivity})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0140}{}\begin{ilasabstract}
\talktitle{Nonbacktracking random walks: mixing rate, Kemeny's constant, and beyond}
    
\textbf{Mark Kempton}, \info{11:30\textrm{--}12:00 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0140}{$\Uparrow$}
    
    
(in {\color{mstitle}MS15: Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham})
        
\mtskip
    Random walks on graphs are ubiquitous in spectral graph theory, both in helping us understand graphs and for applications in graph algorithms.  Considerable research has been done in the last two decades around understanding how forbidding backtracking affects the random walk.  We will discuss past and current research on how forbidding backtracking affects mixing rates, hitting times, Kemeny's constant, and other aspects of random walks, and we will discuss some future directions for exploration.

\end{ilasabstract}
    

\hypertarget{down0138}{}\begin{ilasabstract}
\talktitle{A geometric adaptation of the Chung-Lu graph model}
    
\textbf{Franklin Kenter}, \info{10:30\textrm{--}11:00 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0138}{$\Uparrow$}
    
    
(in {\color{mstitle}MS15: Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham})
        
\mtskip
    The Chung-Lu graph model specifies the expected degree of each vertex in a graph and, provided the degree distribution is not excessively skewed, generates a random graph where the existence of each edge is determined independently.

A common characteristic of many ``real-world'' graphs is a degree distribution that follows an inverse power law. Specifically, the number of vertices with degree $x$ is proportional to $x^\beta$, where $\beta$ typically ranges between 1 and 3. The Chung-Lu model offers a straightforward approach to capturing this power-law behavior in synthetic networks.

We extend the Chung-Lu model to random geometric graphs. In this extension, each vertex is assigned both an expected degree and a random position in Euclidean space according to a probability distribution. Once the vertices are placed, the realization of each edge occurs independently of others. We rigorously establish the conditions necessary to ensure that the assigned degrees align with the expected degrees. This geometric Chung-Lu model is tested on the connectome of the \emph{Drosophila} medulla (fruit fly), where the random model successfully replicates the graph-theoretical structure of the original network, including the eigenvalues of various graph-theoretic matrices.

This is joint work with Susama Agarwala.

\end{ilasabstract}
    

\hypertarget{down0378}{}\begin{ilasabstract}
\talktitle{Leaky forcing: extending zero forcing results to a fault-tolerant setting}
    
\textbf{Franklin Kenter}, \info{17:30\textrm{--}18:00 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0378}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    We study a recent variation of zero forcing called leaky forcing.  Zero forcing is a propagation process on a network whereby some nodes are initially blue with all others white. Blue vertices can ``force'' a white neighbor to become blue if all other  neighbors are blue. The goal is to find the minimum number of initially blue vertices to eventually force all vertices blue after exhaustively applying the forcing rule above.
Leaky forcing is a fault-tolerant variation of zero forcing where certain vertices (not necessarily initially blue) cannot force. The goal in this context is to find the minimum number of initially blue vertices needed that can eventually force all vertices to be blue, {\it regardless} of which small number of vertices can't force.

This work extends results from zero forcing in terms of leaky forcing. New results regarding leaky forcing presented here include:
\begin{itemize}
\item Complete determination of all leaky forcing numbers for all unicyclic graphs.
\item Robust upper bounds for generalized Petersen graphs.
\item Bounds for the effect of both edge removal and vertex removal.
\item A complete characterization for which connected graphs have the maximum possible $1$-leaky forcing number (i.e., when $Z_{(1)}(G) = |V(G)|-1$).
\end{itemize}

This is joint work with 
Beth Bjorkman, Lei Cao, Ryan Moruzzi, Carolyn Reinhart and Violeta Vasilevska and is part of the AIM Mathematical Research Communities. 

\end{ilasabstract}
    

\hypertarget{down0257}{}\begin{ilasabstract}
\talktitle{Geometric means of HPD GLT matrix-sequences: structure, invertibility, and convergence}
    
\textbf{Muhammad Faisal Khan}, \info{11:00\textrm{--}11:30 @ SC1003 (June 25, Wednesday)} \hfill \hyperlink{up0257}{$\Uparrow$}
    
    
(in {\color{mstitle}MS19: Explicit and hidden asymptotic structures, GLT Analysis, and applications})
        
\mtskip
    \begin{bibunit}
        In this work, we extend our previous analysis on the spectral distribution of the geometric mean of matrix-sequences formed by Hermitian Positive Definite (HPD) matrices, under the framework of Generalized Locally Toeplitz (GLT) $\ast$-algebra. Building on prior results~\cite{ahmad2025matrix}, we now investigate whether the assumption of invertibility of the GLT symbols almost everywhere is essential. Motivated by the fact that inversion is often required due to matrix non-commutativity, we explore the scenario where the symbols commute, aiming to relax the invertibility condition. Furthermore, we study the Karcher mean of more than two HPD GLT matrix-sequences, focusing on how an initial guess that itself belongs to the GLT algebra influences the convergence of the iterative computation. Numerical experiments support our theoretical claims and demonstrate improved convergence behavior under structured initialization.

Finally, we extend the theoretical results to the multilevel block case (for $r = 1$, $d \geq 1$), offering a a broader generalization and deeper numerical validation. 

\vspace{2em}

\begin{thebibliography}{99}

\bibitem{ahmad2025matrix}
Ahmad, D.; Khan, M.F.; Serra-Capizzano, S. \textit{Matrix-Sequences of Geometric Means in the Case of Hidden (Asymptotic) Structures.} Mathematics 2025, 13, 393.
\url{https://doi.org/10.3390/math13030393}.

\bibitem{barbarino2020a}
G.~Barbarino, C.~Garoni, and S.~Serra-Capizzano, \textit{Block generalized locally Toeplitz sequences: theory and applications in the unidimensional case},
Electronic Transactions on Numerical Analysis, 53 (2020), pp.~28--112.

\bibitem{barbarino2020b}
G.~Barbarino, C.~Garoni, and S.~Serra-Capizzano,
\textit{Block generalized locally Toeplitz sequences: theory and applications in the multidimensional case},
Electronic Transactions on Numerical Analysis, 53 (2020), pp.~113--216.

\bibitem{garoni2017}
C.~Garoni and S.~Serra-Capizzano,
\textit{Generalized Locally Toeplitz Sequences: Theory and Applications, Vol.~I},
Springer, Cham, 2017.

\bibitem{garoni2018}
C.~Garoni and S.~Serra-Capizzano,
\textit{Generalized Locally Toeplitz Sequences: Theory and Applications, Vol.~II},
Springer, Cham, 2018.


\end{thebibliography}
        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0012}{}\begin{ilasabstract}
\talktitle{Univariate preservers of totally positive matrices and kernels
}
    
\textbf{Apoorva Khare}, \info{12:00\textrm{--}12:30 @ SC0008 (June 23, Monday)} \hfill \hyperlink{up0012}{$\Uparrow$}
    
    
(in {\color{mstitle}MS9: Total positivity})
        
\mtskip
    We will discuss recent results on preservers of totally
positive/nonnegative matrices and kernels, together with some
observations that go into their proofs. Partly joint with Alexander
Belton, Dominique Guillot, and Mihai Putinar. 

\end{ilasabstract}
    

\hypertarget{down0136}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Kshitij Khare}, \info{11:00\textrm{--}11:30 @ SC1003 (June 24, Tuesday)} \hfill \hyperlink{up0136}{$\Uparrow$}
    
    
(in {\color{mstitle}MS26: Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0189}{}\begin{ilasabstract}
\talktitle{Streaming data tensors efficiently and accurately
}
    
\textbf{Joe Kileel}, \info{13:30\textrm{--}14:00 @ SC3001 (June 24, Tuesday)} \hfill \hyperlink{up0189}{$\Uparrow$}
    
    
(in {\color{mstitle}MS18: New methods in numerical multilinear algebra})
        
\mtskip
    In this talk, I will present a new randomized method for maintaining
low-rank CP decompositions of tensorial data streams.  Numerical
results indicate that the approach has acceptable computational costs
at scale, while singificantly improving accuracy and adaptivity to changes in the data stream over existing methods.  Joint work with Yifan Zhang (UT Austin).  

\end{ilasabstract}
    

\hypertarget{down0023}{}\begin{ilasabstract}
\talktitle{Quasi-Wasserstein mean of positive definite matrices}
    
\textbf{Sejong Kim}, \info{11:30\textrm{--}12:00 @ SC1001 (June 23, Monday)} \hfill \hyperlink{up0023}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    The typical examples of Kubo-Ando's operator means are the weighted arithmetic, geometric, and harmonic means. In particular, they are interpolated by the power means (introduced by Lim and Palfia) monotonically in terms of the Loewner order. On the other hand, there are other important means of non-Kubo-Ando's operator means such as the weighted spectral geometric and Wasserstein means. We define quasi-Wasserstein means, which interpolate the weighted spectral geometric and Wasserstein means monotonically in terms of the near-order. We also study their properties including trace and norm inequalities.

\end{ilasabstract}
    

\hypertarget{down0283}{}\begin{ilasabstract}
\talktitle{Quasiorthogonality of commutative algebras
}
    
\textbf{Sooyeong Kim}, \info{10:30\textrm{--}11:00 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0283}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    The notion of quasiorthogonality for operator algebras was introduced to provide a quantitative measure of the geometric relationships between algebras. Pivotal to the development and motivation for considering quasiorthogonality were applications in quantum information theory. We deepen the theory of quasiorthogonal operator algebras through an analysis of the commutative algebra case. We give a new approach to calculate the measure of orthogonality between two such subalgebras of matrices, based on a matrix-theoretic notion we introduce that has a connection to complex Hadamard matrices. We also show how this new tool can yield significant information on the general non-commutative case.

\end{ilasabstract}
    

\hypertarget{down0295}{}\begin{ilasabstract}
\talktitle{A centrality measure for cut edges in undirected graphs
}
    
\textbf{Steve Kirkland}, \info{10:30\textrm{--}11:00 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0295}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    We consider an edge centrality measure, introduced by Altafini et al, which is based on Kemeny's constant for a connected undirected graph. We revisit that centrality measure for the case of cut edges, providing an intuitive  interpretation for it, and showing how it can be computed using tools from combinatorial matrix theory. Explicit expressions for the edge centralities are given for certain types of trees. Joint work with Dario Bini, Guy Latouche and Beatrice Meini.  

\end{ilasabstract}
    

\hypertarget{down0135}{}\begin{ilasabstract}
\talktitle{A low-complexity algorithm to search for Legendre pairs
}
    
\textbf{Ilias Kotsireas}, \info{10:30\textrm{--}11:00 @ SC1003 (June 24, Tuesday)} \hfill \hyperlink{up0135}{$\Uparrow$}
    
    
(in {\color{mstitle}MS26: Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics})
        
\mtskip
    Legendre pairs constitute an important combinatorial object that can be used to construct Hadamard matrices. 
In our LAA paper, we studied the matrix equation of Legendre pairs and its properties, focusing on the spectra of the matrices involved, utilizing Gershgorin circles. Legendre pairs are characterized by two invariants related to the discrete Fourier transform (DFT) matrix. We propose a low-complexity fast Fourier transform (FFT)-like algorithm to compute the product of the DFT matrix with each sequence of the Legendre pair. By utilizing the FFT-like algorithm, we present a low-time complexity algorithm to search for Legendre pairs. We present numerical results from our C implementation of the FFT-like algorithm, which offers a lower time complexity for finding Legendre pairs compared to traditional combinatorial algorithms. 
\\\\
This is a joint work with Sirani M. Perera.

\end{ilasabstract}
    

\hypertarget{down0352}{}\begin{ilasabstract}
\talktitle{New results on second eigenvalue extremization}
    
\textbf{Hitesh Kumar}, \info{16:30\textrm{--}17:00 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0352}{$\Uparrow$}
    
    
(in {\color{mstitle}MS24: Nonnegative and related families of matrices})
        
\mtskip
     For an $n$-vertex graph $G$ with adjacency matrix $A(G)$, let $\lambda_1$ and $\lambda_2$ denote the first and the second largest eigenvalue of $A(G)$. The extremization problem for $\lambda_1$ has been extensively investigated in the literature. The second eigenvalue has been investigated primarily for regular graphs, and there are relatively fewer results on $\lambda_2$-extremization. In this talk, the speaker will discuss several new results on $\lambda_2$-extremization, which include:
\begin{enumerate}
 \item determining extremal trees of given order and diameter having maximum/minimum $\lambda_2$.
 \item determining complements of trees with given order and maximum/minimum $\lambda_2$.
 \item determining extremal trees of given order for the convex combination of $\lambda_1$ and $\lambda_2$, and the asymptotic behaviour of the convex combination. 
\end{enumerate}
The results are based on joint work with several people: Saieed Akbari, Bojan Mohar,  Shivaramakrishna Pragada, and Hanmeng Zhan.

\end{ilasabstract}
    

\hypertarget{down0247}{}\begin{ilasabstract}
\talktitle{On bijections which strongly preserve Birkhoff-James orthogonality on finite-dimensional $C^*$-algebras}
    
\textbf{Bojan Kuzma}, \info{10:30\textrm{--}11:00 @ SC0012 (June 25, Wednesday)} \hfill \hyperlink{up0247}{$\Uparrow$}
    
    
(in {\color{mstitle}MS35: Preserver Problems, II})
        
\mtskip
    We classify bijections which in both directions preserve Birkhoff-James orthogonality on finite-dimensional $C^*$-algebras. It turns out that such maps are  real-linear isometries  multiplied by a  central-valued (possibly nonlinear) function. The result differs from smooth normed spaces, where every such preserver is a (conjugate)linear isometry multiplied by a  scalar-valued function.
Our main technique  is using left symmetric elements, relative to Birkhoff-James orthogonality, of certain subspaces. 

This is a joint work With Srdjan Stefanovi\'c

\end{ilasabstract}
    

\hypertarget{down0252}{}\begin{ilasabstract}
\talktitle{Global locations of Schmidt number witnesses
}
    
\textbf{Seung-Hyeok Kye}, \info{11:30\textrm{--}12:00 @ SC0014 (June 25, Wednesday)} \hfill \hyperlink{up0252}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    We investigate global locations of Schmidt number witnesses which
are outside of the convex set of all bi-partite states. Their
locations are classified by interiors of faces of the convex set of
all states, by considering the line segments from them to the
maximally mixed state. In this way, a nonpositive Hermitian matrix
of trace one is located outside of one and only one face. Faces of
the convex set of all states are classified by subspaces, which are
range spaces of states belonging to specific faces. For a given
subspace, we show that there exist Schmidt number $k+1$ witnesses
outside of the face arising from this subspace if and only if every
vector in the orthogonal complement of the subspace has Schmidt rank
greater than $k$. Once we have Schmidt number $k+1$ witnesses
outside of a face, we also have Schmidt number $2,3,\dots, k$
witnesses outside of the face.

\end{ilasabstract}
    

\hypertarget{down0321}{}\begin{ilasabstract}
\talktitle{Extrapolation for iterative solvers for matrix equations
}
    
\textbf{Patrick Kürschner}, \info{14:30\textrm{--}15:00 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0321}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    Given a convergent vector sequence, the speed to convergence can be improved by  reduced rank extrapolation (RRE) [1,2]. Often, the vector sequences of interest are generated by an iterative process to solve algebraic equations.
This presentation shows how to  generalize  this extrapolation framework to sequences of (low-rank) matrices which are generated by iterative methods for matrix equations. At first, we will briefly have a glance at recent developments to incorporate RRE  in low-rank alternating directions implicit methods for Lyapunov and Riccati equations [3]. 
After this, the main focus lies in RRE for stationary and non-stationary iterations [4] for general linear matrix equations
$\mathcal{A}(X)=\sum\limits_{k=1}^LA_kXB_k=C$ with $L>2$, where the linear operator $\mathcal{A}$ admits a convergent additive splitting. We discuss the incorporation of RRE in those iterations for small to moderately sized problems and
also in low-rank variants for large-scale problems [5].


\begin{enumerate}
 \item R. P. Eddy: Extrapolating to the limit of a vector sequence. In \textit{Information linkage between applied mathematics and industry}, pp. 387–396.Academic Press, Cambridge, MA, 1979.
 \item     A. Sidi: Efficient implementation of minimal polynomial and reduced
    rank extrapolation methods, \textit{J. Comput. Appl. Math}., 36(3):305–337,  1991.
  \item    P. den Boef, P. Kürschner, X. Liu, J. Maubach, J. Saak, W. Schilders, J. Schulze, N. van de Wouw: Generalizing Reduced Rank Extrapolation to Low-Rank Matrix Sequences, \textit{Arxiv preprint} 2502.09165, 2025.
  \item T. Damm: Direct methods and ADI-preconditioned Krylov subspace methods for generalized Lyapunov equations. \textit{Numer. Lin. Alg. Appl}., 15(9):853–871, 2008
  \item     S. D. Shank, V. Simoncini and D. B. Szyld: Efficient low-rank solutions of Generalized Lyapunov equations, \textit{Numer. Math.}, 134:327–342, 2016
\end{enumerate}
    

 


\end{ilasabstract}
    

\hypertarget{down0285}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Zehua Lai}, \info{11:30\textrm{--}12:00 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0285}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0223}{}\begin{ilasabstract}
\talktitle{Inverse eigenvalue problem for discrete Schrödinger operators of a graph}
    
\textbf{Anzila Laikhuram}, \info{17:00\textrm{--}17:30 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0223}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    The Inverse Eigenvalue Problem of a Graph (IEPG) determines whether a set of real numbers can be realized as the spectrum of a real symmetric matrix in $\mathcal{S}(G)$, where $\mathcal{S}(G)$ consists of symmetric matrices associated with a graph $G$, having non-zero off-diagonal entries only for adjacent vertices. Extending this, the Inverse Eigenvalue Problem for discrete Schr\"odinger operators investigates if a given set of real numbers can be the spectrum of a matrix in $\ddot{\mathcal{S}}(G)$, where off-diagonal entries are negative for edges and zero otherwise, with unrestricted diagonal entries. We begin with connected graphs on 4 vertices. For a list of real numbers $\lambda_1 < \lambda_2 \leq \lambda_3 \leq \lambda_4$, we determine if there exists a matrix in $\ddot{\mathcal{S}}(G)$ with spectrum $\{\lambda_1, \lambda_2, \lambda_3, \lambda_4\}$ and the smallest eigenvalue simple. We identify feasible ordered multiplicity lists, noting that not all are valid.   Our investigation extends to families of graphs such as paths ($P_n$), and complete graphs ($K_n$). For $P_n$, any set of $n$ distinct real numbers is realizable as a spectrum in $\ddot{\mathcal{S}}(P_n)$. For $K_n$, any ordered list $\lambda_1 < \lambda_2 \leq \dots \leq \lambda_n$ is achievable. 
\end{ilasabstract}
    

\hypertarget{down0225}{}\begin{ilasabstract}
\talktitle{Domino tilings, domino shuffling, and the nabla operator}
    
\textbf{Yi-Lin Lee}, \info{16:00\textrm{--}16:30 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0225}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    In this talk, I will present a $q,t$-generalization of domino tilings of certain regions $R_\lambda$, indexed by partitions $\lambda$, weighted according to generalized area and dinv statistics. These statistics arise from the $q,t$-Catalan combinatorics and Macdonald polynomials. We present a formula for the generating polynomial of these domino tilings in terms of the Bergeron--Garsia nabla operator. When $\lambda = (n^n)$ is a square shape, domino tilings of $R_\lambda$ are equivalent to those of the Aztec diamond of order $n$. In this case, we give a new product formula for the resulting polynomials by domino shuffling and its connection with alternating sign matrices. In particular, we obtain a combinatorial proof of the joint symmetry of the generalized area and dinv statistics. This is based on joint work with Ian Cavey.
\end{ilasabstract}
    

\hypertarget{down0265}{}\begin{ilasabstract}
\talktitle{$J$-selfadoint matrix means and their indefinite inequalities}
    
\textbf{Rute Lemos}, \info{10:30\textrm{--}11:00 @ SC2006 (June 25, Wednesday)} \hfill \hyperlink{up0265}{$\Uparrow$}
    
    
(in {\color{mstitle}MS3: Matrix inequalities with applications})
        
\mtskip
    Consider the indefinite inner product induced by a non trivial involutive Hermitian matrix $J$, 
which endows the matrix algebra of $n$-square complex matrices with a partial order relation between $J$-selfadjoint matrices.
Indefinite inequalities are given in this setup, involving the $J$-selfadjoint $\alpha$-weighted geometric matrix mean. 
In particular, an indefinite version of Ando–Hiai inequality is proved to be equivalent to Furuta inequality of indefinite type.

This talk is based on a joint work with Nat\'alia Bebiano and Gra\c ca Soares.

This work is supported by the
Center for Research and Development in Mathematics and Applications (CIDMA) under the
Portuguese Foundation for Science and Technology 
(FCT, \url{https://ror.org/00snfqn58})   
Multi-Annual Financing Program for R\&D Units.
\end{ilasabstract}
    

\hypertarget{down0147}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Gilad Lerman}, \info{10:30\textrm{--}11:00 @ SC3001 (June 24, Tuesday)} \hfill \hyperlink{up0147}{$\Uparrow$}
    
    
(in {\color{mstitle}MS18: New methods in numerical multilinear algebra})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0054}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Chi-Kwong Li}, \info{15:00\textrm{--}15:30 @ SC0014 (June 23, Monday)} \hfill \hyperlink{up0054}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0196}{}\begin{ilasabstract}
\talktitle{Reduced Krylov basis methods}
    
\textbf{Yuwen Li}, \info{15:00\textrm{--}15:30 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0196}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    The reduced basis method is the dominating numerical solver for a family of parametrized PDEs. In this talk, I will present our new reduced basis algorithm based on preconditioned Krylov subspace methods such as the conjugate gradient method, generalized minimum residual method, and bi-conjugate gradient method. The proposed methods use a preconditioned Krylov subspace method for a high-fidelity discretization of one parameter instance to generate orthogonal basis vectors of the reduced basis subspace. Then the family of large-scale discrete parameter-dependent problems are approximately solved in the low-dimensional Krylov subspace. The material in my talk is based on joint works with Ludmil Zikatanov and Cheng Zuo.

\end{ilasabstract}
    

\hypertarget{down0235}{}\begin{ilasabstract}
\talktitle{Factorizations of penalized differentiation matrices
}
    
\textbf{Yung-Ta Li}, \info{17:00\textrm{--}17:30 @ SC3001 (June 24, Tuesday)} \hfill \hyperlink{up0235}{$\Uparrow$}
    
    
(in {\color{mstitle}MS11: Structured matrix computations and its applications})
        
\mtskip
    To solve boundary value problems by pseudospectral methods with penalty leads to penalized differentiation matrices. 
We had proposed a factorization of the inverse of the penalized differentiation matrix  in 2020. 
The factorization contains a tridiagonal matrix and is  crucial in solving Poisson's equations.  
However, to solve 2D Poisson's equations, we aim to diagonalize the penalized differentiation matrix.
Thus, we propose a new factorization  of the  penalized differentiation matrix containing a block diagonal matrix plus low ranks.
\end{ilasabstract}
    

\hypertarget{down0267}{}\begin{ilasabstract}
\talktitle{The orthogonal equivalence transversality property 
}
    
\textbf{Zhongshan Li}, \info{11:30\textrm{--}12:00 @ SC2006 (June 25, Wednesday)} \hfill \hyperlink{up0267}{$\Uparrow$}
    
    
(in {\color{mstitle}MS3: Matrix inequalities with applications})
        
\mtskip
    Let $A$ be an  $m\times n$ real matrix. If the  manifold  consisting of all matrices orthogonally equivalent to $A$ and the manifold consisting of all real matrices having the same sign pattern as $A$ (both considered as embedded submanifolds of $\mathbb R^{m \times n}$),  intersect transversally at $A$, we say that $A$ has the \emph{orthogonal equivalence transversality property} (OETP) and that $A$ is an OETP matrix. By examining the tangent spaces, it can be seen that $A$ has the OETP iff as $S$ and $K$ run over all $m\times m$ and $n\times n$ skew-symmetric matrices, the matrices $AS + KA$ can attain independent and arbitrary values at the positions where the corresponding entries of $A$ are equal to  zero.  Using the normal spaces, it can be shown that $A$ has the OETP iff $X=0$ is the only matrix satisfying the following three conditions $A\circ X=0,$ $AX^T$ is symmetric, and $X^TA$ is symmetric. Many fundamental facts about the OETP matrices are presented. For instance, if $A$ is an OETP matrix, then every superpattern of sgn$(A)$ allows a matrix orthogonally equivalent  to $A$. The direct sum of two square matrices $B$ and $C$ has the OETP iff both $B$ and $C$ have the OETP, and $B$ and $C$ do not have any common singular value.        
The bidiagonal  zero-nonzero pattern with all entries on the diagonal and  the first superdiagonal nonzero requires the OETP.  
This is joint work with M. Arav, H. van der Holst, F. Hall, J. Seo, L. Wang, Y. Xu, and  Y. Zhao
\end{ilasabstract}
    

\hypertarget{down0071}{}\begin{ilasabstract}
\talktitle{A gradient flow method to differentiate between classical and quantum correlations
}
    
\textbf{Matthew M. Lin}, \info{14:30\textrm{--}15:00 @ SC3001 (June 23, Monday)} \hfill \hyperlink{up0071}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    In this talk, we aim to quantify measurement disturbance by minimizing the distinction between input and post-measurement states, enabling us to determine whether the correlations are classical or quantum. Theoretically, we employ a complex-valued gradient flow over Stiefel manifolds for optimization. Our approach applies the well-known Lojasiewicz gradient inequality, guaranteeing the global convergence of the flow from any initial point. Experimental results
demonstrate that our method can accurately and reliably classify correlations as classical or quantum.

\end{ilasabstract}
    

\hypertarget{down0072}{}\begin{ilasabstract}
\talktitle{Fast SDDRE-based maneuvering-target interception at prespecified orientation}
    
\textbf{Li-Gang Lin}, \info{15:00\textrm{--}15:30 @ SC3001 (June 23, Monday)} \hfill \hyperlink{up0072}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    This talk considers the 3-D guidance law based on target lead angle information and the state-dependent differential Riccati equation (SDDRE) scheme. In an application-oriented manner, it presents theories to significantly improve critical computational performance and thus aims at a fast implementation for impact-angle-constrained interception of agile maneuvering targets. More specifically, regarding the two major computational burdens using SDDRE, we have replaced the burden in numerical applicability checking by a simple, equivalent, and closed-form condition for the entire state space, which is actually the dominant burden as supported by complexity analysis and extensive validations. Notably, the proposed analysis not only complements the early findings of applicability guarantee in literature, but also promotes the efficiency of the proposed philosophy when compared to the classic method, where the latter has caused concerns/reservations due to its feasibility and difficulty. On the other hand, we have largely mitigated the second major burden of SDDRE by -- after exhaustive trials -- selecting the most efficient Riccati-equation solver until the latest benchmarks. Such evaluations are: 1) in favor of a much-less-known achievement, rather than the common QR-based benchmark and 2) subject to both numerical and hardware experiments including, notably, implementations on microcontrollers and field-programmable gate arrays.

\end{ilasabstract}
    

\hypertarget{down0074}{}\begin{ilasabstract}
\talktitle{Distributed $t$-SNE}
    
\textbf{Szu-Han Lin}, \info{14:30\textrm{--}15:00 @ SC4011 (June 23, Monday)} \hfill \hyperlink{up0074}{$\Uparrow$}
    
    
(in {\color{mstitle}MS20: Manifold learning and statistical applications})
        
\mtskip
    The $t$-distributed stochastic neighbor embedding method  ($t$-SNE, Maaten
and Hinton, 2008) has gained popularity for data exploration, particularly for its highly effective visualization of high-dimensional data, offering valuable insights before analysis. However, with a computational complexity of $O(n^2)$, its applicability to large datasets is limited. In practical applications, the Barnes-Hut $t$-SNE  (BH $t$-SNE, Maaten, 2014), a $t$-SNE variant with computational complexity $O(n\log n)$, is commonly employed for large datasets due to its high computational efficiency. In this work, we propose a divide-and-conquer approach that further reduces the computational complexity to $O(n)$, significantly lowering both computational time and memory usage by processing only subsets of the data at a time. Implementing the divide-and-conquer approach requires careful parameter adjustments to ensure asymptotic equivalence to the original $t$-SNE. We provide theoretical proof of this convergence and support our findings with simulation studies on the MNIST dataset. In summary, this work offers a scalable solution for applying $t$-SNE to extremely large datasets, maintaining its consistency and efficiency.

\end{ilasabstract}
    

\hypertarget{down0221}{}\begin{ilasabstract}
\talktitle{Inverse fiedler vector problem of a graph
}
    
\textbf{Jephian C.-H. Lin}, \info{16:00\textrm{--}16:30 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0221}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    Given a graph and one of its weighted Laplacian matrix, a Fiedler vector is an eigenvector with respect to the second smallest eigenvalue. The Fiedler vectors have been used widely for graph partitioning, graph drawing, spectral clustering, and suggesting the center of a network.  The inverse Fiedler vector problem studies the possible Fiedler vectors for different weighted Laplacian matrices of a given graph.  For a given tree, we characterize all possible Fiedler vectors among its weighted Laplacian matrix.  As an application, the characteristic set can be anywhere on a tree, except for the set containing a single leaf.  For a given cycle, we characterize all possible eigenvectors corresponding to the second or the third smallest eigenvalue.

\end{ilasabstract}
    

\hypertarget{down0236}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Ching Kai Lin}, \info{17:30\textrm{--}18:00 @ SC3001 (June 24, Tuesday)} \hfill \hyperlink{up0236}{$\Uparrow$}
    
    
(in {\color{mstitle}MS11: Structured matrix computations and its applications})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0261}{}\begin{ilasabstract}
\talktitle{Engaging students with collaborative tasks in linear algebra
}
    
\textbf{Jephian C.-H. Lin}, \info{11:30\textrm{--}12:00 @ SC1005 (June 25, Wednesday)} \hfill \hyperlink{up0261}{$\Uparrow$}
    
    
(in {\color{mstitle}MS27: Linear algebra education})
        
\mtskip
    The main challenge in teaching linear algebra, or mathematics in general, in Taiwan is the lack of motivation. Many students have been conditioned to view learning as solely a means to achieve good exam scores, while higher education should focus on more than just grades. Hands-on activities can help spark students' interest in learning. In this talk, we will present several collaborative tasks that encourage students to work and learn together.

\end{ilasabstract}
    

\hypertarget{down0324}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Yen-chi Lin}, \info{14:00\textrm{--}14:30 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0324}{$\Uparrow$}
    
    
(in {\color{mstitle}MS34: Combinatorics, association scheme, and graphs})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0271}{}\begin{ilasabstract}
\talktitle{Nonnegative rank-2 approximations -- on choosing a starting point for ANLS}
    
\textbf{Etna Lindy}, \info{10:30\textrm{--}11:00 @ SC4011 (June 25, Wednesday)} \hfill \hyperlink{up0271}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    \begin{bibunit}
        Given a nonnegative $m \times n$ matrix $X$, its nonnegative rank-$r$ approximation (NMF-$r$) consists of two nonnegative matrices, $A $ and $B$ of sizes $m\times r$ and $n\times r$, such that the Frobenius norm of $X - AB^\top$ is minimized. The rank-2 case is special in the sense that while the problem is NP-hard for general $r$ and somewhat trivial in the case of $r=1$, the complexity of rank-2 NMF is not known. Furthermore, NMF-2 is equivalent to rank-2 optimization with a non-negativity constraint, which is not true for larger $r$.
NMF-2 is commonly approached by solving for the components $A$ and $B$ separately in an alternating fashion (ANLS). This means solving several independent nonnegative least squares problems, which can be done exactly with relatively low computational cost in the rank-2 case. The ANLS method is not guaranteed to converge to the global minimum, and choosing a good starting point is crucial. Specifically, the ANLS method often seems to converge to a trivial solution with a column of zeros when the starting point is chosen carelessly. 
We suggest using a certain angular coordinate representation of the matrices $A$ and $B$ and then optimizing over these new sets of coordinates.
This approach has the benefit of introducing only a few zeros, which is a good property for a starting point for ANLS.
The tests we have implemented suggest that our method gives a better approximation than other existing methods such as SPA \cite{gillis2014hierarchical} while maintaining the same level of computational complexity.
Ideally the method could be generalized for $r > 2$, but it is still under consideration how this could be done.

\begin{thebibliography}{9}
\bibitem{gillis2014hierarchical}
N. Gillis, D. Kuang, H. Park, ''Hierarchical clustering of hyperspectral images using rank-two nonnegative matrix factorization'', {\it IEEE Transactions on Geoscience and
Remote Sensing} (2014)
\end{thebibliography}
        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0067}{}\begin{ilasabstract}
\talktitle{Spherical volume-preserving parameterization via energy minimization}
    
\textbf{Shu-Yung Liu}, \info{14:00\textrm{--}14:30 @ SC2006 (June 23, Monday)} \hfill \hyperlink{up0067}{$\Uparrow$}
    
    
(in {\color{mstitle}MS22: Linear algebra applications in computational geometry})
        
\mtskip
    For a simplicial $3$-manifold, such as a tetrahedral mesh sampled from a solid brain, a spherical volume-preserving parameterization is a bijective mapping onto the unit solid sphere. In this presentation, we introduce a novel energy functional to measure the volume distortion of such mappings and propose an associated minimization method to obtain volume-preserving parameterizations. Our method is theoretically guaranteed to converge globally and demonstrates improved effectiveness compared to a state-of-the-art method. Finally, we present its application in brain imaging, showcasing its real-world utility.
\end{ilasabstract}
    

\hypertarget{down0234}{}\begin{ilasabstract}
\talktitle{An index search method for solving nonnegative least squares problems
}
    
\textbf{Ching-Sung Liu}, \info{16:30\textrm{--}17:00 @ SC3001 (June 24, Tuesday)} \hfill \hyperlink{up0234}{$\Uparrow$}
    
    
(in {\color{mstitle}MS11: Structured matrix computations and its applications})
        
\mtskip
    We introduce a novel Index Search Method (ISM) for efficiently solving Nonnegative Least Squares (NNLS) problems. ISM employs a two-level iterative structure: an outer iteration that updates the estimated index set of the nonzero components in the solution, and an inner iteration that solves associated subproblems to refine the solution within this index set. A key feature of ISM is that the objective function value decreases monotonically across iterations, ensuring that the index sets do not repeat and the optimal solution is reached in finitely many steps. The dominant computational cost lies in solving normal equations during the inner iterations. We also present numerical results to demonstrate the efficiency and reliability of the proposed method, supporting our theoretical findings.


\end{ilasabstract}
    

\hypertarget{down0287}{}\begin{ilasabstract}
\talktitle{An iteration method for attaining the spectral radius of nonnegative irreducible matrices
}
    
\textbf{Chia-An Liu}, \info{11:00\textrm{--}11:30 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0287}{$\Uparrow$}
    
    
(in {\color{mstitle}MS34: Combinatorics, association scheme, and graphs})
        
\mtskip
    It is well known that the spectral radius of a nonnegative irreducible matrix $A$ is no more than the maximum row sum of $A$ with equality if and only if $A$ has constant row sum. Let $R$ be the diagonal matrix with row sums of $A$ on the diagonal and $B=R^{-1}AR.$ Then, the maximum row sum of $B$ is at most the maximum row sum of $A$. Do the process repeatedly, and we obtain a sequence of matrices that are similar to $A$. Its convergence will be investigated. This is a joint work with Prof. Yen-Jen Cheng.

\end{ilasabstract}
    

\hypertarget{down0302}{}\begin{ilasabstract}
\talktitle{Generalizing reduced rank extrapolation to low-rank matrix sequences
}
    
\textbf{Xiaobo Liu}, \info{11:00\textrm{--}11:30 @ SC3001 (June 26, Thursday)} \hfill \hyperlink{up0302}{$\Uparrow$}
    
    
(in {\color{mstitle}MS16: Approximations and errors in Krylov-based solvers})
        
\mtskip
    Reduced Rank Extrapolation (RRE) is an acceleration method typically used to  accelerate iterative solutions of nonlinear systems of equations arising from a fixed-point process, which is usually vector-valued.
When considering the iterative solution of large-scale matrix equations, the iterates are nevertheless low-rank matrices generated by a fixed-point process in which, in general, the mapping function changes at each iteration.
To enable acceleration of the iterative solution for such problems, we propose two novel generalizations of RRE.
First, we show how to effectively compute RRE for sequences of low-rank matrices.
Second, we derive a formulation of RRE that is suitable for fixed-point processes in which the mapping function changes at each iteration.
We demonstrate the potential of the proposed methods on several numerical examples involving the iterative solution of large-scale Lyapunov and Riccati matrix equations.


\end{ilasabstract}
    

\hypertarget{down0367}{}\begin{ilasabstract}
\talktitle{On cyclic-shift-full-rank matrices
}
    
\textbf{Yuan Hsun Lo}, \info{16:00\textrm{--}16:30 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0367}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    A binary matrix is said to be cyclic-shift-full-rank (CSFR) if it has full row rank no matter how its rows are cyclically shifted.
In this talk, we will construct CSFR matrices for any row size and introduce their applications on collision channels without feedback in which CSFR matrices are employed as protocol sequences.

\end{ilasabstract}
    

\hypertarget{down0354}{}\begin{ilasabstract}
\talktitle{On cones of polynomials preserving nonnegative matrices}
    
\textbf{Raphael Loewy}, \info{17:30\textrm{--}18:00 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0354}{$\Uparrow$}
    
    
(in {\color{mstitle}MS24: Nonnegative and related families of matrices})
        
\mtskip
    We consider polynomials preserving nonnegative matrices. Let $n$ be a positive integer and

\begin{equation*}
{\mathcal{P}}_{n}=\{p \in {{\mathbb{R}}}[x]: p(A)\geq 0 \mbox{ for all~}  A \geq 0, A \in {\mathbb{R}}^{n,n}\}.
\end{equation*}
${\mathcal{P}}_{n}$ was defined by Loewy and London, motivated by the Nonnegative Inverse Eigenvalue Problem (NIEP), but is of independent interest. Clearly, ${\mathcal{P}}_{n}$ is a closed, convex cone.

\medskip
Given any polynomial $p$, we identify $p$ with its sequence of coefficients. In order to consider only finite dimensional vector spaces, we restrict the degree of the polynomials. Given a positive integer $m$, define

\begin{equation*}
{\mathcal{P}}_{n,m}=\{p \in {\mathcal{P}}_{n} : degree(p) \leq m \}.
\end{equation*}
Then, ${\mathcal{P}}_{n,m}$ can be thought as a cone in ${\mathbb{R}}^{m+1}$.

\medskip
It is clear that any polynomial with nonnegative coefficients is in ${\mathcal{P}}_{n}$. Therefore, the number, relative size and distribution of the negative coefficients of polynomials in ${\mathcal{P}}_{n}$ are of significant interest. Clark and Paparella showed that if $p \in {\mathcal{P}}_{n}$, then its first and last $n$ coefficients must be nonnegative. Hence, ${\mathcal{P}}_{n,m}$ is a simplicial cone, for any $0 < m <2n$.

\medskip
Let $m \geq 2n$. Then, ${\mathcal{P}}_{n,m}$ contains polynomials with negative coefficients. For example, there exists $a > 0$ such that $1+x+x^{2}+\cdots+x^{n-1}-ax^{n}+x^{n+1}+\cdots+x^{2n} \in {\mathcal{P}}_{n,2n}$ (the question of the optimal $a$ is of interest).
It follows that the structure of ${\mathcal{P}}_{n,m}$ is nontrivial. We consider its face structure, and in particular the one dimensional faces, that is, the extreme rays. Using some information on the possible coefficients of polynomials in  ${\mathcal{P}}_{n,m}$, we show that  ${\mathcal{P}}_{n,m}$ is not polyhedral, that is, contains infinitely many extreme rays. Additional preliminary results on the faces are obtained.
\end{ilasabstract}
    

\hypertarget{down0309}{}\begin{ilasabstract}
\talktitle{Product of two involutions in special linear groups}
    
\textbf{Tejbir Lohan}, \info{14:30\textrm{--}15:00 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0309}{$\Uparrow$}
    
    
(in {\color{mstitle}MS31: Matrix decompositions and applications})
        
\mtskip
    An element of a group is called an involution if its square equals the identity element. Decomposing a group element into a product of involutions has applications in various areas of mathematics, with a particular focus on elements that can be expressed as the product of two involutions, known as \textit{strongly reversible}, \textit{strongly real}, or \textit{bireflectional} elements. Classifying strongly reversible elements in a group is a problem of broad interest. It is known that an element of the general linear group over a field is strongly reversible if and only if it is similar to its inverse. However, this result does not hold for special linear groups over a field or a division ring. In this talk, we will use the notion of reversibility to classify the strongly reversible elements in the complex special linear group and the quaternionic special linear group. This talk is based on joint work with Krishnendu Gongopadhyay and Chandan Maity.

\end{ilasabstract}
    

\hypertarget{down0173}{}\begin{ilasabstract}
\talktitle{Spectral analysis, approximation, and preconditioning for block structured matrix-sequences}
    
\textbf{Valerio Loi}, \info{13:30\textrm{--}14:00 @ SC1003 (June 24, Tuesday)} \hfill \hyperlink{up0173}{$\Uparrow$}
    
    
(in {\color{mstitle}MS19: Explicit and hidden asymptotic structures, GLT Analysis, and applications})
        
\mtskip
    Large block-structured matrices with Toeplitz-type blocks of different sizes frequently arise in various applications, but pose computational issues when solving the associated linear systems. In our setting, the matrices \(A_n\) are composed of (block rectangular) Toeplitz blocks defined by rectangular \(s \times t\) matrix-valued generating functions, and can be viewed as a generalization of classical GLT (Generalized Locally Toeplitz) sequences. Under mild assumptions on the block dimensions, the asymptotic distribution of the singular values of the associated matrix sequences is recently known. Moreover, when the singular value symbol is Hermitian, the spectral symbol coincides with the singular value symbol. Starting from the tools used to determine this singular value distribution, we develop a general preconditioning framework to construct simplified block matrices that approximate the original matrices. These simplified matrices offer two key advantages:\\
1. They maintain the same singular value distributions as \(\{A_n\}_{n}\); \\
2. They enable the solution of linear systems in \(\mathcal{O}(n \log n)\) arithmetic operations.\\
In this way, we propose a natural preconditioning strategy for linear systems with coefficient matrix \(A_n\). We provide detailed singular value and spectral analyses of the preconditioned matrix sequences and validate our approach through numerical experiments concerning the convergence of various (preconditioned) Krylov solvers.

\end{ilasabstract}
    

\hypertarget{down0028}{}\begin{ilasabstract}
\talktitle{Cospectral constructions for the generalized distance matrix}
    
\textbf{Kate Lorenzen}, \info{11:00\textrm{--}11:30 @ SC1005 (June 23, Monday)} \hfill \hyperlink{up0028}{$\Uparrow$}
    
    
(in {\color{mstitle}MS15: Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham})
        
\mtskip
    The generalized distance matrix of a graph is a matrix in which every entry is function of the distance between the vertices. With special choices of the function, the generalized distance matrix family includes the adjacency matrix and distance matrix. Surprisingly, some pairs of graph are cospectral independent of the choice of function.  We present a construction that builds on Godsil-McKay Switching to produce cospectral pairs for the generalized distance matrix connecting cospectral constructions for many different graph matrices.

\end{ilasabstract}
    

\hypertarget{down0070}{}\begin{ilasabstract}
\talktitle{Uncertainty principle of condition number}
    
\textbf{Tzon-Tzer Lu}, \info{14:00\textrm{--}14:30 @ SC3001 (June 23, Monday)} \hfill \hyperlink{up0070}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    Schaback in 1995 has proved the Uncertainty Principle of radial basis function interpolation, which states that the condition number and the error cannot be both kept small at the same time. Hence it is a Trade-off Principle. It seems to violet our cognition about ill/well-conditioned problems. In this talk we like to extend this principle, i.e. there is no case where the error and the condition number are both small, from interpolation matrices to arbitrary linear systems. The underlying theory behind the conflict between accuracy and stability flips our misconceptions about condition numbers and provides us with a brand-new interpretation of it. 

\end{ilasabstract}
    

\hypertarget{down0188}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Xiang Lu}, \info{15:00\textrm{--}15:30 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0188}{$\Uparrow$}
    
    
(in {\color{mstitle}MS32: Advances in matrix manifold optimization})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0206}{}\begin{ilasabstract}
\talktitle{Dynamic flows and iterative methods for identifying the Choi representation of an unknown quantum channel from partial data
}
    
\textbf{Bing-Ze Lu}, \info{16:30\textrm{--}17:00 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0206}{$\Uparrow$}
    
    
(in {\color{mstitle}MS7: Linear algebra and quantum information science})
        
\mtskip
    Identifying quantum channels clarifies how quantum states evolve and how information propagates. Because exact reconstruction is NP‑hard, we focus on efficient numerical approximations.

Exploiting the unitary nature of channel dynamics, we cast the problem on the Stiefel manifold—the intrinsic geometric space of real or complex unitary matrices---to devise practical reconstruction algorithms.

\textbf{Part I -- Single-unitary channels} \\
\noindent When the channel is generated by a single unitary operator, we combine polar decomposition with manifold geometry to achieve exact recovery and delineate the minimal data requirements.

\textbf{Part II -- Multi-unitary channels} \\
\noindent For channels expressible as convex mixtures of several unitaries, we formulate a gradient‑flow scheme on the Stiefel manifold and prove convergence guarantees, showcasing the method’s accuracy and flexibility.

\end{ilasabstract}
    

\hypertarget{down0368}{}\begin{ilasabstract}
\talktitle{Ternary circulant almost orthogonal arrays with (near) D-optimality and good binary sequence pairs}
    
\textbf{Xiao-Nan Lu}, \info{16:30\textrm{--}17:00 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0368}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    Circulant almost orthogonal arrays (CAOAs) are a type of circulant matrices used in the statistical design of fMRI experiments. D-optimality, which maximizes the determinant of the information matrix of a design, plays a key role in ensuring efficiency of experiments.
This talk will focus on ternary CAOAs with strength $2$, emphasizing the characterization of D-optimal and near D-optimal CAOAs and investigating their relations with binary sequence pairs with good correlation properties.

\end{ilasabstract}
    

\hypertarget{down0371}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Ding Lu}, \info{16:00\textrm{--}16:30 @ SC1003 (June 26, Thursday)} \hfill \hyperlink{up0371}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0035}{}\begin{ilasabstract}
\talktitle{Density-equalizing quasiconformal surface and volmeteric parameterization}
    
\textbf{Ronald Lok Ming Lui}, \info{11:30\textrm{--}12:00 @ SC2006 (June 23, Monday)} \hfill \hyperlink{up0035}{$\Uparrow$}
    
    
(in {\color{mstitle}MS22: Linear algebra applications in computational geometry})
        
\mtskip
    This talk explores various methods for computing bijective density-equalizing quasiconformal mappings for both surface and volumetric parameterizations. The primary objective is to achieve parameterizations of geometric shapes—whether 2D surfaces or 3D volumes—that minimize local geometric distortion while adhering to a prescribed density distribution of vertices. The density diffusion process is modeled as a quasiconformal flow, enabling effective control over local geometric distortions and ensuring mapping bijectivity. The talk will cover the underlying numerical algorithms and showcase experimental results. This work is supported by the Hong Kong Research Grants Council General Research Fund (Project ID: 14310224).

\end{ilasabstract}
    

\hypertarget{down0137}{}\begin{ilasabstract}
\talktitle{A low-complexity structured neural network approach for dynamical systems}
    
\textbf{Sirani M. Perera}, \info{11:30\textrm{--}12:00 @ SC1003 (June 24, Tuesday)} \hfill \hyperlink{up0137}{$\Uparrow$}
    
    
(in {\color{mstitle}MS26: Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics})
        
\mtskip
    Data-driven learning is advancing rapidly, offering a new perspective on understanding dynamic systems. On the other hand, traditional methods for solving chaotic and highly non-linear systems face challenges in computational efficiency due to their inherent complexity and dynamics. Fortunately, neural networks excel in solving highly non-linear systems, showing exceptional performance.  
\\\\
In this talk, we propose a neural network approach to update the states of dynamical systems through a structured operator known as a Hankel operator -- an operator characterized by a Hankel structure. Our goal is to develop an optimal, low-complexity learning algorithm that utilizes time-delay measurements to forecast future states effectively. By the conclusion of the talk, we will demonstrate how this operator can be employed to model state-space dynamical systems, enabling predictions and insights into future dynamics compared to conventional techniques: SINDy and HAVOK followed by the feedforward neural networks.
\\\\
This is a joint work with Hansaka Aluvihare, Levi Lingsch, and Xianqi Li. This work was funded by the Division of Mathematical Sciences at the National Science Foundation with the award numbers 2410676, 2410677, \& 2410678.

\end{ilasabstract}
    

\hypertarget{down0038}{}\begin{ilasabstract}
\talktitle{Stochastic iterative methods for solving tensor linear systems}
    
\textbf{Anna Ma}, \info{11:30\textrm{--}12:00 @ SC3001 (June 23, Monday)} \hfill \hyperlink{up0038}{$\Uparrow$}
    
    
(in {\color{mstitle}MS18: New methods in numerical multilinear algebra})
        
\mtskip
    Solving linear systems is a crucial subroutine and challenge in data science and scientific computing. Classical approaches for solving linear systems assume that data is readily available and small enough to be stored in memory. However, in the large-scale data setting, data may be so large that only partitions (e.g., single rows/columns of the matrix/tensor) can be utilized at a time. In this presentation, we discuss the advantages and role of randomization in iterative methods for approximating the solution to large-scale linear systems. Time permitting, we will also discuss our recent work on applications to solving systems involving higher-dimensional arrays, or tensors. Unlike previously proposed randomized iterative strategies, such as the tensor randomized Kaczmarz method (row slice method) or the tensor Gauss-Seidel method (column slice method), which are natural extensions of their matrix counterparts, our approach delves into a distinct scenario utilizing frontal slice sketching.

\end{ilasabstract}
    

\hypertarget{down0055}{}\begin{ilasabstract}
\talktitle{Spherical triangular configurations with invariant geometric mean}
    
\textbf{Luís Machado}, \info{14:00\textrm{--}14:30 @ SC1001 (June 23, Monday)} \hfill \hyperlink{up0055}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    The goal is to characterize all configurations of three distinct points on a finite-dimensional Riemannian manifold that share the same geometric mean and to develop efficient computation methods to obtain such configurations. The geometric mean typically minimizes the sum of squared geodesic distances to the data points. This approach has been applied to various manifolds, such as the \(n\)-sphere \(S^n\), the orthogonal group, hyperbolic space, and the cone of positive symmetric matrices.  \\
To keep the scope manageable, we focus on the standard sphere \(S^2\) in \(\mathbb{R}^3\) with three points, introducing new ideas beyond minimizing squared geodesic distances. These ideas also emerge from known formulas for the mean of points forming regular geodesic polygons, such as equilateral geodesic triangles. As an initial step, we apply this approach to Euclidean spaces. \\
Theoretical results are supported by numerical experiments and illustrated with meaningful plots.\\ \\

\end{ilasabstract}
    

\hypertarget{down0214}{}\begin{ilasabstract}
\talktitle{Sign characteristic in the inverse problem for Hermitian matrix polynomials}
    
\textbf{Steve Mackey}, \info{16:30\textrm{--}17:00 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0214}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    The sign characteristic is a structural feature of Hermitian matrix polynomials
that is important for both theory and applications. 
It consists of a plus or minus sign associated to each elementary divisor
corresponding to a real or infinite eigenvalue;
these $\pm$ signs are invariants under unimodular congruence.
Motivated by the generic eigenstructure problem
for Hermitian matrix polynomials,
it is natural to consider the special scenario 
when all eigenvalues are simple.
In this case these signs can be naturally ordered to form a \emph{sign sequence}. 
 For an $n \times n$ Hermitian polynomial of degree $d$
with $dn$ simple real eigenvalues, for example, 
there are $2^{dn}$ possible sign sequences.
However, most of these sign sequences 
cannot be realized by any degree $d$ \,Hermitian polynomial. 
Is it possible to characterize exactly which sign sequences 
are realizable and which are not? 
And does the degree play any role in the story?

This talk completely settles these questions, 
discussing several new constraints on signs 
beyond the well-known signature constraint (1),
clarifying the dichotomy between even and odd degrees 
in the characterization,
as well as describing an underlying group of symmetries 
on the collection of all sign sequences 
that sheds light on the characterization question. 
In addition,
this characterization of realizable sign sequences enables a complete solution 
of the inverse problem for Hermitian matrix polynomials of all degrees, 
albeit only in the generic scenario when all eigenvalues are simple.

% \vspace*{-10mm}
\noindent 
(1){V. Mehrmann, V. Noferini, F. Tisseur, and H. Xu},
 {\em On the sign characteristics of Hermitian matrix polynomials}, 
    Linear Alg. App., 511 (2016), pp.~328--364.

\end{ilasabstract}
    

\hypertarget{down0294}{}\begin{ilasabstract}
\talktitle{Exciting eigenvectors: seeing is believing}
    
\textbf{Steve Mackey}, \info{11:30\textrm{--}12:00 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0294}{$\Uparrow$}
    
    
(in {\color{mstitle}MS27: Linear algebra education})
        
\mtskip
    There is a simple, inexpensive, easy-to-build, and easy-to-operate device 
(adapted from (1)) 
that can be used to demonstrate to students the physical reality of eigenvectors.
Steve will begin the talk by showing you that device, 
and briefly discussing some of its properties.
% and tell a bit about how I have used this in various settings, 
% both undergraduate and graduate, since the 1980's. 
Although he has used it primarily in lecture/demonstration mode, 
there is considerable scope for adapting this 
to a more hands-on, direct-engagement-by-students mode.  
In the second half of the talk, 
Raf will tell you about his recent classroom experience
with this device, used in exactly that way.

(1) {H. V. McIntosh} 
{\em Matrix Analysis II: Further Introduction and some Applications to Physical Problems},  
1952.

\end{ilasabstract}
    

\hypertarget{down0335}{}\begin{ilasabstract}
\talktitle{A generalized class of matrices associated to threshold and chain graphs}
    
\textbf{Iswar Mahato}, \info{13:30\textrm{--}14:00 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0335}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    Motivated by the distance matrix $D(G)$ of a connected graph $G$, we define a new class of matrix $D_{\alpha,\beta,\gamma, \delta}(G)$ of a connected graph $G$ with diameter at most $3$, by substituting the entries $0,1,2$ and $3$ of $D(G)$ by the real variables $\alpha,\beta, \gamma$ and $\delta$, respectively. Clearly, by putting suitable values of $\alpha,\beta, \gamma$ and $\delta$, we get six interesting known matrices, such as adjacency matrix, Seidel matrix, distance matrix, squared distance matrix, $q$-distance matrix and exponential distance matrix. Therefore, for a graph $G$ with diameter at most $3$, the matrix $D_{\alpha,\beta,\gamma, \delta}(G)$ generalizes these six known matrices. In this article, we consider $D_{\alpha,\beta,\gamma}(G)$ of a threshold graph $G$ and determine an eigenvalue free-interval for $D_{\alpha,\beta,\gamma}(G)$. As a consequence of this result, we recover the known results about the eigenvalue free-interval of the adjacency matrix, the Seidel matrix and the distance matrix of a threshold graph, respectively and obtain an eigenvalue free-interval for the squared distance matrix, the $q$-distance matrix and the exponential distance matrix of a threshold graph, respectively. Moreover, we give an explicit expression for the characteristic polynomial of $D_{\alpha,\beta,\gamma}(G)$. Furthermore, we consider $D_{\alpha,\beta,\gamma, \delta}(G)$ of a chain graph $G$ and find the characteristic polynomial of  $D_{\alpha,\beta,\gamma, \delta}(G)$. As a consequence of these results, we give a determinant formula for the distance matrix, the squared distance matrix, the $q$-distance matrix and the exponential distance matrix of a threshold graph and a chain graph, respectively. 
\end{ilasabstract}
    

\hypertarget{down0240}{}\begin{ilasabstract}
\talktitle{Error formulas for block rational Krylov approximations of matrix functions}
    
\textbf{Stefano Massei}, \info{17:30\textrm{--}18:00 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0240}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    We investigate explicit expressions for the error associated with the block rational Krylov approximation of matrix functions. Two formulas are proposed, both derived from  characterizations of the block FOM residual. The first formula employs a block generalization of the residual polynomial, while the second leverages the block collinearity of the residuals. A posteriori error bounds based on the knowledge 
of spectral information of the argument are derived and tested on a set of examples. Notably, both error formulas and their corresponding upper bounds do not require the evaluation of contour integrals.  

\end{ilasabstract}
    

\hypertarget{down0249}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Izuho Matsuzaki}, \info{11:30\textrm{--}12:00 @ SC0012 (June 25, Wednesday)} \hfill \hyperlink{up0249}{$\Uparrow$}
    
    
(in {\color{mstitle}MS35: Preserver Problems, II})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0194}{}\begin{ilasabstract}
\talktitle{Rational approximations of fractional power operators applied to preconditioning}
    
\textbf{Mariarosa Mazza}, \info{14:00\textrm{--}14:30 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0194}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    In this talk, we consider the Riesz operator \( -(- \Delta)^{\frac{\alpha}{2}} \), \(\alpha \in (1, 2]\), which arises in fractional models such as anomalous diffusion, and develop effective preconditioners for its efficient numerical solution. First, we approximate \( -(-\Delta)^{\frac{\alpha}{2}} \) as the fractional power of a discretized Laplacian using the Matrix Transfer Technique and represent the result in integral form via the Dunford-Taylor integral representation. Various quadrature rules are then explored to approximate the integral, leading to rational approximations of the fractional power operator.  
This approach enables us to construct preconditioners expressed as a sum of \( m \) inverses of shifted Laplacian matrices, where \( m \) depends on the chosen quadrature scheme. For \(\alpha\) close to $2$, it is well known that the Laplacian itself serves as an effective preconditioner with linear computational cost. However, as \(\alpha\) decreases toward 1, its performance deteriorates, requiring more specialized approaches. Using Gauss-Jacobi quadrature, we show that our preconditioner significantly improves performance for \(\alpha\) close to $1$, even with a modest \( m \), while maintaining the same computational complexity as the Laplacian.  
To further enhance efficiency, we investigate the use of exponentially convergent quadrature rules to minimize the number of required inverses while achieving optimal preconditioning performance. Specifically, we examine both sinc and Gauss-Laguerre quadratures and demonstrate that, with appropriate parameter tuning, both approaches outperform the Gauss-Jacobi one, ensuring numerical optimality.
\end{ilasabstract}
    

\hypertarget{down0220}{}\begin{ilasabstract}
\talktitle{Trace approximation using GLT theory and the matrix-less method
}
    
\textbf{David Meadon}, \info{17:30\textrm{--}18:00 @ SC1003 (June 24, Tuesday)} \hfill \hyperlink{up0220}{$\Uparrow$}
    
    
(in {\color{mstitle}MS19: Explicit and hidden asymptotic structures, GLT Analysis, and applications})
        
\mtskip
    \begin{bibunit}
        The theory of Generalised Locally Toeplitz (GLT) Sequences, see for example \cite{garoni171}, has been successfully used to study the spectra of different classes of Toeplitz(-like) matrix sequences such as Hermitian, non-Hermitian, block-valued, variable coefficient, etc. Specifically, it is a tool that allows us to approximate the eigenvalues of Hermitian Toeplitz(-like) matrices by sampling a function, called the symbol, using an equispaced grid. GLT theory has also been extended to include the concept of momentary symbols, that is, symbols which change depending on the size of the matrix, see \cite{Bolten2022}. This is particularly useful in the case of, for example, PDE discetisations of some  operators which may have some variety of grid size \(h\) in the symbol that would change depending on the matrix size, that is, it would change with refinement.
The Matrix-less method, see \cite{ekstrom2018matrix,expmathmlm,ekstromreal, variablecoef}, aims to use the inherent structure of Toeplitz matrices to accurately compute the spectrum of a much larger matrix in the sequence using a number of (much) smaller matrices. It computes so called ``higher-order'' symbols, and then using an interpolation-extrapolation scheme allow it to approximate the eigenvalues with much higher accuracy.
We show that these methods, which approximate the eigenvalues of the operator, are able to cheaply approximate the trace of different matrix functions without having to actually construct the (potentially very large) matrix or do any computations on it. We investigate computing the traces of matrix functions such as \(\mathrm{Tr}\left(e^{-\beta \mathbf{A}}\right),~\mathrm{Tr}\left(\mathbf{A}e^{-\beta \mathbf{A}}\right),~-\mathrm{Tr}\left(\mathbf{A}\log\left(\mathbf{A}\right)\right)\) and others, where \(\mathbf{A}\) is the Toeplitz(-like) linear operator.

\begin{thebibliography}{99}
    {}
    \bibitem{variablecoef}
    G. Barbarino et al. “Matrix-less spectral approximation for large structured
    matrices”. In: \emph{BIT. Numerical mathematics} (Jan. 2025). (In Press). \textsc{doi}: \url{10.1007/s10543-024-01041-w}.
    {}
    \bibitem{Bolten2022}
    M. Bolten et al. “Toeplitz momentary symbols: definition, results, and limitations in
    the spectral analysis of structured matrices”. In: \emph{Linear Algebra and its
    Applications} 651 (Oct. 2022), pp. 51–82. \textsc{issn}: 0024-3795. \textsc{doi}: \url
    {10.1016/j.laa.2022.06.017}.
    {}
    \bibitem{ekstrom2018matrix}
    S-E. Ekstr\"{o}m. “Matrix-Less Methods for Computing Eigenvalues of Large Structured
    Matrices”. PhD thesis. Uppsala University, 2018. \textsc{isbn}: 978-91-513-0288-1.
    {}
    \bibitem{expmathmlm}
    S-E. Ekstr\"{o}m, C. Garoni, and S. Serra-Capizzano. “Are the Eigenvalues of
    Banded Symmetric Toeplitz Matrices Known in Almost Closed Form?” In:
    \emph{Experimental Mathematics} 27.4 (May 2017), pp. 478–487. \textsc{doi}: \url
    {10.1080/10586458.2017.1320241}.
    {}
    \bibitem{ekstromreal}
    S-E. Ekstr\"{o}m and P Vassalos. “A matrix-less method to approximate the spectrum
    and the spectral function of Toeplitz matrices with real eigenvalues”. In: \emph{Numerical Algorithms} 89.2 (June 2021), pp. 701–720. \textsc{issn}: 1572-9265. \textsc{doi}:
    \url {10.1007/s11075-021-01130-9}.
    {}
    \bibitem{garoni171}
    C. Garoni and S. Serra-Capizzano. \emph{Generalized Locally Toeplitz Sequences: Theory and Applications (Volume 1)}. Springer International Publishing,
    2017. \textsc{doi}: \url {10.1007/978-3-319-53679-8}.
    \end{thebibliography}

        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0064}{}\begin{ilasabstract}
\talktitle{A combination of cyclic reduction and shift-and-deflate techniques for solving quadratic matrix equations
}
    
\textbf{Beatrice Meini}, \info{14:00\textrm{--}14:30 @ SC2001 (June 23, Monday)} \hfill \hyperlink{up0064}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    We consider the problem of computing the minimal solvent $G$ of a quadratic matrix equation $A_0+A_1X+A_2X^2=0$.  If the eigenvalues of the corresponding quadratic matrix polynomial $P(z)=A_0+A_1z+A_2z^2$ have a splitting with respect to the unit circle, Cyclic Reduction (CR) algorithm converges quadratically to the sought solution $G$.
In this talk we consider the case where $P(z)$ has some eigenvalues on the unit circle, therefore convergence of CR is not generally guaranteed. 
More specifically, we propose an algorithm based on a combination of CR and a shift-and-deflate technique. CR is used to approximate the eigensapce of $G$ corresponding to the eigenvalues in the open unit disk, while the eigenspace corresponding to the eigenvalues on the unit circle is computed by solving a reduced quadratic matrix equation.


\smallskip\noindent
Joint work with Xu Li, Lanzhou University of Technology, China.

\end{ilasabstract}
    

\hypertarget{down0047}{}\begin{ilasabstract}
\talktitle{Convergence properties of sequences related to the Ando-Li-Mathias construction and to the weighted Cheap mean}
    
\textbf{Jie Meng}, \info{14:30\textrm{--}15:00 @ SC0009 (June 23, Monday)} \hfill \hyperlink{up0047}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    Sequences defining a weighted matrix geometric mean are investigated and their convergence speed is analyzed.
The superlinear convergence of a weighted mean based on the Ando-Li-Mathias (ALM) construction is proved. A weighted Cheap mean is defined and conditions on the weights for linear or superlinear convergence of order at least three are provided.

\end{ilasabstract}
    

\hypertarget{down0056}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Vatsalkumar Mer}, \info{14:30\textrm{--}15:00 @ SC1001 (June 23, Monday)} \hfill \hyperlink{up0056}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0292}{}\begin{ilasabstract}
\talktitle{Computational labs to enhance linear algebra intuition}
    
\textbf{Mike Michailidis}, \info{10:30\textrm{--}11:00 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0292}{$\Uparrow$}
    
    
(in {\color{mstitle}MS27: Linear algebra education})
        
\mtskip
    Linear algebra is a key topic in mathematics and a core component of science and engineering education. In this talk, we will explore the role of programming in enhancing linear algebra education. Specifically, we will report on a study about a proof-based second course in linear algebra encompassing various topics, including vector spaces, finite-dimensional vector spaces, linear maps, polynomials, inner product spaces, operators on inner product spaces, eigenvalues, and eigenvectors. The existing course was reorganized to incorporate six labs and a final project using MATLAB, to help students explore numerical linear algebra and its applications via programming. 22 mathematics and engineering students were enrolled in this course and 15 agreed to participate in this study, the findings of which we will report and present during this talk. 

\end{ilasabstract}
    

\hypertarget{down0019}{}\begin{ilasabstract}
\talktitle{A new class of distances between pure quantum states}
    
\textbf{Tomasz Miller}, \info{11:00\textrm{--}11:30 @ SC0014 (June 23, Monday)} \hfill \hyperlink{up0019}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    For any $n \times n$ distance matrix $(E_{ij})$, we show that the map
\begin{align*}
d(\textup{\textbf{x}},\textup{\textbf{y}}) := \sqrt{\sum_{i<j}E_{ij}^2|x_iy_j - x_jy_i|^2},
\end{align*}
where $\textup{\textbf{x}},\textup{\textbf{y}} \in {\mathbb C}^n$ are unit vectors, gives rise to a bona fide distance on the projective space ${\mathbb P}({\mathbb C}^n)$, a far-reaching generalization of the standard distance on ${\mathbb P}({\mathbb C}^n)$ arising from the wedge product $\|\textup{\textbf{x}} \wedge \textup{\textbf{y}}\| = \sqrt{1 - |\langle \textup{\textbf{x}} | \textup{\textbf{y}} \rangle|^2}$. We also discuss how this result carries over to the $n \rightarrow +\infty$ case, offering a way to `lift' the metric structure from some underlying metric measure space $(X,D,\mu)$ to the projective Hilbert space ${\mathbb P}(L^2(X,\mu))$. The talk builds on and extends the results of [1].

[1] R. Bistro\'{n}, M. Eckstein, S. Friedland, TM, K. \.{Z}yczkowski, \textit{A new class of distances on complex projective spaces}, Linear Algebra Appl., 2024
\end{ilasabstract}
    

\hypertarget{down0275}{}\begin{ilasabstract}
\talktitle{The algebra generated by nilpotent elements in a matrix centralizer}
    
\textbf{Eloise Misa}, \info{11:00\textrm{--}11:30 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0275}{$\Uparrow$}
    
    
(in {\color{mstitle}MS31: Matrix decompositions and applications})
        
\mtskip
    For an arbitrary square matrix $S$, denote by $C(S)$ the centralizer of $S$, and by $C(S)_N$ the set of all nilpotent elements in $C(S)$.
In this paper, we use the Weyr canonical form to study the subalgebra $\mathcal{A}(S)$ of $C(S)$ generated by $C(S)_N$. We give a necessary and/or sufficient condition such that $A \in C(S)$ is a sum or product of nilpotent matrices in $C(S)$. We determine conditions on $S$ such that $C(S)_N$ is a subalgebra of $C(S)$, that is, when $\mathcal{A}(S)=C(S)_N$. We also determine conditions on $S$ such that the subalgebra generated by $C(S)_N$ is $C(S)$, that is, when $\mathcal{A}(S)=C(S)$.
\end{ilasabstract}
    

\hypertarget{down0164}{}\begin{ilasabstract}
\talktitle{Surjective isometries on Banach spaces with derivatives}
    
\textbf{Takeshi Miura}, \info{15:00\textrm{--}15:30 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0164}{$\Uparrow$}
    
    
(in {\color{mstitle}MS12: Preserver problems, I})
        
\mtskip
    We shall give the characterization of surjective, possibly nonlinear,
isometries from Banach spaces with derivatives.
This unifies the former results on isometries on the following
Banach spaces:
\begin{enumerate}
\item
$C^1([0,1])$ of all continuously differentiable complex-valued functions
on the closed interval $[0,1]$.

\item
The Banach space of all continuous extensions to $\overline{\mathbb{D}}$,
the closure of the open unit disc $\mathbb{D}$,
of all analytic functions on $\mathbb{D}$,
which can be extended to continuous functions on $\overline{\mathbb{D}}$.

\item
The Banach space of all Gelfand transforms of analytic functions
on $\mathbb{D}$ whose derivatives are bounded on $\mathbb{D}$.
\end{enumerate}

\end{ilasabstract}
    

\hypertarget{down0347}{}\begin{ilasabstract}
\talktitle{Some norm bounds on the complimentary error matrix functions}
    
\textbf{Shinya Miyajima}, \info{13:30\textrm{--}14:00 @ SC4011 (June 26, Thursday)} \hfill \hyperlink{up0347}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    \begin{bibunit}
        Let $A \in \mathbf{C}^{n \times n}$ be a square matrix such that ${\rm Re}(\lambda) > |{\rm Im}(\lambda)|$, $\forall \lambda \in \sigma(A)$, where $\sigma(A)$ is the spectrum of $A$. 
The error matrix function ${\rm erf}(A)$ and complimentary error matrix function ${\rm erfc}(A)$, which are introduced in \cite{Cortes}, are defined as 
$$
{\rm erf}(A) := \frac{2A}{\sqrt{\pi}}\int_{0}^{1} e^{-(Av)^{2}} dv \quad \mbox{and} \quad {\rm erfc}(A) := \frac{2A}{\sqrt{\pi}}\int_{1}^{\infty} e^{-(Av)^{2}} dv,
$$
respectively. 

One of the most important application of the complimentary error matrix function is the solution to systems of partial differential equation. 
Let $u_0, u(x,t) \in \mathbf{C}^n$. 
It is proven in \cite{Cortes} that the solution to semi-finite coupled diffusion problem 
\begin{eqnarray*}
u_{t} &=& A^2u_{xx}, \ x>0, \ t>0, \\
u(x,0) &=& 0, \ x>0, \quad 
u(0,t) = u_{0}, \ t>0, \quad 
u(x,t) \to 0, \ \textrm{as} \ x\rightarrow\infty, \ t > 0
\end{eqnarray*}
can be represented by using the complimentary error matrix function as follows:
$$
u(x,t) = {\rm erfc}\left(\frac{A^{-1}x}{2\sqrt{t}}\right)u_{0}, \quad x>0, \quad t>0. 
$$

Analogously to the scaler case, the functions ${\rm erf}(A)$ and ${\rm erfc}(A)$ satisfy the property ${\rm erf}(A) + {\rm erfc}(A) = I$, where $I$ is the $n \times n$ identity matrix. 
According to the Taylor expansion of $e^{-(Av)^{2}}$ where $v \in [0,1]$, and integrating term by term, we obtain 
$$
{\rm erf}(A) = \frac{2A}{\sqrt{\pi}}\sum_{k=0}^{\infty}\frac{(-1)^k A^{2k}}{k! (2k+1)}, 
$$
which is the Taylor expansion of ${\rm erf}(A)$ \cite{Cortes}. 
From this expansion and ${\rm erf}(A) + {\rm erfc}(A) = I$, we obtain 
$$
{\rm erfc}(A) = I - \frac{2A}{\sqrt{\pi}}\sum_{k=0}^{\infty}\frac{(-1)^k A^{2k}}{k! (2k+1)}. 
$$
In \cite{Cortes}, an upper bound on $\|{\rm erfc}(A)\|_2$ under the condition ${\rm Re}(\lambda) > |{\rm Im}(\lambda)|$, $\forall \lambda \in \sigma(A)$ has been derived as a corollary of the fact that ${\rm erfc}(A)$ is well-defined. 

The purpose of this talk is to present the following norm bounds: 
\begin{itemize}
\item a new upper bound on $\|{\rm erfc}(A)\|_2$ under a condition which is different from ${\rm Re}(\lambda) > |{\rm Im}(\lambda)|$, $\forall \lambda \in \sigma(A)$, 
\item upper bounds on $\|{\rm erf}(A) - {\rm erf}(B)\|_2$ and $\|{\rm erfc}(A) - {\rm erfc}(B)\|_2$, where $B \in \mathbf{C}^{n \times n}$, under an assumption, and 
\item upper bounds on 
$$
\left\|{\rm erf}(A) - \frac{2A}{\sqrt{\pi}}\sum_{k=0}^{m}\frac{(-1)^k A^{2k}}{k! (2k+1)}\right\|_2 \ \mbox{and} \ 
\left\|{\rm erfc}(A) - \left(I - \frac{2A}{\sqrt{\pi}}\sum_{k=0}^{m}\frac{(-1)^kA^{2k}}{k!(2k+1)}\right)\right\|_2,
$$ 
where $m$ is a nonnegative integer, under an assumption. 
\end{itemize}
We report results of numerical experiments in order to observe how much larger the presented bounds are compared to the corresponding norms. 
This talk is based on the joint work with Prof. Amir Sadeghi in Islamic Azad University. 

\begin{thebibliography}{5}
\bibitem{Cortes}
J. Cort$\acute{{\rm e}}$s, R. Company, L. J$\acute{{\rm o}}$dar, 
The complementary error matrix function and its role solving coupled diffusion mathematical models, 
Math. Comput. Modell, 42(9--10), 1023--1034 (2005). 
\end{thebibliography}
        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0018}{}\begin{ilasabstract}
\talktitle{Relative entropy preserving maps on positive cones in operator algebras and in matrix algebras}
    
\textbf{Lajos Molnár}, \info{12:00\textrm{--}12:30 @ SC0012 (June 23, Monday)} \hfill \hyperlink{up0018}{$\Uparrow$}
    
    
(in {\color{mstitle}MS12: Preserver problems, I})
        
\mtskip
    We consider several concepts of (not only numerical valued) relative entropies on positive cones in $C^*$-algebras. We present recent results showing that surjective transformations between positive cones that preserve any of those quantities necessarily originate from Jordan *-isomorphisms between the underlying full algebras. In the special case of matrix algebras, we consider the problem of relaxing the condition of surjectivity.

Partly, joint work with Lei Li and Xueyan Yang (Nankai University).

\end{ilasabstract}
    

\hypertarget{down0172}{}\begin{ilasabstract}
\talktitle{A $q$-analogue of the distance matrix of a tree with matrix weights}
    
\textbf{Madhab Mondal}, \info{15:00\textrm{--}15:30 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0172}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    A $q$-analogue of the distance matrix (called the $q$-distance matrix) of a tree was introduced in [Bapat RB, Lal AK, Pati S. A $q$-analogue of the distance matrix of a tree. Linear Algebra Appl. 2006;416(2-3):799--814]. It was formed from the distance matrix $D$ by substituting each entry $d(i,j)$ of $D$ by $1+q+\cdots+q^{d(i,j)-1}$. In this article, we consider the $q$-distance matrix of a weighted tree, where the edge weights are matrices of the same size. We deduce a formula for the determinant of the $q$-distance matrix of a tree. Subsequently, we present a necessary and sufficient condition for the $q$-distance matrix to be invertible and derive an expression for the inverse whenever it exists. The expression for the inverse of the $q$-distance matrix leads us to introduce the $q$-analogue of the Laplacian matrix (named as the $q$-Laplacian matrix) for a tree with matrix weights. A formula for the determinant of the $q$-Laplacian matrix is also provided. Our results extend the existing results for the $q$-distance matrix of a weighted tree when the weights are real numbers, as well as the distance matrix of a tree with matrix weights (that can be obtained by setting $q=1$).
\end{ilasabstract}
    

\hypertarget{down0381}{}\begin{ilasabstract}
\talktitle{Smallest positive eigenvalue of non-bipartite unicyclic graphs}
    
\textbf{Debabrota Mondal}, \info{17:00\textrm{--}17:30 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0381}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    Let $G$ be a simple graph with the adjacency matrix $A(G)$. By the smallest positive eigenvalue of $G$, we mean the smallest positive eigenvalue of $A(G)$, and it is denoted by $\tau(G)$. This spectral parameter has significant applications in both chemical graph theory and spectral graph theory. In the literature, the study of the smallest positive eigenvalue has primarily focused on trees, bipartite unicyclic graphs, and bipartite graphs. In this talk, we discuss bounds on the smallest positive eigenvalue of non-bipartite unicyclic graphs and characterize the extremal graphs. This talk is based on joint work with Sasmita Barik and Subhasish Behera.
\end{ilasabstract}
    

\hypertarget{down0180}{}\begin{ilasabstract}
\talktitle{Uniform mixing and apportionability
}
    
\textbf{Hermie Monterde}, \info{15:00\textrm{--}15:30 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0180}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    Let $X$ be a graph on $n$ vertices with adjacency matrix $A$. A \textit{quantum walk} on $X$ is defined by the matrix
\begin{equation*}
U(t)=\exp({\mathrm{i}tA}),\quad t\in\mathbb{R}
\end{equation*}
which is unitary for each $t\in\mathbb{R}$. If we write $A=S^TDS$ where $D=\operatorname{diag}(\lambda_1,\ldots,\lambda_n)$ is the diagonal matrix of eigenvalues of $A$ and $S$ is an orthogonal matrix, then the above equation can be written as
\begin{equation}
\label{1}
U(t)=S^Te^{\mathrm{i}tD}S,
\end{equation}
where $e^{\mathrm{i}tD}=\operatorname{diag}(e^{\mathrm{i}t\lambda_1},\ldots,e^{\mathrm{i}t\lambda_n})$. We say that $X$ admits \textit{uniform mixing} at time $\tau$ if all entries of $U(\tau)$ have equal magnitude. Uniform mixing symbolizes maximal entanglement amongst all qubits in a graph representing a quantum spin network - a phenomenon that is useful in the theory of quantum information and computation.

To apportion a complex matrix means to apply a similarity so that all entries of the resulting matrix have the same magnitude. The study of matrix apportionment was initiated by Leslie and three of her collaborators in a 2024 LAA paper. From (\ref{1}), the existence of uniform mixing at time $\tau$ is equivalent to $U(\tau)$ being apportionable.  

In this talk, we survey old and new results on uniform mixing, and explore its connections to matrix apportionment. Some results in this talk are joint work with Steve Kirkland and Sarah Plosker.

\end{ilasabstract}
    

\hypertarget{down0351}{}\begin{ilasabstract}
\talktitle{Nonnegativity in quantum walks
}
    
\textbf{Hermie Monterde}, \info{16:00\textrm{--}16:30 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0351}{$\Uparrow$}
    
    
(in {\color{mstitle}MS24: Nonnegative and related families of matrices})
        
\mtskip
    Let $X$ be a connected graph on $n$ vertices and let $H$ be a nonnegative symmetric matrix associated with $X$. A \textit{quantum walk} on $X$ is defined by the matrix
\begin{equation*}
U(t)=\exp({\mathrm{i}tH}),\quad t\in\mathbb{R}
\end{equation*}
which is unitary for each $t\in\mathbb{R}$. We say that two linearly independent unit vectors $\mathbf{x}$ and $\mathbf{y}$ in $\mathbb{C}^n$ admit \textit{perfect state transfer} if there exists a time $\tau$ and a unit complex number $\gamma$ such that
\begin{equation*}
U(\tau)\mathbf{x}=\gamma\mathbf{y}.
\end{equation*}
Perfect state transfer represents accurate transmission of pure quantum states associated with $\mathbf{x}$ and $\mathbf{y}$ -- a topic that is of paramount importance in quantum information processing. In this talk, we show how techniques from nonnegative matrix theory can be used to derive fundamental properties of perfect state transfer between nonnegative vectors. This is joint work with Chris Godsil and Stephen Kirkland.

\end{ilasabstract}
    

\hypertarget{down0143}{}\begin{ilasabstract}
\talktitle{Spectral upper bounds for the Grundy number of a graph}
    
\textbf{Emanuel Juliano Morais Silva}, \info{11:30\textrm{--}12:00 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0143}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    The Grundy number of a graph is the minimum number of colors needed to properly color the graph using the first-fit greedy algorithm regardless of the initial vertex ordering. Computing the Grundy number of a graph is an NP-Hard problem. There is a characterization in terms of induced subgraphs: a graph has a Grundy number at least k if and only if it contains a $k$-atom. 
In this talk, we focus on a natural quotient matrix of the adjacency matrix of $k$-atoms and use its combinatorial properties to derive bounds on the Grundy number in terms of the largest eigenvalue and the size of the graph.
This talk is based on a joint work with Gabriel Coutinho and Thiago Assis.

\end{ilasabstract}
    

\hypertarget{down0165}{}\begin{ilasabstract}
\talktitle{Structure-preserving model order reduction of linear time-varying port-Hamiltonian systems}
    
\textbf{Riccardo Morandin}, \info{13:30\textrm{--}14:00 @ SC0014 (June 24, Tuesday)} \hfill \hyperlink{up0165}{$\Uparrow$}
    
    
(in {\color{mstitle}MS6: Model reduction})
        
\mtskip
    Many physical processes can be naturally modeled using port-Hamiltonian (pH) systems, which are inherently passive and stable, and allow for structure-preserving interconnection, making them particularly suitable for the modeling of complex networks. Furthermore, many dedicated numerical methods have been developed to exploit and preserve the structure of pH systems, e.g. for space- and time-discretization, and model order reduction (MOR).
In our work, we focus on the structure-preserving MOR of linear time-varying (LTV) pH systems. LTV systems appear quite naturally in many applications, e.g. in the linearization of nonlinear systems around non-stationary reference solutions, or when some of the system parameters are time-dependent.
In this talk we introduce a general approach based on (Petrov)-Galerkin projection for the structure-preserving MOR of LTV-pH systems. This includes (but is not limited to) the extension of the effort constraint method to LTV-pH systems. Furthermore, we combine balancing and projection to obtain a reduced model that is guaranteed to be pH. We exhibit numerical experiments to validate our algorithms.

\end{ilasabstract}
    

\hypertarget{down0127}{}\begin{ilasabstract}
\talktitle{On the Scottish Book Problem 155 by Mazur and Sternbach}
    
\textbf{Michiya Mori}, \info{11:00\textrm{--}11:30 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0127}{$\Uparrow$}
    
    
(in {\color{mstitle}MS12: Preserver problems, I})
        
\mtskip
    The Scottish Book was a notebook used by mathematicians of the Lw\'ow School of Mathematics in Poland to collect unsolved problems in mathematics.
Problem 155 of the Scottish Book asks whether every bijection $U\colon X\to Y$ between two Banach spaces $X, Y$ with the property that, each point of $X$ has a neighborhood on which $U$ is isometric, is globally isometric on $X$. 
In this talk, I will explain that this is true under the additional assumption that $X$ is separable and the weaker assumption of surjectivity instead of bijectivity.

\end{ilasabstract}
    

\hypertarget{down0253}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Milán Mosonyi}, \info{10:30\textrm{--}11:00 @ SC1001 (June 25, Wednesday)} \hfill \hyperlink{up0253}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0286}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Akihiro Munemasa}, \info{10:30\textrm{--}11:00 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0286}{$\Uparrow$}
    
    
(in {\color{mstitle}MS34: Combinatorics, association scheme, and graphs})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0262}{}\begin{ilasabstract}
\talktitle{An approach to computing maximum multiplicity of eigenvalues in graphs}
    
\textbf{Shahla Nasserasr}, \info{10:30\textrm{--}11:00 @ SC2001 (June 25, Wednesday)} \hfill \hyperlink{up0262}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    For a simple graph $G$, the maximum multiplicity of an eigenvalue among all symmetric matrices with the graph of $G$ is denoted by $M(G)$. It is known that for trees, $M(G)$, can be computed by removing certain vertices to reduce the tree to paths. We propose a method to generalize this approach to graphs. Using this generalized method, we compute the maximum multiplicity for unicyclic graphs and several other families of graphs.
This is joint work with Charles R. Johnson, Ant\'onio Leal-Duarte and Carlos M. Saiago.

\end{ilasabstract}
    

\hypertarget{down0039}{}\begin{ilasabstract}
\talktitle{Optimal matrix-mimetic tensor algebras via variable projection
}
    
\textbf{Elizabeth Newman}, \info{12:00\textrm{--}12:30 @ SC3001 (June 23, Monday)} \hfill \hyperlink{up0039}{$\Uparrow$}
    
    
(in {\color{mstitle}MS18: New methods in numerical multilinear algebra})
        
\mtskip
    Many data are naturally represented as multiway arrays or tensors, and as a result, multilinear data analysis tools have revolutionized feature extraction and data compression. Despite the success of tensor-based approaches, fundamental linear algebra properties often break down in higher dimensions. Recent advances in matrix-mimetic tensor algebra in have made it possible to preserve linear algebraic properties and, as a result, to obtain optimal representations of multiway data. Matrix-mimeticity arises from interpreting tensors as t-linear operators, which in turn are parameterized by invertible linear transformations. The choice of transformation is critical to representation quality, and thus far, has been made heuristically. In this talk, we will learn data-dependent, orthogonal transformations by leveraging the optimality of matrix-mimetic representations. In particular, we will exploit the coupling between transformations and optimal tensor representations using variable projection. We will highlight the efficacy of our proposed approach on image compression and reduced order modeling tasks.

\end{ilasabstract}
    

\hypertarget{down0148}{}\begin{ilasabstract}
\talktitle{A tensor alternating Anderson--Richardson method for solving multilinear systems with $ \mathcal{M} $-tensors}
    
\textbf{Jing Niu}, \info{11:00\textrm{--}11:30 @ SC3001 (June 24, Tuesday)} \hfill \hyperlink{up0148}{$\Uparrow$}
    
    
(in {\color{mstitle}MS18: New methods in numerical multilinear algebra})
        
\mtskip
    It is well-known that a multilinear system with a nonsingular $ \mathcal{M} $-tensor and a positive right-hand side has a unique positive solution.
Tensor splitting methods are efficient because they do not require computing the Jacobian matrix.
Anderson acceleration is also a Jacobian-free technique. 
The Alternating Anderson--Richardson (AAR) method is also a Jacobian-free method for solving linear systems.
Inspired by the AAR method,
we propose a tensor AAR method for solving multilinear systems.
Specifically, we first present a tensor Richardson method, then apply Anderson acceleration and derive a tensor Anderson--Richardson method, finally, we periodically employ the tensor Anderson--Richardson method within the tensor Richardson method and propose a tensor AAR method.
Numerical experiments show that the proposed method outperforms some tensor splitting methods.

\end{ilasabstract}
    

\hypertarget{down0213}{}\begin{ilasabstract}
\talktitle{Invertible bases and root vectors for analytic matrix-valued functions}
    
\textbf{Vanni Noferini}, \info{16:00\textrm{--}16:30 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0213}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    I will revisit the notion of a minimal basis from the viewpoint of the theory of modules over a commutative ring. I will define the concept of an invertible basis and link it to the Main Theorem in the famous paper [G. D. Forney Jr., SIAM J. Control 13, 493-520, 1975]. When the underlying ring $R$ is an elementary divisor domain, the submodules that have an invertible basis are precisely the free pure submodules of $R^n$. As an application, I will consider the ring $\mathcal{A}$ of functions that are analytic on $\Omega \subseteq \mathbb{C}$, where $\Omega$ is either a connected compact set or a connected open set. I will show that, for all matrices $M \in \mathcal{A}^{m \times n}$, $\ker M \cap \mathcal{A}^n$ is a free $\mathcal{A}$-module that admits an invertible basis, or equivalently a basis that is full rank upon evaluation at every $\lambda \in \Omega$. This provides a tool to define maximal sets of root vectors at $\lambda$, and in particular to meaningfully define eigenvectors also for analytic matrices that do not have full rank.

\end{ilasabstract}
    

\hypertarget{down0327}{}\begin{ilasabstract}
\talktitle{Nearest $\Omega$-stable pencil with Riemannian optimization}
    
\textbf{Lauri Nyman}, \info{13:30\textrm{--}14:00 @ SC1003 (June 26, Thursday)} \hfill \hyperlink{up0327}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    In this talk, we consider the problem of finding the nearest $\Omega$-stable pencil to a given square pencil $A+xB \in \mathbb{C}^{n \times n}$, where a pencil is called $\Omega$-stable if it is regular and all of its eigenvalues belong to the closed set $\Omega$. We propose a new method, based on the Schur form of a matrix pair and Riemannian optimization over the manifold $U(n) \times U(n)$, that is, the Cartesian product of the unitary group with itself. While the developed theory holds for any closed set $\Omega$, we focus on two cases that are the most common in applications: Hurwitz stability and Schur stability. 

\end{ilasabstract}
    

\hypertarget{down0277}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Ryan O'Loughlin}, \info{10:30\textrm{--}11:00 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0277}{$\Uparrow$}
    
    
(in {\color{mstitle}MS33: Norms of matrices, numerical range, applications of functional analysis to matrix theory})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0014}{}\begin{ilasabstract}
\talktitle{Generalization of B\"ottcher-Wenzel inequality and its application}
    
\textbf{Hiromichi Ohno}, \info{11:30\textrm{--}12:00 @ SC0009 (June 23, Monday)} \hfill \hyperlink{up0014}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    The B\"ottcher-Wenzel inequality states that the Hilbert-Schmidt norm of the commutator of matrices $A$ and $B$ is less than or equal to $\sqrt{2}$ times the product of the Hilbert-Schmidt norms of $A$ and $B$. In this talk, we discuss generalizations of the B\"ottcher-Wenzel inequality in which the Hilbert-Schmidt norm is replaced by a weighted Hilbert-Schmidt norm. An application to the uncertainty relation is also considered.
\end{ilasabstract}
    

\hypertarget{down0163}{}\begin{ilasabstract}
\talktitle{Periodic surjective isometries on Banach algebras}
    
\textbf{Shiho Oi}, \info{14:30\textrm{--}15:00 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0163}{$\Uparrow$}
    
    
(in {\color{mstitle}MS12: Preserver problems, I})
        
\mtskip
    We study periodic surjective isometries on $C^{*}$-algebras.  We establish a relation between the complex spectrum of periodic surjective isometries on Banach algebras  and provide several examples that illustrate the range of possibilities that can occur for the complex spectrum of the isometry and classical spectrum of the Jordan $\ast$-isomorphism.

\end{ilasabstract}
    

\hypertarget{down0181}{}\begin{ilasabstract}
\talktitle{Bounded Littlewood identities for cylindric Schur functions and related combinatorics}
    
\textbf{Soichi Okada}, \info{13:30\textrm{--}14:00 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0181}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    The bounded Littlewood identities are determinant formulas for 
the sum of Schur functions indexed by partitions with bounded height. 
These have interesting combinatorial consequences involving 
standard Young tableaux of bounded height. In this talk, we 
give affine analogs of the bounded Littlewood identities, which 
are determinant formulas for sums of cylindric Schur functions. 
As an application, we obtain equinumerous results between cylindric 
standard Young tableaux and partial matchings.

This talk is based on a joint work with JiSun Huh, Jang Soo Kim, 
and Christian Krattenthaler.

\end{ilasabstract}
    

\hypertarget{down0343}{}\begin{ilasabstract}
\talktitle{Mixed precision parallel operations for tensor train arithmetic}
    
\textbf{Eda Oktay}, \info{13:30\textrm{--}14:00 @ SC3001 (June 26, Thursday)} \hfill \hyperlink{up0343}{$\Uparrow$}
    
    
(in {\color{mstitle}MS16: Approximations and errors in Krylov-based solvers})
        
\mtskip
    Tensor Train (TT) decomposition is a widely used low-rank tensor factorization technique known for its memory efficiency and scalability in high-dimensional data. Its advantages have motivated the development of various TT-based methods and applications across fields, such as chemistry, quantum physics, and machine learning. However, constructing low-rank tensors and performing operations in TT arithmetic can be computationally intensive, often due to challenges on the cost of tensor construction and the complexity of numerical operations. To address these issues, high-performance computing (HPC) techniques such as parallelism and mixed-precision arithmetic have become essential tools for enhancing computational efficiency and reducing memory and communication requirements in (multi)linear algebra. In this talk, we discuss recent advances in HPC for TT arithmetic and introduce parallel TT operations using mixed-precision arithmetic. We then explore the potential of these developments to improve large-scale tensor computations and discuss their implications for future applications in scientific computing.
\end{ilasabstract}
    

\hypertarget{down0385}{}\begin{ilasabstract}
\talktitle{Jordan and isometric cone automorphisms in Euclidean Jordan algebras}
    
\textbf{Michael Orlitzky}, \info{17:00\textrm{--}17:30 @ SC2006 (June 26, Thursday)} \hfill \hyperlink{up0385}{$\Uparrow$}
    
    
(in {\color{mstitle}MS28: From matrix theory to Euclidean Jordan algebras, FTvN systems, and beyond})
        
\mtskip
    Every symmetric cone $K$ arises as the cone of squares in a Euclidean
Jordan algebra $V$. As $V$ is a real inner-product space, we may
denote by $\operatorname{Isom}\left(V\right)$ its group of
isometries. The groups $\operatorname{JAut}\left(V\right)$ of its
Jordan-algebra automorphisms and $\operatorname{Aut}\left(K\right)$
of the linear cone automorphisms are then related. For certain inner
products,
%
\begin{equation*}
  \operatorname{JAut}\left(V\right)
  =
  \operatorname{Aut}\left(K\right)
  \cap
  \operatorname{Isom}\left(V\right).
\end{equation*}
%
We characterize the inner products for which this holds.

\end{ilasabstract}
    

\hypertarget{down0266}{}\begin{ilasabstract}
\talktitle{Generalized Hellinger divergences generated by monotone functions.
}
    
\textbf{Hiroyuki Osaka}, \info{11:00\textrm{--}11:30 @ SC2006 (June 25, Wednesday)} \hfill \hyperlink{up0266}{$\Uparrow$}
    
    
(in {\color{mstitle}MS3: Matrix inequalities with applications})
        
\mtskip
    \begin{bibunit}
        Let $p$ and $q$ be two discrete probability distributions, that is, $p=(p_1, \dots, p_n)$, $q = (q_1, \dots, q_n)$ are $n$-vectors with nonnegative coordinates such that $\sum_{i=1}^np_i = \sum_{i=1}^nq_i = 1$. The Hellinger distance $d_H$ between $p$ and $q$ is the Euclidean norm of the difference between the squre roots of $p$ and $q$; 
$$
d(p,q) = \|\sqrt{p}-\sqrt{q}\|^2 = \left[\sum_{i=1}^n(\sqrt{p_i}-\sqrt{q_i})^2\right]^{1/2}
 = \left[\sum_{i=1}^n(p_i+q_i) -2\sum_{i=1}^n\sqrt{p_iq_i}\right]^{1/2}.
$$
and define $d_H(p, q) = \frac{1}{\sqrt{2}}d(p,q) = \sqrt{{\rm Tr} \mathcal{A}(p,q) - {\rm Tr}\mathcal{G}(p,q)}$, where 
$\mathcal{A}(p,q)$ is the arithmetic mean of the vectors $p,q$, $\mathcal{G}(p,q)$ is their geometric mean.  

A matrix version of the Hellinger distance is extended on the set %$\mathcal{P}_n$ 
of $n \times n$   density matrices $A$ and $B$ such that $A, B > 0$ and ${\rm Tr}(A) = {\rm Tr}(B) = 1$ as follows:
$$
\widetilde{d_H}(A, B) = \left[{\rm Tr}\left(\frac{A + B}{2}\right) - {\rm Tr}(A\sharp B)\right]^{1/2} 
= \left[{\rm Tr}(A\nabla B) - {\rm Tr}(A\sharp B)\right]^{1/2} ,
$$
where $A \sharp B = A^{1/2}(A^{-1/2}BA^{-1/2})^{1/2}A^{1/2}$ is called the geometric mean of $A$ and $B$.
Note that $\widetilde{d_H}$ does not satisfy the triangle inequality in the metric axioms and when $AB = BA$, ${\rm Tr}(A \sharp B) = {\rm Tr}(A^{1/2}B^{1/2})$.  In \cite{BGJ  2019} 
they show that $\Phi_H(A, B) = \widetilde{d_H}(A,B)^2$ is a divergence on the set $\mathcal{P}_n$ of $n \times n$ positive definite matrices %\mathcal{P} =  \cup_{n\in\N}\mathcal{P}_n$ 
as in \cite[Sects 1.2 and 1.3]{SA 2016}.
%:A smooth function $\Phi$ from $\mathcal{P}_n \times \mathcal{P}_n$ to the set of nonnegative real numbers $\R_+$ is called a divergence if 
%\begin{enumerate}
%\item
%$\Phi(A, B) = 0$ if and only if $A=B$.
%\item
%The first derivative $D\Phi$ with respect to the second variable vanishes on the diagonal, that is, $D\Phi(A,X)|_{X=A} = 0$.
%\item
%The second derivative $D^2\Phi$ is positive on the diagonal, that is, 
%$D^2\Phi(A,X)|_{X=A}(Y,Y) \geq 0$ for all Hermitian $Y$. 
%\end{enumerate}

\vskip 2mm

In this talk we present the extended version of the above divergence as follows:

Let $\lambda \in (0, 1)$ and $\sigma$ be an operator mean in the sense of Kubo-Ando \cite{KA 1980} such that $!_\lambda \leq \sigma < \nabla_\lambda$. Let $g:[0,\infty) \rightarrow [0,\infty)$ be strictly increasing function such that $g^{-1}$ is operator monotone function on $(0, \infty)$. Then the quantity $\Phi_{g,\sigma}(X,Y) = {\rm Tr}(g(X\nabla_\lambda Y))-g(X\sigma Y))$ is a quantum divergence for $X,Y \in \mathcal{P}_n$.

This is a joint work with Trung Hoa Dinh, Anh Vu Le and Ngoc Yen Phan, and Hiroki Shudo.

\begin{thebibliography}{99}

\bibitem{SA 2016} S. Amari, 
\textit{Information Geometry and its Applications}, Springer, Tokyo (2016).


\bibitem{BGJ 2019} R. Bhatia, S. Gaubert and T. Jain,
\textit{Matrix versions of the Hellinger distance}, Letters in Mth. Phys. (2019), 109:1777-1804.

\bibitem{DLOP 2025} T. R. Dinh, A. V. Le, H. Osaka, and N. Y. P,
\textit{New quantum dyvergences generated by monotonicity inequality},
Math. Ineq. Appl. 28 (2025), no. 1, 143–157.

\bibitem{KA 1980} F. Kubo and T. Ando,
\textit{Means of positive monotone operators}, Math. Ann. 246 (1980), 205-244.

\bibitem{OS 2025} H. Osaka and H. Shudo, in preparation.

\end{thebibliography}
        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0322}{}\begin{ilasabstract}
\talktitle{A subspace-conjugate gradient method for linear matrix equations
}
    
\textbf{Davide Palitta}, \info{15:00\textrm{--}15:30 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0322}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    The efficient solution of large-scale multiterm linear matrix equations is a challenging task in numerical linear algebra, and it is a largely open problem. In this talk, a new iterative scheme for symmetric and positive definite operators is presented, significantly advancing methods such as truncated matrix-oriented Conjugate Gradients (CG). The new algorithm capitalizes on the low-rank matrix format of its iterates by fully exploiting the subspace information of the factors as iterations proceed. The approach implicitly relies on orthogonality conditions imposed over much larger subspaces than in CG, unveiling insightful connections with subspace projection methods. The new method is also equipped with memory-saving strategies. In particular, for a given matrix $Y$, the action $\mathcal{L}(Y)$ in low rank format may not be evaluated exactly due to memory constraints. This problem is often underestimated, though it will eventually produce Out-of-Memory breakdowns for a sufficiently large number of terms. We propose an ad-hoc randomized range-finding strategy that appears to fully resolve this shortcoming. Experimental results with typical application problems illustrate the potential of our approach over various methods developed in the recent literature.

This is a joint work with Martina Iannacito and Valeria Simoncini.

\end{ilasabstract}
    

\hypertarget{down0190}{}\begin{ilasabstract}
\talktitle{The importance of linear algebra
}
    
\textbf{JunJun Pan}, \info{14:00\textrm{--}14:30 @ SC3001 (June 24, Tuesday)} \hfill \hyperlink{up0190}{$\Uparrow$}
    
    
(in {\color{mstitle}MS18: New methods in numerical multilinear algebra})
        
\mtskip
    Linear algebra is a fundamental branch of mathematics that underpins numerous scientific and technological advancements. It provides essential tools for solving systems of equations, transforming geometric spaces, and analyzing data. With applications in engineering, computer science, physics, economics, and machine learning, linear algebra plays a crucial role in modern innovations, from image processing to artificial intelligence. 

\end{ilasabstract}
    

\hypertarget{down0305}{}\begin{ilasabstract}
\talktitle{Integrative co-embedding of multi-view data sets
}
    
\textbf{Haesun Park}, \info{11:00\textrm{--}11:30 @ SC4011 (June 26, Thursday)} \hfill \hyperlink{up0305}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    An integrative co-embedding method based on constrained low rank approximation is introduced. The method achieves knowledge fusion of multi-type data and projects the various types of objects onto a common lower-dimensional space. This produces a more informed representation that maintains both in-type and across-type semantic proximity between objects.
The effectiveness of the proposed method is illustrated using examples of document data clustering where we utilize co-embedding of papers, authors, key words, and patient profiling in healthcare data utilizing traditional medical records, as well as patients’ interactions via browsing and searching on healthcare web portals. One important feature of the proposed co-embedding method is its ability to compute embeddings for new, previously unobserved patient data efficiently and effectively, eliminating the need to revisit the entire data set or recomputing the embedding.  

\end{ilasabstract}
    

\hypertarget{down0328}{}\begin{ilasabstract}
\talktitle{On the numerical stability of compact Krylov methods}
    
\textbf{Javier Perez}, \info{14:00\textrm{--}14:30 @ SC1003 (June 26, Thursday)} \hfill \hyperlink{up0328}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    Computational methods like TOAR, CORK, and their variants help solve large polynomial, rational, and more generally, nonlinear eigenvalue problems. 
These methods apply (rational) Arnoldi to a matrix or pencil with a special Kronecker structure.
In this talk, I will present some results on the numerical stability of these methods and compare them to  (rational) Arnoldi applied without exploiting the Kronecker structure.
\end{ilasabstract}
    

\hypertarget{down0280}{}\begin{ilasabstract}
\talktitle{Linear preservers of rank one projections}
    
\textbf{Lucijan Plevnik}, \info{10:30\textrm{--}11:00 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0280}{$\Uparrow$}
    
    
(in {\color{mstitle}MS35: Preserver Problems, II})
        
\mtskip
    Let $\mathcal H$ be a complex Hilbert space and let ${\mathcal F}_{s}(\mathcal H)$ be the real vector space of all self-adjoint finite rank operators on $H$.
We will present the description of linear maps on ${\mathcal F}_{s}(\mathcal H)$ sending rank one projections to rank one projections.
Such maps are either induced by a linear or conjugate-linear isometry on $\mathcal H$ or constant on the set of rank one projections.

We will also discuss linear maps ${\mathcal F}_{s}(\mathcal H) \to {\mathcal F}_{s}(\mathcal K)$ sending rank one projections to projections of a fixed rank.
In the case $\dim \mathcal H = 2$, we will present the description of such maps, including a new kind of (injective) maps additionally to the previously mentioned one.
In the case $\dim \mathcal H = 3$, we will show by an example that such maps may be neither injective nor constant on the set of rank one projections.

\end{ilasabstract}
    

\hypertarget{down0229}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Jamie Pommersheim}, \info{16:00\textrm{--}16:30 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0229}{$\Uparrow$}
    
    
(in {\color{mstitle}MS30: Bohemian matrices: Theory, applications, and explorations})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0017}{}\begin{ilasabstract}
\talktitle{Linear preservers of parallel pairs}
    
\textbf{Edward Poon}, \info{11:30\textrm{--}12:00 @ SC0012 (June 23, Monday)} \hfill \hyperlink{up0017}{$\Uparrow$}
    
    
(in {\color{mstitle}MS12: Preserver problems, I})
        
\mtskip
    Two vectors $x$,$y$ in a normed space $(\mathcal{X}, \| \cdot \|)$ are said to be parallel if there exists a scalar $c$ with modulus 1 such that $\|x+c y\| = \|x\| + \|y\|$.
We consider the case of norms on a matrix space (in particular the Ky Fan $k$-norms and the $k$-numerical radius) and characterize the linear bijections on this matrix space which preserve parallel pairs of matrices.

\end{ilasabstract}
    

\hypertarget{down0048}{}\begin{ilasabstract}
\talktitle{Schur-Horn theorem and Ky Fan principle for symplectic eigenvalues
}
    
\textbf{Aedan Jarrod Potot}, \info{15:00\textrm{--}15:30 @ SC0009 (June 23, Monday)} \hfill \hyperlink{up0048}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    In matrix theory, the Schur and Horn theorems reveal that majorization
is the precise relationship between the diagonal entries and the eigenvalues
of a Hermitian matrix. Schur’s theorem is known to be equivalent to the
so-called Ky Fan principle. In 2015 and 2020, Bhatia and Jain proved the
Ky Fan principle and Schur-Horn theorem for symplectic eigenvalues. In
this study, it is shown that the symplectic analogues of Schur’s theorem and
the Ky Fan principle are equivalent. Moreover, the symplectic Schur-Horn
theorem is extended to generalized means.

\end{ilasabstract}
    

\hypertarget{down0394}{}\begin{ilasabstract}
\talktitle{Krylov subspace methods an the $\star$-algebra}
    
\textbf{Stefano Pozza}, \info{17:30\textrm{--}18:00 @ SC4011 (June 26, Thursday)} \hfill \hyperlink{up0394}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    \begin{bibunit}
        The $\star$-algebra \cite{Man24} has been successfully employed to solve a system of linear ODEs with time-dependent coefficients by transforming the ODE into a system of linear $\star$-equations \cite{BonPozVan23,GisPoz}. Many classical linear algebra methods and decomposition can be recovered in the $\star$-algebra. The recovered methods are a time-dependent version of the original ones. For example, the $\star$-Lanczos algorithm \cite{GisPoz} generalizes the (classical) non-Hermitian Lanczos algorithm and extends the well-known connections between matrix moments, and the Lanczos algorithm \cite{GolMeu,PozPraStr} to the time-dependent case.
The relation between the classical Krylov subspace methods and their $\star$-counterparts can be used as a way to compute the solution of ODEs by the $\star$-algebra approach and, vice versa, to analyze classical Krylov subspace methods for time-dependent matrices with possible applications to perturbed matrices.

\begin{thebibliography}{99}
\bibitem{BonPozVan23}
Bonhomme, C., Pozza, P., Van Buggenhout, N.:
A new fast numerical method for the generalized Rosen-Zener model. arXiv:2311.04144 [math.NA] (2023)

\bibitem{GisPoz}
Giscard, P-L., Pozza, S., A Lanczos-like method for non-autonomous linear ordinary differential equations. Boll. Unione Mat. Ital 16, 81--102 (2023)

\bibitem{GolMeu}
Golub, G.H., Meurant, G.: Matrices, Moments and Quadrature with Applications. Princeton University Press, Princeton (2010)

\bibitem{PozPraStr}
Pozza, S., Prani\'c, M.S., Strako\v s, Z.: Gauss quadrature for quasi-definite linear functionals. IMA J. Numer. Anal. 37(3), 1468--1495 (2017)

\bibitem{Man24}
Ryckebusch, M.: A Fr\'echet-Lie group on distributions. arXiv:2307.09037 [math.FA] (2024).

\end{thebibliography}
        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0199}{}\begin{ilasabstract}
\talktitle{Triangle counting and Bollob\'{a}s-Nikiforov conjecture.
}
    
\textbf{Shivaramakrishna Pragada}, \info{17:00\textrm{--}17:30 @ SC0008 (June 24, Tuesday)} \hfill \hyperlink{up0199}{$\Uparrow$}
    
    
(in {\color{mstitle}MS24: Nonnegative and related families of matrices})
        
\mtskip
    Let $G$ be a graph with $n$ vertices. Let $A(G)$ be its adjacency matrix. Let $\lambda_1(G), \lambda_2(G)$ denote the largest and second largest eigenvalues of the adjacency matrix. Bollob\'{a}s and Nikiforov (2007) conjectured that for any graph $G \neq K_n$ with $m$ edges
\[\lambda_1^2+\lambda_2^2\le \bigg( 1-\frac{1}{\omega(G)}\bigg)2m\]
where $\omega(G)$ denotes the clique number of $G$. In this talk, we prove this conjecture for graphs with not so many triangles, using the method of triangle counting. This is a joint work with Hitesh Kumar.

\end{ilasabstract}
    

\hypertarget{down0132}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Miklós Pálfia}, \info{10:30\textrm{--}11:00 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0132}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0149}{}\begin{ilasabstract}
\talktitle{Efficient Galerkin interpolative tensor train decomposition of high order tensors
}
    
\textbf{Jingmei Qiu}, \info{11:30\textrm{--}12:00 @ SC3001 (June 24, Tuesday)} \hfill \hyperlink{up0149}{$\Uparrow$}
    
    
(in {\color{mstitle}MS18: New methods in numerical multilinear algebra})
        
\mtskip
    High-dimensional functions and tensors frequently arise in scientific computing and data science, yet their low-rank representations are often obscured by noise and numerical instability. This work addresses the fundamental challenge of constructing accurate and robust tensor train (TT) decompositions without incurring the curse of dimensionality (CoD). We propose an efficient Galerkin interpolative framework that integrates a randomized range-finding strategy with adaptive pivot selection to identify low-dimensional structure in high-order tensors. Our method avoids explicit enumeration of the full tensor and leverages hierarchical structure to construct the TT format with near-optimal complexity. Despite its reduced computational cost, the proposed approach retains competitive accuracy, robustness, and stability compared to state-of-the-art full complexity algorithms. Numerical experiments demonstrate its effectiveness in capturing low-rank structure across a range of high-dimensional benchmark problems.

\end{ilasabstract}
    

\hypertarget{down0141}{}\begin{ilasabstract}
\talktitle{Idempotent alternating sign matrices}
    
\textbf{Rachel Quinlan}, \info{10:30\textrm{--}11:00 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0141}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    An alternating sign matrix (ASM) is a square $(0,1,-1)$-matrix in which the nonzero entries alternate between 1 and $-1$ and sum to 1, within each row and column. Permutation matrices are examples of ASMs, and ASMs generalize permutation matrices in several apparently natural but unexpected ways. Every multiplicative group of nonsingular ASMs is a group of permutation matrices, but the set of all $n\times n$ ASMs also contains multiplicative groups of singular matrices. The identity element $E$ of such a group is an idempotent ASM, it satisfies $E^2=E$. In this talk we will discuss some methods for construction of idempotent ASMs, and identify the minimum rank of an idempotent ASM of specified size. \\
This is joint work with Cian O'Brien.

\end{ilasabstract}
    

\hypertarget{down0293}{}\begin{ilasabstract}
\talktitle{Project work in an undergraduate linear algebra course}
    
\textbf{Rachel Quinlan}, \info{11:00\textrm{--}11:30 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0293}{$\Uparrow$}
    
    
(in {\color{mstitle}MS27: Linear algebra education})
        
\mtskip
    This talk will report on the work of some students in a free-form project
that was one component of assessment in an undergraduate linear algebra course taken by second year students at the University of Galway. Students were encouraged to connect their linear algebra knowledge to their other interests and to submit work in any medium of their choice. Submissions included work connected to education and lifelong learning, poetry, craftwork and the visual arts, along with many topics more prominently associated with linear algebra. The talk will share some highlights, and discuss some of the motivation for the inclusion of this project element and some of the learning outcomes for the instructor.


\end{ilasabstract}
    

\hypertarget{down0244}{}\begin{ilasabstract}
\talktitle{Exploring the numerical range of block Toeplitz operators}
    
\textbf{Brooke Randell}, \info{10:30\textrm{--}11:00 @ SC0009 (June 25, Wednesday)} \hfill \hyperlink{up0244}{$\Uparrow$}
    
    
(in {\color{mstitle}MS33: Norms of matrices, numerical range, applications of functional analysis to matrix theory})
        
\mtskip
    We will discuss the numerical range of a family of Toeplitz operators with symbol function \(\phi(z)=A_0+zA_1\), where \(A_0\) and \(A_1\) are \(2 \times 2\) matrices with complex-valued entries. A special case of a result proved by Bebiano and Spitkovsky in 2011 states that the closure of the numerical range of the Toeplitz operator \(T_{\phi(z)}\) is the convex hull of \(\{W(\phi(z)): z \in \partial \mathbb{D}\}\). Here, \(W(\phi(z))\) denotes the numerical range of \(\phi(z)\). We combine this result with the envelope algorithm to describe the boundary of the convex hull of \(\{W(\phi(z)): z \in \partial \mathbb{D}\}\). We also place specific conditions on the matrices \(A_0\) and \(A_1\) so that \(\{W(\phi(z)): z \in \partial \mathbb{D}\}\) is a set of potentially degenerate circular disks. The convex hull of \(\{W(\phi(z)): z \in \partial \mathbb{D}\}\) takes on a wide variety of shapes, including the convex hull of lima\c{c}ons.
\end{ilasabstract}
    

\hypertarget{down0278}{}\begin{ilasabstract}
\talktitle{On the generalizations of $q$-numerical range and radius}
    
\textbf{Jyoti Rani}, \info{11:00\textrm{--}11:30 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0278}{$\Uparrow$}
    
    
(in {\color{mstitle}MS33: Norms of matrices, numerical range, applications of functional analysis to matrix theory})
        
\mtskip
    Let $\mathcal{B(H)}$ be the $C^*$ algebra of all bounded linear operators acting on the Hilbert space $(\mathcal{H}, \langle .,. \rangle )$ equipped with the operator norm. For any $T \in \mathcal{B(H)}$, 
a generalization of the classical numerical range, namely $q$-numerical range was introduced by Marcus and Andresen in 1977 on $n$- dimensional unitary space. In 1984, the convexity of $q$-numerical range was proved by Nam-Kiu Tsing. The $q$-numerical range of $T \in \mathcal{B}(\mathcal{H})$ is defined by 
\[
W_q(T)=\{ \langle Tx,y \rangle: x,y \in H, \|x\|=\|y\|=1, \langle x,y \rangle=q \}.
\]
		And the $q$-numerical radius of $T \in B(\mathcal{H})$ is of the form
\[
			w_q(T)=\sup_{w \in W_q(T)}|w|.
\]
We introduce and examine the concept of the $q$-numerical range, namely, $q$-joint numerical range, for $n$-tuples of bounded linear operators in Hilbert spaces. We derive several inequalities related to the $q$-numerical radius of these operator tuples. Furthermore, we present a generalization of the $q$-numerical range of an operator $T \in \mathcal{B}(\mathcal{H})$ within the context of semi-Hilbertian spaces. Initially, we established the convexity properties of the $q$-numerical range within semi-Hilbertian space, followed by an examination of its relationship with the spectrum in the same context. We have derived several numerical-radius inequalities for the $q$-numerical radius in semi-Hilbertian space, which generalize numerous existing inequalities in the literature. 

Some part of this work has been jointly done with Dr. Arnab Patra, Dr. Kais Feki, Dr. Zakaria Taki.
\end{ilasabstract}
    

\hypertarget{down0356}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Vishwas Rao}, \info{16:30\textrm{--}17:00 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0356}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0182}{}\begin{ilasabstract}
\talktitle{Principal minors of tree distance matrices}
    
\textbf{Harry Richman}, \info{14:00\textrm{--}14:30 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0182}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    Suppose $D$ is the distance matrix of a tree. 
Graham and Pollack showed that the determinant of $D$ satisfies a surprising identity that depends only on the number of vertices in the given tree.
We generalize this result to a combinatorial identity for the determinant of any principal submatrix of $D$.
This new identity involves counts of spanning forests and is proved by use of potential-theoretic concepts on graphs.

\end{ilasabstract}
    

\hypertarget{down0284}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Albert Rico}, \info{11:00\textrm{--}11:30 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0284}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0193}{}\begin{ilasabstract}
\talktitle{Krylov techniques for estimating spectral gaps of sparse symmetric matrices}
    
\textbf{Michele Rinelli}, \info{13:30\textrm{--}14:00 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0193}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    We propose and analyze an algorithm for identifying spectral gaps of a real symmetric matrix $A$ by simultaneously approximating the traces of spectral projectors associated with multiple different spectral slices. Our method utilizes Hutchinson's stochastic trace estimator together with the Lanczos algorithm to approximate quadratic forms involving spectral projectors.\\
Instead of focusing on determining the gap between two particular consecutive eigenvalues of $A$, we aim to find all gaps that are wider than a specified threshold. By examining the problem from this perspective, and thoroughly analyzing both the Hutchinson and the Lanczos components of the algorithm, we obtain error bounds that allow us to determine the numbers of Hutchinson's sample vectors and Lanczos iterations needed to ensure the detection of all gaps above the target width with high probability.\\
We conclude that the most efficient strategy is to always use a single random sample vector for Hutchinson's estimator and concentrate all computational effort in the Lanczos algorithm. Our numerical experiments demonstrate the efficiency and reliability of this approach.

\end{ilasabstract}
    

\hypertarget{down0037}{}\begin{ilasabstract}
\talktitle{A multilinear Nyström algorithm for low-rank approximation of tensors in Tucker format}
    
\textbf{Leonardo Robol}, \info{11:00\textrm{--}11:30 @ SC3001 (June 23, Monday)} \hfill \hyperlink{up0037}{$\Uparrow$}
    
    
(in {\color{mstitle}MS18: New methods in numerical multilinear algebra})
        
\mtskip
    The Nystr\"om method offers an effective way to obtain low-rank approximation of SPD matrices and has been recently extended and analyzed to nonsymmetric matrices (leading to the generalized Nystr\"om method). It is a randomized, single-pass, streamable, cost-effective, and accurate alternative to the randomized SVD, and it facilitates the computation of several matrix low-rank factorizations. We take these advancements a step further by introducing a higher-order variant of Nystrom’s methodology tailored to approximating low-rank tensors in the Tucker format: the multilinear Nystr\"om technique. We show that, by introducing appropriate small modifications in the formulation of the higher-order method, strong stability properties can be obtained. This algorithm retains the key attributes of the generalized Nystr\"om method, positioning it as a viable substitute for the randomized higher-order SVD algorithm.
\end{ilasabstract}
    

\hypertarget{down0374}{}\begin{ilasabstract}
\talktitle{Row completion of polynomial and rational matrices and partial prescription of their  structure}
    
\textbf{Alicia Roca}, \info{17:30\textrm{--}18:00 @ SC1003 (June 26, Thursday)} \hfill \hyperlink{up0374}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    The matrix completion problem consists in characterizing the existence of a matrix with certain properties when a submatrix is prescribed.  It is an important problem in Matrix Theory.
Completion problems of matrices frequently arise in applications, for instance in structural changes of the dynamics of a system or in pole placement problems in control  theory. They also appear in solutions of perturbation problems. 
This work is devoted to the row completion problem for polynomial and rational matrices. 
We characterize the existence of a polynomial matrix when its complete structural data  (the invariant factors, the invariants orders at infinity, and the column and row minimal indices) and some of its rows are prescribed, allowing the completed matrix to increase the degree.
The same problem is solved for rational matrices.
We have also  solved the corresponding problem of partial prescription of the complete structural data covering  all of the possibilities. We will show here some cases.
Obviously, the results obtained hold for the corresponding column  completion problems.



\end{ilasabstract}
    

\hypertarget{down0313}{}\begin{ilasabstract}
\talktitle{Numerical linear algebra and optimization: the interplay between inner and outer iterations
}
    
\textbf{Fred Roosta}, \info{14:30\textrm{--}15:00 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0313}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    Newton-type methods offer key advantages over first-order optimization, including resilience to ill-conditioning, reduced sensitivity to hyper-parameters, superior local convergence, improved communication efficiency in distributed settings, and affine invariance. However, every iteration of these methods requires solving non-trivial subproblems--an aspect often overlooked. In this talk, we revisit examples of Newton-type methods, highlighting the role of iterative linear algebra subroutines in solving these subproblems, and show how leveraging their theoretical and empirical properties within the inner iterations can eliminate unnecessary safeguards and assumptions, resulting in simpler algorithms and analyses of the outer iterations.

\end{ilasabstract}
    

\hypertarget{down0162}{}\begin{ilasabstract}
\talktitle{Preservation of orthogonality by unitary and isometric dilations}
    
\textbf{Saikat Roy}, \info{14:00\textrm{--}14:30 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0162}{$\Uparrow$}
    
    
(in {\color{mstitle}MS12: Preserver problems, I})
        
\mtskip
    In this talk, we will focus on the orthogonality (in the sense of Birkhoff-James) relation of two contractions and that of their unitary (isometric) dilations. In particular, the theme of the talk is ``whether the orthogonality relation between two contractions is preserved by their unitary and isometric dilations." In the process, we consider the Sch\"{a}ffer unitary dilations, Ando dilation for a commuting pair of contractions and regular unitary dilations. In this direction, we construct the unitary dilation of a contraction and show that such kinds of unitary dilation preserve the orthogonality relation of two basic contractions.
\end{ilasabstract}
    

\hypertarget{down0269}{}\begin{ilasabstract}
\talktitle{Linear-time algorithm for finding the Frobenius normal form of symmetric Toeplitz matrices.}
    
\textbf{Homoon Ryu}, \info{11:00\textrm{--}11:30 @ SC3001 (June 25, Wednesday)} \hfill \hyperlink{up0269}{$\Uparrow$}
    
    
(in {\color{mstitle}MS11: Structured matrix computations and its applications})
        
\mtskip
    According to Chu and Ryu (2025), the Frobenius normal form of a symmetric Toeplitz matrix is a direct sum of irreducible symmetric Toeplitz matrices. 
In this talk, we present an algorithm which determines the blocks of the Frobenius normal form of a symmetric Toeplitz matrix. 
This algorithm can be implemented in $O(n)$-time where $n$ is the order of given symmetric Toeplitz matrix. 

\end{ilasabstract}
    

\hypertarget{down0069}{}\begin{ilasabstract}
\talktitle{A method for searching for a globally optimal k-partition of higher-dimensional datasets}
    
\textbf{Kristian Sabo}, \info{15:00\textrm{--}15:30 @ SC2006 (June 23, Monday)} \hfill \hyperlink{up0069}{$\Uparrow$}
    
    
(in {\color{mstitle}MS22: Linear algebra applications in computational geometry})
        
\mtskip
    Finding a globally optimal \( k \)-partition of a set is a highly complex optimization problem. In general, except for the special case of one-dimensional data (i.e., data with a single feature), no exact solution method exists. In the one-dimensional case, efficient methods leverage the fact that the problem can be reformulated as a global optimization task for a symmetric Lipschitz-continuous function, which can be solved using the global optimization algorithm DIRECT.   We propose a method for finding a globally optimal \( k \)-partition in the general case (\( n \)-dimensional data, \( n > 1 \)), extending an approach originally designed for solving Lipschitz global optimization for symmetric functions. Our method integrates a global optimization algorithm with linear constraints and the \( k \)-means algorithm. The global optimization component is used solely to generate a high-quality initial approximation for \( k \)-means.   We evaluated our approach on multiple artificial datasets and several benchmark examples from the UCI Machine Learning Repository. The results demonstrate that the proposed method is more efficient compared to some other methods from the literature. 
\end{ilasabstract}
    

\hypertarget{down0318}{}\begin{ilasabstract}
\talktitle{On linear preservers of semimonotone matrices}
    
\textbf{Manideepa Saha}, \info{15:00\textrm{--}15:30 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0318}{$\Uparrow$}
    
    
(in {\color{mstitle}MS35: Preserver Problems, II})
        
\mtskip
    A real square matrix $A$ is said to be {\it semimonotone} if for any entrywise nonnegative vector $x\neq 0$, there exists an index $i$ such that  $x_i$, the $i$-th entry of $x$, satisfies $x_i>0$ and $(Ax)_i\ge 0$, and $\mathbf{E}_{0}$ denotes the class of such matrices.  Semimonotone matrices are noteworthy because of their appearance in studying the linear complementarity problem (LCP), which plays an significant role in areas of  bimatrix games, linear programming, quadratic programming etc.   A linear  map $\mathcal{L}:\mathbb{R}^{n\times n}\to\mathbb{R}^{n\times n}$ is said to be an {\it$X$-(linear) preserver} if it preserves certain property $X$, that is, if $X\subset\mathbb{R}^{n\times n}$, then $\mathcal{L}(X)\subseteq X$. In case, $\mathcal{L}(X)= X$, then $\mathcal{L}$ is known as an {\it onto/strong $X$-(linear) preserver}. In this paper, we study strong/onto linear preservers of semimonotone  and almost semimonotone (all proper principal submatrices are semimonotone) matrices. In particular, we prove that an onto $\mathbf{E}_0$-preserver can be written as direct sum of monomial and generalized monominal matrices. We further characterize all strong/onto $\mathbf{E}_0$-preservers in terms of transposition, permutation similarity and positive diagonal equivalence transformations. At last, we provide three types of onto linear preservers that preservers almost semimonotone matrices.

\end{ilasabstract}
    

\hypertarget{down0366}{}\begin{ilasabstract}
\talktitle{Computing the nearest structured non-prime polynomial matrix: theory, algorithms, and numerical approaches}
    
\textbf{Tanay Saha}, \info{17:30\textrm{--}18:00 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0366}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    We first address the problem of computing the nearest non-prime polynomial matrix to a given left-prime polynomial matrix, without imposing structural constraints. This problem extends the classical task of finding the nearest non-coprime polynomials to a set of coprime polynomials. Our approach begins by establishing the equivalence between the left-primeness property of a polynomial matrix and the rank deficiency of a specific block Toeplitz matrix derived from the polynomial matrix. By leveraging this equivalence, we reformulate the problem as finding the nearest Structured Low-Rank Approximation (SLRA) to the associated block Toeplitz matrix, with a particular focus on cases where the leading coefficient matrix of the left-prime polynomial matrix has full row rank.

We further generalize the problem to compute a non-prime matrix that is as close as possible to a given left-prime polynomial matrix while preserving a predefined structural form. In this setting, the problem is again recast as computing the nearest SLRA of a structured matrix in case of full rank leading coefficient matrix. For computing SLRA, we employ numerical techniques such as the STLN method and regularized factorization, both of which are well-documented in the literature.

Additionally, we prove that it is possible to approximate a left-prime polynomial matrix with a rank-deficient leading coefficient matrix by a non-prime polynomial matrix, without adhering to the underlying structure. For cases involving structured coefficient matrices, we reformulate the problem as a constrained optimization task. By applying numerical optimization methods, we solve this optimization problem effectively.

Finally, we demonstrate the efficacy of our proposed algorithm with several numerical examples and compare the results with existing approaches in the literature wherever possible.
\end{ilasabstract}
    

\hypertarget{down0358}{}\begin{ilasabstract}
\talktitle{Efficient hyperparameter estimation in Bayesian inverse problems using sample average approximation
}
    
\textbf{Arvind Krishna Saibaba}, \info{17:30\textrm{--}18:00 @ SC0009 (June 26, Thursday)} \hfill \hyperlink{up0358}{$\Uparrow$}
    
    
(in {\color{mstitle}MS4: Linear algebra methods for inverse problems and data assimilation})
        
\mtskip
    In Bayesian inverse problems, it is common to consider several hyperparameters that define the prior and the noise model that must be estimated from the data. In particular, we are interested in linear inverse problems with additive Gaussian noise and Gaussian priors defined using Matérn covariance models. In this case, we estimate the hyperparameters using the maximum a posteriori (MAP) estimate of the marginalized posterior distribution. However, this is a computationally intensive task since it involves computing log determinants. To address this challenge, we consider a stochastic average approximation (SAA) of the objective function and use the preconditioned Lanczos method to compute efficient approximations of the function and gradient evaluations. We propose a new preconditioner that can be updated cheaply for new values of the hyperparameters and an approach to compute approximations of the gradient evaluations, by reutilizing information from the function evaluations. We demonstrate the performance of our approach on static and dynamic seismic tomography problems.

\end{ilasabstract}
    

\hypertarget{down0276}{}\begin{ilasabstract}
\talktitle{The $\phi_S$ polar decomposition when $S$ is skew-symmetric}
    
\textbf{Jenny Salinasan}, \info{11:30\textrm{--}12:00 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0276}{$\Uparrow$}
    
    
(in {\color{mstitle}MS31: Matrix decompositions and applications})
        
\mtskip
    Let $F$ be a field with characteristic not equal to $2$, and $S \in M_{2n}(F)$ be skew-symmetric $(S^{\top}=-S)$ and nonsingular.
Let $\phi_S$ be the function defined by $\phi_S(A)=S^{-1}A^{\top}S$ for all $A \in M_{2n}(F)$.
Suppose $A \in M_{2n}(F)$.
We say that $A$ is $\phi_S$-orthogonal if $A$ is nonsingular and $\phi_S(A)=A^{-1}$; and $A$ is $\phi_S$-symmetric if $\phi_S(A)=A$.
We say that $A$ has a $\phi_S$ polar decomposition if $A=XY$ for some $\phi_S$-orthogonal $X \in M_{2n}(F)$ and $\phi_S$-symmetric $Y \in M_{2n}(F)$.
We give necessary and sufficient conditions for an $X \in M_{2n}(F)$ to have a $\phi_S$ polar decomposition.
\end{ilasabstract}
    

\hypertarget{down0125}{}\begin{ilasabstract}
\talktitle{Convex matrix functions}
    
\textbf{Takashi Sano}, \info{11:30\textrm{--}12:00 @ SC0009 (June 24, Tuesday)} \hfill \hyperlink{up0125}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    I would like to talk about some topics related to convex matrix functions: 
Kraus matrices; conditionally negative semidefiniteness; inertia problems, strongly convex matrix functions, etc. 

\end{ilasabstract}
    

\hypertarget{down0307}{}\begin{ilasabstract}
\talktitle{On commutators of unipotent matrices of index $2$}
    
\textbf{Juan Paolo Santos}, \info{13:30\textrm{--}14:00 @ SC0008 (June 26, Thursday)} \hfill \hyperlink{up0307}{$\Uparrow$}
    
    
(in {\color{mstitle}MS31: Matrix decompositions and applications})
        
\mtskip
    A commutator of unipotent matrices of index $2$ is a matrix of the form $XYX^{-1}Y^{-1}$, where $X$ and $Y$ are unipotent matrices of index $2$, that is, $X \ne I_n$, $Y \ne I_n$, and $(X-I_n)^2=(Y-I_n)^2=0_n$. If $n>2$ and $\mathbb{F}$ is a field with $|\mathbb{F}| \geq 4$, then it is shown that every $n \times n$ matrix over $\mathbb{F}$ with determinant $1$ is a product of at most four commutators of unipotent matrices of index $2$. Consequently, every $n \times n$ matrix over $\mathbb{F}$ with determinant $1$ is a product of at most eight unipotent matrices of index $2$. Conditions on $\mathbb{F}$ are given that improve the upper bound on the commutator factors from four to three or two. The situation for $n=2$ is also considered. This study reveals a connection between factorability into commutators of unipotent matrices and properties of $\mathbb{F}$ such as its characteristic or its set of perfect squares.
\end{ilasabstract}
    

\hypertarget{down0303}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Michael Saunders}, \info{11:30\textrm{--}12:00 @ SC3001 (June 26, Thursday)} \hfill \hyperlink{up0303}{$\Uparrow$}
    
    
(in {\color{mstitle}MS16: Approximations and errors in Krylov-based solvers})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0030}{}\begin{ilasabstract}
\talktitle{Perfect codes and spectrum of graphs - a brief survey
}
    
\textbf{Lavanya Selvaganesh}, \info{12:00\textrm{--}12:30 @ SC1005 (June 23, Monday)} \hfill \hyperlink{up0030}{$\Uparrow$}
    
    
(in {\color{mstitle}MS15: Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham})
        
\mtskip
    Perfect codes have been key subject of study since the emergence of coding theory in the late 1940s, and they continue to garner considerable interest even after more than sixty years. Hamming and Golay codes are well-known perfect codes, and their significance to information theory is widely recognized. A \textit{code} in a graph $X=(V,E)$ is a non-empty subset of $V$. Given an integer $t\geq 1$, the ball with radius $t$ and centre $u \in V$ is defined as $B_t(u, X) := \{v \in V: d(u, v) \leq t\}$, where $d(u,v)$ is the distance in $X$ between $u$ and $v$. A code $C\subseteq V$ is called a \textit{perfect t-error-correcting code} or a \textit{perfect t-code} in $X$ if the balls $B_t(u, X)$ with radius $t$ and centres $u\in C$ form a partition of $V$. In graph theory, $B_t(u, X)$ is called the $t$-neighbourhood of $u$ in $X$, each vertex in $B_t(u, X)$ is said to be \textit{$t$-dominated} by$u$, a perfect $t$-code in $X$ is called a \textit{perfect t-dominating set} of $X$, and a perfect 1-code in $X$ is called an \textit{efficient dominating set} or \textit{independent perfect dominating set}. In this talk, our goal is to highlight the interplay between the perfect 1-codes and the eigenvalues of graphs. In particular, we focus on the spectrum of special classes of graphs such as Cayley graphs and circulant graphs, and characterize a perfect-1-code in such graphs.  
%Note that this vector has $n/2r$ entries $-(2r-1)$ as we need $(2r) |C| = n$ for $C$ being a perfect code. All other entries of this eigenvector are $1$, so the entry-sum is $0$. 


\end{ilasabstract}
    

\hypertarget{down0226}{}\begin{ilasabstract}
\talktitle{Exploring graph characterization via specialized matrices
}
    
\textbf{Lavanya Selvaganesh}, \info{16:30\textrm{--}17:00 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0226}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    Combinatorial matrix theory has found applications in various fields, particularly in spectral graph theory, which has many connections to areas such as chemistry and network analysis. Some of the well-studied objects in this context include the adjacency matrix, Laplacian matrix, signless Laplacian, and distance matrix. More recently, since 2013 and 2021, the eccentricity and neighborhood matrices, respectively, have garnered significant attention due  to several influential articles. A key aspect of spectral graph theory is identifying graphs that can be characterized by their matrix spectrum. We will present recent developments in the study of eccentricity and neighborhood matrices for special classes of graphs, including products of graphs, regular graphs, and multipartite graphs, among others. 

The eccentricity matrix of a connected graph $G$ is derived from its distance matrix by retaining only the largest nonzero entries in each row and column, setting all other entries to zero. This class of matrix was introduced as an application of graph theory to chemical structures.  It is well known that, unlike the distance and the adjacency matrix, the eccentricity matrix is not irreducible for all connected graphs, making it an important problem to identify classes of graphs for which it is irreducible. In this talk, we  investigate various properties of eccentricity matrix and their spectral characteristics. Expanding the scope, we delve into the irreducibility and spectrum of eccentricity matrix for some well-known families of \textit{distance-regular graphs}. 

The neighborhood matrix $\mathcal{NM}(G)$ of a graph $G$ is a graph matrix obtained by the product of adjacency and the Laplacian matrix and is also defined using the neighborhood sets of vertices of $G$. We show that the neighborhood matrix of a connected graph is irreducible.  We determine the $\mathcal{NM}$-eigenvalues of a complete multipartite graph and find that they are always real and non-positive. Moreover, the $\mathcal{NM}$-energy of a complete multipartite graph is twice the number of edges. Further, we show that no two complete multipartite graphs are $\mathcal{NM}$-cospectral.

\end{ilasabstract}
    

\hypertarget{down0016}{}\begin{ilasabstract}
\talktitle{Local order isomorphisms on operator and matrix domains}
    
\textbf{Peter Semrl}, \info{11:00\textrm{--}11:30 @ SC0012 (June 23, Monday)} \hfill \hyperlink{up0016}{$\Uparrow$}
    
    
(in {\color{mstitle}MS12: Preserver problems, I})
        
\mtskip
    Let $H_n$ denote the set of all $n\times n$ complex hermitian matrices and $S_n$ the set of all $n \times n$ real symmetric matrices. A subset $U \subset H_n$ ($U \subset S_n$) is called a matrix domain if it is open and connected. The general form of maps $\phi : U \to H_n$ ($\phi : U \to S_n$) preserving the usual Loewner order in both directions will be discussed. We will also treat the infinite-dimensional case.

\end{ilasabstract}
    

\hypertarget{down0157}{}\begin{ilasabstract}
\talktitle{Matrix trace inequalities related to quantum Tsallis relative entropies
}
    
\textbf{Yuki Seo}, \info{13:30\textrm{--}14:00 @ SC0009 (June 24, Tuesday)} \hfill \hyperlink{up0157}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    Let ${\mathbb M}_n = {\mathbb M}_n({\mathbb C})$ be the algebra of $n\times n$ complex matrices. For $\rho \in {\mathbb M}_n$, we write $\rho \geq 0$ if $\rho$ is positive semidefinite and $\rho >0$ if $\rho$ is positive definite. For two Hermitian matrices $\rho$ and $\sigma$ in ${\mathbb M}_n$, we write $\rho \geq \sigma$ if $\rho - \sigma \geq 0$, and $\rho > \sigma$ if $\rho - \sigma >0$. This is called the L\"{o}wner partial order for Hermitian matrices. Let ${\mathbb S}_n = {\mathbb S}_n({\mathbb C})$ be the set of all density matrices, which mean  positive definite matrices with trace one. The matrix $\alpha$-geometric mean of two positive definite matrices $\rho$ and $\sigma$ is defined by
\[
\rho\ \sharp_{\alpha}\ \sigma = \rho^{1/2}(\rho^{-1/2}\sigma \rho^{-1/2})^{\alpha}\rho^{1/2}\qquad \mbox{for $\alpha \in [0,1]$}.
\]
We use the notation $\natural_{\alpha}$ for the binary operation
\[
\rho\ \natural_{\alpha}\ \sigma = \rho^{1/2}(\rho^{-1/2}\sigma \rho^{-1/2})^{\alpha}\rho^{1/2}\qquad \mbox{for $\alpha \not\in [0,1]$},
\]
that has formula in common with $\sharp_{\alpha}$. Notice that the geodesic connecting two points on the differentiable manifold ${\mathbb P}_n$ of positive definite matrices is the matrix $\alpha$-geometric mean.\\
\quad In this talk, we show matrix trace inequalities related to two quantum Tsallis relative entropies of all real order: For density matrices $\rho$ and $\sigma$ in ${\mathbb S}_n$, and each $\alpha \in {\mathbb R}\backslash \{0\}$, the quantum Tsallis relative entropy ${\rm D}_{\alpha}(\rho|\sigma)$ due to Abe is defined by 
\[
{\rm D}_{\alpha}(\rho|\sigma)=-{\rm Tr}\left(\frac{\rho^{1-\alpha}\sigma^{\alpha}-\rho}{\alpha}\right)
\]
and $NT_{\alpha}(\rho | \sigma)$ due to Yanagi, Kuriyama and Furuichi is defined by 
\[
NT_{\alpha}(\rho|\sigma)=-{\rm Tr}\left(\frac{\rho\ \natural_{\alpha}\ \sigma-\rho}{\alpha}\right).
\]
If $\rho$ and $\sigma$ commute, then we have ${\rm D}_{\alpha}(\rho|\sigma)=NT_{\alpha}(\rho|\sigma)$. Then we show the order relation between two quantum Tsallis relative entropies $D_{\alpha}$ and $NT_{\alpha}$ of all real order $\alpha \in {\mathbb R}$ and a $1$-parameter extension of the path connecting them of all real order.\\
{\bf e-mail:} yukis@cc.osaka-kyoiku.ac.jp
\end{ilasabstract}
    

\hypertarget{down0215}{}\begin{ilasabstract}
\talktitle{Eigenvalue backward errors of Rosenbrock systems}
    
\textbf{Punit Sharma}, \info{17:00\textrm{--}17:30 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0215}{$\Uparrow$}
    
    
(in {\color{mstitle}MS14: Pencils, polynomial, and rational matrices})
        
\mtskip
    We address the problem of computing the eigenvalue backward error
of the Rosenbrock system matrix under various types of block perturbations.
%%We establish computable formulas for these backward errors 
We establish novel characterizations of these backward errors 
using a class of minimization problems involving the 
Sum of Two generalized Rayleigh Quotients (SRQ2). 
%
For computational purposes and analysis, we reformulate such optimization problems 
as minimization of a rational function over the
joint numerical range of three Hermitian matrices. 
%
This reformulation eliminates certain local minimizers of the
original SRQ2 minimization and allows for 
convenient visualization of the solution.
%
Furthermore, by exploiting the convexity within the joint numerical range,
we derive a characterization of the optimal solution %of the SRQ2 minimization 
using a Nonlinear Eigenvalue Problem with eigenvector dependency (NEPv).
%
Our numerical experiments demonstrate the benefits and effectiveness of 
the NEPv approach for SRQ2 minimization in computing eigenvalue backward
errors of Rosenbrock systems.
\end{ilasabstract}
    

\hypertarget{down0233}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Shih-Feng Shieh}, \info{16:00\textrm{--}16:30 @ SC3001 (June 24, Tuesday)} \hfill \hyperlink{up0233}{$\Uparrow$}
    
    
(in {\color{mstitle}MS11: Structured matrix computations and its applications})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0237}{}\begin{ilasabstract}
\talktitle{Lanczos with compression for symmetric matrix functions}
    
\textbf{Igor Simunec}, \info{16:00\textrm{--}16:30 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0237}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    In this talk we present a low-memory method for the approximation of the action of a symmetric matrix function $f(A)$ on a vector $b$, where the matrix $A$ is large and sparse. 
The algorithm that we propose combines the Lanczos method for $f(A) b$ with a basis compression procedure involving rational Krylov subspaces, which is employed whenever the basis grows beyond a certain size in order to reduce memory usage. 
This method has essentially the same convergence behaviour as Lanczos, with the addition of an error term that depends on rational approximation of the function $f$ and is typically negligible. 
The cost of the basis compression procedure is also negligible with respect to the cost of the Lanczos algorithm. In particular, the rational Krylov subspaces used for the compression of the Lanczos basis are built using small projected matrices, so their construction is cheap and does not require the expensive solution of linear systems with the matrix $A$. 
Numerical experiments demonstrate that our algorithm exhibits competitive performance when compared against other low-memory methods for $f(A) b$.

[1] A. A. Casulli and I. Simunec, A low-memory Lanczos method with rational Krylov compression for matrix functions, arXiv:2403.04390, 2024. To appear in SIAM J. Sci. Comput.

\end{ilasabstract}
    

\hypertarget{down0282}{}\begin{ilasabstract}
\talktitle{Linear maps preserving product of involutions}
    
\textbf{Sushil Singla}, \info{11:30\textrm{--}12:00 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0282}{$\Uparrow$}
    
    
(in {\color{mstitle}MS35: Preserver Problems, II})
        
\mtskip
    Let $M_n(\mathbb F)$ the algebra of $n \times n$ matrices over a field  $\mathbb F$.  A matrix $A\in M_n(\mathbb F)$ is said to be involution if $A^2=I$ (the identity matrix in $M_n(\mathbb F)$). Two interesting known facts about the product of involutions are as follows.\\ \\
 (a) A matrix in $  M_n(\mathbb F)$ is similar to its inverse if and only if it can be written as a product of two involutions in $M_n(\mathbb F)$.\\ \\
 (b) An element $X \in M_n(\mathbb F)$ has $\det(X) =\pm 1$ if and only if $X$ can be written as a product of at most four involutions from $M_n(\mathbb F)$. As a consequence, any matrix which is products of involutions can be written as product of at most four involutions.\\ \\
In this talk, we will investigate the bijective linear preservers of matrices in $M_n(\mathbb F)$, which are products of at most two, or three, or four involutions. This is a joint work with Chi-Kwong Li and Tejbir Lohan.


\end{ilasabstract}
    

\hypertarget{down0337}{}\begin{ilasabstract}
\talktitle{The $2$-Steiner distance and two other matrices associated to a tree}
    
\textbf{Krishnan Sivasubramanian}, \info{14:30\textrm{--}15:00 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0337}{$\Uparrow$}
    
    
(in {\color{mstitle}MS21: Linear algebra techniques in graph theory})
        
\mtskip
    Let $T$ be a tree with vertex set $V(T)=\{1,2,\ldots,n\}$. 
The Steiner distance of $S\subseteq V(T)$ of vertices
of $T$ is defined to be the number of edges in a smallest 
connected subtree of $T$ that contains all the vertices of $S$. 
The 2-Steiner distance matrix ${\mathfrak{D}}_k(T)$ of $T$ is the 
$\binom{n}{2}\times \binom{n}{2}$ matrix whose rows 
and columns are indexed by subsets of vertices of size $2$.
The entry in the row indexed by $P$ and column indexed 
by $Q$ is equal to Steiner distance of $P \cup Q$. 

%Your abstract goes here\dots The citation can be done using \verb|\cite{key}| and this will result the respective number in the reference list, Eg.\cite{einstein}.

We show that ${\mathrm{rank}}({\mathfrak{D}}_2(T)) = 2n -p - 1$ 
where $p$ is the number of pendant vertices (or leaves) in $T$.
We construct a basis ${\mathfrak{B}}$ for the row space of ${\mathfrak{D}}_2(T)$ and obtain 
a formula for the inverse of the nonsingular square submatrix 
${\mathfrak{D}}={\mathfrak{D}}_2(T)[{\mathfrak{B}},{\mathfrak{B}}]$.  We also compute the determinant of 
${\mathfrak{D}}$ and show that its absolute value is independent of the 
structure of $T$. % and 
%apply it to obtain the inertia of ${\mathfrak{D}}_2(T)$.  

Two other matrices associated to Buneman's 
Four point condition (4PC) about distances in a tree $T$ 
are the ${\mathrm{Min}}_T$ and ${\mathrm{Max}}_T$.  These are also $\binom{n}{2} 
\times \binom{n}{2}$ matrices.  The entry in the row
indexed by $\{x,y\}$ and column $\{p,q\}$ equals the 
minimum or the maximum of the set $D_{p,q,x,y} = \{d_{x,y} + d_{p,q},
d_{x,p} + d_{y,q}, d_{x,q} + d_{y,p} \}$.  We show for 
all trees $T$, that
${\mathfrak{D}}_2(T) = 1/2({\mathrm{Min}}_T + {\mathrm{Max}}_T)$ and give our results on these three 
matrices.
\end{ilasabstract}
    

\hypertarget{down0186}{}\begin{ilasabstract}
\talktitle{Randomized Riemannian submanifold subgradient method for optimization over Stiefel manifold}
    
\textbf{Anthony Man-Cho So}, \info{14:00\textrm{--}14:30 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0186}{$\Uparrow$}
    
    
(in {\color{mstitle}MS32: Advances in matrix manifold optimization})
        
\mtskip
    In this talk, we present the randomized Riemannian submanifold subgradient method (RSSM), a lightweight ``block-coordinate''-type algorithm for weakly convex optimization over the Stiefel manifold. We show that RSSM finds an $\epsilon$-nearly stationary point in $O(\epsilon^{-4})$ iterations. To the best of our knowledge, this is the first convergence guarantee of a coordinate-type algorithm for tackling non-convex non-smooth optimization over the Stiefel manifold.

This is joint work with Andy Yat-Ming Cheung, Jinxin Wang, and Man-Chung Yue.

\end{ilasabstract}
    

\hypertarget{down0325}{}\begin{ilasabstract}
\talktitle{Formal orthogonal systems}
    
\textbf{Wasin So}, \info{14:30\textrm{--}15:00 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0325}{$\Uparrow$}
    
    
(in {\color{mstitle}MS34: Combinatorics, association scheme, and graphs})
        
\mtskip
    Dreaming of an effective way to generate orthogonal bases in ${\bf R}^n$, 
we study  formal orthogonal systems which are  collections of nonzero $n \times n$  real matrices 
\[ \{A_0=I_n, A_1, A_2, \ldots,A_{n-1}\}\]
such that $\{A_0x, A_1x,A_2x,\cdots,A_{n-1}x\}$
 is an orthogonal set for all $x$ in ${\bf R}^n$. We prove that 
 formal orthogonal systems of order $n$ exist if and only if $n=1, 2,4,$ or  $8$.
 The proof has an unexpected connection to the famous results of Adolf Hurwitz
  on the product of two sums of $n$ squares.
 
 \vspace{.3in}
 
 Joint work with Ardak Kapbasov and Shaunak Mashalkar.
\end{ilasabstract}
    

\hypertarget{down0020}{}\begin{ilasabstract}
\talktitle{Tensor train completion of multiway data observed in a single mode}
    
\textbf{Shakir Showkat Sofi}, \info{11:30\textrm{--}12:00 @ SC0014 (June 23, Monday)} \hfill \hyperlink{up0020}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    \begin{bibunit}
        Tensor completion is an extension of matrix completion aimed at recovering a partially observed data tensor by leveraging the observations and the pattern of observation. Completion is more important for tensors than for matrices for several reasons. Higher-order datasets are larger, increasing the likelihood of missing or unreliable entries. Large-scale data often exhibits low-rank properties (intuitively, not every entry is ``equally important,'' unlike in smaller matrices). Many interesting problems can be framed as instances of low-rank tensor completion, including image and video recovery, collaborative filtering, and quantum state tomography \cite{liu2013tc, gross2010quantum}. Low-rank tensor completion is generally solved via convex optimization techniques. Current theories concerning these methods often study probabilistic recovery guarantees under conditions such as random uniform observations and incoherence requirements \cite{candes2009exact, liu2013tc}. However, if an observation pattern has some structure, more efficient algorithms can be developed by leveraging the structure.\par

Algebraic methods exploit the low-rank structure to design algorithms that rely solely on standard numerical linear algebra (NLA) operations. They are fast and are guaranteed to work under reasonable deterministic conditions on the observation pattern. In this line, a specific type of ``fiber-wise'' observation pattern has been discussed, where some of the fibers of a tensor (along a specific mode) are either fully observed or entirely missing, unlike the usual entry-wise observations. This observation is interesting because it appears in many real-life applications and highlights a key difference between matrices and tensors. While missing fibers (rows or columns) in a matrix make completion underdetermined, higher-order tensors can still be completed even if some fibers are entirely missing along one mode. It has been shown that under reasonable conditions, canonical polyadic decomposition (CPD) and multilinear singular value decomposition (MLSVD) of such an incomplete tensor can still be obtained using only standard NLA \cite{mikael2019fibersamp, stijn2023mlsvdfsj}. Note that there is an important difference with the technique of cross or skeleton approximation in the sense that we assume the availability of fibers in one mode only. \par

With the increasing prevalence of big data, the demand for reliable and scalable algorithms has become more pressing. The tensor train (TT) decomposition is stable and can break the curse of dimensionality \cite{oseledets2010tensortrain}. This talk shows how to extend the fiber-wise completion to the TT format. We discuss the deterministic conditions under which the uniqueness of the solution is guaranteed \cite{stijn2023mlsvdfsj, shakir2024ttfw}. Furthermore, we discuss a few interesting applications and briefly highlight the possibility of utilizing this tensor completion framework as a fundamental experimental primitive for efficient quantum state tomography with fewer measurements.

\begin{thebibliography}{7}
\bibitem{liu2013tc} J. Liu, P. Musialski, P. Wonka, and J. Ye. Tensor Completion for Estimating Missing Values in Visual Data. \textit{IEEE Trans. Pattern Anal. Mach. Intell.}, 35:208--220, 2013.

\bibitem{gross2010quantum} D. Gross, Y. K. Liu, S. T. Flammia, S. Becker, and J. Eisert. Quantum State Tomography via Compressed Sensing. \textit{Phys. Rev. Lett.}, 105(15):150401, 2010. APS.

\bibitem{candes2009exact} E. J. Cand{\`e}s and B. Recht. Exact Matrix Completion via Convex Optimization. \textit{Found. Comput. Math.}, 9(6):717--772, 2009. Springer.


\bibitem{mikael2019fibersamp} M. S{\o}rensen and L. De Lathauwer. Fiber Sampling Approach to Canonical Polyadic Decomposition and Application to Tensor Completion. \textit{SIAM J. Matrix Anal. Appl.}, 40:888--917, 2019.

\bibitem{stijn2023mlsvdfsj} M. S{\o}rensen, S. Hendrikx, and L. De Lathauwer. Multilinear Singular Value Decomposition Based Completion with Fibers Observed in a Single Mode. \textit{SIAM J. Matrix Anal. Appl.}, 2025. [Accepted for publication], \url{https://ftp.esat.kuleuven.be/pub/stadius//shendrik/hendrikx2023mlsvdfibersimax.pdf}.

\bibitem{oseledets2010tensortrain} I. Oseledets. Tensor-Train Decomposition. \textit{SIAM J. Sci. Comput.}, 33:2295--2317, 2011.

\bibitem{shakir2024ttfw} S. S. Shakir, S. Hendrikx, and L. De Lathauwer. Tensor Train Completion of Multi-Way Data Observed Along One Mode. In \textit{Proc. 32nd EUSIPCO}, pages 1067--1071, 2024. IEEE.
\end{thebibliography}
        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0301}{}\begin{ilasabstract}
\talktitle{Numerical algorithms for matrix functions using the double exponential formulas
}
    
\textbf{Tomohiro Sogabe}, \info{10:30\textrm{--}11:00 @ SC3001 (June 26, Thursday)} \hfill \hyperlink{up0301}{$\Uparrow$}
    
    
(in {\color{mstitle}MS16: Approximations and errors in Krylov-based solvers})
        
\mtskip
    Matrix functions play a critical role in various scientific fields, including quantum chromodynamics, large-scale electronic structure calculations, and quantum information science. In this talk, we present our recent work on numerical algorithms for computing matrix functions---specifically, the matrix logarithm, matrix fractional powers, and matrix exponential---based on the double exponential (DE) formula.


\end{ilasabstract}
    

\hypertarget{down0027}{}\begin{ilasabstract}
\talktitle{Model reduction and matrix compression in dictionary learning applications}
    
\textbf{Erkki Somersalo}, \info{12:00\textrm{--}12:30 @ SC1003 (June 23, Monday)} \hfill \hyperlink{up0027}{$\Uparrow$}
    
    
(in {\color{mstitle}MS26: Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics})
        
\mtskip
    Dictionary learning and matching is an attractive way to solve numerically inverse problems in which the forward model is too complex to be used in the inversion process.
Dictionary matching problems lead often to very large underdetermined problems, and dictionary compression is therefore desired. In this talk, we propose a dictionary
compression method that leverages ideas from Bayesian inverse problems with sparsity promoting priors, and takes advantage of the structure of the underlining matrix to design computationally efficient algorithms.

\end{ilasabstract}
    

\hypertarget{down0175}{}\begin{ilasabstract}
\talktitle{GLT-based preconditioning for nonsymmetric Toeplitz systems}
    
\textbf{Rosita Luisa Sormani}, \info{14:30\textrm{--}15:00 @ SC1003 (June 24, Tuesday)} \hfill \hyperlink{up0175}{$\Uparrow$}
    
    
(in {\color{mstitle}MS19: Explicit and hidden asymptotic structures, GLT Analysis, and applications})
        
\mtskip
    \begin{bibunit}
        Preconditioning for Toeplitz systems has been a prominent area of research for several decades, with many efficient preconditioners available in the real symmetric or Hermitian case. However, the real nonsymmetric setting remains less explored due to the challenges associated with analyzing the eigenvalues and, consequently, the convergence behavior of iterative solvers. To address this, we employ a symmetrization technique that permutes the coefficient matrix into a real symmetric Hankel structure, whose eigenvalue distribution is known. Then, by leveraging Generalized Locally Toeplitz (GLT) theory, we develop a novel preconditioning strategy that involves centrosymmetric preconditioners, such as those derived from the $\tau$ algebra. This approach constitutes a general framework, as it relies solely on the generating function of the Toeplitz matrix, provided that it is defined. We extend all theoretical results to both the multilevel and block settings and demonstrate their effectiveness through numerical experiments on space-fractional diffusion equations, providing several examples to critically evaluate the performance of the proposed preconditioners.

\begin{thebibliography}{2}
\bibitem{1}
C. Garoni, S. Serra-Capizzano, \emph{Generalized locally Toeplitz sequences: theory and applications, vol. II}. Springer, Cham, 2018.
\bibitem{2}
S.Y. Hon, C. Li, R.L. Sormani, R. Krause, S. Serra-Capizzano, \emph{Symbol-based multilevel block $\tau$ preconditioners for multilevel block Toeplitz systems: GLT-based analysis and applications}. SIAM J. Matrix Anal. Appl., to appear
\end{thebibliography}

        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0386}{}\begin{ilasabstract}
\talktitle{Commutation principles for optimization problems involving strictly Schur-convex functions in Euclidean Jordan algebras
}
    
\textbf{David Sossa}, \info{17:30\textrm{--}18:00 @ SC2006 (June 26, Thursday)} \hfill \hyperlink{up0386}{$\Uparrow$}
    
    
(in {\color{mstitle}MS28: From matrix theory to Euclidean Jordan algebras, FTvN systems, and beyond})
        
\mtskip
    In this talk, we present several commutation principles for optimizers of shifts of spectral functions in the context of Euclidean Jordan Algebras (EJAs). For instance, we show that under certain assumptions, if $\bar x$ is a (local) optimizer of $F(x-a)$ for $x\in\Omega$, where $\Omega\subset \mathcal V$ is a spectral set of an EJA $\mathcal V$, $a\in \mathcal V$ and $F:\mathcal V\rightarrow \mathbb{R}$ is a strictly Schur-convex spectral function, then $a$ and $\bar x$ operator commute. We make no further assumption on the smoothness of $F$; instead, we take advantage of the smoothness (Lie structure) of the Automorphism group of $\mathcal V$ and make use of majorization techniques for the eigenvalues of elements in EJAs. Our approach allows us to deal with several problems considered in the literature, related to strictly convex spectral functions and strictly convex spectral norms. In particular, we use our commutation principles to analyze the problem of minimizing the condition number in EJAs.
\end{ilasabstract}
    

\hypertarget{down0334}{}\begin{ilasabstract}
\talktitle{Bridging abstract and numerical linear algebra}
    
\textbf{Sepideh Stewart}, \info{15:00\textrm{--}15:30 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0334}{$\Uparrow$}
    
    
(in {\color{mstitle}MS27: Linear algebra education})
        
\mtskip
    Linear algebra is a key mathematics topic applicable to many other fields. Hence, equipping students with knowing linear algebra well with the ability to tackle problems numerically is an excellent way of preparing them for the future wo\
rkforce.  In this talk, we will discuss the importance of teaching both abstract and numerical linear algebra in our classrooms. We will discuss ways to transform an existing abstract linear algebra into a course that includes numerical \
linear algebra, as well as create a new course. Deciding to balance the amount of theory and computation is a challenge we often face in our lectures.  We will address some challenges of creating such courses and ways to combat them.
We welcome your input and invite you to join us as we continue this work. This is a joint work with Rachel Quinlan and Mike Michailidis.
\end{ilasabstract}
    

\hypertarget{down0323}{}\begin{ilasabstract}
\talktitle{On $(2s-1)$-designs with $s$-distances in the Hamming association schemes
}
    
\textbf{Sho Suda}, \info{13:30\textrm{--}14:00 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0323}{$\Uparrow$}
    
    
(in {\color{mstitle}MS34: Combinatorics, association scheme, and graphs})
        
\mtskip
    It was shown by Delsarte that a $(2s-2)$-design with $s$-distances in a Hamming association scheme 
induces an $s$-classes association scheme. 
In this talk, we prove that a $(2s-1)$-design with $s$-distances gives rise to a $2s$- 
or $(2s-1)$-classes fission association scheme. 
As a corollary, a new necessary condition for the existence of tight $3$-design in the Hamming association schemes is obtained. 
This talk is based on joint work with Alexander Gavrilyuk. 

\end{ilasabstract}
    

\hypertarget{down0387}{}\begin{ilasabstract}
\talktitle{Generalized minimal residual method with flexible Arnoldi process}
    
\textbf{Sofia Sukmaniuk}, \info{16:00\textrm{--}16:30 @ SC3001 (June 26, Thursday)} \hfill \hyperlink{up0387}{$\Uparrow$}
    
    
(in {\color{mstitle}MS16: Approximations and errors in Krylov-based solvers})
        
\mtskip
    We present an extension of the Arnoldi process for subspaces \({\mathcal L}_k\) with a chain \({\mathcal L}_{i-1} \subset {\mathcal L}_i\), for \(i = \overline{2 \dots k}\). As it takes place in the Arnoldi process, it produces an orthonormal basis for \({\mathcal L}_k + A {\mathcal L}_k\), where the basis for \({\mathcal L}_k\) is formed by its first \(\dim {\mathcal L}_k\) vectors. Moreover, the basis for \({\mathcal L}_i\) is represented using the first \(\dim {\mathcal L}_i\) vectors of the basis for \({\mathcal L}_k\), for all \(i = \overline{1 \dots k}\). This enhancement enables a universal GMRES extension, where ${\mathcal L}_k$ and $A{\mathcal L}_k$ greatly coincide.  The extension is suitable for systems with multiple right-hand sides, allowing dynamic block size changes and on-the-fly integration of new right-hand sides. It also supports deflated restarts with any selected deflation strategy and a flexible preconditioner. Since all essential bases are compactly represented within a common basis, memory and computational demands are minimal relative to constructing the common basis.

% The GMRES method for solving linear systems $Ax=b$, $A \in \C^{N \times N}$, $b \in \C^{N}$ effectively implements the idea of approximating the solution in a Krylov subspace $\K_k$ through minimizing  the current residual over the subspace $A\K_k$. It is done through construction of the common basis of $\K_k+ A\K_k = \K_{k+1}$ with the Arnoldi process.
% Meanwhile, a variety of GMRES extensions(flexible, deflated versions) use search spaces $\L_k$ that  do not constitute a Krylov subspace. However, $\Dim \L_k$ + $\Dim A\L_k$ exceeds greatly $\Dim (\L_k + A\L_k)$. For this reason we developed a mechanism that constructs the common basis of $A\L_k + \L_k$ for a general case of $\L_k$. With this, we developed the GMRES method extension with the following properties: (1) flexible preconditioning can be applied, (2)  different deflation strategies for restarting can be implemented effectively with the common basis, (3) systems with multiple right-hand sides $Ax^{(s)} = b^{(s)}$, $b \in \C^{N}$, $s=\overline{1, M}$ can be solved one-by one, (4) systems with multiple right-hand sides can be solved 

 

\end{ilasabstract}
    

\hypertarget{down0326}{}\begin{ilasabstract}
\talktitle{Power difference sets and cyclotomic matrices}
    
\textbf{Wei-Liang Sun}, \info{15:00\textrm{--}15:30 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0326}{$\Uparrow$}
    
    
(in {\color{mstitle}MS34: Combinatorics, association scheme, and graphs})
        
\mtskip
    A difference set in a finite field is a subset where every nonzero element can be expressed as the difference of two elements from the subset, each occurring a fixed number of times. Every difference set gives rise to a symmetric balanced incomplete block design.

In 1933, R. Paley characterized when a set of squares forms a difference set. Later, S. Chowla extended this result to fourth powers. A difference set formed by $\ell$-th powers is called a power difference set. A natural question is whether all $\ell$-th power difference sets can be characterized. However, so far, researchers have only been able to construct such sets for $\ell = 2, 4, 8$ when $\ell \leq 24$, and it is conjectured that no other power difference sets exist.

Cyclotomic numbers captures the sizes of certain subsets intersections in a finite field. These numbers provide crucial information about the existence of a power difference set. The cyclotomic matrix is a matrix whose entries are cyclotomic numbers. By exploring properties of the cyclotomic matrix, we are able to conclude that if a power difference set exists, and if the size of elements outside the set is a square, then $\ell$ is congruent to $0$ or $2$ modulo $8$. This result holds for a power difference set that forms a finite projective plane. In contrast, our result allows for discussing an infinite number of $\ell$ values, extending the scope of previous finite cases. As far as we know, this may be the first application of cyclotomic matrices to power difference sets.

\end{ilasabstract}
    

\hypertarget{down0036}{}\begin{ilasabstract}
\talktitle{Riemannian gradient descent for spherical area-preserving mappings
}
    
\textbf{Marco Sutti}, \info{12:00\textrm{--}12:30 @ SC2006 (June 23, Monday)} \hfill \hyperlink{up0036}{$\Uparrow$}
    
    
(in {\color{mstitle}MS22: Linear algebra applications in computational geometry})
        
\mtskip
    We propose a new Riemannian gradient descent method for computing spherical area-preserving mappings of topological spheres using a Riemannian retraction-based framework with theoretically guaranteed convergence.
The objective function is based on the stretch energy functional, and the minimization is constrained on a power manifold of unit spheres embedded in three-dimensional Euclidean space.
Numerical experiments on several mesh models demonstrate the accuracy and stability of the proposed framework. Comparisons with three existing state-of-the-art methods for computing area-preserving mappings demonstrate that our algorithm is both competitive and more efficient. Finally, we present a concrete application to the problem of landmark-aligned surface registration of two brain models. This is joint work with Mei-Heng Yueh.

\end{ilasabstract}
    

\hypertarget{down0250}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Raymond Sze}, \info{10:30\textrm{--}11:00 @ SC0014 (June 25, Wednesday)} \hfill \hyperlink{up0250}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0339}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Daniel B. Szyld}, \info{13:30\textrm{--}14:00 @ SC2006 (June 26, Thursday)} \hfill \hyperlink{up0339}{$\Uparrow$}
    
    
(in {\color{mstitle}MS13: Advances in QR factorizations})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0061}{}\begin{ilasabstract}
\talktitle{Expansion and the normalized distance Laplacian matrix}
    
\textbf{Michael Tait}, \info{14:00\textrm{--}14:30 @ SC1005 (June 23, Monday)} \hfill \hyperlink{up0061}{$\Uparrow$}
    
    
(in {\color{mstitle}MS15: Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham})
        
\mtskip
    The normalized distance Laplacian of a graph $G$ is defined as $\mathcal{D}^\mathcal{L}(G)=T(G)^{-1/2}(T(G)-\mathcal{D}(G))T(G)^{-1/2}$ where $\mathcal{D}(G)$ is the matrix with pairwise distances between vertices and $T(G)$ is the diagonal transmission matrix. We discuss the spectral gap of this matrix and the related distance Cheeger constant. Contrary to the classical case, both of these quantities are bounded away from $0$. We characterize graphs with minimal distance Cheeger constant and we make a conjecture about graphs with minimal spectral gap. 
 
This is joint work with John Byrne, Jacob Johnston, and Carl Schildkraut.
\end{ilasabstract}
    

\hypertarget{down0178}{}\begin{ilasabstract}
\talktitle{Extremal problems on graphs with $q=2$}
    
\textbf{Michael Tait}, \info{14:00\textrm{--}14:30 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0178}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    For a graph $G$, let $q(G)$ denote the minimum number of distinct eigenvalues over all symmetric matrices with the same zero/nonzero pattern as $G$, with the diagonal free (this family of matrices denoted $\mathcal{S}(G)$). A graph has $q(G) = 2$ if and only if there is an orthogonal matrix in $\mathcal{S}(G)$. We discuss extremal problems on graphs with $q(G)=2$. In particular we consider how sparse such graphs or their complements can be.

This is joint work with Wayne Barrett, Shaun Fallat, Vera Furst, Shahla Nasserasr, and Brendan Rooney.


\end{ilasabstract}
    

\hypertarget{down0227}{}\begin{ilasabstract}
\talktitle{On the maximal $A_\alpha$-index of graphs with a prescribed number of edges}
    
\textbf{Bit-Shun Tam}, \info{17:00\textrm{--}17:30 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0227}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    \noindent  For any real number $\alpha\in [0,1]$, by the {\it
$A_\alpha$-matrix} of a graph $G$ we mean the matrix
$A_{\alpha}(G)=\alpha D(G)+(1-\alpha)A(G)$, where $A(G)$ and $D(G)$
are the adjacency matrix and the diagonal matrix of vertex degrees
of $G$, respectively. The largest eigenvalue of $A_{\alpha}(G)$ is
called the $A_\alpha$-index of $G$. Chang and Tam (2023) have solved
the problem of determining graphs with maximal $A_{\alpha}$-index
over $\mathcal{G}(n,m)$, the class of graphs with $n$ vertices and
$m$ edges, for $\alpha \in [\frac{1}{2},1)$ and $1\le m\le 2n-3$. In
the same paper, they posed the problem of characterizing graphs in
$\mathcal{G}(n,m)$ that maximize the $A_{\alpha}$-index for $0<
\alpha < \frac{1}{2}$ and $m\le n-1$. In this work, it is noted
that, for any $\alpha\in [0,1)$, the problem of characterizing
graphs with maximal $A_{\alpha}$-index over $\mathcal{G}(n,m)$ with
$m\le n-1$ is equivalent to the problem of characterizing graphs
with maximal $A_{\alpha}$-index over $\mathscr{S}(m)$, the class of
graphs with $m$ edges. In connection with the latter problem, we
pose the following conjecture: Let $m\ge 3$ be a positive integer
and suppose that $m={\binom{d}{2}}+t$ with $0\le t < d$. There exists
a real number $\alpha_0$, $\alpha_0=\frac{1}{2}$ for $m=3$ and
$\alpha_0\in [0,\frac{1}{2})$ for $m\ge 4$, such that for any
$\alpha \in [0,1)$, $C^m_{d+1}$ (replaced by $K_d$, in case $t=0$),
where $C^m_n$ denotes the quasi-complete graph with $n$ vertices and
$m$ edges, or $K_{1,m}$ is the unique connected graph with $m$ edges
that maximize the $A_{\alpha}$-index over $\mathscr{S}(m)$,
depending on whether $\alpha\in [0,\alpha_0)$ or $\alpha\in
(\alpha_0,1)$; when $\alpha = \alpha_0$, there are exactly two
connected graphs that maximize the $A_{\alpha}$-index over
$\mathscr{S}(m)$, namely, $C^m_{d+1}$ (or $K_d$, in case $t=0$) and
$K_{1,m}$. The conjecture is established when $t=0$.

\vspace{2mm} \noindent{\it Keywords}\,: Maximal $A_{\alpha}$-index
problem; Maximal graph; Threshold graph; Neighborhood equivalence
classes; Quasi-complete graphs; Quasi-stars.
 \vspace{2mm}

\noindent{AMS subject classification:} 05C35,\ 05C50
\end{ilasabstract}
    

\hypertarget{down0255}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Tin-Yau Tam}, \info{11:30\textrm{--}12:00 @ SC1001 (June 25, Wednesday)} \hfill \hyperlink{up0255}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0161}{}\begin{ilasabstract}
\talktitle{On homeomorphisms between geometric structure spaces of primitive $C^*$-algebras}
    
\textbf{Ryotaro Tanaka}, \info{13:30\textrm{--}14:00 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0161}{$\Uparrow$}
    
    
(in {\color{mstitle}MS12: Preserver problems, I})
        
\mtskip
    The notion of geometric structure spaces of Banach spaces was introduced for classifying non-smooth Banach spaces under Birkhoff-James isomorphisms. The geometric structure space $\mathfrak{S}(X)$ of a Banach space $X$ reflects the geometric features of the unit ball $B_X$ of $X$, and is equipped with a closure operator which does not necessarily induce a topology. There is a natural notion of homeomorphisms between (generalized) closure spaces. Banach spaces $X$ and $Y$ are said to have homeomorphic geometric structure spaces, denoted by $X\sim_\mathfrak{S} Y$, if there exists a homeomorphism between $\mathfrak{S} (X)$ and $\mathfrak{S} (Y)$. The classification of Banach spaces with respect to $\sim_\mathfrak{S}$ is strictly coarser (and hence, the results are stronger) than that with respect to the Birkhoff-James equivalence $\sim_{BJ}$.

The purpose of this talk is to present a recent progress on the theory of geometric structure spaces of $C^*$-algebras. In particular, a description of homeomorphisms between the normal parts of geometric structure spaces of $C^*$-algebras acting irreducibly on Hilbert spaces is given.

\end{ilasabstract}
    

\hypertarget{down0315}{}\begin{ilasabstract}
\talktitle{Isometries of Lipschitz free Banach spaces}
    
\textbf{Tamas Titkos}, \info{13:30\textrm{--}14:00 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0315}{$\Uparrow$}
    
    
(in {\color{mstitle}MS35: Preserver Problems, II})
        
\mtskip
    In the first part of the talk, I will focus on isometries of $\mathcal{W}_p(M)$ spaces, mainly in the case when $p=1$ -- the case which is closely connected to the theory of Lipschitz-free spaces. It is known that if $F$ is an isometry of M, then its push-forward $F_{\#}$ is an isometry of $\mathcal{W}_p(M)$. A natural question arises: is this embedding surjective? We know several concrete examples where the answer is yes, but the answer, in general, is no. In the second part of the talk, I will present some new results about isometries of Lipschitz-free spaces. In particular, I will describe surjective linear isometries and linear isometry groups of a large class of Lipschitz-free spaces.

\end{ilasabstract}
    

\hypertarget{down0342}{}\begin{ilasabstract}
\talktitle{Parallel-in-Time Kalman Smoothing Using Orthogonal Transformations
}
    
\textbf{Sivan Toledo}, \info{15:00\textrm{--}15:30 @ SC2006 (June 26, Thursday)} \hfill \hyperlink{up0342}{$\Uparrow$}
    
    
(in {\color{mstitle}MS13: Advances in QR factorizations})
        
\mtskip
    The talk will present a numerically-stable parallel-in-time linear 
Kalman smoother. The smoother uses a novel highly parallel
QR factorization for a class of structured sparse
matrices for state estimation, and an adaptation of the SelInv
selective-inversion algorithm to evaluate the covariance matrices
of estimated states. Our implementation of the new
algorithm, using the Threading Building Blocks (TBB) library,
scales well on both Intel and ARM multi-core servers, achieving
speedups of up to 47x on 64 cores. The algorithm performs
more arithmetic than sequential smoothers; consequently it is
1.8x to 2.5x slower on a single core. The new algorithm is faster
and scales better than the parallel Kalman smoother proposed
by Särkkä and García-Fernández in 2021.
This is joint work with Shahaf Gargir.

\end{ilasabstract}
    

\hypertarget{down0167}{}\begin{ilasabstract}
\talktitle{Efficient solution of sequences of parametrized Lyapunov equations with applications}
    
\textbf{Zoran Tomljanovic}, \info{14:30\textrm{--}15:00 @ SC0014 (June 24, Tuesday)} \hfill \hyperlink{up0167}{$\Uparrow$}
    
    
(in {\color{mstitle}MS6: Model reduction})
        
\mtskip
    The solutions of parametrized Lyapunov equations frequently serve as intermediate steps in a broader procedure aimed at computing $trace(EX)$, where $X$ represents the solution to the Lyapunov equation and $E$ is a given matrix. Our focus is on studying problems where the parameter dependence of the coefficient matrix is encoded as a low-rank modification of a fixed, seed matrix.\\
We propose two novel numerical procedures that fully exploit such a common structure. The first one builds upon the Sherman-Morrison-Woodbury   formula and recycling Krylov techniques, and it is well-suited for small dimensional problems as it uses dense numerical linear algebra tools. The second algorithm can instead address large-scale problems by relying on state-of-the-art projection techniques based on the extended Krylov subspace. We test the new algorithms on several problems arising in studying damped vibrational systems and analyzing output synchronization problems for multi-agent systems. Our results show that the proposed algorithms are superior to state-of-the-art techniques as they can remarkably speed up the computation of accurate solutions.\\
This is joint work with Davide Palitta, Ivica Naki\'{c} and Jens Saak.
\end{ilasabstract}
    

\hypertarget{down0057}{}\begin{ilasabstract}
\talktitle{Results on the symplectic spectrum of some special classes of operators}
    
\textbf{Anmary Tonny}, \info{15:00\textrm{--}15:30 @ SC1001 (June 23, Monday)} \hfill \hyperlink{up0057}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    Williamson's Normal form for $2n\times 2n$ real positive matrices is a symplectic analogue of the spectral theorem for normal matrices. With the recent developments in quantum information theory,  Williamson's normal form has opened up an active research area that may be dubbed as ``finite dimensional symplectic spectral theory'', analogous to the usual spectral theory and matrix analysis. An infinite dimensional analogue of the Williamson's Normal form has appeared recently and has already become a corner stone for the theory of infinite mode quantum Gaussian states. However, most existing results pertain to finite-dimensional operators, leaving a dearth of literature in the infinite-dimensional context. The aim of this talk is to discuss some recent results in this direction. Specifically, we discuss the recently proved inequality between the eigenvalues and symplectic eigenvalues for positive invertible operators $T$ on $\mathcal{H} \oplus \mathcal{H}$ (where $\mathcal{H}$ is a real separable Hilbert space) such that $T- \alpha I$ is compact for some $\alpha > 0$ and see its applications on the Gaussian covariance operators and positive Absolutely Norm attaining operators ($(\mathcal{AN})_+$ operators). We also show that the symplectic spectrum lies within the bounds of the spectrum for operators on specific classes. Additionally, we provide a method to recover the symplectic spectrum of Gaussian covariance operators through truncation.
\end{ilasabstract}
    

\hypertarget{down0281}{}\begin{ilasabstract}
\talktitle{Multiplicative trace and spectrum preservers  on   nonnegative and stochastic matrices
}
    
\textbf{Ming-Cheng Tsai}, \info{11:00\textrm{--}11:30 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0281}{$\Uparrow$}
    
    
(in {\color{mstitle}MS35: Preserver Problems, II})
        
\mtskip
    In this talk, we mainly explore multiplicative trace and spectrum preservers on the set of nonnegative and stochastic matrices. We will give concrete description of trace and spectrum preservers on the sets of nonnegative matrices, doubly stochastics, row stochastic, and column stochastic, respectively. Some related results and examples are provieded.

\end{ilasabstract}
    

\hypertarget{down0370}{}\begin{ilasabstract}
\talktitle{Extremal and saturation function of multidimensional 0-1 matrices
}
    
\textbf{Shen-Fu Tsai}, \info{17:30\textrm{--}18:00 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0370}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    Pattern avoidance is a central topic in combinatorics. With connection to ordered graph and sequence, extremal theories about avoidance of 0-1 matrices have had applications on areas like geometry problems, robot navigation, etc. In recent years, investigation of a similar extremal function called saturation function has gained interests in the community although saturation of graph dated long back to Erd\H{o}s. For both the original and new extremal functions, we give an overview of related works that extend 0-1 matrices to multidimensional 0-1 matrices.

\end{ilasabstract}
    

\hypertarget{down0288}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Pin-Chieh Tseng}, \info{11:30\textrm{--}12:00 @ SC1001 (June 26, Thursday)} \hfill \hyperlink{up0288}{$\Uparrow$}
    
    
(in {\color{mstitle}MS34: Combinatorics, association scheme, and graphs})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0075}{}\begin{ilasabstract}
\talktitle{Integrating covariates in learning spatio-temporal patterns}
    
\textbf{ShengLi Tzeng}, \info{15:00\textrm{--}15:30 @ SC4011 (June 23, Monday)} \hfill \hyperlink{up0075}{$\Uparrow$}
    
    
(in {\color{mstitle}MS20: Manifold learning and statistical applications})
        
\mtskip
    We consider a dimension reduction approach for spatio-temporal data analysis of the primary measurements (i.e., the main phenomenon being studied) while integrating covariates of interest. Unlike traditional principal component analysis (PCA), our method not only identifies similarities and distinctions among data points but also investigates how these relationships are associated with covariates across both spatial and temporal domains.

We develop data-driven functions that uncover spatial patterns and temporal trends, while also revealing connections between covariates and the underlying data structure. Furthermore, we introduce visualization techniques to illustrate the relationships between extracted geometric features, covariates, and the spatial and temporal patterns of the primary measurements. This approach offers a more comprehensive understanding of the factors driving data similarities and discrepancies.

The key innovation of our method, in contrast to traditional PCA, lies in its ability to reveal how these functions relate to covariates, providing deeper insights into the underlying characteristics of the data by examining how covariates interact with spatial and temporal patterns in the primary measurements.
\end{ilasabstract}
    

\hypertarget{down0260}{}\begin{ilasabstract}
\talktitle{What is our most urgent task today in Mathematics?
}
    
\textbf{Frank Uhlig}, \info{11:00\textrm{--}11:30 @ SC1005 (June 25, Wednesday)} \hfill \hyperlink{up0260}{$\Uparrow$}
    
    
(in {\color{mstitle}MS27: Linear algebra education})
        
\mtskip
    This is a talk on modern Linear Algebra teaching and learning and on our most urgent task in Mathematics as a whole and in Linear Algebra today, namely that   of building Matrix Theory and Matrix Computation based syllabi. Full semester Lesson Plans for first Linear Algebra courses are introduced and discussed. To prepare our post Covid students we need to use interactive teaching methods and inversely taught syllabi which are slowly creating  grass roots fire among students and catching instructors as well. Such courses follow the Teaching Principles of Jean Piaget from 80 years ago who established that we only learn deeply and retain what we need to understand, and not what we are taught to pass a test. Such a course in elementary Linear Algebra can be designed from only two mathematical  principles : the Row Echelon Form Reduction teaches us of the value of pivot searches and  Krylov Vector Iterations that allow us an inside look at intrinsic matrix qualities such as eigenvectors and eigenvalues. Both of these rely on Riesz's Theorem on Matrix Representations of Linear Functions in varying vector space bases. Students should build their own basic codes to perform reliable algorithms for these essential tasks of modern Linear Algebra as it is used everywhere in our internet, cell-phone and computer worlds and in Engineering, Medicine, Shipping, Traveling, Banking and so forth.
Such a course would follow the Piaget Principle of deep learning.



\end{ilasabstract}
    

\hypertarget{down0142}{}\begin{ilasabstract}
\talktitle{Matrix sign patterns that allow the strong multiplicity property}
    
\textbf{Kevin Vander Meulen}, \info{11:00\textrm{--}11:30 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0142}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    Various strong multiplicity properties have been developed to aid
with inverse eigenvalue problems. The nonsymmetric strong multiplicity
property (nSMP) has recently been introduced to provide information
about the possible eigenvalue multiplicities of a matrix based on the
sign pattern of the matrix. The nSMP is useful for the problem
of determining the number of distinct eigenvalues allowed by a pattern.
We provide a characterization of the patterns that allow
the nSMP. We also describe classes of patterns of arbitrary order
that require the nSMP. This presentation includes joint work
with Abhilash Saha, Leona Tilis, and Adam Van Tuyl.

\end{ilasabstract}
    

\hypertarget{down0392}{}\begin{ilasabstract}
\talktitle{An inverse eigenvalue problem linked to multiple orthogonal polynomials
}
    
\textbf{Robbe Vermeiren}, \info{16:30\textrm{--}17:00 @ SC4011 (June 26, Thursday)} \hfill \hyperlink{up0392}{$\Uparrow$}
    
    
(in {\color{mstitle}MS23: Advances in Krylov subspace methods and their applications})
        
\mtskip
    Multiple orthogonal polynomials (MOPs) arise in various applications, including approximation theory, random matrix theory, and numerical integration. To define MOPs, one needs orthogonality conditions with respect to multiple measures. In this talk, we restrict our attention to the case of two measures. These MOPs satisfy recurrence relations, and we focus specifically on the stepline recurrence relation.
We derive an inverse eigenvalue problem: given some initial spectral data, retrieve the recurrence matrix associated with the stepline recurrence relation. Several techniques for solving this inverse problem are proposed, and numerical illustrations are provided to demonstrate their correctness.

\end{ilasabstract}
    

\hypertarget{down0388}{}\begin{ilasabstract}
\talktitle{Mixed precision strategies for preconditioned GMRES
}
    
\textbf{Bastien Vieublé}, \info{16:30\textrm{--}17:00 @ SC3001 (June 26, Thursday)} \hfill \hyperlink{up0388}{$\Uparrow$}
    
    
(in {\color{mstitle}MS16: Approximations and errors in Krylov-based solvers})
        
\mtskip
    The Generalized Minimal Residual methods (GMRES) for the solution of general square linear systems $Ax = b$ is often combined with a preconditioner to improve the convergence speed and the overall computing performance of the method. Successful mixed precision implementations for the application of the preconditioner inside GMRES have been previously proposed: certain strategy prescribes to apply the preconditioner in low precision to reduce overall time and memory consumption, other strategies propose to apply the preconditioner in higher precision to improve robustness and accuracy. These existing studies tend to focus on one kind of preconditioner combined with one kind of preconditioning technique (left-, right-, and flexible-preconditioning). In this talk, we propose to unify most of the state-of-the-art mixed precision implementations for preconditioned GMRES under the same comprehensive theory and give a clear and exhaustive list of the possible strategies to set the precisions and how they compare numerically. To achieve this, we derive new descriptive bounds for the attainable forward errors of the computed solutions. From the study of these bounds, we uncover yet unknown mixed precision implementations that achieve new tradeoffs between computing performance and accuracy. As importantly, we explain that there are critical differences in robustness and accuracy between left-, right-, and flexible-preconditioning for a same given set of precisions and that, therefore, the choice between the three preconditioning techniques has higher stakes in mixed precision. We substantiate our theoretical findings with a comprehensive experimental study on random dense and SuiteSparse matrices with various preconditioners.

\end{ilasabstract}
    

\hypertarget{down0126}{}\begin{ilasabstract}
\talktitle{Isometries and metric properties of quantum Wasserstein distances}
    
\textbf{Dániel Virosztek}, \info{10:30\textrm{--}11:00 @ SC0012 (June 24, Tuesday)} \hfill \hyperlink{up0126}{$\Uparrow$}
    
    
(in {\color{mstitle}MS12: Preserver problems, I})
        
\mtskip
    Although the theory of classical optimal transport has been playing an important role in mathematical physics (especially in fluid dynamics) and probability since the late 80s, concepts of optimal transportation in quantum mechanics have emerged only very recently. We briefly review the most relevant approaches and discuss a non-quadratic generalization of the quantum mechanical optimal transport problem introduced by De Palma and Trevisan where quantum channels realize the transport. Relying on this general machinery, we introduce p-Wasserstein distances and divergences and study their fundamental geometric properties. Finally, we demonstrate that the quadratic quantum Wasserstein divergences are genuine metrics, and summarize our recent results on the isometries of the qubit state space with respect to Wasserstein distances induced by distinguished transport cost operators.

\end{ilasabstract}
    

\hypertarget{down0246}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Jani A. Virtanen}, \info{11:30\textrm{--}12:00 @ SC0009 (June 25, Wednesday)} \hfill \hyperlink{up0246}{$\Uparrow$}
    
    
(in {\color{mstitle}MS33: Norms of matrices, numerical range, applications of functional analysis to matrix theory})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0045}{}\begin{ilasabstract}
\talktitle{On total positivity of sequences generated by 
real polynomials and $q$-polynomials
}
    
\textbf{Anna Vishnyakova}, \info{15:00\textrm{--}15:30 @ SC0008 (June 23, Monday)} \hfill \hyperlink{up0045}{$\Uparrow$}
    
    
(in {\color{mstitle}MS9: Total positivity})
        
\mtskip
    Let $P, P(0) >0,$ be a real polynomial of degree $m.$ It is easy to check that
$$ \sum_{k=0}^\infty P(k) x^k =\frac{Q_m(x)}{(1-x)^{m+1}},  $$
where $Q_m$ is a real polynomial of degree at most $m.$

We will discuss the following problem: for which $P$ the sequence 
$(P(k))_{k=0}^\infty$ is totally positive? According to the famous 
theorem by Aissen, Schoenberg, Whitney and Edrei it happens if and
only if all the zeros of $Q_m$ are real and non-positive.

The following statement is one of our results.

{\bf Statement}  {\it Let $P(x) =(x+\alpha_1)(x+\alpha_2)\cdot \ldots \cdot (x+\alpha_m),$  where $0\leq \alpha_1 \leq \alpha_2 \leq \ldots \leq \alpha_m,$ and for every $j=1, 2, \ldots, m-1$ we have $ \alpha_{j+1} - \alpha_j \leq 1.$  Then the sequence $(P(k))_{k=0}^\infty$ is totally positive. }

We will also discuss the sequences of the form 
$$\left((1-c_1 q^k)(1-c_2 q^k)\cdot \ldots \cdot (1-c_m q^k) x^k\right)_{k=0}^\infty, $$ 
where  $0< q < 1,  q< c_j < 1.$

The talk is based on joint work with Dmitrii Karp and, partially, Thu Hien Nguyen.




\end{ilasabstract}
    

\hypertarget{down0134}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Trung Dung Vuong}, \info{11:30\textrm{--}12:00 @ SC1001 (June 24, Tuesday)} \hfill \hyperlink{up0134}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0124}{}\begin{ilasabstract}
\talktitle{On some multi-variable means of ALM type}
    
\textbf{Shuhei Wada}, \info{11:00\textrm{--}11:30 @ SC0009 (June 24, Tuesday)} \hfill \hyperlink{up0124}{$\Uparrow$}
    
    
(in {\color{mstitle}MS29: Matrix functions and related topics})
        
\mtskip
    The study of multivariable operator geometric means was pioneered by Ando, Li, and Mathias (ALM). In recent years, research has primarily focused on operator means obtained as solutions to operator equations. Nevertheless, there has been growing interest in operator means of ALM type, which are obtained by generalizing their approach. ALM-type means are particularly notable because the approximating sequences are explicitly given, making it easier to understand their properties. In this talk, we will introduce an example of an ALM-type mean and discuss its properties. Additionally, we will touch upon related results.

\end{ilasabstract}
    

\hypertarget{down0041}{}\begin{ilasabstract}
\talktitle{Contrastive principal component analysis in high dimension}
    
\textbf{ShaoHsuan Wang}, \info{11:30\textrm{--}12:00 @ SC4011 (June 23, Monday)} \hfill \hyperlink{up0041}{$\Uparrow$}
    
    
(in {\color{mstitle}MS20: Manifold learning and statistical applications})
        
\mtskip
    Principal component analysis (PCA) has been widely used in exploratory data analysis. 
Contrastive PCA (Abid et al., 2018), a generalized method of PCA, is a new tool used to 
capture features of a target dataset relative to a background dataset while preserving the 
maximum amount of information contained in the data. With high dimensional data, contrastive PCA becomes impractical due to its high computational requirement of forming the 
contrastive covariance matrix and associated eigenvalue decomposition for extracting leading 
components. In this work, we propose a geometric curvilinear-search method to solve this 
problem and provide a convergence analysis. Our approach offers significant computational 
efficiencies. Specifically, it reduces the time complexity from $O((n \wedge m)p^2 )$ to a more manageable $O((n \wedge m)pr)$, where n, m are the sample sizes of the target data and background
data, respectively, p is the data dimension and r is the number of leading components. Additionally, we streamline the space complexity from $O(p^2)$, necessary for storing the contrastive 
covariance matrix, to a more economical $O((n \wedge m)p)$, sufficient for storing the data alone.
Numerical  examples  are  presented  to  show  the  merits  of  the  proposed  algorithm.
\end{ilasabstract}
    

\hypertarget{down0297}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Wei Wang}, \info{11:30\textrm{--}12:00 @ SC2001 (June 26, Thursday)} \hfill \hyperlink{up0297}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0316}{}\begin{ilasabstract}
\talktitle{Linear maps preserving disjoint idempotents
}
    
\textbf{Ya-Shu Wang}, \info{14:00\textrm{--}14:30 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0316}{$\Uparrow$}
    
    
(in {\color{mstitle}MS35: Preserver Problems, II})
        
\mtskip
    Let ${\bf M}_n(F)$ denote the set of all $n \times n$ matrices and ${\bf S}_n(F)$ denote the set of symmetric $n \times n$ matrices over a field $F$, respectively.
In this talk, I will present a characterization of linear maps on ${\bf M}_n(F)$ and ${\bf S}_n(F)$ that send disjoint rank one idempotents to disjoint idempotents. As an application,  I will also characterize linear maps on ${\bf M}_n(F)$ and ${\bf S}_n(F)$ that preserve matrices annihilated by a fixed polynomial under certain assumptions.

\end{ilasabstract}
    

\hypertarget{down0058}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Aaron Welters}, \info{14:00\textrm{--}14:30 @ SC1003 (June 23, Monday)} \hfill \hyperlink{up0058}{$\Uparrow$}
    
    
(in {\color{mstitle}MS26: Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0273}{}\begin{ilasabstract}
\talktitle{Generalized Smith method for large-scale nonsymmetric algebraic Riccati equations}
    
\textbf{Peter Chang-Yi Weng}, \info{11:30\textrm{--}12:00 @ SC4011 (June 25, Wednesday)} \hfill \hyperlink{up0273}{$\Uparrow$}
    
    
(in {\color{mstitle}MS1: Embracing new opportunities in numerical linear algebra})
        
\mtskip
    This paper presents an effective algorithm about a computation of the numerical
low-rank solution to a large-scale nonsymmetric algebraic Riccati equation with
a nonsingular $M$-matrix. The method first applies the Newton’s method to compute the nonsymmetric algebraic Riccati equation, followed by a derivation of
generalized Sylvester equations. By extending the Smith method, the proposed
algorithm achieves a quadratic convergence and has the $O(n)$ computational
complexity. A detailed convergence, error analysis, truncation and compression
process, and numerical examples will be provided.
\end{ilasabstract}
    

\hypertarget{down0166}{}\begin{ilasabstract}
\talktitle{Reduced-order modeling of mechanical systems via structured barycentric forms}
    
\textbf{Steffen W. R. Werner}, \info{14:00\textrm{--}14:30 @ SC0014 (June 24, Tuesday)} \hfill \hyperlink{up0166}{$\Uparrow$}
    
    
(in {\color{mstitle}MS6: Model reduction})
        
\mtskip
    \begin{bibunit}
        Data-driven reduced-order modeling is an essential tool in constructing
high-fidelity compact models to approximate physical phenomena when explicit
models, such as state-space formulations with access to internal variables, are
not available yet abundant input/output data are.
When deriving models from theoretical principles, the results
typically contain differential structures that lead to certain system
properties.
A common example are dynamical systems with second-order time derivatives
like
\begin{equation*}
  M \ddot{x}(t) + D \dot{x}(t) + K x(t) = B u(t), \quad
  y(t) = C x(t),
\end{equation*}
arising in the modeling of mechanical or electro-mechanical processes.
In this case, data are often available in the frequency domain, where the
systems' input-to-output behavior is described by rational functions
of the form
\begin{equation*}
  H(s) = C (s^{2} M + s D + K)^{-1} B,
\end{equation*}
rather than differential equations.
Classical frequency domain approaches like the Loewner framework, vector
fitting and AAA are available and can be used to learn unstructured
(first-order) models from data.
However, these models in their original formulation do not reflect the
structure-inherited properties.
The key element in the derivation of frequency domain approaches is the
barycentric form of rational functions.
In this work, we present a structured extension of the barycentric form for the
case of mechanical systems.
This structured barycentric form is given by
\begin{equation*}
  \widehat{H}(s) = \left(\sum_{j = 1}^k\frac{h_{j} w_{j}}{(s - \lambda_{j})
    (s - \sigma_{j})} \right) \left/ \left(1 + \sum_{j = 1}^{k}
    \frac{w_{j}}{(s - \lambda_{j})(s - \sigma_{j})}\right)\right.;
\end{equation*}
see~\cite{WernerSWR_GosGW24}.
Building on this structured rational function representation, we develop new
algorithms for learning reduced-order models of mechanical phenomena in the
frequency domain, while enforcing the mechanical system structure in the model
description.

\begin{thebibliography}{10}
\bibitem{WernerSWR_GosGW24}
  I.~V. Gosea, S.~Gugercin, and S.~W.~R. Werner.
  \newblock Structured barycentric forms for interpolation-based data-driven
    reduced modeling of second-order systems.
  \newblock {\em Adv. Comput. Math.}, 50(2):26, 2024.
  \newblock doi:10.1007/s10444-024-10118-7
\end{thebibliography}

        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0363}{}\begin{ilasabstract}
\talktitle{Efficiently solving nonstandard Riccati equations via indefinite factorizations}
    
\textbf{Steffen W. R. Werner}, \info{16:00\textrm{--}16:30 @ SC0014 (June 26, Thursday)} \hfill \hyperlink{up0363}{$\Uparrow$}
    
    
(in {\color{mstitle}MS5: Advances in matrix equations: Theory, computations, and applications})
        
\mtskip
    \begin{bibunit}
        The continuous-time symmetric algebraic Riccati equation (CARE) is a special
type of nonlinear matrix-valued equation and an essential component
of many applications, including controller design, model order reduction and
game theory.
While there have been many developments in recent years regarding new solution
methods of CAREs in the setting of large-scale sparse coefficient matrices,
these methods are typically based on semi-definite low-rank factorizations of
their solutions and consider the classical CARE formulation
\begin{equation*}
  A^{\mathsf{T}} X E + E^{\mathsf{T}} X A + C^{\mathsf{T}} Q C -
    E^{\mathsf{T}} X B R B^{\mathsf{T}} X E = 0,
\end{equation*}
with $Q$ and $R$ symmetric positive definite.
In this work, we investigate solution methods for large-scale sparse generalized
CAREs of the form
\begin{equation*}
  A^{\mathsf{T}} X E + E^{\mathsf{T}} X A + C^{\mathsf{T}} Q C -
    (E^{\mathsf{T}} X B + S) R (E^{\mathsf{T}} X B + S)^{\mathsf{T}} = 0,
\end{equation*}
where $Q$ and $R$ can be symmetric positive definite,  negative definite,
or even indefinite.
The solutions and intermediate approximations to such general equations often
do not follow the classical semi-definite structure.
Therefore, we are utilizing low-rank symmetric indefinite $LDL^{\mathsf{T}}$
factorizations of the CARE solution in our algorithms, which enable efficient
computations; see, for example,~\cite{Werner_SaaW24}.

\begin{thebibliography}{10}
\bibitem{Werner_SaaW24}
J.~Saak and S.~W.~R. Werner.
\newblock Using {$LDL^{T}$} factorizations in {N}ewton's method for solving
  general large-scale algebraic {R}iccati equations.
\newblock {\em Electron. Trans. Numer. Anal.}, 62:95--118, 2024.
\newblock doi:10.1553/etna\_vol62s95
\end{thebibliography}

        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0317}{}\begin{ilasabstract}
\talktitle{Tingley's problems for positive spheres of operator algebras}
    
\textbf{Ngai-Ching Wong}, \info{14:30\textrm{--}15:00 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0317}{$\Uparrow$}
    
    
(in {\color{mstitle}MS35: Preserver Problems, II})
        
\mtskip
    Let $T: \mathbf{S}_E\to \mathbf{S}_F$ be a bijective isometry  between the unit spheres of two real normed spaces $E, F$,
 i.e.,
$$
\|Tx - Ty\|_F = \|x-y\|_E, \quad\forall x,y\in E.
$$
Tingley  asked in 1987 whether we  
can   extend any such $T$ to a linear isometry from $E$ onto $F$.
We answer, in the affirmative,
Tingley's problem for positive unit spheres of (complex) von Neumann algebras.  

More precisely,
let $\Lambda: \mathrm{S}_{\mathcal{A}^+} \to \mathrm{S}_{\mathcal{B}^+}$ be a bijective isometry
between the sets of positive norm-one elements of two von Neumann algebras $\mathcal{A}$ and $\mathcal{B}$.
We show that $T$ extends to a bijective complex linear Jordan $^*$-isomorphism from $\mathcal{A}$ onto $\mathcal{B}$.
Actually, the above results are proved in the slightly more general situations that $\mathcal{A}$ and $\mathcal{B}$ are  $AW^*$-algebras, or separable $C^*$-algebras with real rank zero.  

This is a joint work with Chi-Keung Ng (Nankai, Tianjin) and Chi-Wai Leung (CUHK, Hong Kong).

\end{ilasabstract}
    

\hypertarget{down0011}{}\begin{ilasabstract}
\talktitle{Linear preservers of sign regularity}
    
\textbf{Shivangi Yadav}, \info{11:30\textrm{--}12:00 @ SC0008 (June 23, Monday)} \hfill \hyperlink{up0011}{$\Uparrow$}
    
    
(in {\color{mstitle}MS9: Total positivity})
        
\mtskip
    The classification of linear maps that act on a space of bounded linear operators and preserve certain functions, subsets, relations, etc. has a long history, beginning with Frobenius, who characterized in 1897 the  determinant-preserving linear maps on matrix algebras. In this talk, I will present a classification of all surjective linear mappings $\mathcal{L}:\mathbb{R}^{m\times n}\to\mathbb{R}^{m\times n}$ that preserve: (i)~sign regularity and (ii)~sign regularity with a given sign pattern, as well as (iii)~strict versions of these. As a special case of our results, we recover the characterization of linear preservers for the class of square totally positive and totally non-negative matrices (by Berman--Hershkowitz--Johnson in 1985). This is a joint work with Projesh Nath Choudhury.

\end{ilasabstract}
    

\hypertarget{down0022}{}\begin{ilasabstract}
\talktitle{Stability of AN-operators under functional calculus}
    
\textbf{Takeaki Yamazaki}, \info{11:00\textrm{--}11:30 @ SC1001 (June 23, Monday)} \hfill \hyperlink{up0022}{$\Uparrow$}
    
    
(in {\color{mstitle}MS10: Matrix means and related topics})
        
\mtskip
    This talk is based on [1].
Let $\mathcal{B}(H)$ be the set of all bounded linear operators on a complex Hilbert space. An operator $T\in \mathcal{B}(H)$ satisfies $\mathcal{AN}$-property if and only if for any closed subspace $K$ of $H$, there exists a unit vector $x\in K$ such that $\|T|_{K}\|=\|T|_{K}x\|$. The set of operators satisfying $\mathcal{AN}$-property is not closed. 
Moreover $\mathcal{AN}$-property is not stable under some operations.
In this talk, we shall introduce stability of $\mathcal{AN}$-property under functional calculus on positive definite operators.

This is a joint work with Professor Golla Ramesh, Hiroyuki Osaka and Yoichi Udagawa.

\noindent
[1] G. Ramesh, H. Osaka,
Y. Udagawa and T. Yamazaki, {\it Stability of  $\mathcal{AN}$ -operators under functional calculus},
Anal. Math. {\bf 49} (2023), 825--839.

\end{ilasabstract}
    

\hypertarget{down0185}{}\begin{ilasabstract}
\talktitle{Nested Grassmannians for dimensionality reduction with applications}
    
\textbf{Chun-Hao Yang}, \info{13:30\textrm{--}14:00 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0185}{$\Uparrow$}
    
    
(in {\color{mstitle}MS32: Advances in matrix manifold optimization})
        
\mtskip
    In the recent past, nested structure of Riemannian manifolds has been studied in the context of dimensionality reduction as an alternative to the popular principal geodesic analysis (PGA) technique, for example, the principal nested spheres. In this paper, we propose a novel framework for constructing a nested sequence of homogeneous Riemannian manifolds. Common examples of homogeneous Riemannian manifolds include the spheres, the Stiefel manifolds, and the Grassmann manifolds. In particular, we focus on applying the proposed framework to the Grassmann manifolds, giving rise to the nested Grassmannians (NG). An important application in which Grassmann manifolds are encountered is planar shape analysis. Specifically, each planar (2D) shape can be represented as a point in the complex projective space which is a complex Grassmann manifold. Some salient features of our framework are: (i) it explicitly exploits the geometry of the homogeneous Riemannain manifolds and (ii) the nested lower-dimensional submanifolds need not be geodesic. With the proposed NG structure, we develop algorithms for the supervised and unsupervised dimensionality reduction problems respectively. The proposed algorithms are compared with PGA via simulation studies and real data experiments and are shown to achieve a higher ratio of expressed variance compared to PGA.

\end{ilasabstract}
    

\hypertarget{down0150}{}\begin{ilasabstract}
\talktitle{Landmark diffusion accelerates alternating diffusion maps for multi-sensor fusion}
    
\textbf{Sing-Yuan Yeh}, \info{10:30\textrm{--}11:00 @ SC4011 (June 24, Tuesday)} \hfill \hyperlink{up0150}{$\Uparrow$}
    
    
(in {\color{mstitle}MS20: Manifold learning and statistical applications})
        
\mtskip
    Alternating Diffusion (AD) is a commonly applied diffusion-based sensor fusion algorithm. While it has been successfully applied to various problems, its computational burden remains limited. Inspired by the landmark diffusion idea considered in the Robust and Scalable Embedding via Landmark Diffusion (ROSELAND), we propose a variation of AD, called Landmark AD (LAD), which captures the essence of AD while offering superior computational efficiency. Through a series of theoretical analyses, we investigate the sample complexity of LAD within the manifold setup. We then apply LAD to address the automatic sleep stage annotation problem using two electroencephalogram channels, demonstrating its efficacy in practical applications.

\end{ilasabstract}
    

\hypertarget{down0362}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Sang-Gyun Youn}, \info{17:30\textrm{--}18:00 @ SC0012 (June 26, Thursday)} \hfill \hyperlink{up0362}{$\Uparrow$}
    
    
(in {\color{mstitle}MS7: Linear algebra and quantum information science})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0224}{}\begin{ilasabstract}
\talktitle{Relationships between minimum rank problem parameters for cobipartite graphs}
    
\textbf{Derek Young}, \info{17:30\textrm{--}18:00 @ SC1005 (June 24, Tuesday)} \hfill \hyperlink{up0224}{$\Uparrow$}
    
    
(in {\color{mstitle}MS17: Graphs and matrices in honor of Leslie Hogben's retirement})
        
\mtskip
    The minimum rank problem for zero-nonzero matrix patterns is to determine the
smallest rank of a matrix whose zero entries occur in specified positions.
Similarly, the minimum rank problem for a simple graph is to find the smallest
rank of a symmetric matrix whose off-diagonal nonzero entries occur according
to the edges of a given graph.  In each case, a fundamental combinatorial lower
bound exists; for the former, it is the triangle number of the pattern, while
for the latter it is the zero forcing number of the graph.  For a given
zero-nonzero pattern, there exists an associated cobipartite graph.  In
previous work, the minimum rank of the pattern and the maximum nullity of its
associated cobipartite graph were shown to obey a simple relationship; each is
equal to the number of vertices in the graph minus the other.  We show that the
corresponding bounds (that of the triangle number and the zero forcing number)
obey this same relationship.  This forms a connection between the goal of
understanding when the triangle number is equal to the minimum rank of a
pattern and that of determining when the zero forcing number of a graph is
equal to its maximum nullity.

\end{ilasabstract}
    

\hypertarget{down0068}{}\begin{ilasabstract}
\talktitle{Authalic energy minimization for area-preserving mappings}
    
\textbf{Mei-Heng Yueh}, \info{14:30\textrm{--}15:00 @ SC2006 (June 23, Monday)} \hfill \hyperlink{up0068}{$\Uparrow$}
    
    
(in {\color{mstitle}MS22: Linear algebra applications in computational geometry})
        
\mtskip
    The authalic energy is a functional specifically designed to measure area distortion in surface mappings, providing a foundation for the efficient computation of area-preserving mappings of simplicial surfaces. Such mappings can serve as parameterizations that define a unified coordinate system, which simplifies various image and geometry processing tasks, such as surface registration and blending. In this talk, I will introduce authalic energy minimization for computing area-preserving simplicial mappings and demonstrate its practical utility in geometry processing.

\end{ilasabstract}
    

\hypertarget{down0184}{}\begin{ilasabstract}
\talktitle{The critical groups of hypercubes and beyond}
    
\textbf{Chi Ho Yuen}, \info{15:00\textrm{--}15:30 @ SC2001 (June 24, Tuesday)} \hfill \hyperlink{up0184}{$\Uparrow$}
    
    
(in {\color{mstitle}MS25: Enumerative/algebraic combinatorics and matrices})
        
\mtskip
    The critical group of a graph $G$ is the torsion part of the cokernel of its Laplacian. It refines the number of spanning trees of $G$ in an algebraic way and is related to the chip-firing game (or abelian sandpile model) on $G$. In this talk, we survey several results on the critical groups of the hypercube graphs and their generalizations, including my works on Cayley graphs (joint with J. Gao, J. Marx-Kuo, and V. McDonald) and Adinkras (partly joint with K. Iga, C. Klivans, J. Kostiuk, and with K. Hung), which are decorated graphs introduced by physicists to encode special supersymmetry algebras. The emphasis will be on the novel algebraic techniques employed to prove these results.
\end{ilasabstract}
    

\hypertarget{down0146}{}\begin{ilasabstract}
\talktitle{On the third-order quaternion tensors and applications
}
    
\textbf{Yang Zhang}, \info{11:30\textrm{--}12:00 @ SC2006 (June 24, Tuesday)} \hfill \hyperlink{up0146}{$\Uparrow$}
    
    
(in {\color{mstitle}MS3: Matrix inequalities with applications})
        
\mtskip
    In this talk, we first discuss the ranks of the third-order quaternion tensors and present some inequalities for boundaries. Then we consider SVD and QR decomposition of this quaternion tensors and applications in color images and videos processing. 
\end{ilasabstract}
    

\hypertarget{down0346}{}\begin{ilasabstract}
\talktitle{Randomized inner iteration preconditioning}
    
\textbf{Ning Zheng}, \info{15:00\textrm{--}15:30 @ SC3001 (June 26, Thursday)} \hfill \hyperlink{up0346}{$\Uparrow$}
    
    
(in {\color{mstitle}MS16: Approximations and errors in Krylov-based solvers})
        
\mtskip
    Many scientific computing problems have associated condition numbers that reflect the sensitivity and difficulty of solving the problem numerically. 
The preconditioning technique replaces a badly conditioned problem with an equivalent problem with a smaller condition number. 
We propose using randomized iteration algorithms as implicit preconditioners for the Krylov subspace methods to solve linear systems and linear least squares problem. 
Theoretical justifications of the preconditioned GMRES are presented. 
Numerical experiments on overdetermined and underdetermined linear systems show that the proposed method is superior to the other classical preconditioners in terms of total CPU time.
\end{ilasabstract}
    

\hypertarget{down0130}{}\begin{ilasabstract}
\talktitle{Maximum volume coordinates for subspace interpolation}
    
\textbf{Ralf Zimmermann}, \info{11:00\textrm{--}11:30 @ SC0014 (June 24, Tuesday)} \hfill \hyperlink{up0130}{$\Uparrow$}
    
    
(in {\color{mstitle}MS6: Model reduction})
        
\mtskip
    Model reduction of complex nonlinear parametric dynamical systems is still a challenge.
One possible approach to deal with such systems is via manifold interpolation. In particular, the interpolation of subspaces, i.e., points on the Grassmann manifold has recently received more and more attention.
Basic manifold interpolation requires working with local coordinate charts and can be subdivided into three key steps:\\
1: {\em Preprocessing.} Map sampled data from manifold  to  coordinate domain. \\
2: {\em Interpolation.}
	Employ a Euclidean interpolation method to interpolate the data images in the coordinate domain.\\
3: {\em Postprocessing.} Map interpolated data from coordinate domain to manifold.\\
The gold standard is arguably to work with Riemannian normal coordinates, since in a sense they exhibite the least possible geometric distortion.
Yet, this may become expensive, especially when derivative data is involved.\\
An alternative for the Grassmann manifold are a certain set of local coordinates, which do not require matrix decompositions. Although these have been known for three decades, to our knowledge they have not yet been investigated in detail and have not been used in connection with model reduction.\\
In this talk, we investigate their usability for Grassmann interpolation. We show that this set of coordinates constitutes a retraction. Moreover, we expose the sources of data processing errors and their impact on the interpolation errors. A pivot in these coordinates is an invertible submatrix of an orthogonal projector.
We show how selection of this subblock by volume maximization improves the condition number of the coordinate charts and eventually reduces the interpolation errors.
The results are illustrated by numerical experiments.
\\
%
This is joint work with Rasmus Jensen, IMADA, University of Southern Denmark. 

\end{ilasabstract}
    

\hypertarget{down0251}{}\begin{ilasabstract}
\talktitle{nan}
    
\textbf{Jeroen Zuiddam}, \info{11:00\textrm{--}11:30 @ SC0014 (June 25, Wednesday)} \hfill \hyperlink{up0251}{$\Uparrow$}
    
    
(in {\color{mstitle}MS8: Tensor and quantum information science})
        
\mtskip
    nan
\end{ilasabstract}
    

\hypertarget{down0263}{}\begin{ilasabstract}
\talktitle{Stochastic matrices with infinitely many stochastic roots}
    
\textbf{Helena Šmigoc}, \info{11:00\textrm{--}11:30 @ SC2001 (June 25, Wednesday)} \hfill \hyperlink{up0263}{$\Uparrow$}
    
    
(in {\color{mstitle}MS2: Combinatorial matrix theory})
        
\mtskip
    We introduce and study the class of arbitrarily finely divisible stochastic matrices ($\mathrm{AFD}_+$-matrices): stochastic matrices that have a stochastic $c$-th root for infinitely many natural numbers $c$. This notion generalises the class of embeddable stochastic matrices. 
We will explore the connection between the spectral properties of an  $\mathrm{AFD}_+$-matrix $A$ and the spectral properties of a limit point $L$ of its stochastic roots. This connection, which is first formalised in the broader context of complex and real square matrices, poses restrictions on $A$ assuming $L$ is given. For example, if an $\mathrm{AFD}_+$-matrix $A$ has a corresponding irreducible limit point $L$, then $A$ has to be a circulant matrix. We close with a complete characterisation of $\mathrm{AFD}_+$-matrices of rank-two.
\end{ilasabstract}
    

\hypertarget{down0331}{}\begin{ilasabstract}
\talktitle{Posing a question}
    
\textbf{Helena Šmigoc}, \info{13:30\textrm{--}14:00 @ SC1005 (June 26, Thursday)} \hfill \hyperlink{up0331}{$\Uparrow$}
    
    
(in {\color{mstitle}MS27: Linear algebra education})
        
\mtskip
    Linear algebra is included in the curriculum for students pursuing various degrees such as computer science, biology, engineering, and pure mathematics. When students from different fields are in the same classroom, it can be challenging to tailor instruction to meet everyone's needs.  We will explore ways of setting a problem in this context, with the aim to motivate students with diverse interests, and  develop their understanding of the topic.

\end{ilasabstract}
    \newpage

\section{Abstracts of Contributed Talks}


\hypertarget{down0423}{}\begin{ilasabstract}
\talktitle{On proper cones in finite dimensional vector spaces}
    
\textbf{Shanmugapriya A}, \info{08:30\textrm{--}09:00 @ SC3001 (June 27, Friday)} \hfill \hyperlink{up0423}{$\Uparrow$}
    
    
\mtskip
    Let $K$ be a proper cone in $\mathbb{R}^n$, its dual is defined as $K^*=\{y\in \mathbb{R}^n|\langle x,y\rangle\geq 0, ~\mbox{for all}~ x\in K\}$. Two cones $K_1$ and $K_2$ are said to be isomorphic if there exists an invertible linear map $L:\mathbb{R}^n\rightarrow \mathbb{R}^n$ such that  $L(K_1)=K_2$. For a cone $K$, the complementarity set is defined as $C(K)=\{(x,a)|x\in K, a\in K^*,\langle x,a \rangle=0\}$. A linear transformation $L$ is said to be Lyapunov-like transformation on $K$ if $\langle L(x), a \rangle=0$, for all $(x,a)\in C(K)$. The set of all Lyapunov-like transformations $LL(K)$ forms a vector space and its dimension is called the Lyapunov rank $\beta(K)$ of a cone $K$. In one of our recent works, we constructed non-isomorphic proper polyhedral cones using Lyapunov rank. Our results used the fact that isomorphic cones have same Lyapunov rank.  We know that the converse of this statement is not true. In this work, we discuss  when the converse of this statement is true. 

\end{ilasabstract}
    

\hypertarget{down0401}{}\begin{ilasabstract}
\talktitle{New approaches to the solutions of bispectral problems}
    
\textbf{Luis Miguel Anguas Márquez}, \info{08:00\textrm{--}08:30 @ SC0012 (June 27, Friday)} \hfill \hyperlink{up0401}{$\Uparrow$}
    
    
\mtskip
    A family of polynomials is a solution to a bispectral problem if it forms a sequence of eigenfunctions of both a finite-order differential operator $L$ and a difference operator $J$. In 1929, S. Bochner studied the case where the differential operator is of order $2$, identifying the sequences of classical orthogonal polynomials as solutions to the bispectral problem. Since then, several contributions have been made to the study of the bispectral problem, but the case of arbitrary order remains open.

The aim of this talk is to present new tools that have helped us obtain results on whether certain differential operators produce sequences of eigenpolynomials that solve the bispectral problem. We will draw examples of such differential operators from the existing literature on bispectral problems.
\end{ilasabstract}
    

\hypertarget{down0403}{}\begin{ilasabstract}
\talktitle{Banach frame structure for the Szego kernels in the Hardy space}
    
\textbf{Noufal Asharaf}, \info{09:00\textrm{--}09:30 @ SC0012 (June 27, Friday)} \hfill \hyperlink{up0403}{$\Uparrow$}
    
    
\mtskip
    \begin{bibunit}
        The rational Blaschke functions are used to create the Multiresolution analysis on the Hardy
space H2(T). We discuss a decomposition using a non-Blashke sequence, which is analogous to
the Whitney cube decomposition of the unit disc. Our primary goal is to successfully recreate an
analytical function from samples at the non-Blaschke sequence. We explore the Banach frame
structure that was produced from the non-Blaschke sequences, look at the frame structure of the
reproducing kernel that corresponds to it, and derive a series representation of any operator in
the space in terms of the sampling sequence.

\begin{thebibliography}{5}
\bibitem{casazza1999} Casazza, Peter G., Deguang Han, and David R. Larson. Frames for Banach spaces, Contemporary Mathematics 247 (1999): 149--182.
\bibitem{christensen2003} O. Christensen, An Introduction to Frames and Riesz basis, Birkh\"{a}user, 2003.
\bibitem{pap2001} Pap, M. Hyperbolic wavelets and multiresolution in H2(T). J. Fourier Anal. Appl. 17(5), 755--776 (2011).
\end{thebibliography}

        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0409}{}\begin{ilasabstract}
\talktitle{On noncommutative partial convexity}
    
\textbf{Sriram Balasubramanian}, \info{09:00\textrm{--}09:30 @ SC1001 (June 27, Friday)} \hfill \hyperlink{up0409}{$\Uparrow$}
    
    
\mtskip
    In this talk, we will discuss the structure of matrix-valued (free) polynomials in several freely noncommuting variables that enjoy certain partial  convexity properties. 
\end{ilasabstract}
    

\hypertarget{down0102}{}\begin{ilasabstract}
\talktitle{Generalized inverses of quaternion matrices: theory, computation, and applications}
    
\textbf{Neha Bhadala}, \info{17:00\textrm{--}17:30 @ SC1005 (June 23, Monday)} \hfill \hyperlink{up0102}{$\Uparrow$}
    
    
\mtskip
    This talk explores the theoretical foundations and computational techniques for quaternion generalized inverses, with a particular emphasis on outer inverses and $\{1,2\}$-inverses under prescribed range and null space constraints. Given the non-commutative nature of quaternions, we provide a structured analysis of left and right range and null spaces of quaternion matrices. Explicit representations for these inverses are formulated, including full-rank decomposition-based constructions. To facilitate efficient computation, we introduce two distinct algorithms: one utilizing the Quaternion Toolbox for MATLAB (QTFM) and another based on a complex structure-preserving framework. Additionally, we establish a novel link between quaternion outer inverses with subspace constraints and the Moore–Penrose inverse, offering a new perspective on their interrelation. The effectiveness of our methods is demonstrated through numerical experiments, and their practical utility is highlighted via a color image deblurring application. These results underscore the significance of quaternion generalized inverses in engineering and applied mathematics.
\end{ilasabstract}
    

\hypertarget{down0081}{}\begin{ilasabstract}
\talktitle{Grover walks on unitary Cayley graphs and integral regular graphs}
    
\textbf{Koushik Bhakta}, \info{16:30\textrm{--}17:00 @ SC0009 (June 23, Monday)} \hfill \hyperlink{up0081}{$\Uparrow$}
    
    
\mtskip
    Quantum walk on graphs is an important concept that lies at the intersection of quantum information and graph theory. There are two types of quantum walk: continuous-time quantum walk and discrete-time quantum walk. We focus on the Grover walk, a type of discrete-time quantum walk. The unitary Cayley graph  has vertex set $\{0,1, \hdots ,n-1\}$, where two vertices  $u$ and $v$ are adjacent if $\gcd(u - v, n) = 1$. We study periodicity and perfect state transfer of Grover walks on the unitary Cayley graphs. We characterize all periodic unitary Cayley graphs. We prove that periodicity is a necessary condition for the occurrence of perfect state transfer on a vertex-transitive graph. Also, we provide a necessary and sufficient condition for the occurrence of perfect state transfer on circulant graphs. Using these, we prove that only four graphs in the class of unitary Cayley graphs exhibit perfect state transfer. Also, we provide a spectral characterization of the periodicity of Grover walks on integral regular graphs.

\end{ilasabstract}
    

\hypertarget{down0419}{}\begin{ilasabstract}
\talktitle{The expansion of functions by Toeplitz matrices}
    
\textbf{Rafik Bouifden}, \info{08:00\textrm{--}08:30 @ SC2006 (June 27, Friday)} \hfill \hyperlink{up0419}{$\Uparrow$}
    
    
\mtskip
    The expansion of a real function is a crucial technique for representing a function as an infinite series of simpler functions. This method serves as the primary tool for locally approximating functions that cannot be expressed solely through basic operations—addition, subtraction, multiplication, and division—using polynomials.
To grasp the significance of this mathematical concept, historical and epistemological research is essential, as noted by Sierpinska $[1]$. The notion of expansion has evolved through several stages, reflecting the development of a broad conceptual framework. R. Kouki $[2]$ categorizes these stages into five non-linear steps, which incorporate various geometric, analytical, and algebraic techniques. The groundwork for this work was laid in the early seventeenth century by mathematicians such as Torricelli, Roberval, Fermat, Descartes, and Isaac Barrow, who addressed tangent problems. This was further articulated by Taylor in 1715 and later expanded upon by Newton and Leibniz through polynomial methods, with significant contributions from Cauchy in 1823 and Abel in 1826, culminating in Poincar\'e's work in 1886.
Today, calculating the expansion of a function often requires divisions based on increasing powers, where approximate reasoning involves neglecting certain terms in this limiting process. In this context, we propose a novel algorithmic matrix technique that leverages the fundamental properties of matrix computations. Specifically, we associate the expansion of a function $f$ to order $n$ near zero with a Toeplitz triangular matrix, where the first column represents the polynomial corresponding to the expansion of $f$. We then outline all calculation rules for these limited developments. Ultimately, our work gives a quick algorithm to find, according to Douady $[3]$ the object ``the expansion'' of non-usual functions, whose Toeplitz matrices we have chosen as a ``tool'' and vice
versa in some cases. This approach highlights the importance of matrix techniques in advancing our understanding and application of function expansions.
\\
References
\\
$[1]$ A.Sierspinka Quelques id\'ees sur la m\'ethodologie de la recherche en didactique des math\'ematiques li\'ees \`a la
notion d'obstacle \'epist\'emologique, Cahier de Didactique des Math\'ematiques, 7,85-86, (1989).
\\
$[2]$ R.Kouki Comparaison entre l'\'evolution historique ayant men\'e aux d\'eveloppements limit\'es et leur pratique
d'enseignement au d\'ebut de l'universit\'e : Entre syntaxe et s\'emantique, First conference of International Network for Didactic Research in University Mathematics, Montpellier, France, (2016) ffhal-01337899ff
\\
$[3]$ R.Douady Jeux de cadres et dialectique outil-objet, Recherches en Didactique des Math\'ematiques, 7(2) 5-31,(1986).  
\end{ilasabstract}
    

\hypertarget{down0422}{}\begin{ilasabstract}
\talktitle{On the shadow graph operation: a generalization of double graphs and its spectrum}
    
\textbf{Francis Joseph Campena}, \info{08:00\textrm{--}08:30 @ SC3001 (June 27, Friday)} \hfill \hyperlink{up0422}{$\Uparrow$}
    
    
\mtskip
    In 2007, E. Munarini et al defined the notion of the double of a graph. The double of a connected graph $G$ denoted $\mathcal{D}_2(G)$  is constructed by taking two copies of $G$ say $G'$ and $G''$ and joining by an edge each vertex $v'$ in $G'$ to the neighbors of the corresponding vertex $v''$ in $G''$. This was later generalized by M. Marino and N. Salvi.\\~\\
\indent In this study, we define a graph operation called shadow graph of $G$ and $H$ denoted by $G \text{\small$ \blacksquare $} H.$ This naturally generalizes this notion of a double graph in the sense that the double of a graph is just the shadow graph of $G$ with a path of order 2, $G\text{\small$ \blacksquare $} P_2$, and the generalized double is simply the shadow graph of $G$ with the complete graph on $m$ vertices. $G\text{\small$ \blacksquare $} K_m$. We determine the spectrum of $G\text{\small$ \blacksquare $} H$  in relation to the spectrum of $G$ and $H$. 
\end{ilasabstract}
    

\hypertarget{down0094}{}\begin{ilasabstract}
\talktitle{Almost (Strictly) semimonotone matrices}
    
\textbf{Bharat Pratap Chauhan}, \info{17:00\textrm{--}17:30 @ SC1001 (June 23, Monday)} \hfill \hyperlink{up0094}{$\Uparrow$}
    
    
\mtskip
    An almost (strictly) semimonotone matrix  $A$ is a real square matrix that is not (strictly) semimonotone but whose proper principal submatrices are (strictly) semimonotone. Furthermore, a real square matrix $A$ is a semimonotone matrix if the operation $Ax$ does not negate all positive entries of any nonzero, entrywise nonnegative real vector $x$. Similarly, a real square matrix $A$ is a strictly semimonotone matrix if the operation $Ax$ does not negate or turn to zero all positive entries of any nonzero, entrywise nonnegative real vector $x$. The class of (strictly) semimonotone matrices generalizes the class of (strictly) copositive matrices, which includes (positive) nonnegative matrices. These matrices play a crucial role in the theory of the linear complementarity problem (LCP). The LCP is the problem of finding a complementary pair of nonnegative vectors in a finite-dimensional real vector space that satisfies a given system of linear inequalities.  The LCP is one of the fundamental problems in optimization theory, providing a unifying framework for studying mathematical programming problems such as linear programming, quadratic programming, and bimatrix games. 
 
One of the major challenges with (strictly) semimonotone matrices lies in their construction and detection. To address these challenges and further advance our understanding of these matrices, we focus on the class of almost (strictly) semimonotone matrices, introduced by Tsatsomeros and Wendler. In [Spec. Matrices 7 (2019) 291--303], Wendler studied various properties of $2 \times 2$  and $3 \times 3$ almost (strictly) semimonotone matrices and proposed a conjecture. In this work, we revisit the class of almost (strictly) semimonotone matrices and address Wendler's conjecture. We conducted a comprehensive study of matrix theoretic properties of almost (strictly) semimonotone matrices and examined the structural and sign-reversing properties of matrices. We explore results concerning the existence and multiplicity of solutions to the linear complementarity problem associated with these matrices.
\end{ilasabstract}
    

\hypertarget{down0101}{}\begin{ilasabstract}
\talktitle{(Generic) Eigenvalue algorithms for matrices of quaternions, reduced biquaternions and their dual, and applications}
    
\textbf{Thaniporn Chaysri}, \info{16:30\textrm{--}17:00 @ SC1005 (June 23, Monday)} \hfill \hyperlink{up0101}{$\Uparrow$}
    
    
\mtskip
    Quaternions are a four-dimensional non-commutative algebra and a division ring of numbers introduced by Hamilton in 1843. The main obstacle in deriving eigenvalue algorithms for matrices of quaternions, due to non-cummutativity, is the efficient implementation of shifts. Other linear algebra concepts naturally carry over from real or complex numbers. 
Reduced biquaternions are a four-dimensional commutative number algebra, introduced by Segre in 1892. The main obstacles when deriving algorithms for matrices of reduced biquaternions are the existence of non-invertible non-zero elements, and the need to consistently define some basic linear algebra concepts in this setting. 
We present new efficient algorithms for the QR factorization and eigenvalue and singular value decompositions of these types of matrices and their dual, keeping them as generic as possible. 
We also present applications to computation of various types of matrix generalized inverses and image analysis. The algorithms are efficiently implemented using the multiple-dispatch feature of the programming language Julia. 
This is joint work with Ivan Slapni{\v c}ar, Nevena Jakov{\v c}evi{\' c} Stor, and Anita Carevi{\' c} from the Department of Mathematics and Physics, FESB, University of Split, Croatia, and Sk. Safique Ahmad, Neha Bhadala, Pinki Khatun, and Gyan Swarup Nag from the Department of Mathematics, IIT Indore, India.
This work has been partially supported by Croatian Science Foundation under the project IP-2020-02-2240.

\end{ilasabstract}
    

\hypertarget{down0405}{}\begin{ilasabstract}
\talktitle{Inner and outer Bohemian inverses}
    
\textbf{Geeta Chowdhry}, \info{08:30\textrm{--}09:00 @ SC0014 (June 27, Friday)} \hfill \hyperlink{up0405}{$\Uparrow$}
    
    
\mtskip
    A matrix $A$ is known as the Bohemian matrix with respect to a population \textbf{P} if all its entries are restricted to the set \textbf{P}. A matrix $X$ is known as the Inner Bohemian inverse (resp. Outer Bohemian inverse) of $A$ with respect to a population \textbf{P} if it satisfies $AXA=A$ (resp. $XAX=X$) and the entries of $X$ are restricted to the set \textbf{P}.
Recently, the Inner Bohemian inverses of some structured matrices have been studied with respect to the general population \textbf{P} containing $\{0,1,-1\}$ in [1]. We have worked on the Inner and outer Bohemian inverses of the extended class of Bohemian matrices. We have characterized some classes of Bohemian matrices with respect to the population \textbf{P}$=\{0,1,-1\}$ and have found results for their Inner and outer Bohemian inverses along with the cardinalities of the sets of Inner and outer Bohemian inverses when the population is fixed to \textbf{P}$=\{0,1,-1\}$ which in turn simplifies the cardinality results obtained in [1]. Additionally, for higher rank Bohemian matrices with respect to the population \textbf{P}$=\{0,1,-1\}$, we have found Inner and Outer Bohemian inverses of a specified class of Bohemian matrices.

\mbox{[1]} Eunice Y. S. Chan, Robert M. Corless, Laureano González-Vega, J. Rafael Sendra, and Juana Sendra. : Inner Bohemian inverses, Applied Mathematics and Computation, 421:126945, May 2022.

\end{ilasabstract}
    

\hypertarget{down0407}{}\begin{ilasabstract}
\talktitle{Structural properties of symmetric Toeplitz and Hankel matrices}
    
\textbf{Hojin Chu}, \info{08:00\textrm{--}08:30 @ SC1001 (June 27, Friday)} \hfill \hyperlink{up0407}{$\Uparrow$}
    
    
\mtskip
    In this paper, we investigate properties of a symmetric Toeplitz matrix and a Hankel matrix by studying the components of its graph.
To this end, we introduce the notion of ``weighted Toeplitz graph'' and ``weighted Hankel graph'', which are weighted graphs whose adjacency matrix are a symmetric Toeplitz matrix and a Hankel matrix, respectively.
By studying the components of a weighted Toeplitz graph, we show that the Frobenius normal form of a symmetric Toeplitz matrix is a direct sum of symmetric irreducible Toeplitz matrices.
Similarly, by studying the components of a weighted Hankel matrix, we show that the Frobenius normal form of a Hankel matrix is a direct sum of irreducible Hankel matrices.
\end{ilasabstract}
    

\hypertarget{down0078}{}\begin{ilasabstract}
\talktitle{Algorithms and inertial algorithms for the inverse mixed variational inequality problems in Hilbert spaces}
    
\textbf{Chih-Sheng Chuang}, \info{17:00\textrm{--}17:30 @ SC0008 (June 23, Monday)} \hfill \hyperlink{up0078}{$\Uparrow$}
    
    
\mtskip
    The inverse mixed variational inequality problem comes from the classical variational inequality, and it has many
applications. In this paper, we propose new algorithms to study the inverse mixed variational inequality problems in Hilbert spaces, and these algorithms based on the generalized projection operator. Next, we establish convergence theorems under inverse strongly monotonicity conditions. Besides, we also give inertial-type algorithms for the inverse mixed variational inequality problems, and the conditions are different from the above convergence theorems. 

\end{ilasabstract}
    

\hypertarget{down0076}{}\begin{ilasabstract}
\talktitle{Canonical form for pairs of matrices associated with linear-time invariant dissipative Hamiltonian descriptor systems}
    
\textbf{Sweta Das}, \info{16:00\textrm{--}16:30 @ SC0008 (June 23, Monday)} \hfill \hyperlink{up0076}{$\Uparrow$}
    
    
\mtskip
    We study pairs of complex matrices associated with Linear-Time Invariant (LTI) dissipative Hamiltonian descriptor systems. These systems appear in energy-based modeling of dynamical systems and are a special case of port-Hamiltonian (pH) descriptor systems. We derive the canonical forms for a pair of $n\times n$ complex matrices $(E,Q)$ under transformations $(E,Q) \rightarrow (UEV,U^{-T}QV)$, and $(E,Q) \rightarrow (UEV,U^{-*}QV)$, where $U$ and $V$ are non-singular complex matrices. We also consider the special cases of $E^TQ$ and $E^*Q$ being (skew-)symmetric and (skew-)Hermitian, respectively. This is a joint work with Andrii Dmytryshyn and Volker Mehrmann. 

\end{ilasabstract}
    

\hypertarget{down0108}{}\begin{ilasabstract}
\talktitle{On the eigenvalues of the matrix $[f(g(p_i-p_j))]$}
    
\textbf{Manisha Devi}, \info{16:00\textrm{--}16:30 @ SC2006 (June 23, Monday)} \hfill \hyperlink{up0108}{$\Uparrow$}
    
    
\mtskip
    We prove that if $g:\mathcal{R}\rightarrow[0,\infty)$ is a conditionally negative definite function and $f:[0,\infty)\rightarrow[0,\infty)$ is a Bernstein function, then the function $f\circ g$ is conditionally negative definite. The inertia of the matrix $[f(g(p_i-p_j))]$ is $(1,0,n-1)$ if $g(x)=0$ only for $x=0$ and $f$ is non-linear. A new and easy proof is also presented to demonstrate that the matrix $[\log(1-p_ip_j)]$ is negative definite for $n$ distinct positive real numbers $p_i<1, ~\forall~i$. Numerous more relevant results are discussed. These results supplements and unifies previous findings for operator monotone functions demonstrated by several authors, including Dyn, Goodman and Michelli, Bhatia and Jain, Garg and Aujla, and Garg and Agarwal.
\end{ilasabstract}
    

\hypertarget{down0400}{}\begin{ilasabstract}
\talktitle{Recursions among and classification of singular $k$-tridiagonal Toeplitz matrices}
    
\textbf{Hamide Dogan}, \info{09:00\textrm{--}09:30 @ SC0009 (June 27, Friday)} \hfill \hyperlink{up0400}{$\Uparrow$}
    
    
\mtskip
    We introduce a novel L/N factorization approach, inspired by Doolittle's L/U factorization, for 
$k$-tridiagonal Toeplitz matrices, $T^{(k)}_n$, where $n=km+s$ and $\det(T^{(1)}_p)=0$ for $p<m$. This factorization allows for the derivation of recursion expressions and provides a classification of singular Toeplitz matrices.
\end{ilasabstract}
    

\hypertarget{down0397}{}\begin{ilasabstract}
\talktitle{Initially positive sign patterns}
    
\textbf{Denise Mae Go}, \info{09:00\textrm{--}09:30 @ SC0008 (June 27, Friday)} \hfill \hyperlink{up0397}{$\Uparrow$}
    
    
\mtskip
    A nonsingular $n \times n$ matrix $A$ is said to be \textit{initially positive} if the first column of $A$ and the first row of $A^{-1}$ are both positive. Initially positive matrices are used to construct matrices with negative entries that still satisfy the Perron-Frobenius property. In this short talk, we determine sign patterns that allow or require initial positivity for orders $n \leq 4$. We provide some ways of constructing initially positive matrices for any order $n$.

\end{ilasabstract}
    

\hypertarget{down0417}{}\begin{ilasabstract}
\talktitle{AMDS symbol-pair constacyclic codes}
    
\textbf{Hieu Ha Van}, \info{08:30\textrm{--}09:00 @ SC2001 (June 27, Friday)} \hfill \hyperlink{up0417}{$\Uparrow$}
    
    
\mtskip
    Let $p$ be an odd prime, and let $\mathbb F_p$ be the finite field with $p$ elements. In this talk, I will first construct new AMDS symbol-pair cyclic codes of length $4p$ by analyzing their generator polynomials. Then, using the generator polynomial, I derive a family of AMDS symbol-pair constacyclic codes of the same length.
\end{ilasabstract}
    

\hypertarget{down0399}{}\begin{ilasabstract}
\talktitle{Quasi-triangularization of matrix polynomials in Maple}
    
\textbf{Richard Hollister}, \info{08:30\textrm{--}09:00 @ SC0009 (June 27, Friday)} \hfill \hyperlink{up0399}{$\Uparrow$}
    
    
\mtskip
    Given a regular matrix polynomial over any field, it is possible to construct a quasi-triangular matrix of the same degree that is unimodularly equivalent to the given polynomial.  The details of this process can be found in the paper by Anguas et al.  In this talk we present Maple code for this quasi-triangularization process and discuss some of our future plans for Maple implementations in the realm of matrix polynomials.

\end{ilasabstract}
    

\hypertarget{down0092}{}\begin{ilasabstract}
\talktitle{The full P-vertex problem for unicyclic graphs}
    
\textbf{Aditi Howlader}, \info{16:00\textrm{--}16:30 @ SC1001 (June 23, Monday)} \hfill \hyperlink{up0092}{$\Uparrow$}
    
    
\mtskip
    Let $A=[a_{ij}] \in \mathbb{R}^{n \times n}$ be a real symmetric and nonsingular matrix and $G$ be the underlying graph with the vertex set $\{v_1,\ldots, v_n\}$ and the edge set $\{(v_i,v_j)\colon a_{ij}\neq 0, i\neq j\}$. Let $A(i)$ be the principal submatrix obtained by removing the $i^\text{th}$ row and the $i^\text{th}$ column of $A$. If the nullity of $A(i)$ is unity, then the vertex $v_i$ is called a P-vertex of the matrix $A$. The full P-vertex problem is to determine if there is a nonsingular matrix $A$ such that each vertex of the corresponding graph $G$, is a P-vertex of $A$. In this article, we investigate the full P-vertex problem for unicyclic graphs.
\end{ilasabstract}
    

\hypertarget{down0411}{}\begin{ilasabstract}
\talktitle{Nonmonotone diagonal quasi-Newton accelerated gradient descent methods for the nearest correlation matrix problems}
    
\textbf{Duc-Quoc Huynh}, \info{08:30\textrm{--}09:00 @ SC1003 (June 27, Friday)} \hfill \hyperlink{up0411}{$\Uparrow$}
    
    
\mtskip
    The nearest correlation matrix (NCM) problem poses computational difficulties with critical implications in finance and actuarial science. Accurate correlation matrices are essential for effective risk management and investment strategies.  
The NCM problem is mathematically formulated as a constrained optimization problem, often solved using the alternating projection method (APM) or alternating direction of multipliers method (ADMM) . However, its slow linear convergence and required complete eigenvalue decomposition at each iteration render it computationally expensive and impractical for large-scale problems. Alternatively, the NCM problem can be reformulated as an unconstrained optimization task in its dual form, taking advantage of its convex structure. It allows for a focus on minimizing the dual objective function by solving for the zeros of its gradient to satisfy first-order optimality conditions. Our proposed method belongs to the framework of the generalized linesearch iterative methods, incorporating two basic elements: search direction and stepsize determination. Additionally, we introduce two practical mechanisms, including an accelerated step and nonlinear preconditioning, to improve the method's robustness and efficiency.
We proposed the quasi-Newton method with diagonal Jacobian approximation (QN-SDAJ), which is used as a nonlinear preconditioner to accelerate gradient descent, significantly reducing the number of iterations and computational time. Numerical results show that our proposed method outperforms existing alternatives, including accelerated gradient descent, semismooth inexact Newton, and APM, particularly for large-scale problems, demonstrating superior efficiency.
\end{ilasabstract}
    

\hypertarget{down0089}{}\begin{ilasabstract}
\talktitle{Generalizing Wilf's inequality for strongly regular graphs}
    
\textbf{Hareshkumar Jadav}, \info{16:30\textrm{--}17:00 @ SC0014 (June 23, Monday)} \hfill \hyperlink{up0089}{$\Uparrow$}
    
    
\mtskip
    The clique number $\omega$ is the size of the largest clique in any graph. Determining the clique number is an NP-complete problem, which implies that there is no polynomial-time algorithm to solve it. Wilf's inequality provides a spectral bound for the clique number of simple graphs, given by $\frac{n}{n - \lambda_{1}} \leq \omega$, where $\lambda_1$ is the largest eigenvalue of the adjacency matrix, and $n$ is the number of vertices in the graph. Strengthening this bound, Elphick and Wocjan proposed a conjecture in 2018 that is $\frac{n}{n - \sqrt{s^{+}}} \leq \omega$, where $s^+ = \sum_{\lambda_{i} > 0} \lambda_{i}^2$ and $\lambda_i$ are eigenvalues of the adjacency matrix. In this work, we have settled this conjecture for seven different classes of graphs: (1) Paley graphs which are strongly regular graphs with parameters $srg(4\beta + 1, 2\beta, \beta - 1, \beta)$, where $q$ is a prime power and $q \equiv 1 \pmod{4}$; (2) strongly regular graphs with $\alpha = \beta$ (i.e., $srg(n, d, \beta, \beta)$); (3) the line graph of $K_{m,m}$; (4) the line graph of $K_{n}$; (5) the Cartesian product of strongly regular graphs $G$ with $G$, where $G$ is a strongly regular graph; (6) general Rook's graphs; and (7) Ramanujan graphs, where the second largest eigenvalue follows the property $\lambda_2 \leq 2\sqrt{d-1}$.
\end{ilasabstract}
    

\hypertarget{down0100}{}\begin{ilasabstract}
\talktitle{Quaternion matrix polynomials: location of eigenvalues}
    
\textbf{Sachindranath Jayaraman}, \info{16:00\textrm{--}16:30 @ SC1005 (June 23, Monday)} \hfill \hyperlink{up0100}{$\Uparrow$}
    
    
\mtskip
    A right quaternion matrix polynomial is an expression of the form 
$P(\lambda) = \displaystyle \sum_{i=0}^{m}A_i \lambda^i$, where 
$A_i \in M_n(\mathbb{H})$ with $A_m \neq 0$, where 
$M_n(\mathbb{H})$ is the set of all square matrices from the ring of quaternions. 
A quaternion $\lambda_0 \in \mathbb{H}$ is a right eigenvalue of $P(\lambda)$ 
if there exists a nonzero vector $y \in \mathbb{H}^n$ such that 
$\displaystyle \sum_{i=0}^{m}A_i  y\lambda_0^i  =0$. The purpose of this talk is to 
bring out some recent results about the location of right eigenvalues of $P(\lambda)$ 
relative to certain subsets of the set of quaternions. The notion of (hyper)stability of 
complex matrix polynomials is extended to quaternion matrix polynomials and 
results are obtained about right eigenvalues of $P(\lambda)$ by  
$(1)$ giving a relation between (hyper)stability of a quaternion matrix polynomial and 
its complex adjoint matrix polynomial, and then by $(2)$ proving that $P(\lambda)$ is 
stable with respect to an open (closed) ball in the set of quaternions, centered at a complex 
number if and only if it is stable with respect to its intersection with the set of 
complex numbers.  We derive as a consequence of the above that right 
eigenvalues of $P(\lambda)$ lie between two concentric balls of specific radii in the 
set of quaternions centered at the origin. A generalization of the 
Enestr{\"o}m-Kakeya theorem to quaternion matrix polynomials is obtained as an 
application. Finally, we also identify classes of quaternion matrix polynomials for 
which stability and hyperstability are equivalent.  This talk is based on the following paper.

\begin{itemize}
\item Pallavi Basavaraju, Shrinath Hadimani and Sachindranath Jayaraman, 
\textit{Stability of quaternion matrix polynomials}, appecped for publication, 
\textit{Linear Algebra, Matrices and their Applications}, Contemporary Mathematics, 
AMS, Edited by Surender Kumar Jain, Manjunatha Prasad Karantha, Steve Kirkland, 
Vinay Madhusudanan, Srinivasa Siva Rama Krishna Rao Taduri.
\end{itemize}


\end{ilasabstract}
    

\hypertarget{down0082}{}\begin{ilasabstract}
\talktitle{Brouwer's conjecture for the corona and edge corona of graphs}
    
\textbf{Pragati Asutosh Jena}, \info{17:00\textrm{--}17:30 @ SC0009 (June 23, Monday)} \hfill \hyperlink{up0082}{$\Uparrow$}
    
    
\mtskip
    Let $G$ be a connected graph on $n$ vertices. Let $S_k(G)$ denote the sum of $k$ largest Laplacian eigenvalues of $G$ and $e(G)$ denote the number of edges in $G$. Brouwer conjectured that $S_k(G)\leq e(G)+\binom{k+1}{2}$ for any $k\in \{1,\ldots,n\}$. Let $H$ be a connected graph on $m\geq 2$ vertices. Here, we show that if $G$ and $H$ satisfy the Brouwer's conjecture, then the corona of $G$ and $H$ also satisfies the Brouwer's conjecture. Furthermore, when $G$ is regular, $n\geq 4$, $m\geq 3$ and $e(H)\geq m+1$, we prove that if $H$ satisfies the Brouwer's conjecture, then the edge corona of $G$ and $H$ also satisfies the Brouwer's conjecture. This talk is based on joint work with Sasmita Barik.
\end{ilasabstract}
    

\hypertarget{down0426}{}\begin{ilasabstract}
\talktitle{Pretty good fractional revival on abelian Cayley graphs}
    
\textbf{Akash Kalita}, \info{08:30\textrm{--}09:00 @ SC4011 (June 27, Friday)} \hfill \hyperlink{up0426}{$\Uparrow$}
    
    
\mtskip
    Let $\Gamma$ be a graph with the adjacency matrix $A$. The transition matrix of $\Gamma$, denoted $H(t)$, is defined as $H(t) := \exp(-\textbf{i}tA)$, where $t \in \mathbb{R}$ and $\textbf{i} := \sqrt{-1}$. The graph $\Gamma$ exhibits pretty good fractional revival (PGFR) between the vertices $a$ and $b$ if there exists a sequence $\{t_k\}$ in $\mathbb{R}$ such that $\lim_{k\to\infty} H(t_k){\textbf{e}_{a}} = \alpha{\textbf{e}_{a}} + \beta{\textbf{e}_{b}}$, where $\alpha, \beta(\neq 0) \in \mathbb{C}$ with $|\alpha|^2 + |\beta|^2 = 1$. In particular, if $\alpha = 0$, then $\Gamma$ exhibits pretty good state transfer (PGST) between $a$ and $b$. In this study, we first present a necessary and sufficient condition for the existence of PGFR on Cayley graphs over abelian groups. Using that necessary and sufficient condition, we prove that complement of a cycle on $2 p^s$ vertices, where $p$ is an odd prime and $s$ is a positive integer, exhibits PGFR.  In the class of unitary Cayley graphs, we prove that an unitary Cayley graph on $n$ ($n \geq 8$) vertices exhibits PGFR if and only if $n = 2p$, where $p$ is an odd prime. The preceding two classes of circulant graphs provide infinitely many circulant graphs exhibiting PGFR that fails to exhibits PGST. Further we obtain more circulant graphs exhibiting PGFR. We also obtain some classes of circulant graphs not exhibiting PGFR. Some of our results generalize the results of Chan et al. [Pretty good quantum fractional revival in paths and cycles. \textit {Algebr. Comb.} 4(6) (2021), 989-1004.] for cycles.        

\end{ilasabstract}
    

\hypertarget{down0088}{}\begin{ilasabstract}
\talktitle{QCLAB: A MATLAB toolbox for quantum numerical linear algebra}
    
\textbf{Sophia Keip}, \info{16:00\textrm{--}16:30 @ SC0014 (June 23, Monday)} \hfill \hyperlink{up0088}{$\Uparrow$}
    
    
\mtskip
    Quantum numerical linear algebra is about solving numerical linear algebra problems on quantum computers - a field that has seen exciting and significant progress in the past few years. Rapid advancements in quantum hardware continue to drive this momentum forward and highlight the fast-paced progress of the field. To facilitate quantum algorithm research, especially as quantum hardware is still maturing, access to robust computational tools is crucial. We introduce QCLAB (\url{https://github.com/QuantumComputingLab/qclab}), an object-oriented MATLAB toolbox for creating, representing and simulating quantum circuits. What sets QCLAB apart is its emphasis on numerical linear algebra, prioritizing numerical stability, efficiency and performance, as well as its seamless integration with MATLAB.
In this talk, featuring a MATLAB tutorial on QCLAB, we will showcase the key features of QCLAB while providing concrete insights into quantum numerical linear algebra through three landmark quantum algorithms: the Quantum Fourier Transform (QFT), Quantum Phase Estimation (QPE), and Quantum Singular Value Estimation (QSVE). This hands-on introduction is intended to encourage the audience to engage actively with this promising research area. With both beginners and experts in mind, the talk is designed for researchers looking for an accessible entry point into quantum computing and experienced practitioners seeking a tool for rapid prototyping of quantum algorithms.



\emph{This is joint work with Daan Camps and Roel Van Beeumen}

\end{ilasabstract}
    

\hypertarget{down0098}{}\begin{ilasabstract}
\talktitle{Structured backward errors for special classes of saddle point problems with applications}
    
\textbf{Pinki Khatun}, \info{17:00\textrm{--}17:30 @ SC1003 (June 23, Monday)} \hfill \hyperlink{up0098}{$\Uparrow$}
    
    
\mtskip
    Saddle point problems (SPPs) have garnered significant attention in recent times due to their pervasive occurrence in applications such as computational fluid dynamics and constrained and weighted least square estimation. Many numerical algorithms have been developed to find the efficient solution of the {SPP}  with {{circulant}}, {Toeplitz}, or {symmetric}-{Toeplitz} block matrices. This prompts a natural inquiry: can an approximate solution obtained from a numerical algorithm be the exact solution to a nearly perturbed problem? The concept of backward error ({BE})  is used to determine how far a computed solution stands from the original problem. Recent research efforts have focused on exploring the  BE for SPPs. However, these investigations overlook the inherent sparsity pattern and {{circulant}},  {Toeplitz} or symmetric-Toeplitz structures of the coefficient matrix of the SPP. To overcome these limitations, we investigate the structured  {BEs} of {SPPs} when the perturbation matrices exploit the sparsity pattern as well as { {circulant}},  {Toeplitz}, and  {symmetric}-{Toeplitz} structures. Furthermore, we construct minimal perturbation matrices that preserve the sparsity pattern and the aforementioned structures. One application of the obtained results is discussed in deriving structured  {BEs} for the weighted regularized least squares problem. Numerical experiment are performed to validate our findings, showcasing the utility of the obtained structured  {BEs} in assessing the strong stability of numerical algorithms.
\end{ilasabstract}
    

\hypertarget{down0416}{}\begin{ilasabstract}
\talktitle{Compressed commuting graphs of matrix rings}
    
\textbf{Damjana Kokol Bukovšek}, \info{08:00\textrm{--}08:30 @ SC2001 (June 27, Friday)} \hfill \hyperlink{up0416}{$\Uparrow$}
    
    
\mtskip
    In the talk we introduce compressed commuting graph of rings. It can be seen as a compression of the standard commuting graph (with the central elements added) where we identify the vertices that generate the same subring. The compression is chosen in such a way that it induces a functor from the category of rings to the category of graphs, which means that our graph takes into account not only the commutativity relation in the ring, but also the commutativity relation in all of its homomorphic images. 

We show that this compression is best possible for matrix algebras over finite fields. We consider the compressed commuting graphs of finite fields, rings of $2 \times 2$ matrices over finite fields and rings of $3 \times 3$ matrices over finite prime fields.

(This is a joint work with Ivan-Vanja Boroja, Hamid Reza Dorbidi, and Nik Stopar.)
\end{ilasabstract}
    

\hypertarget{down0085}{}\begin{ilasabstract}
\talktitle{Singular matrices possessing the triangle property - II}
    
\textbf{Kadali Kranthi Priya}, \info{16:30\textrm{--}17:00 @ SC0012 (June 23, Monday)} \hfill \hyperlink{up0085}{$\Uparrow$}
    
    
\mtskip
    It is known that an invertible real square matrix has the triangle property, if and only if the inverse is a tridiagonal matrix.
This result has an implicit importance due to the fact that nonsingular tridiagonal matrices arise in a variety of problems in pure and applied mathematics and for this reason they have been extensively studied in the literature. However, the singular case has received comparatively much lesser attention. In particular, there has been little focus on the generalized inverses of such matrices.  In this paper, we provide a complete description of those singular matrices possessing the triangle property to have tridiagonal Moore-Penrose inverse or group inverse.



\end{ilasabstract}
    

\hypertarget{down0420}{}\begin{ilasabstract}
\talktitle{An alternating algorithm for tropical best discrete approximation}
    
\textbf{Nikolai Krivulin}, \info{08:30\textrm{--}09:00 @ SC2006 (June 27, Friday)} \hfill \hyperlink{up0420}{$\Uparrow$}
    
    
\mtskip
    We consider a best discrete approximation problem in the setting of tropical (idempotent) algebra dealing with the theory and application of semirings and semifields with idempotent operations. Given a set of input-output pairs of an unknown function defined on a tropical semifield, the problem is to determine an approximating rational function formed by two Puiseux polynomials as numerator and denominator in the function. With specified numbers of monomials in both polynomials, the approximation aims at evaluating the exponent and coefficient for each monomial in the polynomials to fit the rational function to the given data in the sense of a tropical distance function. To solve the problem, we transform it into approximation of a vector equation with unknown vectors on both sides with one side answered to the numerator polynomial and the other side to the denominator. Each side of the equation involves a matrix with entries dependent on the unknown exponents, multiplied by the vector of unknown coefficients of monomials in the corresponding polynomial. We propose an algorithm that constructs a series of approximate solutions by alternatively fixing one side of the equation to the already found result and leaving the other intact. The obtained equation is first approximated with respect to the vector of coefficients, which results in a vector of coefficients and approximation error both parameterized by the exponents. Furthermore, the values of exponents are found by minimization of the approximation error, using an optimization procedure that is based on an agglomerative clustering technique. To illustrate applications, we present results for approximation problems formulated in terms of max-plus algebra (a real semifield with addition defined as maximum and multiplication as arithmetic addition), which correspond to ordinary problems of piecewise linear approximation of real functions. As our numerical experience shows, the proposed algorithm converges in a finite number of steps and provides a reasonably good solution to approximation problems considered.   

\end{ilasabstract}
    

\hypertarget{down0395}{}\begin{ilasabstract}
\talktitle{A new perspective on partial ordering by matrix representation}
    
\textbf{Hojoon Lee}, \info{08:00\textrm{--}08:30 @ SC0008 (June 27, Friday)} \hfill \hyperlink{up0395}{$\Uparrow$}
    
    
\mtskip
    In the study of partially ordered sets (posets), various matrix representations provide useful tools for understanding their structure and properties. One particularly interesting representation is the {\it poset matrix}, which encodes the partial order relations between poset elements. This matrix can also be interpreted as a {\it bit matrix} whose entries encode the bits of the binary representation. This perspective offers a new way to explore and analyze posets by focusing on their binary structure. Viewing poset matrices as bit matrices provides new insights into the enumeration, classification, and properties of posets. In this talk, we will discuss the implications of this approach, explore its potential for enumerating finite posets, and demonstrate how this framework contributes to the understanding of order structures in combinatorics and computer science.
This is a joint work with Gi-Sang Cheon, Hong Joon Choi, Gukwon Kwon, and Yaling Wang.

\end{ilasabstract}
    

\hypertarget{down0412}{}\begin{ilasabstract}
\talktitle{A two-grid spectral deferred correction method for the generalized multi-order fractional differential equations}
    
\textbf{Quen-Yi Lin}, \info{09:00\textrm{--}09:30 @ SC1003 (June 27, Friday)} \hfill \hyperlink{up0412}{$\Uparrow$}
    
    
\mtskip
    The spectral deferred correction (SDC) method is a traditional deferred and defect correction method for ordinary differential equations (ODEs).
The SDC method constructs numerical methods of arbitrary order by iteratively applying a lower-order method to an error function,
enabling significant reductions in computational cost while maintaining strong stability properties.
For first-order ODE problems, many theoretical and numerical results for SDC are available.
However, for fractional differential equations (FDEs), although there are many numerical results, only a few theoretical studies can be found.
FDEs can be considered a generalization of ODEs, replacing integer orders with non-integer ones.
Since FDEs can describe many natural and artificial phenomena, they have attracted increasing attention in recent years.
In this talk, we will apply a two-grid SDC method to multi-order FDEs and present an analysis of their stability and convergence.
Numerical experiments are included to illustrate the theoretical results.
This work is based on joint research with Professor Ming-Cheng Shiue.

\end{ilasabstract}
    

\hypertarget{down0413}{}\begin{ilasabstract}
\talktitle{Riordan matrices' structures}
    
\textbf{Ana Luzón}, \info{08:00\textrm{--}08:30 @ SC1005 (June 27, Friday)} \hfill \hyperlink{up0413}{$\Uparrow$}
    
    
\mtskip
    \begin{bibunit}
        In this talk, I will present how to construct matrices of the Riordan group by row, column, and diagonal. We will look at some Riordan matrices in particular, including their bi-infinite expressions. These constructions will lead to recurrence formulas, numerical identities, group isomorphisms, special subgroups, Lie groups,  commutators, involutions, etc.

%\begin{thebibliography}{99}
%
%\normalsize
%
%
%
%\bibitem{Lie} {G.-S. Cheon, A. Luz\'{o}n, M. A. Mor\'{o}n, L. F. Prieto-Martinez and M. Song}
%{\it Finite and infinite dimensional Lie group structures on Riordan
%groups.} {Adv. Math. }{ 319}{ (2017) } {522-566}.
%
%
%\bibitem{2ways} A.Luz\'{o}n. Iterative processes related to Riordan arrays:
%The reciprocation and the inversion of power series. Discrete Math. 310 (2010), 3607--3618.
%
%\bibitem{Constr}
%{A. Luz\'{o}n, D. Merlini, M. A. Mor\'{o}n and R. Sprugnoli.} {\it
%Identities induced by Riordan arrays. } {Linear Algebra Appl. }{
%436} { (2012) } {631-647}.
%
%\bibitem{formula}
%{A. Luz\'{o}n, M. A. Mor\'{o}n and L. F. Prieto-Martinez.} {\it A formula to
%construct all involutions in Riordan matrix groups. } {Linear
%Algebra Appl. }{533} { (2017) } {397-417}.
%
%
%\bibitem{Lie} {A. Luz\'{o}n, M. A. Mor\'{o}n, and L. F. Prieto-Martinez}
%{\it Commmutators and commutator subgroups of the Riordan group.} {Adv. Math. }{ 428}{ (2023) } {522-566}.
%
%
%\end{thebibliography}


        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0410}{}\begin{ilasabstract}
\talktitle{Approximate two-sided Grasmann-Reyleigh shifts for QR, Core-Chasing, and pole-swapping algorithms}
    
\textbf{Thomas Mach}, \info{08:00\textrm{--}08:30 @ SC1003 (June 27, Friday)} \hfill \hyperlink{up0410}{$\Uparrow$}
    
    
\mtskip
    In each iteration of Francis's implicitly shifted QR algorithm $m$ shift are
chosen to drive the process toward convergence. The most common choice is the
Wilkinson shift for~$m=1$ or~$2$. Rayleigh quotient shifts dominate when
multiple shifts $m\gg 1$ are used. We present alternatives to the Rayleigh
quotient and the Wilkinson shift for the single or double shift case. We present
novel shift strategies for QR algorithms and generalize them to pole-swapping
algorithms.

For normal matrices the Wilkinson shift is proven globally convergent locally
with a cubic convergence rate. The local convergence rate is based on the cubic
convergence of the Rayleigh quotient iteration. Usually for non-normal matrices
locally only a quadratic convergence rate is observed both in Francis's QR
algorithm and in Rayleigh quotient iteration.

It has been shown by Ostrowski in 1959 that the two-sided Rayleigh quotient
iteration is cubic convergent also for non-normal matrices.  We aim to improved
the shift strategy for non-normal matrices by incorporating ideas from the
two-sided Rayleigh quotient following ideas by Chen and Xu. The two-sided
Rayleigh quotient requires an approximation to the right eigenvector, which is
expensive to compute. Hence, we focus on a heuristic approximation to the right
eigenvector.

The discussions also apply to derivatives of Francis's algorithm like the QZ
algorithm by Moler and Stewart, the core-chasing, and the pole-swapping
variants.

We present extensive numerical experiments comparing the different shift
strategies. These provide valuable insights for practical implementations since
the typical number of iterations to reach machine precision is far more
important than the convergence rate at infinity.

This research is joint work with Raf Vandebril (KU Leuven). The research has
been partially funded by the Deutsche Forschungsgemeinschaft (DFG)---Project-ID
318763901---SFB1294.


\end{ilasabstract}
    

\hypertarget{down0090}{}\begin{ilasabstract}
\talktitle{On order $5$ trace zero doubly stochastic matrices and the corresponding eigenvalue region}
    
\textbf{Amrita Mandal}, \info{17:00\textrm{--}17:30 @ SC0014 (June 23, Monday)} \hfill \hyperlink{up0090}{$\Uparrow$}
    
    
\mtskip
     A non-negative square matrix is called a doubly stochastic (DS) matrix if all its row and column sums are exactly equal to $1.$ A vast literature is known for such matrices concerning the eigenvalue region, inverse eigenvalue problem or entry-wise distribution of the non-negative numbers when matrix size or order of the matrix is restricted up to $4,$
 whereas only a little is known for matrices of order $5$ or more except for some sets of doubly structured matrices. 
 %A DS matrix always can be represented as the convex combination of permutation matrices of concerned size.
 
 This talk concerns the following questions: What are those trace zero order $5$ DS matrices whose $k$-times multiplications are also trace zero matrices for some values of $k?$ What is the eigenvalue region of the set of trace zero order $5$ DS matrices? 
 
 We address these questions by proposing a graph theoretic approach to determine the trace of the product of two permutation matrices through a weighted digraph representation for a pair of permutation matrices. Then, we derive the DS matrices of order $5$ whose $k$-th power is also a trace-zero DS matrix for $k\in\{2,3,4,5\}$. Then, we determine necessary conditions for the coefficients of a generic polynomial of degree $5$ to be realizable as the characteristic polynomial of a trace-zero DS matrix of order $5$. Using this, we approximate the eigenvalue region of trace-zero DS matrices of order $5.$ 
 
 
 
\end{ilasabstract}
    

\hypertarget{down0414}{}\begin{ilasabstract}
\talktitle{Roots of elements in a matrix groups}
    
\textbf{Arunava Mandal}, \info{08:30\textrm{--}09:00 @ SC1005 (June 27, Friday)} \hfill \hyperlink{up0414}{$\Uparrow$}
    
    
\mtskip
    Let $F_r$ be a free group of $r$-generators, and $w\in F_r.$ For every group $G$, one defines a ``word map'' $w: G^r\to G$. Let $w(G)$ denote the image of this map. In recent times, it emerged as one of the potential research areas, and produced several astonishing results. Though it has a long history dating back to A. Borel, it has attracted a significant amount of attention, especially after the settlement of the long-standing Ore’s conjecture (which states that every element of a finite non-abelian simple group is a commutator). Note that if $G$ is a field, this is nothing else than a linear form with integer coefficients in $r$ variables. Thus the study of $w(G)$ can be thought of as finding solutions to equations in objects belonging to the category of groups. For non-abelian $G$, word maps are more subtle objects and a lot of effort has been required to unravel some of their properties. Fix an integer $k\geq 2$ and consider the word $x^k\in F_1$. The corresponding word map is called a power map and it has been studied for several decades in various contexts. A remarkable result by McCrudden connects the power map with the exponential map. McCrudden's result states that, for a connected Lie group $G$, $g\in G$ has roots of all orders if and only if $g$ is contained in a one-parameter subgroup (and hence $g=\exp(X)$). In this talk, we will discuss the analogous result for a linear algebraic group over non-Archimedean local field $F$ with any characteristic.  We discuss our recent result about when an element $g\in G(F)\subset GL(V)$ admits roots of all orders? Also, we will discuss the above theme in the context of linear algebraic groups over global fields.
This talk is based on joint work with Parteek Kumar.
\end{ilasabstract}
    

\hypertarget{down0097}{}\begin{ilasabstract}
\talktitle{Completely positive factorization}
    
\textbf{Manu Mathew}, \info{16:30\textrm{--}17:00 @ SC1003 (June 23, Monday)} \hfill \hyperlink{up0097}{$\Uparrow$}
    
    
\mtskip
    A real symmetric matrix $M$ of size $n$ is a completely positive matrix if there exists a real non-negative(entrywise) matrix $B$ of size $n\times m$ such that $M=BB^T$. Completely positive matrix has applications in block designs, complementarity problems and optimization problems. The collection of all completely positive matrices of size $n$  is a proper cone in the vector space of all real symmetric matrices of size $n$. The dual of the completely positive cone is the copositive cone. These cones are widely studied in copositive programming. It is well known that a positive semidefinite matrix $M$ of size $n$ can be factorized as $M=AA^T$ for some real matrix $A$ of size $n$. The membership problem of the completely positive matrices is proven to be NP-hard. In this talk, we discuss, a sufficient condition for a symmetric matrix $M$ to be completely positive, when $M$ has initial factorization $M=AA^T$. We also find a completely positive factorization of $M$ when it is completely positive.
\end{ilasabstract}
    

\hypertarget{down0080}{}\begin{ilasabstract}
\talktitle{Spectral properties and perfect state transfer in unitary $(t-1)$-matching $t$-Cayley graphs}
    
\textbf{Yotsanan Meemark}, \info{16:00\textrm{--}16:30 @ SC0009 (June 23, Monday)} \hfill \hyperlink{up0080}{$\Uparrow$}
    
    
\mtskip
    We introduce a new family of Cayley graphs arising from a collection of subsets of a finite group. It is a generalization of a Cayley graph and a bi-Cayley  graphs, so we call it a $t$-Cayley graph. Let ${\mathcal{R}}$ be direct products of finite matrix rings.
 We work on  unitary $(t-1)$-matching $t$-Cayley graph of ${\mathcal{R}}$ and its complement graph. We show that the graphs are hyperenergetic and obtain a criterion on $t$ and the rings ${\mathcal{R}}$ for each graph being a Ramanujan graph.  Moreover, we show that the unitary $(t-1)$-matching $t$-Cayley graph of ${\mathcal{R}}$ is always periodic and also
  characterize $t$ and the rings ${\mathcal{R}}$ such that its corresponding unitary $(t-1)$-matching $t$-Cayley graph has perfect state transfer between vertices.
\end{ilasabstract}
    

\hypertarget{down0118}{}\begin{ilasabstract}
\talktitle{Tucker decomposition with temporal regularization for motion capture data completion}
    
\textbf{Souad Mohaoui}, \info{17:00\textrm{--}17:30 @ SC4011 (June 23, Monday)} \hfill \hyperlink{up0118}{$\Uparrow$}
    
    
\mtskip
    Tensor decompositions are powerful frameworks for analyzing high-dimensional data by factorizing multi-way arrays into smaller, interpretable components. In particular, Tucker decomposition has emerged as a tool for modeling multi-dimensional data, helping to uncover underlying patterns, especially in the presence of missing data. In this study, we leverage Tucker decomposition for the completion of motion capture (MoCap) data, which is inherently multi-dimensional and characterized by complex temporal dependencies. MoCap data often suffers from gaps due to missing markers during the recording process, leading to the need for efficient and accurate gap-filling methods. We propose two gap-filling algorithms based on Tucker decomposition: Tucker and TuckerTNN. These methods exploit the low-rank properties of MoCap tensors. To address the computational challenges associated with traditional smoothness regularization, we introduce a temporal nuclear norm regularization in the TuckerTNN model, which provides a more efficient solution for large-scale MoCap datasets. We evaluate the proposed algorithms using the publicly available HDM05 MoCap dataset.
\end{ilasabstract}
    

\hypertarget{down0104}{}\begin{ilasabstract}
\talktitle{$P$-matrix powers}
    
\textbf{Samir Mondal}, \info{16:00\textrm{--}16:30 @ SC2001 (June 23, Monday)} \hfill \hyperlink{up0104}{$\Uparrow$}
    
    
\mtskip
    A $P$-matrix is a matrix all of whose principal minors are positive. In this talk, we demonstrate that the fractional 
powers of a $P$-matrix are also $P$-matrices. This insight allows us to affirmatively address a 
longstanding conjecture raised in [D. Hershkowitz and C.R. Johnson, Spectra of matrices with
$P$-matrix powers, {\it Linear Algebra Appl.}, 80:159--171, 1986]: It is shown that if $A^k$ is a $P$-matrix 
for all positive integers $k$, then the eigenvalues of $A$ are positive.

\end{ilasabstract}
    

\hypertarget{down0109}{}\begin{ilasabstract}
\talktitle{Edge completion of signed graphs with spectral integral variation}
    
\textbf{Sunyo Moon}, \info{16:30\textrm{--}17:00 @ SC2006 (June 23, Monday)} \hfill \hyperlink{up0109}{$\Uparrow$}
    
    
\mtskip
    Spectral variation of two matrices is integral if their spectra differ by integer quantities. For two signed graphs, where one is obtained from the other by adding a new edge, we characterize when the spectral variation of their signed Laplacian matrices becomes integral. Furthermore, for every fixed signed complete graph, we fully characterize the class of signed graphs to which one can recursively add new edges keeping spectral integral variation to make the signed complete graph.This generalizes Kirkland's characterization for integrally completable graphs (Discrete Math., 2005). This is joint work with Jungho Ahn and Cheolwon Heo.

\end{ilasabstract}
    

\hypertarget{down0415}{}\begin{ilasabstract}
\talktitle{Weaving phase retrieval and weaving norm retrieval in tensor product space}
    
\textbf{Saikat Mukherjee}, \info{09:00\textrm{--}09:30 @ SC1005 (June 27, Friday)} \hfill \hyperlink{up0415}{$\Uparrow$}
    
    
\mtskip
    Phase retrieval and norm retrieval sequences for Hilbert spaces were introduced by Balan et al. in 2006 and by Bahmanpour et al. in 2015, respectively. In signal processing, phase retrieval plays a crucial role in reconstructing a signal from its intensity measurements. Similarly, norm retrieval restores the norm of a signal from its intensity measurements. Bemrose et al., in 2016, instigated weaving frames for Hilbert spaces. Weaving phase and norm retrieval sequences for a Hilbert space were recently studied by Dowerah et al. In this paper we study weaving phase and weaving norm retrieval sequences in the tensor product of Hilbert spaces defined by Folland, in the year 1995, as a space of bounded antilinear maps between Hilbert spaces. Several characterizations and methods of construction of weaving phase and norm retrieval sequences in tensor product spaces are discussed. 

\end{ilasabstract}
    

\hypertarget{down0398}{}\begin{ilasabstract}
\talktitle{Comparison of several schemes for the CSR expansion of max-plus matrices}
    
\textbf{Yuki Nishida}, \info{08:00\textrm{--}08:30 @ SC0009 (June 27, Friday)} \hfill \hyperlink{up0398}{$\Uparrow$}
    
    
\mtskip
    Max-plus algebra is a semiring with addition $a\oplus b := \max(a,b)$ and $a\otimes b := a+b$. The CSR expansion of a max-plus square matrix $A$ is a decomposition of the matrix power $A^{\otimes t}$ into the sum of matrices of the forms $C \otimes S^{\otimes t} \otimes R$, where $S$ is a permutation matrix. Several schemes for the CSR expansion have been introduced, such as Nachtigall (1997), Hartmann-Arguelles (1999) and Merlet et al.~(2014). In Nishida (2025), the author proposes a new scheme for the CSR expansion based on the factorization of the characteristic polynomial of a max-plus matrix. In this study, we compare the CSR expansions given by these schemes from the viewpoint of the transient bound, which is the minimum exponent $t$ such that the expansion is valid, and the number of terms in the expansion.
\end{ilasabstract}
    

\hypertarget{down0116}{}\begin{ilasabstract}
\talktitle{The existence of close to optimal cross approximations in the Frobenius norm}
    
\textbf{Alexander Osinsky}, \info{16:00\textrm{--}16:30 @ SC4011 (June 23, Monday)} \hfill \hyperlink{up0116}{$\Uparrow$}
    
    
\mtskip
    It will be shown that there exists a cross $CUR$ approximation with relative error of the order $1+r/n+o(r/n)$, which improves on the best currently known bound of $1+40r/n+o(r/n)$ by Boutsidis and Woodruff. Notably, the generator $U$ in such an approximation is the pseudoinverse of the rank $r$ projection of the submatrix at the intersection of the selected rows and columns, similar to how maximum projective volume approximations are formed. This allows to view any cross approximation algorithm of a similar form as an approximate projection onto subspace of rank $r$ matrices, and as a faster alternative to randomized approximate SVD. In particular, projections with such cross approximations outperform modern matrix completion algorithms, when the fraction of known elements is high enough.


\end{ilasabstract}
    

\hypertarget{down0105}{}\begin{ilasabstract}
\talktitle{Some extensions of the class of $Q$-matrices}
    
\textbf{Sushmitha P}, \info{16:30\textrm{--}17:00 @ SC2001 (June 23, Monday)} \hfill \hyperlink{up0105}{$\Uparrow$}
    
    
\mtskip
    A real square matrix $A$ is called a $Q$-matrix if LCP$(A,q)$ has a solution for all $q\in \mathbb{R}^n$, i.e., for every vector $q$, there exists an $x\in \mathbb{R}^n$ such that $x\geq 0$, $Ax+q\geq 0$ and $x^T(Ax+q)=0$. A well known result states that a $Q$-matrix with nonpositive off-diagonal entries is inverse nonnegative. In this talk, we shall look at properties of two classes of matrices that extend the inverse nonnegativity of the $Q$-matrices to the generalized inverse of a matrix. We shall also look at a new result for the class of $Q$-matrices.

\end{ilasabstract}
    

\hypertarget{down0408}{}\begin{ilasabstract}
\talktitle{Universal winner in trees}
    
\textbf{Sirshendu Pan}, \info{08:30\textrm{--}09:00 @ SC1001 (June 27, Friday)} \hfill \hyperlink{up0408}{$\Uparrow$}
    
    
\mtskip
    Let $A \in M_n$ be nonnegative, irreducible and $E_{ii}=e_ie_i^t$, where $e_i$ is the $i$-th standard basis vector. For a fixed $t_0>0$, an index $p \in [n]:={1,2,\ldots,n}$ is called a winner for $t_0$ if the spectral radius $\rho(A+t_0E_{pp})=\max\limits_{i\in [n]}\rho(A+t_0E_{ii})$. If $p$ remains a winner for each $t>0$, then it is called a universal winner. The concepts have been introduced in 1996 and studied in only a few articles till now. When $G$ is a simple connected graph (or a strongly connected digraph), the nonnegative weighted adjacency matrix $A(G)$ being irreducible, one can talk of a universal winner vertex with respect to $A(G)$. The universal winners seem to capture the graph structures well. It is known that the only connected digraph $G$ in which all vertices are universal winners with respect to all nonnegative weighted $A(G)$, is the directed cycle, thereby characterizing it. Let $U\subset [n]$ be nonempty. In a recent article, the class of directed connected graphs with vertex set $[n]$, for which only the vertices in $U$ are the universal winners with respect to all nonnegative weighted $A(G)$ was characterized, generalizing the earlier result. Many other combinatorial results exploiting the graph structure were proved establishing the importance of the study of universal winner vertices. In this article, we further the study for the class of undirected graphs, in particular for trees, with respect to only the adjacency matrix. As expected, we supply a class of trees in which no universal winner exists. More interestingly, every tree is a subtree of a tree with a unique universal winner and also a subtree of a tree without a universal winner. Trees with exactly $k>1$ universal winners are not easy to find. A construction of a class of trees with exactly $k$ universal winners is provided. Interestingly, it turns out that for any undirected connected graph $G$, the set of universal winners of $G$ and the corona $G\circ K_1$ are the same, where the later is obtained by adding a new pendent vertex to each vertex of $G$. It is also shown that if $\rho(A(G))>2$, then no vertex of degree one or two can be a universal winner. Previously, it was known that for a path $P$, the central vertices are the universal winners and as a vertex $u$ goes farther from the center, the spectral radius $\rho(A(P)+tE_{uu})$ decreases. We prove that a similar statement also holds for a grid graph.
\end{ilasabstract}
    

\hypertarget{down0424}{}\begin{ilasabstract}
\talktitle{Spectral properties of the eccentricity matrix of graph products}
    
\textbf{Smrati Pandey}, \info{09:00\textrm{--}09:30 @ SC3001 (June 27, Friday)} \hfill \hyperlink{up0424}{$\Uparrow$}
    
    
\mtskip
    Let $G$ be a connected and simple graph. The eccentricity of a vertex $u \in G$, $(e(u))$, is defined as the maximum distance from $u$ to any other vertex $v \in G$ in the graph. The eccentricity matrix, $\epsilon(G)$ is derived from the distance matrix whose $(u, v)$-th entry is equal to $d(u, v)$ if $d(u, v)$ is the minimum of $\{e(u), e(v)\}$, and is zero otherwise. Note that $d(u, v)$ is the distance between the vertices $u$ and $v$. A graph $G$ is said to be self centered if the eccentricity of each vertex of $G$ is same. 

The corona product is a prominent graph operation known for its distinct structural features and has been the focus of extensive research. Over the time, several variations of the corona product have been introduced and analyzed.

Assume that $G$ and $H$ are two finite graphs on $m$ and $n$ vertices, respectively. The corona product $G \circ H$ of two graphs $G$ and $H$, is constructed by keeping a single copy of $G$ and $m$ copies of $H$, and then connecting each vertex of the $j$-th copy of $H$ to the $j$-th vertex of $G$. The one-point-corona, denoted as $G \circ_z H$, is constructed similarly by taking one copy of $H$ for each vertex of $G$, but only the the root vertex $z$ from each copy of $H$ is connected to corresponding vertex in $G$ with an edge.

In this talk, we discuss the irreducibility and spectra of eccentricity matrices obtained from the  corona product and the one point corona product of graphs $G$ and $H$, where $G$ is a self-centered graph.
\end{ilasabstract}
    

\hypertarget{down0404}{}\begin{ilasabstract}
\talktitle{Inverse $Z$-matrices with the bi-diagonal ramp structure}
    
\textbf{Samapti Pratihar}, \info{08:00\textrm{--}08:30 @ SC0014 (June 27, Friday)} \hfill \hyperlink{up0404}{$\Uparrow$}
    
    
\mtskip
    In the literature, there are only a handful of articles that are devoted to listing some classes of matrices for which properties such as the characteristic equation, eigenvectors, associated determinant and the inverse, can be found in a relatively simple manner. The number of matrices for which these properties may be expressed analytically is surprisingly small. The main purpose of studying these matrix classes is to provide test matrices for evaluating the accuracy and efficiency of computational processes. These matrix classes have the advantage that they may be chosen of arbitrary order, and by appropriately selecting their elements they may be made singular or nonsingular as desired in specific instances. This enables, for instance, to draw conclusions on the efficacy of new numerical methods by comparing computed inverses (or the Moore-Penrose inverses, as the case may be) with the known exact expressions for the inverse (or the Moore-Penrose inverse), and other such processes, that may be necessary in the application problems that motivate such considerations. In this talk we propose another extension of these test matrices including some of the more recent generalizations. Specifically, we are considering those invertible matrices whose inverses are what we refer to as {\it bi-diagonal ramp matrices}. We use such matrices to identify some new classes of inverse $Z$-matrices. Time permitting, a graph theoretic interpretation will also be presented.

\end{ilasabstract}
    

\hypertarget{down0396}{}\begin{ilasabstract}
\talktitle{Some symmetric sign patterns requiring unique inertia}
    
\textbf{Partha Rana}, \info{08:30\textrm{--}09:00 @ SC0008 (June 27, Friday)} \hfill \hyperlink{up0396}{$\Uparrow$}
    
    
\mtskip
    A sign pattern is a matrix whose entries are from the set $\{+,-,0\}$. A sign pattern requires unique inertia if every matrix in its qualitative class has the same inertia. For symmetric tree sign patterns, several necessary and sufficient conditions to require unique inertia are known. In this paper, sufficient conditions for symmetric tree sign patterns to require unique inertia based on the sign and position of the loops in the underlying graph are given. Further, some sufficient conditions for a symmetric sign pattern to require unique inertia if the underlying graph contains cycles are determined.
\end{ilasabstract}
    

\hypertarget{down0402}{}\begin{ilasabstract}
\talktitle{Matrix analysis of orthogonal polynomials and uvarov perturbations}
    
\textbf{Miguel Rojas Rodríguez}, \info{08:30\textrm{--}09:00 @ SC0012 (June 27, Friday)} \hfill \hyperlink{up0402}{$\Uparrow$}
    
    
\mtskip
    In this talk, we emphasize the decisive role of matrix analysis in studying orthogonal polynomials. The theory of classical orthogonal polynomials and matrix analysis naturally arises in the study of tridiagonal matrices (Jacobi matrices), whose spectrum, under certain conditions, coincides with the support of a measure associated with a sequence of orthogonal polynomials. Furthermore, the GaussâBorel factorization of the moment matrix plays a fundamental role in characterizing orthogonality and uncovering key structural properties. \\
We focus on MMOP, which are orthogonal polynomials with respect to a matrix of measures. In this case, the associated Jacobi matrix is a banded matrix, where the number of nonzero diagonals depends on the size of the measure. Within this framework, we study how orthogonal polynomials transform when the matrix of measures undergoes matrix polynomial perturbations. The most general perturbation we consider follows Uvarovâs form:   \\
    $ \mathrm{d}\tilde{\mu}(x) R(x) = L(x) \mathrm{d} \mu(x),$\\
where $R(x),\,L(x)$ are polynomial matrices, $\mathrm{d} \mu (x)$ is the original measure matrix, and $\mathrm{d} \tilde{\mu}(x)$ is the perturbed measure matrix. By taking $R(x) = I$ or $L(x) = I$, we obtain a Christoffel or Geronimus perturbation, respectively.   \\
The main contribution of our work is the generalization of these perturbations beyond diagonal matrix polynomials, extending the theory to include cases with non-monic leading matrices. This generalization leads to an analysis of the spectral properties of the perturbation matrix polynomials. Furthermore, we reduce the problem of ensuring orthogonalityâframed as a question of the quasi-definiteness of a matrix measureâto a linear algebra problem involving the compatibility of certain systems of linear equations.
\end{ilasabstract}
    

\hypertarget{down0106}{}\begin{ilasabstract}
\talktitle{Schur and Hurwitz diagonal stability of parametric interval matrices}
    
\textbf{Falguni Roy}, \info{17:00\textrm{--}17:30 @ SC2001 (June 23, Monday)} \hfill \hyperlink{up0106}{$\Uparrow$}
    
    
\mtskip
    Consider the parametric interval matrix
$A(\mathbf{c})=\Big\{A^{(0)}+\displaystyle \sum_{k=1}^{l}c_kA^{(k)}\in \mathbb{R}^{n \times n}:c\in\mathbf{c}\Big\}$, where $\mathbf{c}$ is an interval vector. This work focuses primarily on the generalized matrix diagonal stability, i.e., Schur / Hurwitz diagonal stability relative to the $p$-norm ( $SDS_p$ / $HDS_p$) introduced in [1], for three newly defined subclasses of the parametric interval matrix $A(\mathbf{c})$.
  First, a necessary and sufficient condition is given for $SDS_p$ and $HDS_p$ of $A(\mathbf{c})$ based on the vertex matrices of $A(\mathbf{c})$. Next, some verifiable sufficient conditions for $SDS_p$ and $HDS_p$  of the first subclass $\mathcal{A}_1(\mathbf{c})$ are given using majorant matrices. Using majorant matrices, the necessary and sufficient condition for $SDS_p$ is obtained for the second subclass $\mathcal{A}_2(\mathbf{c})$ and $HDS_p$ for the third subclass $\mathcal{A}_3(\mathbf{c})$, respectively. From these, it is shown that $SDS_p$ / $HDS_p$ for complex interval matrices is a special case. Methods for finding a common diagonal matrix that meets conditions $SDS_p$ / $HDS_p$ and the robustness analysis of $SDS_p$ / $HDS_p$ are also discussed.

\end{ilasabstract}
    

\hypertarget{down0421}{}\begin{ilasabstract}
\talktitle{Results on strong coupled best proximity point with application to non-linear differential equation}
    
\textbf{Deb Sarkar}, \info{09:00\textrm{--}09:30 @ SC2006 (June 27, Friday)} \hfill \hyperlink{up0421}{$\Uparrow$}
    
    
\mtskip
    Fixed point theory plays very crucial role in different fields specially in functional analysis. In this paper, some results on strong coupled best proximity point using some new inequalities have been established. A suitable example has also been given supporting the result. In consequences, a result of strong coupled fixed point has been given. Also, an application to non-linear differential equation has been shown. 
\end{ilasabstract}
    

\hypertarget{down0093}{}\begin{ilasabstract}
\talktitle{Combinatorial description of the inverse of the adjacency matrix of non-bipartite bicyclic graphs}
    
\textbf{Kshitij Sharma}, \info{16:30\textrm{--}17:00 @ SC1001 (June 23, Monday)} \hfill \hyperlink{up0093}{$\Uparrow$}
    
    
\mtskip
    Barik et al. [On nonsingular trees and a reciprocal eigenvalue property, Linear Multilinear Algebra, 54(6)(2006) 453-465] provided a combinatorial description of the inverse of the adjacency matrix for bipartite graphs in terms of $mm$-alternating paths, enabling deeper exploration of bipartite graph properties. However, for non-bipartite graphs, a similar framework remained an open challenge. In 2022, a combinatorial description was established for non-bipartite unicyclic graphs.
This paper advances the understanding of non-bipartite graphs by providing a comprehensive combinatorial description of the inverse of the adjacency matrix for non-bipartite bicyclic graphs, utilizing $mm$-alternating paths between vertices. It further determines the conditions under which the adjacency matrix of a bicyclic graph is unimodular and establishes criteria for the adjacency matrix of a non-bipartite graph to be signable. Additionally, it is definitively shown that the inverse graph of a non-bipartite bicyclic graph remains non-bipartite, reinforcing the structural properties of such graphs.


\end{ilasabstract}
    

\hypertarget{down0096}{}\begin{ilasabstract}
\talktitle{Minimum-norm solutions of the non-symmetric semidefinite Procrustes problem}
    
\textbf{Stefano Sicilia}, \info{16:00\textrm{--}16:30 @ SC1003 (June 23, Monday)} \hfill \hyperlink{up0096}{$\Uparrow$}
    
    
\mtskip
    \begin{bibunit}
        Given two matrices $X,B\in \mathbb{R}^{n\times m}$ and a set $\mathcal{A}\subseteq \mathbb{R}^{n\times n}$, a Procrustes problem  consists in finding a matrix $A \in \mathcal{A}$ such that the Frobenius norm of $AX-B$ is minimized. When $\mathcal{A}$ is the set of the matrices whose symmetric part is positive semidefinite, we obtain the so-called non-symmetric positive semidefinite Procrustes (NSPSDP) problem.  The NSPSDP problem arises in the estimation of compliance or stiffness matrix in solid and elastic structures. 
 If $X$ has rank $r$, Baghel et al. in [1] proposed a three-step semi-analytical approach: 
 (1) construct a reduced NSPSDP problem in dimension $r\times r$, 
 (2) solve the reduced problem by means of a fast gradient method with a linear rate of convergence, and 
 (3) post-process the solution of the reduced problem to construct a solution of the larger original NSPSDP problem. We revisit this approach of  Baghel et al.\ and identify an unnecessary assumption used by the authors leading to cases where their algorithm cannot attain a minimum and produces solutions with unbounded norm.  
 In fact, revising the post-processing phase of their semi-analytical approach, we show that the infimum of the NSPSDP problem is always attained, and we show how to compute a minimum-norm solution. We also prove that the symmetric part of the computed solution has minimum rank bounded by $r$, and that the skew-symmetric part has rank bounded by $2r$. Several numerical examples show the efficiency of this algorithm, both in terms of computational speed and of finding optimal minimum-norm solutions.
 
\begin{thebibliography}{2} 
\bibitem{one}Mohit Kumar Baghel, Nicolas Gillis, and Punit Sharma. On the non-symmetric semidefinite Procrustes problem. Linear Algebra and its Applications, 648:133--159, 2022.
\bibitem{two}Nicolas Gillis and Stefano Sicilia. Minimum-norm solutions of the non-symmetric semidefinite procrustes problem. arXiv preprint arXiv:2406.02203, 2024.
\end{thebibliography}
        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0406}{}\begin{ilasabstract}
\talktitle{Dual core-EP generalized inverse and decomposition}
    
\textbf{Bibekananda Sitha}, \info{09:00\textrm{--}09:30 @ SC0014 (June 27, Friday)} \hfill \hyperlink{up0406}{$\Uparrow$}
    
    
\mtskip
    In this work, we introduce a new type of generalized inverse called dual core-EP generalized inverse (in short DCEPGI) for dual square matrices. We analyze the existence and uniqueness of the DCEPGI inverse and its compact formula using dual Drazin and dual MP inverses. Moreover, some characterizations using core-EP  decomposition are obtained. We present a new dual matrix decomposition named the dual core-EP decomposition for square dual matrices. In addition, some relationships with other dual generalized inverses are established. Solutions to some inconsistent system of linear dual equations are derived. 

\end{ilasabstract}
    

\hypertarget{down0425}{}\begin{ilasabstract}
\talktitle{Hyperbolic wavelets and multiresolution in $A_{\alpha}^{2} (\mathbb{D})$}
    
\textbf{Anusree Sreedharan}, \info{08:00\textrm{--}08:30 @ SC4011 (June 27, Friday)} \hfill \hyperlink{up0425}{$\Uparrow$}
    
    
\mtskip
    We examine rational Blaschke functions that are capable to formulate a Multiresolution on the weighted Bergman space of the open unit disc $A_{\alpha}^{2} (\mathbb{D})$. We construct a rational orthogonal wavelet system that generates the levels of the multiresolution. The levels of the multiresolution are finite dimensional, which makes it easier to find a basis on each level. We can approximate any $f \in A_{\alpha}^{2} (\mathbb{D})$ by the projection operator on the $n^{\mbox{th}}$ resolution level. The projection will be an interpolation operator and whose coefficients can be computed through the evaluation of $f$ on a given set of points in the unit disc. We extend the results to weighted Bergman space of upper half plane and we introduce a numerical method to compute the coefficients when the values of $f$ are given on a set of points in the upper half-plane. 
\end{ilasabstract}
    

\hypertarget{down0077}{}\begin{ilasabstract}
\talktitle{Products of infinite upper triangular matrices that satisfy fixed polynomial equation}
    
\textbf{Roksana Słowik}, \info{16:30\textrm{--}17:00 @ SC0008 (June 23, Monday)} \hfill \hyperlink{up0077}{$\Uparrow$}
    
    
\mtskip
    \begin{bibunit}
        There is plenty of results concerning representation elements of an algebraic structure, mainly a group, as products of elements possessing some particular properties. In the matrix groups one of the most famous one is being an involution. The famous theorem states that every square matrix with determinant $\pm 1$ defined over a field is a product of at most four involutions. Simply by their definition, the involutions satisfy equation $x^2-1=0$, i.e. a quadratic equation. Hence, it is natural to raise a question does a similar result hold for matrices that satisfy some other fixed quadratic equation.
\par
Consider a field $F$ and an algebra $\mathcal{A}$ defined over $F$. Define polynomial $q$ by the formula $q(x)=a_2x^2+a_1x+a_0$, where $a_2 \neq 0$. If element $a \in \mathcal{A}$ satisfies $q(a)=0$, then we say that $a$ is quadratic with respect to $q(x)$, or shortly that $a$ is $q(x)$-quadratic.
Recently, Bien et al. \cite{bi_ta_tr_tr} proved that every $\mathbb{N} \times \mathbb{N}$ upper triangular matrix whose diagonal entries are of the form $\lambda_1^{s_i}\lambda_2^{t_i}$, where $s_i+t_i=k$ for every $i \in \mathbb{N}$, $\lambda_1$, $\lambda_2 \neq 0$, can be expressed as a product of at most $k$ quadratic matrices with respect to $q_{\lambda_1,\lambda_2}(x)=(x-\lambda_1)(x-\lambda_2)$.
This result brings up further questions. Does the same claim holds when $\lambda_1\lambda_2=0$? Does it also hold when we replace the quadratic polynomial by a polynomial of degree $n$ ($\ngeqslant 3$)? During this talk we are going to discuss these issues.


\begin{thebibliography}{66}
\bibitem{bi_ta_tr_tr} M.H. Bien, V.M. Tam, D.C.M. Tri, L.Q. Truong, Products of infinite upper triangular matrices, Linear Algebra Appl. 699 (2024), 59-71.
\bibitem{tr_sl} L.Q. Truong, R. S{\l}owik, Products of infinite upper triangular matrices that satisfy fixed polynomial equation, in preparation.
\end{thebibliography}
        \end{bibunit}
        
\end{ilasabstract}
    

\hypertarget{down0084}{}\begin{ilasabstract}
\talktitle{Characterizations and interlacing property of Euclidean distance matrices}
    
\textbf{Divyadevi T}, \info{16:00\textrm{--}16:30 @ SC0012 (June 23, Monday)} \hfill \hyperlink{up0084}{$\Uparrow$}
    
    
\mtskip
    Motivated by the inverse formula of the distance matrix of a tree and the 
Moore-Penrose inverse of a circum-Euclidean distance matrix (CEDM), in this 
talk, we study a general real square matrix $M$  whose Moore-Penrose inverse 
can be expressed as the sum of a Laplacian-like matrix $L$  and a rank one 
matrix. In particular, for a symmetric hollow matrix $M$, under an assumption, 
we show that $M$ is a Euclidean distance matrix if and only if $L$ is positive 
semidefinite.  Based on this, we obtain a new characterization for CEDMs 
involving their Moore-Penrose inverses. As an application, we show that the 
distance matrices of block graphs and odd-cycle-clique graphs are CEDMs. 
Finally, we establish an interlacing property between the eigenvalues of  a
Euclidean distance matrix $M$ (including the singular case) and its associated 
Laplacian-like matrix $L$, which generalizes the interlacing property proved 
for the distance matrices of trees. 

\end{ilasabstract}
    

\hypertarget{down0418}{}\begin{ilasabstract}
\talktitle{On the UV limit of Wilsonian renormalization group flows of Feynman measures}
    
\textbf{Zsigmond Tarcsay}, \info{09:00\textrm{--}09:30 @ SC2001 (June 27, Friday)} \hfill \hyperlink{up0418}{$\Uparrow$}
    
    
\mtskip
    In nonperturbative formulation of Euclidean signature quantum field theory, the vacuum state is characterized by the Wilsonian renormalization group  flow of Feynman measures. Such a  flow is a family $(\mu_\eta)_{\eta\in\mathcal S}$ of finite measures on Borel sets  of the space of Schwartz distributions $\mathcal S'$, linked by the Wilsonian renormalization group equation $\mu^{}_{\eta*\zeta}=(C_\eta)^{}_{\#}\mu^{}_\zeta$, for every pair Schwartz functions $\zeta,\eta\in \mathcal S$. Here, $C_\eta\zeta:=\eta*\zeta$ stands for the convolution of  the Schwartz functions $\zeta,\eta\in \mathcal{S}$, while $(C_\eta)_{\#}\mu_\zeta$ denotes the corresponding pushforward measure by $C_\eta$. The goal of this talk is to show the existence of an ultimate Borel measure $\mu$ (called the UV limit of the flow), such that for all $\eta\in\mathcal{S}$ the factorization identity $\mu_{\eta}=(C_{\eta})_{\#}\,\mu$ holds.
\end{ilasabstract}
    

\hypertarget{down0110}{}\begin{ilasabstract}
\talktitle{Laplacian spectral properties of token graphs}
    
\textbf{Piyush Verma}, \info{17:00\textrm{--}17:30 @ SC2006 (June 23, Monday)} \hfill \hyperlink{up0110}{$\Uparrow$}
    
    
\mtskip
    Let $G$ be a graph on $n$ vertices. For a given integer $k$ such that $1\leq k \leq n$, the $k$-token graph $F_k(G)$ of $G$ is defined as the graph whose vertices are the $k$-subsets of the vertex set of $G$, and two of them are adjacent whenever their symmetric difference is a pair of adjacent vertices in $G$. Token graphs have applications in coding theory and quantum mechanics. It was conjectured that for any graph $G$, the algebraic connectivity of $F_k(G)$ is equal to the algebraic connectivity of $G$. This result turned out to be a theorem, as it was proved by using the theory of the continuous Markov chain of random walks and interchange process. However, proving this theorem using algebraic and combinatorial methods is still an open and interesting problem. In this talk, we discuss the algebraic connectivity and Laplacian spectral radius of token graphs. Moreover, we study the Laplacian integral token graphs. This talk is based on joint work with Sasmita Barik.
\end{ilasabstract}
    

\hypertarget{down0117}{}\begin{ilasabstract}
\talktitle{TTCrossOrth: a better way to construct tensor train approximation}
    
\textbf{Dmitry Zheltkov}, \info{16:30\textrm{--}17:00 @ SC4011 (June 23, Monday)} \hfill \hyperlink{up0117}{$\Uparrow$}
    
    
\mtskip
    The TT-cross method efficiently approximates the tensor with a logarithmic count of tensor element evaluations, maintaining low computational complexity by heuristically selecting submatrices of the TT-unfolding matrices to form an approximation.

TT-cross approximation has certain limitations: the tensor's approximation error may be exponentially linked to that of selected submatrices, and determining ranks poses a challenge.

In this talk we introduce the TTCrossOrth algorithm, which optimizes the TT-cross method through error orthogonalization to mitigate exponential error growth and incorporates a novel rank adaptation strategy.

\end{ilasabstract}
    \newpage

\end{document}
