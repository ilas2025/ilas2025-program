SESSION,ROOM,S_ORDER,FIRST_NAME,LAST_NAME,FULL_NAME,START,TYPE,MS_TITLE,WEEKDAY,START_STR,END_STR,SESSION_ORDER,TYPE_ORDER,TITLE,ABSTRACT
P1,SYS Hall,1,Karol,Życzkowski,Karol Życzkowski,2025-06-23 08:30:00,Plenary,,Monday,08:30,09:30,1,100,"A ramble through mathematics relevant for quantum theory:  A personal perspective
","<p>Which branches of mathematics are the most important for a physicist
working in quantum theory? How to foster an interdisciplinary
collaboration of a theoretical physicists and a mathematician? Which
problems motivated by quantum theory can be inspiring for the
mathematical community? Basing on personal experience concerning
research related to linear algebra, operator theory, matrix analysis,
random matrices, geometry of convex sets, group theory and
combinatorics, I will argue that such a collaboration is possible and
can be fruitful.</p>
"
P2,SYS Hall,1,Fumio,Hiai,Fumio Hiai,2025-06-23 09:30:00,Plenary,,Monday,09:30,10:30,2,100,Various inequalities for quasi-arithmetic mean and quasi-geometric type means of matrices,"<p>Our targets in this talk are the quasi extensions of the weighted
arithmetic mean and of the weighted geometric type means, including the
weighted geometric mean, the weighted spectral geometric mean, the Rényi
mean, and the Log-Euclidean mean, for positive (semi)definite matrices.
For example, <span class=""math display"">$$\begin{aligned}
&amp;\mathcal{A}_{\alpha,p}(A,B):=(\alpha A^p+(1-\alpha)B^p)^{1/p},
\ \mbox{the quasi-weighted arithmetic mean}, \\
&amp;G_{\alpha,p}(A,B):=(A^p\#_\alpha B^p)^{1/p},
\ \mbox{the quasi-weighted geometric mean}, \\
&amp;R_{\alpha,p}(A,B):=\bigl(B^{{\frac{1-\alpha}{2}}p}A^{\alpha
p}B^{{\frac{1-\alpha}{2}}p}\bigr)^{1/p},
\ \mbox{the R\'enyi mean}, \\
&amp;LE_\alpha(A,B):=\exp(\alpha\log A+(1-\alpha)\log B),
\ \mbox{the weighted Log-Euclidean mean},
\end{aligned}$$</span> where <span
class=""math inline""><em>α</em> ∈ (0, 1)</span> (or all <span
class=""math inline""><em>α</em> &gt; 0</span>) is the weight parameter
and <span class=""math inline""><em>p</em> &gt; 0</span> is the parameter
of the quasi extension. For the quasi versions of these weighted matrix
means we consider inequalities in different types of orders such as the
Loewner order <span class=""math inline"">≤</span>, the chaotic <span
class=""math inline"">≤<sub>ch</sub></span> (i.e., <span
class=""math inline"">log <em>X</em> ≤ log <em>Y</em></span>), the near
order <span class=""math inline"">≤<sub>ne</sub></span> (i.e., <span
class=""math inline""><em>X</em>#<em>Y</em><sup>−1</sup> ≤ <em>I</em></span>),
the entrywise eigenvalue order <span
class=""math inline"">≤<sub><em>λ</em></sub></span>, the log-majorization
<span class=""math inline"">≺<sub>log</sub></span>, the weak majorization
<span class=""math inline"">≺<sub><em>w</em></sub></span>, and the order
under trace (i.e., <span
class=""math inline"">Tr <em>X</em> ≤ Tr <em>Y</em></span>), whose order
relations weaken in this writing order. Our objective is to pursue under
which condition of the parameters <span
class=""math inline""><em>α</em>, <em>p</em>, <em>q</em></span> the
inequality <span
class=""math inline"">ℳ<sub><em>α</em>, <em>p</em></sub>(<em>A</em>, <em>B</em>) ⊲ 𝒩<sub><em>α</em>, <em>q</em></sub>(<em>A</em>, <em>B</em>)</span>
holds for all positive (semi)definite matrices <span
class=""math inline""><em>A</em>, <em>B</em></span>, for any pair <span
class=""math inline"">(ℳ<sub><em>α</em>, <em>p</em></sub>, 𝒩<sub><em>α</em>, <em>q</em></sub>)</span>
from the above quasi-weighted means and for any order <span
class=""math inline"">⊲</span> mentioned above. For instance, it is shown
that <span
class=""math inline"">𝒜<sub><em>α</em>, <em>p</em></sub>(<em>A</em>, <em>B</em>) ≤ 𝒜<sub><em>α</em>, <em>q</em></sub>(<em>A</em>, <em>B</em>)</span>
holds for all <span
class=""math inline""><em>A</em>, <em>B</em> ≥ 0</span> if and only if
<span class=""math inline""><em>p</em> = <em>q</em></span> or <span
class=""math inline"">1 ≤ <em>p</em> &lt; <em>q</em></span> or <span
class=""math inline"">1/2 ≤ <em>p</em> &lt; 1 ≤ <em>q</em></span>,
whereas, for any other weaker order <span class=""math inline"">⊲</span>,
<span
class=""math inline"">𝒜<sub><em>α</em>, <em>p</em></sub>(<em>A</em>, <em>B</em>) ⊲ 𝒜<sub><em>α</em>, <em>q</em></sub>(<em>A</em>, <em>B</em>)</span>
holds for all <span
class=""math inline""><em>A</em>, <em>B</em> ≥ 0</span> if and only if
<span class=""math inline""><em>p</em> ≤ <em>q</em></span>. When <span
class=""math inline"">(ℳ<sub><em>α</em>, <em>p</em></sub>, 𝒩<sub><em>α</em>, <em>q</em></sub>)</span>
is a pair from the quasi-weighted geometric type means, we are mostly
interested in the condition of <span
class=""math inline""><em>α</em>, <em>p</em>, <em>q</em></span> under
which the log-majorization <span
class=""math inline"">ℳ<sub><em>α</em>, <em>p</em></sub>(<em>A</em>, <em>B</em>)≺<sub>log</sub>𝒩<sub><em>α</em>, <em>q</em></sub>(<em>A</em>, <em>B</em>)</span>
holds and whether <span
class=""math inline""><em>A</em><em>B</em> = <em>B</em><em>A</em></span>
follows from the equality case <span
class=""math inline"">Tr ℳ<sub><em>α</em>, <em>p</em></sub>(<em>A</em>, <em>B</em>) = Tr 𝒩<sub><em>α</em>, <em>q</em></sub>(<em>A</em>, <em>B</em>)</span>
in this situation.</p>
"
P3,SYS Hall,1,Polona,Oblak,Polona Oblak,2025-06-24 08:00:00,Plenary,,Tuesday,08:00,09:00,3,100,"Extremal eigenvalue multiplicities of matrices of a given pattern
","<p>We explore the family <span class=""math inline"">𝒮(<em>G</em>)</span>
of real symmetric matrices whose off-diagonal zero-nonzero pattern
matches the one of the adjacency matrix of a given simple graph <span
class=""math inline""><em>G</em></span>. Our focus is on the eigenvalue
multiplicities that such matrices can attain, which is a subproblem of
the well-studied Inverse Eigenvalue Problem for a Graph (IEP-<span
class=""math inline""><em>G</em></span>).</p>
<p>While every <span class=""math inline"">𝒮(<em>G</em>)</span> contains a
matrix with all eigenvalues simple, understanding constraints on high
multiplicities remains a significant challenge. Interpreting
multiplicity lists as partitions, we will examine the following key
parameters: the maximum achievable multiplicity of any eigenvalue, the
largest possible minimal multiplicity, and the minimal number of
distinct eigenvalues attainable by matrices in <span
class=""math inline"">𝒮(<em>G</em>)</span>. We will also discuss
constraints on matrices that realise the extreme values of the relevant
parameter.</p>
"
P4,SYS Hall,1,Fernando,De Terán,Fernando De Terán,2025-06-24 09:00:00,Plenary,,Tuesday,09:00,10:00,4,100,The canonical form for congruence: some history and applications,"<p>A square matrix <span class=""math inline""><em>A</em></span> can be
either seen as a linear map or as a bilinear form. When considered as a
linear map, it is natural to introduce the relation of “similarity”,
<span
class=""math inline""><em>P</em><sup>−1</sup><em>A</em><em>P</em></span>
(with <span class=""math inline""><em>P</em></span> invertible), which is
a change of basis that allows us to represent the linear map in a
simpler form, in particular in the well-known “Jordan canonical form”.
When considering the matrix <span class=""math inline""><em>A</em></span>
as a bilinear form, the natural relation instead is the one of
“congruence”, <span
class=""math inline""><em>P</em><sup>⊤</sup><em>A</em><em>P</em></span>
(with <span class=""math inline""><em>P</em></span> invertible), which is
the suitable change of basis for bilinear forms. Is there a canonical
form for such a relation? The answer is yes, and actually some different
canonical forms for congruence have been introduced over the years since
the 1930’s. In this talk I will introduce the most recent one (by Horn
and Sergeichuk, 2006), review the history of this and the other
canonical forms, and show some applications in the context of my past
and current research, including:</p>
<ul>
<li><p>The solution of the equation <span
class=""math inline""><em>A</em><em>X</em> + <em>X</em><sup>⊤</sup><em>A</em> = 0</span>
and its connection to <span class=""math inline"">⊤</span>-palindromic
pencils.</p></li>
<li><p>The consistency of the equation <span
class=""math inline""><em>X</em><sup>⊤</sup><em>A</em><em>X</em> = <em>B</em></span>
when <span class=""math inline""><em>B</em></span> is either symmetric or
skew-symmetric.</p></li>
</ul>
"
P5,SYS Hall,1,Daniel,Kressner,Daniel Kressner,2025-06-25 08:00:00,Plenary,,Wednesday,08:00,09:00,5,100,Adaptive randomized pivoting,"<p>Finding good subsets of row and column indices, often called pivots,
is a ubiquitous task in applied and numerical linear algebra. One of its
most famous appearances is arguably in Gaussian elimination for solving
linear systems, where a good choice of pivots is crucial for numerical
stability. This talk will focus on pivoting in the context of
low-dimensional approximation, including column subset selection,
discrete empirical interpolation, and various interpolative
decompositions, such as the CUR and Cholesky/Nystrom approximations. In
all of these cases, a greedy choice of pivots usually works well but
there are well-known counterexamples where such a choice leads to poor
results. We present a new randomized pivot selection strategy that
avoids such unfavorable worst-case performance by using adaptivity in
two senses: It adapts to information on the range / co-range of a
matrix, and the sampling distribution is updated after each pivot
selection. Adaptive randomized pivoting enjoys error guarantees that
match, in expectation, the best known existence results. At the same
time, it is simpler and usually cheaper than volume-based techniques,
which achieve similar guarantees through volume sampling or iterative
local volume maximization. We will illustrate several applications of
adaptive randomized pivoting and discuss derandomized variants. This
talk is based on joint work with Alice Cortinovis, University of
Pisa.</p>
"
P6,SYS Hall,1,Dario Andrea,Bini,Dario Andrea Bini,2025-06-25 09:00:00,Plenary,,Wednesday,09:00,10:00,6,100,Matrix structures in queueing and network models: An overview,"<p>We provide an overview of some results concerning classes of matrices
involved in queueing and network models. We show specific examples where
the analysis of matrix structures, besides providing a better
understanding of the original problem, is a fundamental step in
designing effective ad hoc solution algorithms.</p>
<p>Two specific issues are considered: the analysis of random walks on a
regular grid in the quarter plane, and the assessment of the centrality
of the edges in a graph. Both issues derive from the analysis of
relevant real-world problems and are modeled by Markov chains describing
random walks on a graph.</p>
<p>In the first topic, the graph is a regular grid, and the specific
features of the problem lead to semi-infinite transition probability
matrices with a two-level tridiagonal and almost Toeplitz structure. We
show that these matrices live in a suitable infinite-dimensional
structured matrix algebra which is also a Banach space with respect to
the infinity norm. This fact will be crucial to designing effective fast
algorithms for computing the steady-state vector of the associated
Markov chain.</p>
<p>In the second topic, the graph is typically a road map of a city or
region. Thus, the Toeplitz structure of the associated transition
probability matrix is lost. However, the sparsity and band structure of
this matrix will allow us to easily compute a centrality measure of the
edges defined in terms of Kemeny’s constant of the associated Markov
chain. The effectiveness of the model and the solution algorithms is
tested on the road maps of Pisa and Tuscany.</p>
"
P7,SYS Hall,1,Fan,Chung,Fan Chung,2025-06-26 08:00:00,Plenary,,Thursday,08:00,09:00,7,100,Clustering in graphs with high clustering coefficients,"<p>Many real world networks possess the so-called small world phenomenon
where every node is relatively close to every other node and have a
large clustering coefficient, i.e., friends of friends are likely
friends. The task of learning an adequate similarity measure on various
feature spaces often involves graphs with high clustering coefficients.
We investigate the clustering effect in sparse clustering graphs by
examining the structural and spectral properties as well as the
enumeration of patterns. In addition, we consider random graph models
for clustering graphs that can be use to analyze the behavior of complex
networks.</p>
"
P8,SYS Hall,1,Karen,Meagher,Karen Meagher,2025-06-26 09:00:00,Plenary,,Thursday,09:00,10:00,8,100,"Using algebra to prove Erd\H{o}s-Ko-Rado type theorems
","<p>My research focuses on variations of the Erdős-Ko-Rado (EKR) theorem.
The question was to determine the largest set of subsets of size <span
class=""math inline""><em>k</em></span> from <span
class=""math inline"">{1, 2, …, <em>n</em>}</span>, with the property that
any two of the <span class=""math inline""><em>k</em></span>-subsets have
non-empty intersection. The Erdős-Ko-Rado (EKR) theorem states that a
largest such set can only be formed by taking all <span
class=""math inline""><em>k</em></span>-subsets that contain a common
fixed point.</p>
<p>More generally, for any object for which “intersection” can be
defined, we can ask the same question: what is the largest set of
objects with the property that any two objects in the set have non-empty
intersection? For many objects the answer to this question is a result
analogous to EKR theorem for <span
class=""math inline""><em>k</em></span>-subsets. When this holds, it can
be considered to be an <strong>EKR-type theorem</strong>.</p>
<p>Typically, these questions are considered to be problems from design
theory and there are many different proof approaches that can applied.
In my work (and in my opinion) the best results come from using tools
from linear algebra.</p>
<p>In this talk, I will give an overview of how to use linear algebra to
prove EKR-type theorems. My focus will be on results for intersecting
sets of permutations from transitive groups. For these objects (the
permutations) we define a graph, called <strong>the derangement
graph</strong>. The eigenvalues of the this graph can be determined from
the group, and the using the <strong>ratio bound</strong> the
eigenvalues give a bound on the size of the largest intersecting set of
permutations. This graph has lovely algebraic properties, in particular
it is a graph in an association scheme, which means that strong tools
from linear algebra are available.</p>
"
P9,SYS Hall,1,Ren-Cang,Li,Ren-Cang Li,2025-06-27 10:00:00,Plenary,,Friday,10:00,11:00,9,100,Principal joint block diagonalization    ,"<p>Matrix joint block-diagonalization frequently arises from diverse
applications such as independent component analysis, blind source
separation, and common principal component analysis (CPCA), among
others. CPCA, a special case, is about joint diagonalization, i.e., each
blocksize being 1-by-1. In the last fifteen years or so, CPCA has
attracted a great deal of attention because of its applications to,
e.g., multivariate data analysis and multiview clustering. Generically
three or more matrices cannot be jointly block-diagonalized, but
practically, a reasonably good approximate joint block-diagonalization
suffices for real-world applications. This talk is concerned with fast
<span><em>Principal Joint Block Diagonalization</em></span>, in which
our focus is on dominant and partial common block-diagonal structure
among the matrices of interest, in contrast to most existing methods,
such as the popular ones based on Givens’ rotation, which by nature have
to go for full joint diagonalization and can be too time-consuming to be
practical for a group of modest sized matrices that are not sufficiently
close to being jointly diagonalizable. An NPDo approach is proposed for
maximizing the common dominant block-diagonal parts. It is shown the
NPDo approach is globally convergent to a stationary point while the
objective function increases monotonically. Along similar lines, joint
principal SVD-type block-diagonalization is also investigated. Numerical
experiments will be presented to illustrate the use of the NPDo approach
and demonstrate its superiority to existing methods for matrices of
dimension 200 or larger.</p>
"
P10,SYS Hall,1,Haim,Avron,Haim Avron,2025-06-27 11:00:00,Plenary,,Friday,11:00,12:00,10,100,"Tubal tensor algebra: mathematical foundations and applications
","<p>Developed in a series of seminal papers in the early 2010s, the tubal
tensor framework provides a clean and effective algebraic setting for
tensor computations, supporting matrix-mimetic features such as a tensor
Singular Value Decomposition and Eckart–Young-like optimality results.
It has proven to be a powerful tool for analyzing inherently multilinear
data arising in hyperspectral imaging, medical imaging, neural dynamics,
scientific simulations, and more.</p>
<p>At the heart of tubal tensor algebra lies a special tensor-tensor
product: originally the t-product, later generalized into a full family
of products via the *M-product. Though initially defined through the
multiplication of a block-circulant unfolding of one tensor by a
matricization of another, it was soon observed that the t-product can be
interpreted as standard matrix multiplication where the scalars are
tubes—i.e., real vectors twisted “inward.” Yet, a fundamental question
remains: Why is this the “right” way to define a tensor-tensor product
in the tubal setting?</p>
<p>In the talk, I will discuss the mathematical foundations of the tubal
tensor framework, and discuss applications and extensions. In
particular, I will show that the t-product and its *M generalization
arises naturally when viewing third-order tensors as matrices of tubes,
together with a small set of desired natural algebraic properties.
Furthermore,*M-product is, in fact, the unique way to define a tubal
product satisfying these properties, and these desired properties are
required for the tubal SVD and Eckart–Young-like optimality results.</p>
"
S1,SC0008,1,Shaun,Fallat,Shaun Fallat,2025-06-23 11:00:00,MS9,Total positivity,Monday,11:00,11:30,101,9,Preservers of totally positive and totally nonnegative matrices,"<p>A matrix is called totally nonnegative (positive) if all its minors
are nonnegative (positive). In this talk we consider functions that
preserve that class of totally nonnegative (positive) matrices. This
subject has rightfully received significant attention over the years,
including previous studies on characterizing surjective linear
preservers and more recent interesting inquiries into various types of
entry-wise preservers for this class of matrices. Building upon the
basic fact that the class of totally nonnegative (positive) matrices
forms a semigroup we highlight some existing work and investigate and
report on some recent progress concerning multiplicative maps that
preserve this semigroup of positive matrices.</p>
"
S1,SC0008,2,Shivangi,Yadav,Shivangi Yadav,2025-06-23 11:00:00,MS9,Total positivity,Monday,11:30,12:00,101,9,Linear preservers of sign regularity,"<p>The classification of linear maps that act on a space of bounded
linear operators and preserve certain functions, subsets, relations,
etc. has a long history, beginning with Frobenius, who characterized in
1897 the determinant-preserving linear maps on matrix algebras. In this
talk, I will present a classification of all surjective linear mappings
<span
class=""math inline"">ℒ : ℝ<sup><em>m</em> × <em>n</em></sup> → ℝ<sup><em>m</em> × <em>n</em></sup></span>
that preserve: (i) sign regularity and (ii) sign regularity with a given
sign pattern, as well as (iii) strict versions of these. As a special
case of our results, we recover the characterization of linear
preservers for the class of square totally positive and totally
non-negative matrices (by Berman–Hershkowitz–Johnson in 1985). This is a
joint work with Projesh Nath Choudhury.</p>
"
S1,SC0008,3,Apoorva,Khare,Apoorva Khare,2025-06-23 11:00:00,MS9,Total positivity,Monday,12:00,12:30,101,9,"Univariate preservers of totally positive matrices and kernels
","<p>We will discuss recent results on preservers of totally
positive/nonnegative matrices and kernels, together with some
observations that go into their proofs. Partly joint with Alexander
Belton, Dominique Guillot, and Mihai Putinar.</p>
"
S1,SC0009,1,Fumio,Hiai,Fumio Hiai,2025-06-23 11:00:00,MS29,Matrix functions and related topics,Monday,11:00,11:30,101,29,Joint concavity/convexity of matrix trace functions for geometric type means,"<p>In this talk we consider the quasi extensions of the weighted
geometric type means, including <span
class=""math display"">$$\begin{aligned}
&amp;G_{\alpha,p}(A,B):=(A^p\#_\alpha B^p)^{1/p},
\ \mbox{the quasi-weighted geometric mean}, \\
&amp;SG_{\alpha,p}(A,B):=(A^p\#_\alpha B^p)^{1/p},
\ \mbox{the quasi-weighted spectral geometric mean}, \\
&amp;R_{\alpha,p}(A,B):=\bigl(B^{{\frac{1-\alpha}{2}}p}A^{\alpha
p}B^{{\frac{1-\alpha}{2}}p}\bigr)^{1/p},
\ \mbox{the R\'enyi mean}, \\
&amp;LE_\alpha(A,B):=\exp(\alpha\log A+(1-\alpha)\log B),
\ \mbox{the weighted Log-Euclidean mean},
\end{aligned}$$</span> where <span
class=""math inline""><em>α</em> &gt; 0</span> is the weight parameter and
<span class=""math inline""><em>p</em> &gt; 0</span> is the parameter of
the quasi extension. We aim at determining the range of the parameters
<span class=""math inline""><em>α</em>, <em>p</em></span> under which the
trace function <span
class=""math inline"">Tr ℳ<sub><em>α</em>, <em>p</em></sub>(<em>A</em>, <em>B</em>)</span>
is jointly concave (also jointly convex) for each <span
class=""math inline"">ℳ<sub><em>α</em>, <em>p</em></sub></span> from the
above quasi-weighted geometric type means. Our discussions are in strong
relation to the monotonicity property (or date-processing inequality) of
quantum divergences in quantum information.</p>
"
S1,SC0009,2,Hiromichi,Ohno,Hiromichi Ohno,2025-06-23 11:00:00,MS29,Matrix functions and related topics,Monday,11:30,12:00,101,29,"Generalization of B\""ottcher-Wenzel inequality and its application","<p>The Böttcher-Wenzel inequality states that the Hilbert-Schmidt norm
of the commutator of matrices <span
class=""math inline""><em>A</em></span> and <span
class=""math inline""><em>B</em></span> is less than or equal to <span
class=""math inline"">$\sqrt{2}$</span> times the product of the
Hilbert-Schmidt norms of <span class=""math inline""><em>A</em></span> and
<span class=""math inline""><em>B</em></span>. In this talk, we discuss
generalizations of the Böttcher-Wenzel inequality in which the
Hilbert-Schmidt norm is replaced by a weighted Hilbert-Schmidt norm. An
application to the uncertainty relation is also considered.</p>
"
S1,SC0009,3,Jinmi,Hwang,Jinmi Hwang,2025-06-23 11:00:00,MS29,Matrix functions and related topics,Monday,12:00,12:30,101,29,Near-order relation of power means,"<p>On the setting of positive definite operators we study the near-order
properties of power means such as the quasi-arithmetic mean (Hölder
mean) and Rényi power mean. We see the monotonicity of spectral
geometric mean and Wasserstein mean on parameters with respect to the
near-order and the near-order relationship between the spectral
geometric mean and Wasserstein mean. Furthermore, the monotonicity of
quasi-arithmetic mean on parameters and the convergence of Rényi power
mean to the log-Euclidean mean with respect to the near-order have been
established.</p>
"
S1,SC0012,1,Peter,Semrl,Peter Semrl,2025-06-23 11:00:00,MS12,"Preserver problems, I",Monday,11:00,11:30,101,12,Local order isomorphisms on operator and matrix domains,"<p>Let <span class=""math inline""><em>H</em><sub><em>n</em></sub></span>
denote the set of all <span
class=""math inline""><em>n</em> × <em>n</em></span> complex hermitian
matrices and <span
class=""math inline""><em>S</em><sub><em>n</em></sub></span> the set of
all <span class=""math inline""><em>n</em> × <em>n</em></span> real
symmetric matrices. A subset <span
class=""math inline""><em>U</em> ⊂ <em>H</em><sub><em>n</em></sub></span>
(<span
class=""math inline""><em>U</em> ⊂ <em>S</em><sub><em>n</em></sub></span>)
is called a matrix domain if it is open and connected. The general form
of maps <span
class=""math inline""><em>ϕ</em> : <em>U</em> → <em>H</em><sub><em>n</em></sub></span>
(<span
class=""math inline""><em>ϕ</em> : <em>U</em> → <em>S</em><sub><em>n</em></sub></span>)
preserving the usual Loewner order in both directions will be discussed.
We will also treat the infinite-dimensional case.</p>
"
S1,SC0012,2,Edward,Poon,Edward Poon,2025-06-23 11:00:00,MS12,"Preserver problems, I",Monday,11:30,12:00,101,12,Linear preservers of parallel pairs,"<p>Two vectors <span class=""math inline""><em>x</em></span>,<span
class=""math inline""><em>y</em></span> in a normed space <span
class=""math inline"">(𝒳, ∥⋅∥)</span> are said to be parallel if there
exists a scalar <span class=""math inline""><em>c</em></span> with modulus
1 such that <span
class=""math inline"">∥<em>x</em> + <em>c</em><em>y</em>∥ = ∥<em>x</em>∥+∥<em>y</em>∥</span>.
We consider the case of norms on a matrix space (in particular the Ky
Fan <span class=""math inline""><em>k</em></span>-norms and the <span
class=""math inline""><em>k</em></span>-numerical radius) and characterize
the linear bijections on this matrix space which preserve parallel pairs
of matrices.</p>
"
S1,SC0012,3,Lajos,Molnár,Lajos Molnár,2025-06-23 11:00:00,MS12,"Preserver problems, I",Monday,12:00,12:30,101,12,Relative entropy preserving maps on positive cones in operator algebras and in matrix algebras,"<p>We consider several concepts of (not only numerical valued) relative
entropies on positive cones in <span
class=""math inline""><em>C</em><sup>*</sup></span>-algebras. We present
recent results showing that surjective transformations between positive
cones that preserve any of those quantities necessarily originate from
Jordan *-isomorphisms between the underlying full algebras. In the
special case of matrix algebras, we consider the problem of relaxing the
condition of surjectivity.</p>
<p>Partly, joint work with Lei Li and Xueyan Yang (Nankai
University).</p>
"
S1,SC0014,1,Tomasz,Miller,Tomasz Miller,2025-06-23 11:00:00,MS8,Tensor and quantum information science,Monday,11:00,11:30,101,8,A new class of distances between pure quantum states,"<p>For any <span class=""math inline""><em>n</em> × <em>n</em></span>
distance matrix <span
class=""math inline"">(<em>E</em><sub><em>i</em><em>j</em></sub>)</span>,
we show that the map <span class=""math display"">$$\begin{aligned}
d(\textup{\textbf{x}},\textup{\textbf{y}}) :=
\sqrt{\sum_{i&lt;j}E_{ij}^2|x_iy_j - x_jy_i|^2},
\end{aligned}$$</span> where <span
class=""math inline"">$\textup{\textbf{x}},\textup{\textbf{y}} \in
{\mathbb C}^n$</span> are unit vectors, gives rise to a bona fide
distance on the projective space <span
class=""math inline"">ℙ(ℂ<sup><em>n</em></sup>)</span>, a far-reaching
generalization of the standard distance on <span
class=""math inline"">ℙ(ℂ<sup><em>n</em></sup>)</span> arising from the
wedge product <span class=""math inline"">$\|\textup{\textbf{x}} \wedge
\textup{\textbf{y}}\| = \sqrt{1 - |\langle \textup{\textbf{x}} |
\textup{\textbf{y}} \rangle|^2}$</span>. We also discuss how this result
carries over to the <span class=""math inline""><em>n</em> → +∞</span>
case, offering a way to ‘lift’ the metric structure from some underlying
metric measure space <span
class=""math inline"">(<em>X</em>, <em>D</em>, <em>μ</em>)</span> to the
projective Hilbert space <span
class=""math inline"">ℙ(<em>L</em><sup>2</sup>(<em>X</em>, <em>μ</em>))</span>.
The talk builds on and extends the results of [1].</p>
<p>[1] R. Bistroń, M. Eckstein, S. Friedland, TM, K. Życzkowski, <em>A
new class of distances on complex projective spaces</em>, Linear Algebra
Appl., 2024</p>
"
S1,SC0014,2,Shakir Showkat,Sofi,Shakir Showkat Sofi,2025-06-23 11:00:00,MS8,Tensor and quantum information science,Monday,11:30,12:00,101,8,Tensor train completion of multiway data observed in a single mode,"<p>Tensor completion is an extension of matrix completion aimed at
recovering a partially observed data tensor by leveraging the
observations and the pattern of observation. Completion is more
important for tensors than for matrices for several reasons.
Higher-order datasets are larger, increasing the likelihood of missing
or unreliable entries. Large-scale data often exhibits low-rank
properties (intuitively, not every entry is “equally important,” unlike
in smaller matrices). Many interesting problems can be framed as
instances of low-rank tensor completion, including image and video
recovery, collaborative filtering, and quantum state tomography <span
class=""citation"" data-cites=""liu2013tc gross2010quantum""></span>.
Low-rank tensor completion is generally solved via convex optimization
techniques. Current theories concerning these methods often study
probabilistic recovery guarantees under conditions such as random
uniform observations and incoherence requirements <span class=""citation""
data-cites=""candes2009exact liu2013tc""></span>. However, if an
observation pattern has some structure, more efficient algorithms can be
developed by leveraging the structure.</p>
<p>Algebraic methods exploit the low-rank structure to design algorithms
that rely solely on standard numerical linear algebra (NLA) operations.
They are fast and are guaranteed to work under reasonable deterministic
conditions on the observation pattern. In this line, a specific type of
“fiber-wise” observation pattern has been discussed, where some of the
fibers of a tensor (along a specific mode) are either fully observed or
entirely missing, unlike the usual entry-wise observations. This
observation is interesting because it appears in many real-life
applications and highlights a key difference between matrices and
tensors. While missing fibers (rows or columns) in a matrix make
completion underdetermined, higher-order tensors can still be completed
even if some fibers are entirely missing along one mode. It has been
shown that under reasonable conditions, canonical polyadic decomposition
(CPD) and multilinear singular value decomposition (MLSVD) of such an
incomplete tensor can still be obtained using only standard NLA <span
class=""citation""
data-cites=""mikael2019fibersamp stijn2023mlsvdfsj""></span>. Note that
there is an important difference with the technique of cross or skeleton
approximation in the sense that we assume the availability of fibers in
one mode only.</p>
<p>With the increasing prevalence of big data, the demand for reliable
and scalable algorithms has become more pressing. The tensor train (TT)
decomposition is stable and can break the curse of dimensionality <span
class=""citation"" data-cites=""oseledets2010tensortrain""></span>. This
talk shows how to extend the fiber-wise completion to the TT format. We
discuss the deterministic conditions under which the uniqueness of the
solution is guaranteed <span class=""citation""
data-cites=""stijn2023mlsvdfsj shakir2024ttfw""></span>. Furthermore, we
discuss a few interesting applications and briefly highlight the
possibility of utilizing this tensor completion framework as a
fundamental experimental primitive for efficient quantum state
tomography with fewer measurements.</p>
<div class=""thebibliography"">
<p><span>7</span> J. Liu, P. Musialski, P. Wonka, and J. Ye. Tensor
Completion for Estimating Missing Values in Visual Data. <em>IEEE Trans.
Pattern Anal. Mach. Intell.</em>, 35:208–220, 2013.</p>
<p>D. Gross, Y. K. Liu, S. T. Flammia, S. Becker, and J. Eisert. Quantum
State Tomography via Compressed Sensing. <em>Phys. Rev. Lett.</em>,
105(15):150401, 2010. APS.</p>
<p>E. J. Cand<span>è</span>s and B. Recht. Exact Matrix Completion via
Convex Optimization. <em>Found. Comput. Math.</em>, 9(6):717–772, 2009.
Springer.</p>
<p>M. S<span>ø</span>rensen and L. De Lathauwer. Fiber Sampling Approach
to Canonical Polyadic Decomposition and Application to Tensor
Completion. <em>SIAM J. Matrix Anal. Appl.</em>, 40:888–917, 2019.</p>
<p>M. S<span>ø</span>rensen, S. Hendrikx, and L. De Lathauwer.
Multilinear Singular Value Decomposition Based Completion with Fibers
Observed in a Single Mode. <em>SIAM J. Matrix Anal. Appl.</em>, 2025.
[Accepted for publication], <a
href=""https://ftp.esat.kuleuven.be/pub/stadius//shendrik/hendrikx2023mlsvdfibersimax.pdf""
class=""uri"">https://ftp.esat.kuleuven.be/pub/stadius//shendrik/hendrikx2023mlsvdfibersimax.pdf</a>.</p>
<p>I. Oseledets. Tensor-Train Decomposition. <em>SIAM J. Sci.
Comput.</em>, 33:2295–2317, 2011.</p>
<p>S. S. Shakir, S. Hendrikx, and L. De Lathauwer. Tensor Train
Completion of Multi-Way Data Observed Along One Mode. In <em>Proc. 32nd
EUSIPCO</em>, pages 1067–1071, 2024. IEEE.</p>
</div>
"
S1,SC0014,3,Shmuel,Friedland,Shmuel Friedland,2025-06-23 11:00:00,MS8,Tensor and quantum information science,Monday,12:00,12:30,101,8,"On entaglement, separability and their computability","<p>In this talk we survey some results on entanglement and separablity
of general, symmetric (bosons), skew-symmetric (fermions) tensors, and
their computability. We will survey briefly some results that I
coauthored.</p>
<div class=""thebibliography"">
<p><span>99</span> M. Aliabadi and S. Friedland, On the complexity of
finding tensor ranks, <em>Commun. Appl. Math. Comput.</em>, Vol. 3 (2)
(2021), 281-289 W. Bruzda, S. Friedland, K. <span>Ż</span>yczkowski,
Tensor rank and entanglement of pure quantum states, <span><em>Linear
and Multilinear Algebra</em></span> 72 (2024), no. 11, 1796-1859. H.
Derksen, S. Friedland, L.-H. Lim, and L. Wang, Theoretical and
computational aspects of entanglement, arXiv:1705.07160. S. Friedland
and L.-H. Lim,The computational complexity of duality, jointly with,
<em>SIAM Journal on Optimization</em>, 26, No. 4 (2016), 2378–2393. S.
Friedland and L.-H. Lim, Nuclear norm of higher-order tensors,
<em>Mathematics of Computation</em>, 87 (2018), 1255–1281. S. Friedand
and T. Kemp, Most Boson quantum states are almost maximally entangled,
<em>Proceedings of Amer. Math. Soc.</em> 146, No.12, (2018), 5035–5049.
S. Friedland and L. Wang, Spectral norm of a symmetric tensor and its
computation, , <em>Mathematics of Computation</em>, 89 (2020),
2175–2215.</p>
</div>
"
S1,SC1001,1,Takeaki,Yamazaki,Takeaki Yamazaki,2025-06-23 11:00:00,MS10,Matrix means and related topics,Monday,11:00,11:30,101,10,Stability of AN-operators under functional calculus,"<p>This talk is based on [1]. Let <span
class=""math inline"">ℬ(<em>H</em>)</span> be the set of all bounded
linear operators on a complex Hilbert space. An operator <span
class=""math inline""><em>T</em> ∈ ℬ(<em>H</em>)</span> satisfies <span
class=""math inline"">𝒜𝒩</span>-property if and only if for any closed
subspace <span class=""math inline""><em>K</em></span> of <span
class=""math inline""><em>H</em></span>, there exists a unit vector <span
class=""math inline""><em>x</em> ∈ <em>K</em></span> such that <span
class=""math inline"">∥<em>T</em>|<sub><em>K</em></sub>∥ = ∥<em>T</em>|<sub><em>K</em></sub><em>x</em>∥</span>.
The set of operators satisfying <span
class=""math inline"">𝒜𝒩</span>-property is not closed. Moreover <span
class=""math inline"">𝒜𝒩</span>-property is not stable under some
operations. In this talk, we shall introduce stability of <span
class=""math inline"">𝒜𝒩</span>-property under functional calculus on
positive definite operators.</p>
<p>This is a joint work with Professor Golla Ramesh, Hiroyuki Osaka and
Yoichi Udagawa.</p>
<p>G. Ramesh, H. Osaka, Y. Udagawa and T. Yamazaki, <span><em>Stability
of <span class=""math inline"">𝒜𝒩</span> -operators under functional
calculus</em></span>, Anal. Math. <span><strong>49</strong></span>
(2023), 825–839.</p>
"
S1,SC1001,2,Sejong,Kim,Sejong Kim,2025-06-23 11:00:00,MS10,Matrix means and related topics,Monday,11:30,12:00,101,10,Quasi-Wasserstein mean of positive definite matrices,"<p>The typical examples of Kubo-Ando’s operator means are the weighted
arithmetic, geometric, and harmonic means. In particular, they are
interpolated by the power means (introduced by Lim and Palfia)
monotonically in terms of the Loewner order. On the other hand, there
are other important means of non-Kubo-Ando’s operator means such as the
weighted spectral geometric and Wasserstein means. We define
quasi-Wasserstein means, which interpolate the weighted spectral
geometric and Wasserstein means monotonically in terms of the
near-order. We also study their properties including trace and norm
inequalities.</p>
"
S1,SC1001,3,Hayoung,Choi,Hayoung Choi,2025-06-23 11:00:00,MS10,Matrix means and related topics,Monday,12:00,12:30,101,10,Geometric mean of T-positive definite tensors,"<p>In this talk, we generalize the geometric mean of two positive
definite matrices to that of third-order tensors using the notion of
T-product. Specifically, we define the geometric mean of two T-positive
definite tensors and verify several properties that “mean” should
satisfy including the idempotence and the commutative property, and so
on. Moreover, it is shown that the geometric mean is a unique T-positive
definite solution of an algebraic Riccati tensor equation and can be
expressed as solutions of algebraic Riccati matrix equations.</p>
"
S1,SC1003,1,Paola,Boito,Paola Boito,2025-06-23 11:00:00,MS26,"Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics",Monday,11:00,11:30,101,26,Decay bounds for inverses of banded matrices via quasiseparable structure,"<p>A well-known result in matrix theory states that, under suitable
hypotheses, the inverse of a banded matrix <span
class=""math inline""><em>A</em></span> exhibits an exponential
off-diagonal decay behavior. In other words, there exist constants <span
class=""math inline""><em>K</em> &gt; 0</span> and <span
class=""math inline"">0 &lt; <em>ξ</em> &lt; 1</span>, independent of
matrix size, such that <span
class=""math display"">[<em>A</em><sup>−1</sup>]<sub><em>i</em><em>j</em></sub> ≤ <em>K</em><em>ξ</em><sup>|<em>i</em> − <em>j</em>|</sup>.</span>
Several versions of such bounds are available in the literature. Most of
them rely on polynomial approximation of the function <span
class=""math inline""><em>x</em> → 1/<em>x</em></span> on a convex subset
of <span class=""math inline"">ℂ</span> containing the spectrum of <span
class=""math inline""><em>A</em></span>; see for instance the seminal work
by Demko, Moss and Smith <span class=""citation""
data-cites=""DMS84""></span>.</p>
<p>Here we take a different approach, which exploits the quasiseparable
structure of <span class=""math inline""><em>A</em></span> and <span
class=""math inline""><em>A</em><sup>−1</sup></span>. Based on recently
proposed inversion algorithms for banded matrices <span class=""citation""
data-cites=""BE23""></span>, we develop new decay bounds for inverses of
one-sided and two-sided banded matrices, under a hypothesis of strong
diagonal dominance. Our bounds are easily computable, do not require
spectral information on <span class=""math inline""><em>A</em></span> and
can be advantageous for symmetric indefinite or nonsymmetric
matrices.</p>
<p>This is joint work with Yuli Eidelman (Tel-Aviv University).</p>
<div class=""thebibliography"">
<p><span>99</span> P. Boito and Y. Eidelman, Computation of
quasiseparable representations of Green matrices. Linear Algebra and its
Applications, in press (available online 6 May 2024). S. Demko,
W. F. Moss, and P. W. Smith, Decay rates for inverses of band matrices.
Mathematics of Computation 43.168 (1984), 491-499.</p>
</div>
"
S1,SC1003,2,Luca,Gemignani,Luca Gemignani,2025-06-23 11:00:00,MS26,"Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics",Monday,11:30,12:00,101,26,On the numerical solution of nonLocal boundary value problems by matrix function computations,"<p>Given a matrix <span
class=""math inline""><em>A</em> ∈ ℝ<sup><em>s</em> × <em>s</em></sup></span>
and a vector <span
class=""math inline""><strong>f</strong> ∈ ℝ<sup><em>s</em></sup>,</span>
under mild assumptions the non-local boundary value problem <span
class=""math display"">$$\begin{aligned}
    &amp;&amp;\odv{\mathbf{u}}{\tau} = A \mathbf{u}, \quad
0&lt;\tau&lt;1,   \label{l1} \\
  &amp;&amp;\displaystyle \int_0^1 \mathbf{u}(\tau) \,\mathrm{d}\tau =
\mathbf {f}, \label{l2}
\end{aligned}$$</span> admits as unique solution <span
class=""math display"">$$\mathbf{u}(\tau)= q(\tau,A) \mathbf {f}, \quad
q(\tau,w)= \frac{w e^{w\tau}}{e^w -1}.$$</span> This talk deals with
efficient numerical methods for computing the action of <span
class=""math inline""><em>q</em>(<em>τ</em>, <em>A</em>)</span> on a
vector, when <span class=""math inline""><em>A</em></span> is a large and
sparse matrix. Methods based on the Fourier expansion of <span
class=""math inline""><em>q</em>(<em>τ</em>, <em>w</em>)</span> are
considered. First, we place these methods in the classical framework of
Krylov-Lanczos (polynomial-rational) techniques for accelerating Fourier
series. This allows us to apply the convergence results developed in
this context to our function. Second, we design some new acceleration
schemes for computing <span
class=""math inline""><em>q</em>(<em>τ</em>, <em>A</em>)<strong>f</strong></span>.
Numerical results are presented to show the effectiveness of the
proposed algorithms.</p>
<p><em>This is joint work with Lidia Aceto.</em></p>
"
S1,SC1003,3,Erkki,Somersalo,Erkki Somersalo,2025-06-23 11:00:00,MS26,"Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics",Monday,12:00,12:30,101,26,Model reduction and matrix compression in dictionary learning applications,"<p>Dictionary learning and matching is an attractive way to solve
numerically inverse problems in which the forward model is too complex
to be used in the inversion process. Dictionary matching problems lead
often to very large underdetermined problems, and dictionary compression
is therefore desired. In this talk, we propose a dictionary compression
method that leverages ideas from Bayesian inverse problems with sparsity
promoting priors, and takes advantage of the structure of the
underlining matrix to design computationally efficient algorithms.</p>
"
S1,SC1005,1,Kate,Lorenzen,Kate Lorenzen,2025-06-23 11:00:00,MS15,Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham,Monday,11:00,11:30,101,15,Cospectral constructions for the generalized distance matrix,"<p>The generalized distance matrix of a graph is a matrix in which every
entry is function of the distance between the vertices. With special
choices of the function, the generalized distance matrix family includes
the adjacency matrix and distance matrix. Surprisingly, some pairs of
graph are cospectral independent of the choice of function. We present a
construction that builds on Godsil-McKay Switching to produce cospectral
pairs for the generalized distance matrix connecting cospectral
constructions for many different graph matrices.</p>
"
S1,SC1005,2,Joshua,Cooper,Joshua Cooper,2025-06-23 11:00:00,MS15,Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham,Monday,11:30,12:00,101,15,Principal eigenvectors and principal ratios in hypergraph Tur\'{a}n problems,"<p>For a general class of hypergraph Turán problems with uniformity
<span class=""math inline""><em>r</em></span>, we investigate the
principal eigenvector for the <span
class=""math inline""><em>p</em></span>-spectral radius of its extremal
graphs, showing in a strong sense that these eigenvectors have equal
weight on each vertex (equivalently, showing that the principal ratio is
close to <span class=""math inline"">1</span>). Our result is sharp for
the conjectural extremizers of the Turán tetrahedron problem, and for
some other problems in which the extremizers are well understood; it is
unclear whether it always sharp. We establish a result which may have
also have independent interest, proving a lower bound on the spectral
radius depending on the degrees of the graph. The case <span
class=""math inline"">1 &lt; <em>p</em> &lt; <em>r</em></span> of our
results leads to some subtleties connected to Nikiforov’s notion of
<span class=""math inline""><em>k</em></span>-tightness. We raise a
conjecture about these issues, and provide some preliminary evidence for
our conjecture.</p>
"
S1,SC1005,3,Lavanya,Selvaganesh,Lavanya Selvaganesh,2025-06-23 11:00:00,MS15,Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham,Monday,12:00,12:30,101,15,"Perfect codes and spectrum of graphs - a brief survey
","<p>Perfect codes have been key subject of study since the emergence of
coding theory in the late 1940s, and they continue to garner
considerable interest even after more than sixty years. Hamming and
Golay codes are well-known perfect codes, and their significance to
information theory is widely recognized. A <em>code</em> in a graph
<span class=""math inline""><em>X</em> = (<em>V</em>, <em>E</em>)</span>
is a non-empty subset of <span class=""math inline""><em>V</em></span>.
Given an integer <span class=""math inline""><em>t</em> ≥ 1</span>, the
ball with radius <span class=""math inline""><em>t</em></span> and centre
<span class=""math inline""><em>u</em> ∈ <em>V</em></span> is defined as
<span
class=""math inline""><em>B</em><sub><em>t</em></sub>(<em>u</em>, <em>X</em>) := {<em>v</em> ∈ <em>V</em> : <em>d</em>(<em>u</em>, <em>v</em>) ≤ <em>t</em>}</span>,
where <span
class=""math inline""><em>d</em>(<em>u</em>, <em>v</em>)</span> is the
distance in <span class=""math inline""><em>X</em></span> between <span
class=""math inline""><em>u</em></span> and <span
class=""math inline""><em>v</em></span>. A code <span
class=""math inline""><em>C</em> ⊆ <em>V</em></span> is called a
<em>perfect t-error-correcting code</em> or a <em>perfect t-code</em> in
<span class=""math inline""><em>X</em></span> if the balls <span
class=""math inline""><em>B</em><sub><em>t</em></sub>(<em>u</em>, <em>X</em>)</span>
with radius <span class=""math inline""><em>t</em></span> and centres
<span class=""math inline""><em>u</em> ∈ <em>C</em></span> form a
partition of <span class=""math inline""><em>V</em></span>. In graph
theory, <span
class=""math inline""><em>B</em><sub><em>t</em></sub>(<em>u</em>, <em>X</em>)</span>
is called the <span class=""math inline""><em>t</em></span>-neighbourhood
of <span class=""math inline""><em>u</em></span> in <span
class=""math inline""><em>X</em></span>, each vertex in <span
class=""math inline""><em>B</em><sub><em>t</em></sub>(<em>u</em>, <em>X</em>)</span>
is said to be <em><span
class=""math inline""><em>t</em></span>-dominated</em> by<span
class=""math inline""><em>u</em></span>, a perfect <span
class=""math inline""><em>t</em></span>-code in <span
class=""math inline""><em>X</em></span> is called a <em>perfect
t-dominating set</em> of <span class=""math inline""><em>X</em></span>,
and a perfect 1-code in <span class=""math inline""><em>X</em></span> is
called an <em>efficient dominating set</em> or <em>independent perfect
dominating set</em>. In this talk, our goal is to highlight the
interplay between the perfect 1-codes and the eigenvalues of graphs. In
particular, we focus on the spectrum of special classes of graphs such
as Cayley graphs and circulant graphs, and characterize a perfect-1-code
in such graphs.</p>
"
S1,SC2001,1,Richard A.,Brualdi,Richard A. Brualdi,2025-06-23 11:00:00,MS2,Combinatorial matrix theory,Monday,11:00,11:30,101,2,(Reverse-)Grassmannian permutation matrices,"<p>A <span><em>Grassmannian permutation</em></span> <span
class=""math inline""><em>i</em><sub>1</sub><em>i</em><sub>2</sub>⋯<em>i</em><sub><em>n</em></sub></span>
is a permutation of <span
class=""math inline"">{1, 2, …, <em>n</em>}</span> with at most one
descent <span
class=""math inline""><em>i</em><sub><em>k</em> + 1</sub> &lt; <em>i</em><sub><em>k</em></sub></span>;
a <span><em>reverse-Grassmannian</em></span> has at most one ascent
<span
class=""math inline""><em>i</em><sub><em>k</em> + 1</sub> &gt; <em>i</em><sub><em>k</em></sub></span>.
We consider reverse-Grassmannians (<span>revG</span>’s) and their
corresponding permutation matrices.The number of such revG’s is <span
class=""math inline"">2<sup><em>n</em></sup> − <em>n</em></span> which
includes the only permutation <span
class=""math inline""><em>n</em>(<em>n</em> − 1)⋯1</span> without any
ascents (the reverse-diagonal matrix or Hankel diagonal matrix <span
class=""math inline""><em>L</em><sub><em>n</em></sub></span>). An <span
class=""math inline""><em>n</em> × <em>n</em></span> <span
class=""math inline"">(0, 1)</span>-matrix <span
class=""math inline""><em>A</em></span> with total support (every 1 of
<span class=""math inline""><em>A</em></span> belongs to a permutationn
matrix <span class=""math inline""><em>P</em> ≤ <em>A</em></span>) is a
<span><em>revG-blocker</em></span> provided that there does not exist a
revG permutation matrix <span
class=""math inline""><em>P</em> ≤ <em>A</em></span>. Such a revG-blocker
must contain at least <span class=""math inline""><em>n</em></span> 0’s.
We determine a Frobenius-König-type theorem for revG-blockers with
exactly <span class=""math inline""><em>n</em></span> 0’s. Just as the
convex polytope <span
class=""math inline""><em>Ω</em><sub><em>n</em></sub></span> of <span
class=""math inline""><em>n</em> × <em>n</em></span> doubly stochastic
matrices gives continuous analogues of permutation matrices, the convex
hull <span
class=""math inline""><em>Ω</em><sub><em>n</em></sub>(revG)</span> of the
<span class=""math inline""><em>n</em> × <em>n</em></span> revG’s gives
continuous analogues of revGs. <span
class=""math inline""><em>Ω</em><sub><em>n</em></sub>(revG)</span> has the
same dimension as <span
class=""math inline""><em>Ω</em><sub><em>n</em></sub></span> since there
is a basis of the <span
class=""math inline""><em>n</em> × <em>n</em></span> permutation matrices
consisting of revGs. (This talk is based on ongoing work with Lei
Cao.)</p>
"
S1,SC2001,2,Jane,Breen,Jane Breen,2025-06-23 11:00:00,MS2,Combinatorial matrix theory,Monday,11:30,12:00,101,2,"Measuring the impact of a single transition on Kemeny's constant
","<p>Kemeny’s constant is a measure of the expected length of a random
trip between states of a Markov chain, and is a useful quantifier of the
mixing properties of the Markov chain. By examining how the value of
Kemeny’s constant changes when the probability transition matrix is
perturbed, one can determine the transitions which have the greatest
impact on the connectivity of the Markov chain. This has been shown to
be useful in a wide range of applications, including road network
dynamics and social network decomposition. In this talk, we give an
overview of several methods to determine the importance of a single
transition to the value of Kemeny’s constant and discuss some
applications.</p>
"
S1,SC2001,3,Zilin,Jiang,Zilin Jiang,2025-06-23 11:00:00,MS2,Combinatorial matrix theory,Monday,12:00,12:30,101,2,Median eigenvalues of subcubic graphs,"<p>We present a resolution to conjectures by Fowler, Pisanski, and Mohar
regarding the median eigenvalues of subcubic (chemical) graphs.
Specifically, we prove that the median eigenvalues of every connected
graph with maximum degree at most three, except for the Heawood graph,
lie within the interval <span class=""math inline"">[−1, 1]</span>. This
result has significant implications in mathematical chemistry,
particularly in the analysis of molecular orbital models, and extends
prior work on bipartite chemical graphs.</p>
"
S1,SC2006,1,Gary,Choi,Gary Choi,2025-06-23 11:00:00,MS22,Linear algebra applications in computational geometry,Monday,11:00,11:30,101,22,Density-equalizing map with applications,"<p>We present surface and volumetric mapping methods based on a natural
principle of density diffusion. Specifically, we start with a prescribed
density distribution in a surface or volumetric domain and then create
shape deformations with different regions enlarged or shrunk based on
the density gradient. Using the proposed methods, we can easily achieve
different mapping effects with controllable area change. Applications to
shape registration, morphing, remeshing, medical shape analysis, and
data visualization will be presented.</p>
"
S1,SC2006,2,Ronald Lok Ming,Lui,Ronald Lok Ming Lui,2025-06-23 11:00:00,MS22,Linear algebra applications in computational geometry,Monday,11:30,12:00,101,22,Density-equalizing quasiconformal surface and volmeteric parameterization,"<p>This talk explores various methods for computing bijective
density-equalizing quasiconformal mappings for both surface and
volumetric parameterizations. The primary objective is to achieve
parameterizations of geometric shapes—whether 2D surfaces or 3D
volumes—that minimize local geometric distortion while adhering to a
prescribed density distribution of vertices. The density diffusion
process is modeled as a quasiconformal flow, enabling effective control
over local geometric distortions and ensuring mapping bijectivity. The
talk will cover the underlying numerical algorithms and showcase
experimental results. This work is supported by the Hong Kong Research
Grants Council General Research Fund (Project ID: 14310224).</p>
"
S1,SC2006,3,Marco,Sutti,Marco Sutti,2025-06-23 11:00:00,MS22,Linear algebra applications in computational geometry,Monday,12:00,12:30,101,22,"Riemannian gradient descent for spherical area-preserving mappings
","<p>We propose a new Riemannian gradient descent method for computing
spherical area-preserving mappings of topological spheres using a
Riemannian retraction-based framework with theoretically guaranteed
convergence. The objective function is based on the stretch energy
functional, and the minimization is constrained on a power manifold of
unit spheres embedded in three-dimensional Euclidean space. Numerical
experiments on several mesh models demonstrate the accuracy and
stability of the proposed framework. Comparisons with three existing
state-of-the-art methods for computing area-preserving mappings
demonstrate that our algorithm is both competitive and more efficient.
Finally, we present a concrete application to the problem of
landmark-aligned surface registration of two brain models. This is joint
work with Mei-Heng Yueh.</p>
"
S1,SC3001,1,Leonardo,Robol,Leonardo Robol,2025-06-23 11:00:00,MS18,New methods in numerical multilinear algebra,Monday,11:00,11:30,101,18,A multilinear Nyström algorithm for low-rank approximation of tensors in Tucker format,"<p>The Nyström method offers an effective way to obtain low-rank
approximation of SPD matrices and has been recently extended and
analyzed to nonsymmetric matrices (leading to the generalized Nyström
method). It is a randomized, single-pass, streamable, cost-effective,
and accurate alternative to the randomized SVD, and it facilitates the
computation of several matrix low-rank factorizations. We take these
advancements a step further by introducing a higher-order variant of
Nystrom’s methodology tailored to approximating low-rank tensors in the
Tucker format: the multilinear Nyström technique. We show that, by
introducing appropriate small modifications in the formulation of the
higher-order method, strong stability properties can be obtained. This
algorithm retains the key attributes of the generalized Nyström method,
positioning it as a viable substitute for the randomized higher-order
SVD algorithm.</p>
"
S1,SC3001,2,Anna,Ma,Anna Ma,2025-06-23 11:00:00,MS18,New methods in numerical multilinear algebra,Monday,11:30,12:00,101,18,Stochastic iterative methods for solving tensor linear systems,"<p>Solving linear systems is a crucial subroutine and challenge in data
science and scientific computing. Classical approaches for solving
linear systems assume that data is readily available and small enough to
be stored in memory. However, in the large-scale data setting, data may
be so large that only partitions (e.g., single rows/columns of the
matrix/tensor) can be utilized at a time. In this presentation, we
discuss the advantages and role of randomization in iterative methods
for approximating the solution to large-scale linear systems. Time
permitting, we will also discuss our recent work on applications to
solving systems involving higher-dimensional arrays, or tensors. Unlike
previously proposed randomized iterative strategies, such as the tensor
randomized Kaczmarz method (row slice method) or the tensor Gauss-Seidel
method (column slice method), which are natural extensions of their
matrix counterparts, our approach delves into a distinct scenario
utilizing frontal slice sketching.</p>
"
S1,SC3001,3,Elizabeth,Newman,Elizabeth Newman,2025-06-23 11:00:00,MS18,New methods in numerical multilinear algebra,Monday,12:00,12:30,101,18,"Optimal matrix-mimetic tensor algebras via variable projection
","<p>Many data are naturally represented as multiway arrays or tensors,
and as a result, multilinear data analysis tools have revolutionized
feature extraction and data compression. Despite the success of
tensor-based approaches, fundamental linear algebra properties often
break down in higher dimensions. Recent advances in matrix-mimetic
tensor algebra in have made it possible to preserve linear algebraic
properties and, as a result, to obtain optimal representations of
multiway data. Matrix-mimeticity arises from interpreting tensors as
t-linear operators, which in turn are parameterized by invertible linear
transformations. The choice of transformation is critical to
representation quality, and thus far, has been made heuristically. In
this talk, we will learn data-dependent, orthogonal transformations by
leveraging the optimality of matrix-mimetic representations. In
particular, we will exploit the coupling between transformations and
optimal tensor representations using variable projection. We will
highlight the efficacy of our proposed approach on image compression and
reduced order modeling tasks.</p>
"
S1,SC4011,1,Shih-Hao,Huang,Shih-Hao Huang,2025-06-23 11:00:00,MS20,Manifold learning and statistical applications,Monday,11:00,11:30,101,20,Coordinate testing for general sufficient dimension reduction methods,"<p>In modern data analysis, the number of covariates is often large, and
the relationship between covariates and response is often complex.
Parametric regression risks model misspecification, while nonparametric
regression suffers from the curse of dimensionality. Sufficient
dimension reduction (SDR) regression provides a flexible alternative,
summarizing covariate effects through a few linear combinations without
imposing a specific functional form. While SDR methods have been
extensively studied, coordinate testing, which assesses the contribution
of a set of linear combinations of covariates, has been largely
overlooked. To address this gap, we propose a novel method that
transforms the coordinate testing problem into a dimension testing
problem by applying appropriate residualization. Since dimension tests
are well-established, this method allows practitioners to leverage
existing inference tools within the SDR framework.</p>
"
S1,SC4011,2,ShaoHsuan,Wang,ShaoHsuan Wang,2025-06-23 11:00:00,MS20,Manifold learning and statistical applications,Monday,11:30,12:00,101,20,Contrastive principal component analysis in high dimension,"<p>Principal component analysis (PCA) has been widely used in
exploratory data analysis. Contrastive PCA (Abid et al., 2018), a
generalized method of PCA, is a new tool used to capture features of a
target dataset relative to a background dataset while preserving the
maximum amount of information contained in the data. With high
dimensional data, contrastive PCA becomes impractical due to its high
computational requirement of forming the contrastive covariance matrix
and associated eigenvalue decomposition for extracting leading
components. In this work, we propose a geometric curvilinear-search
method to solve this problem and provide a convergence analysis. Our
approach offers significant computational efficiencies. Specifically, it
reduces the time complexity from <span
class=""math inline""><em>O</em>((<em>n</em> ∧ <em>m</em>)<em>p</em><sup>2</sup>)</span>
to a more manageable <span
class=""math inline""><em>O</em>((<em>n</em> ∧ <em>m</em>)<em>p</em><em>r</em>)</span>,
where n, m are the sample sizes of the target data and background data,
respectively, p is the data dimension and r is the number of leading
components. Additionally, we streamline the space complexity from <span
class=""math inline""><em>O</em>(<em>p</em><sup>2</sup>)</span>, necessary
for storing the contrastive covariance matrix, to a more economical
<span
class=""math inline""><em>O</em>((<em>n</em> ∧ <em>m</em>)<em>p</em>)</span>,
sufficient for storing the data alone. Numerical examples are presented
to show the merits of the proposed algorithm.</p>
"
S1,SC4011,3,Szu-Chi,Chung,Szu-Chi Chung,2025-06-23 11:00:00,MS20,Manifold learning and statistical applications,Monday,12:00,12:30,101,20,A framework for exploring the conformational landscape of cryo-EM using energy-aware pathfinding algorithm,"<p>Cryo-electron microscopy (cryo-EM) is a powerful technique for
investigating macromolecular structures and holds great promise for
uncovering kinetically preferred transition sequences between
conformational states. While such transitions are often explored using
two-dimensional energy landscapes, the intrinsic complexity of
biomolecular conformations frequently renders low-dimensional
representations insufficient. Recent advances in reconstruction models
have enabled the characterization of structural heterogeneity from
cryo-EM images through high-dimensional latent spaces. However,
constructing conformational landscapes in these spaces and identifying
preferred transition pathways remain major challenges.</p>
<p>In this study, we propose a novel framework for identifying preferred
trajectories within high-dimensional conformational landscapes. Our
method formulates the problem as a graph-based search for minimum energy
paths, where edge weights are computed from local energy estimates
derived from density in high-dimensional space. We demonstrate the
effectiveness of this approach by accurately identifying transition
states in both synthetic and experimental datasets exhibiting continuous
conformational changes. To facilitate future research and
reproducibility, we provide a modular implementation of our framework at
https://github.com/tengyulin/energy_aware_pathfinding/.</p>
"
S2,SC0008,1,Jorge,Delgado,Jorge Delgado,2025-06-23 14:00:00,MS9,Total positivity,Monday,14:00,14:30,102,9,Computations with high relative accuracy for the collocation matrices of q-Jacobi polynomials,"<p>In this talk the bidiagonal decomposition of the Collocation Matrices
of q-Jacobi Polynomials will be presented. In addition, it will be shown
that this bidiagonal decomposition can be constructed with high relative
accuracy (HRA) in many cases. Then, for these cases, the bidiagonal
decomposition will be used to solve with HRA the following linear
algebra problems: computation of the inverse, the eigenvalues and the
singular values of those collocation matices, and the solution of some
related linear systems of equations.</p>
<p>This is a joint work with Jorge Delgado, Héctor Orera and Juan Manuel
Peña.</p>
"
S2,SC0008,2,Dmitrii,Karp,Dmitrii Karp,2025-06-23 14:00:00,MS9,Total positivity,Monday,14:30,15:00,102,9,Unimodality preservation by ratios of functional series and integral transforms,"<p>Elementary, but very useful lemma due to Biernacki and Krzyż (1955)
asserts that the ratio of two power series inherits monotonicity from
that of the sequence of ratios of their respective coefficients. Over
the last two decades it has been realized that, under some additional
assumptions, similar claims hold for more general ratios of series and
integral transforms as well as for unimodality in place of monotonicity.
In the talk, we discuss conditions on the functional sequence and the
kernel of an integral transform ensuring the preservation property.
Numerous series and integral transforms appearing in applications
satisfy our sufficient conditions, including Dirichlet, factorial (and
<span class=""math inline""><em>q</em></span>-factorial) series, inverse
factorial series, Laplace, Mellin and generalized Stieltjes transforms,
among many others. We illustrate our results by ratios of generalized
hypergeometric functions and Nuttall’s <span
class=""math inline""><em>Q</em></span> functions. The key role in our
considerations is played by the notion of sign regularity.</p>
<p>The talk is based on the the joint work with Anna Vishnyakova and Yi
Zhang.</p>
"
S2,SC0008,3,Anna,Vishnyakova,Anna Vishnyakova,2025-06-23 14:00:00,MS9,Total positivity,Monday,15:00,15:30,102,9,"On total positivity of sequences generated by 
real polynomials and $q$-polynomials
","<p>Let <span
class=""math inline""><em>P</em>, <em>P</em>(0) &gt; 0,</span> be a real
polynomial of degree <span class=""math inline""><em>m</em>.</span> It is
easy to check that <span class=""math display"">$$\sum_{k=0}^\infty P(k)
x^k =\frac{Q_m(x)}{(1-x)^{m+1}},$$</span> where <span
class=""math inline""><em>Q</em><sub><em>m</em></sub></span> is a real
polynomial of degree at most <span
class=""math inline""><em>m</em>.</span></p>
<p>We will discuss the following problem: for which <span
class=""math inline""><em>P</em></span> the sequence <span
class=""math inline"">(<em>P</em>(<em>k</em>))<sub><em>k</em> = 0</sub><sup>∞</sup></span>
is totally positive? According to the famous theorem by Aissen,
Schoenberg, Whitney and Edrei it happens if and only if all the zeros of
<span class=""math inline""><em>Q</em><sub><em>m</em></sub></span> are
real and non-positive.</p>
<p>The following statement is one of our results.</p>
<p><span><strong>Statement</strong></span> <span><em>Let <span
class=""math inline""><em>P</em>(<em>x</em>) = (<em>x</em> + <em>α</em><sub>1</sub>)(<em>x</em> + <em>α</em><sub>2</sub>) ⋅ … ⋅ (<em>x</em> + <em>α</em><sub><em>m</em></sub>),</span>
where <span
class=""math inline"">0 ≤ <em>α</em><sub>1</sub> ≤ <em>α</em><sub>2</sub> ≤ … ≤ <em>α</em><sub><em>m</em></sub>,</span>
and for every <span
class=""math inline""><em>j</em> = 1, 2, …, <em>m</em> − 1</span> we have
<span
class=""math inline""><em>α</em><sub><em>j</em> + 1</sub> − <em>α</em><sub><em>j</em></sub> ≤ 1.</span>
Then the sequence <span
class=""math inline"">(<em>P</em>(<em>k</em>))<sub><em>k</em> = 0</sub><sup>∞</sup></span>
is totally positive.</em> </span></p>
<p>We will also discuss the sequences of the form <span
class=""math display"">((1 − <em>c</em><sub>1</sub><em>q</em><sup><em>k</em></sup>)(1 − <em>c</em><sub>2</sub><em>q</em><sup><em>k</em></sup>) ⋅ … ⋅ (1 − <em>c</em><sub><em>m</em></sub><em>q</em><sup><em>k</em></sup>)<em>x</em><sup><em>k</em></sup>)<sub><em>k</em> = 0</sub><sup>∞</sup>,</span>
where <span
class=""math inline"">0 &lt; <em>q</em> &lt; 1, <em>q</em> &lt; <em>c</em><sub><em>j</em></sub> &lt; 1.</span></p>
<p>The talk is based on joint work with Dmitrii Karp and, partially, Thu
Hien Nguyen.</p>
"
S2,SC0009,1,Masatoshi,Ito,Masatoshi Ito,2025-06-23 14:00:00,MS29,Matrix functions and related topics,Monday,14:00,14:30,102,29,The weighted power difference mean and its generalization,"<p>Pal, Singh, Moslehian and Aujla (2016) introduced the weighted
logarithmic mean for two positive numbers or operators on a complex
Hilbert space, which is based on an extension of the Hermite-Hadamard
inequality. Furuichi and Minculete (2020) obtained a refinement of the
inequality by Pal et al. On the other hand, we discussed relations among
some weighted operator means by considering the notion of a transpose
symmetric path of weighted means, and we introduced the weighted Heinz
mean. In this talk, based on these arguments, we newly introduce the
weighted power difference mean and get relations among the weighted
power, power difference and arithmetic means. Moreover, we generalize
these results from the viewpoint of a transpose symmetric path.</p>
"
S2,SC0009,2,,,,2025-06-23 14:00:00,MS29,Matrix functions and related topics,Monday,14:30,15:00,102,29,,
S2,SC0009,3,Aedan Jarrod,Potot,Aedan Jarrod Potot,2025-06-23 14:00:00,MS29,Matrix functions and related topics,Monday,15:00,15:30,102,29,"Schur-Horn theorem and Ky Fan principle for symplectic eigenvalues
","<p>In matrix theory, the Schur and Horn theorems reveal that
majorization is the precise relationship between the diagonal entries
and the eigenvalues of a Hermitian matrix. Schur’s theorem is known to
be equivalent to the so-called Ky Fan principle. In 2015 and 2020,
Bhatia and Jain proved the Ky Fan principle and Schur-Horn theorem for
symplectic eigenvalues. In this study, it is shown that the symplectic
analogues of Schur’s theorem and the Ky Fan principle are equivalent.
Moreover, the symplectic Schur-Horn theorem is extended to generalized
means.</p>
"
S2,SC0012,1,,,,2025-06-23 14:00:00,,,Monday,14:00,14:30,102,1000,,
S2,SC0012,2,,,,2025-06-23 14:00:00,,,Monday,14:30,15:00,102,1000,,
S2,SC0012,3,,,,2025-06-23 14:00:00,,,Monday,15:00,15:30,102,1000,,
S2,SC0014,1,Michal,Eckstein,Michal Eckstein,2025-06-23 14:00:00,MS8,Tensor and quantum information science,Monday,14:00,14:30,102,8,Max-type quasidistances probability simplices,"<p>A quasidistance is a function on a set, which is non-negative,
non-degenerate and satisfies the triangle inequality. Despite the lack
of symmetry, quasidistances lead to a rich theory involving geometric
structures, such as geodesics.</p>
<p>We introduce a new family of max-type quasimetrics on probability
simplices <span
class=""math inline""><em>Δ</em><sub><em>N</em></sub></span> defined by
<span
class=""math display""><em>D</em><sub><em>f</em></sub>(<em>P</em>, <em>Q</em>) = max<sub><em>i</em></sub>(<em>f</em>(<em>q</em><sub><em>i</em></sub>) − <em>f</em>(<em>p</em><sub><em>i</em></sub>)),</span>
where <span class=""math inline""><em>f</em>: [0, 1] → [0, 1]</span> is a
continuous, strictly increasing function with <span
class=""math inline""><em>f</em>(0) = 0</span> and <span
class=""math inline""><em>f</em>(1) = 1</span>. Under mild regularity
assumptions on <span class=""math inline""><em>f</em></span>, the
quasimetric space <span
class=""math inline"">(<em>Δ</em><sub><em>N</em></sub>, <em>D</em><sub><em>f</em></sub>)</span>
has a Finslerian structure and admits geodesics (both forward and
backward) between any two points. Moreover, the function <span
class=""math inline""><em>D</em><sub><em>f</em></sub></span> is monotone
under bistochastic maps.</p>
"
S2,SC0014,2,Gilad,Gour,Gilad Gour,2025-06-23 14:00:00,MS8,Tensor and quantum information science,Monday,14:30,15:00,102,8,Tensors structures in single-shot quantum information: from convex splits to induced divergences,"<p>Recent advances in quantum information theory reveal the power of
tensor structures in communication and coding tasks. In this talk, I
present two results that reformulate key protocols using tools from
matrix analysis: an equality-based version of the convex split lemma,
relying on collision mutual information derived from the sandwiched
Rényi relative entropy of order <span class=""math inline"">2</span>, and
the induced divergence, a new family of smoothed quantum divergences.
These developments yield sharper achievability bounds for state merging,
splitting, and communication over quantum channels, while highlighting
the central role of the collision relative entropy in quantum
information.</p>
"
S2,SC0014,3,Chi-Kwong,Li,Chi-Kwong Li,2025-06-23 14:00:00,MS8,Tensor and quantum information science,Monday,15:00,15:30,102,8,"Quantum tomography: theory and practice
","<p>We study some basic theoretical and implementation issues of quantum
state tomography problems. Under the assumption that one can do
measurements of many identical copies of a quantum state <span
class=""math inline""><em>ρ</em></span> represented as an <span
class=""math inline""><em>N</em> × <em>N</em></span> density matrix, we
show that one can determine (estimate) <span
class=""math inline""><em>ρ</em></span> using the measurements with
respect to <span class=""math inline""><em>N</em> + 1</span> different
bases, i.e,, the quantum state can be determined diagonal entries of
<span
class=""math inline""><em>U</em><sub><em>j</em></sub><em>ρ</em><em>U</em><sub><em>j</em></sub><sup>†</sup></span>,
where <span class=""math inline""><em>U</em><sub><em>j</em></sub></span>
is a unitary matrix for <span
class=""math inline""><em>j</em> = 0, …, <em>N</em></span>. When <span
class=""math inline""><em>N</em> = 2<sup><em>n</em></sup></span>, one may
choose unitary <span
class=""math inline""><em>U</em><sub>0</sub>, …, <em>U</em><sub><em>N</em></sub></span>
corresponding to a collection of mutually unbiased bases. We show that
the recovery of the quantum state using such measurements will involve
the solving an ill-conditioned linear system. For a more stable scheme
in terms of measurements and determination of the quantum state from the
measurement values, we show that one may also use the measurements of
<span
class=""math inline""><em>V</em><sub><em>j</em></sub><em>ρ</em><em>V</em><sub><em>j</em></sub><sup>†</sup></span>
to determine the quantum state for <span
class=""math inline""><em>j</em> = 1, …, 3<sup><em>n</em></sup></span>,
where each <span
class=""math inline""><em>V</em><sub><em>j</em></sub></span> corresponds
to a local measurement operator, i.e., <span
class=""math inline""><em>V</em><sub><em>j</em></sub></span> is a tensor
product of <span class=""math inline"">2 × 2</span> unitary matrices. It
is proved that <span class=""math inline"">3<sup><em>n</em></sup></span>
is the minimum number of local measurement bases one can use to
determine an <span class=""math inline""><em>n</em></span>-qubit state.
Moreover, we show that one may determine <span
class=""math inline""><em>ρ</em></span> by a single measurement basis
using an ancilla <span class=""math inline""><em>ρ</em></span> of the same
dimension as <span class=""math inline""><em>ρ</em></span>. In other
words, we can determine <span class=""math inline""><em>ρ</em></span>
using the diagonal entries of <span
class=""math inline""><em>U</em>(<em>σ</em> ⊗ <em>ρ</em>)<em>U</em><sup>†</sup></span>,
where <span class=""math inline""><em>σ</em></span> is an <span
class=""math inline""><em>n</em></span>-qubit pure state. All the above
schemes are demonstrated using the IBM online computers.</p>
"
S2,SC1001,1,Luís,Machado,Luís Machado,2025-06-23 14:00:00,MS10,Matrix means and related topics,Monday,14:00,14:30,102,10,Spherical triangular configurations with invariant geometric mean,"<p>The goal is to characterize all configurations of three distinct
points on a finite-dimensional Riemannian manifold that share the same
geometric mean and to develop efficient computation methods to obtain
such configurations. The geometric mean typically minimizes the sum of
squared geodesic distances to the data points. This approach has been
applied to various manifolds, such as the <span
class=""math inline""><em>n</em></span>-sphere <span
class=""math inline""><em>S</em><sup><em>n</em></sup></span>, the
orthogonal group, hyperbolic space, and the cone of positive symmetric
matrices.<br />
To keep the scope manageable, we focus on the standard sphere <span
class=""math inline""><em>S</em><sup>2</sup></span> in <span
class=""math inline"">ℝ<sup>3</sup></span> with three points, introducing
new ideas beyond minimizing squared geodesic distances. These ideas also
emerge from known formulas for the mean of points forming regular
geodesic polygons, such as equilateral geodesic triangles. As an initial
step, we apply this approach to Euclidean spaces.<br />
Theoretical results are supported by numerical experiments and
illustrated with meaningful plots.<br />
<br />
</p>
"
S2,SC1001,2,Vatsalkumar,Mer,Vatsalkumar Mer,2025-06-23 14:00:00,MS10,Matrix means and related topics,Monday,14:30,15:00,102,10,,
S2,SC1001,3,Anmary,Tonny,Anmary Tonny,2025-06-23 14:00:00,MS10,Matrix means and related topics,Monday,15:00,15:30,102,10,Results on the symplectic spectrum of some special classes of operators,"<p>Williamson’s Normal form for <span
class=""math inline"">2<em>n</em> × 2<em>n</em></span> real positive
matrices is a symplectic analogue of the spectral theorem for normal
matrices. With the recent developments in quantum information theory,
Williamson’s normal form has opened up an active research area that may
be dubbed as “finite dimensional symplectic spectral theory”, analogous
to the usual spectral theory and matrix analysis. An infinite
dimensional analogue of the Williamson’s Normal form has appeared
recently and has already become a corner stone for the theory of
infinite mode quantum Gaussian states. However, most existing results
pertain to finite-dimensional operators, leaving a dearth of literature
in the infinite-dimensional context. The aim of this talk is to discuss
some recent results in this direction. Specifically, we discuss the
recently proved inequality between the eigenvalues and symplectic
eigenvalues for positive invertible operators <span
class=""math inline""><em>T</em></span> on <span
class=""math inline"">ℋ ⊕ ℋ</span> (where <span
class=""math inline"">ℋ</span> is a real separable Hilbert space) such
that <span class=""math inline""><em>T</em> − <em>α</em><em>I</em></span>
is compact for some <span class=""math inline""><em>α</em> &gt; 0</span>
and see its applications on the Gaussian covariance operators and
positive Absolutely Norm attaining operators (<span
class=""math inline"">(𝒜𝒩)<sub>+</sub></span> operators). We also show
that the symplectic spectrum lies within the bounds of the spectrum for
operators on specific classes. Additionally, we provide a method to
recover the symplectic spectrum of Gaussian covariance operators through
truncation.</p>
"
S2,SC1003,1,Aaron,Welters,Aaron Welters,2025-06-23 14:00:00,MS26,"Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics",Monday,14:00,14:30,102,26,"Structural constraints on response matrices of passive electrical networks
","<p>In this talk, we discuss the problem of realizing a passive
electrical network (circuit) with a given response matrix. We begin by
considering resistor-only networks and present the well-known solution
using a star network with one interior node. Then, we introduce the
long-standing open problem associated with two-element-kind networks
(e.g., RC, RL, or LC networks). Next, we present a theorem that provides
necessary conditions for a matrix to be a response matrix viewed as both
a structured matrix and as a rational multivariate matrix function of
the network parameters. Finally, we conclude with some additional open
problems and highlight our recent work on these problems. This talk is
based on joint work with Fernando Guevara Vasquez (Univ. of Utah) and
Graeme W. Milton (Univ. of Utah).</p>
"
S2,SC1003,2,Hansaka,Aluvihare,Hansaka Aluvihare,2025-06-23 14:00:00,MS26,"Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics",Monday,14:30,15:00,102,26,"A low-complexity LSTM network to realize multibeam beamforming
","<p>Even large amounts of data can be efficiently realized by imposing
structures into neural networks through structured weight matrices.
These structured weight matrices could be trained to realize phase
shifts for specific beams in multi-beam beamforming, along with input
and output vectors made up of time-domain signals. In our previous
research, we showed that wideband multi-beam beamformers using
true-time-delays (TTDs) can be represented by delay Vandermonde matrices
(DVM). We use a frequency-domain transformation to explicitly express
the TTD-based time delay data in terms of the elements of the
DVM-structured weight matrices. Building upon these weight matrices, we
introduce a novel low-complexity neural network LSTM architecture for
realizing wideband multi-beam beamformers. The proposed structured LSTM
network reduces the computational complexity for realizing wideband
multi-beam beamformers from <span
class=""math inline"">𝒪(<em>N</em><sup>2</sup><em>L</em>)</span> to <span
class=""math inline"">𝒪(<em>N</em><sup><em>s</em></sup><em>L</em>)</span>,
where <span class=""math inline"">1 &lt; <em>s</em> &lt; 2</span> and
<span class=""math inline""><em>L</em></span> is the number of layers.</p>
"
S2,SC1003,3,Natalia,Bebiano,Natalia Bebiano,2025-06-23 14:00:00,MS26,"Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics",Monday,15:00,15:30,102,26,"Revisiting an Inverse Problem Proposed by Boor and Golub
","<p>Let <span
class=""math inline""><em>H</em> = <em>d</em><em>i</em><em>a</em><em>g</em>(<em>δ</em><sub>1</sub>, <em>δ</em><sub>2</sub>, ⋯, <em>δ</em><sub><em>n</em></sub>)</span>
be a signature matrix, where <span
class=""math inline""><em>δ</em><sub><em>k</em></sub> ∈ {−1, +1}</span>.
Consider <span
class=""math inline""><em>R</em><sub><em>n</em></sub></span> endowed with
the indefinite inner product <span
class=""math inline""> &lt; <em>x</em>, <em>y</em> &gt; <em>H</em> :=  &lt; <em>H</em><em>x</em>, <em>y</em> &gt;  = <em>y</em><sup><em>T</em></sup><em>H</em><em>x</em></span>
for all <span
class=""math inline""><em>x</em>, <em>y</em> ∈ <em>R</em><sub><em>n</em></sub></span>.
A pseudo-Jacobi matrix of order <span
class=""math inline""><em>n</em></span> is a real tridiagonal symmetric
matrix with respect to this indefinite inner product. In this paper, the
reconstruction of a pair of <span
class=""math inline""><em>n</em></span>-by-<span
class=""math inline""><em>n</em></span> pseudo-Jacobi matrices, one
obtained from the other by a rank-one modification, is investigated
given their prescribed spectra. Necessary and sufficient conditions
under which this problem has a solution are presented. As a special case
of the obtained results, a related problem for Jacobi matrices proposed
by de Boor and Golub is completely solved.</p>
<p>This is a joint work with Wei-Ru Xu and Qian-Yu Shu.</p>
"
S2,SC1005,1,Michael,Tait,Michael Tait,2025-06-23 14:00:00,MS15,Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham,Monday,14:00,14:30,102,15,Expansion and the normalized distance Laplacian matrix,"<p>The normalized distance Laplacian of a graph <span
class=""math inline""><em>G</em></span> is defined as <span
class=""math inline"">𝒟<sup>ℒ</sup>(<em>G</em>) = <em>T</em>(<em>G</em>)<sup>−1/2</sup>(<em>T</em>(<em>G</em>) − 𝒟(<em>G</em>))<em>T</em>(<em>G</em>)<sup>−1/2</sup></span>
where <span class=""math inline"">𝒟(<em>G</em>)</span> is the matrix with
pairwise distances between vertices and <span
class=""math inline""><em>T</em>(<em>G</em>)</span> is the diagonal
transmission matrix. We discuss the spectral gap of this matrix and the
related distance Cheeger constant. Contrary to the classical case, both
of these quantities are bounded away from <span
class=""math inline"">0</span>. We characterize graphs with minimal
distance Cheeger constant and we make a conjecture about graphs with
minimal spectral gap.</p>
<p>This is joint work with John Byrne, Jacob Johnston, and Carl
Schildkraut.</p>
"
S2,SC1005,2,Kristin,Heysse,Kristin Heysse,2025-06-23 14:00:00,MS15,Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham,Monday,14:30,15:00,102,15,Degenerate eigenvalues for the non-backtracking matrix,"<p>The non-backtracking matrix is the transition matrix for a walk in a
graph which cannot traverse an edge twice in immediate succession. The
spectral information of this matrix has seen great interest, notably in
applications of network analysis. The non-symmetric nature of this
matrix allows for graphs without a full basis of eigenvectors, which
results in nontrivial Jordan chains. In this talk, we will consider the
Jordan form of this matrix and construct infinite families of graphs
with nontrivial Jordan chains.</p>
"
S2,SC1005,3,Himanshu,Gupta,Himanshu Gupta,2025-06-23 14:00:00,MS15,Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham,Monday,15:00,15:30,102,15,"On the eigenvalues of the graphs $D(5, q)$","<p>In 1995, Lazebnik and Ustimenko introduced the family of <span
class=""math inline""><em>q</em></span>-regular graphs <span
class=""math inline""><em>D</em>(<em>k</em>, <em>q</em>)</span>, which is
defined for any positive integer <span
class=""math inline""><em>k</em></span> and prime power <span
class=""math inline""><em>q</em></span>. The connected components of the
graph <span
class=""math inline""><em>D</em>(<em>k</em>, <em>q</em>)</span> have
provided the best-known general lower bound on the size of a graph for
any given order and girth to this day. Furthermore, Ustimenko
conjectured that the second largest eigenvalue of <span
class=""math inline""><em>D</em>(<em>k</em>, <em>q</em>)</span> is always
less than or equal to <span class=""math inline"">$2\sqrt{q}$</span>,
indicating that the graphs <span
class=""math inline""><em>D</em>(<em>k</em>, <em>q</em>)</span> are almost
Ramanujan graphs. In this talk, we will discuss some recent progress on
this conjecture. This includes the result that the second largest
eigenvalue of <span class=""math inline""><em>D</em>(5, <em>q</em>)</span>
is less than or equal to <span class=""math inline"">$2\sqrt{q}$</span>
when <span class=""math inline""><em>q</em></span> is an odd prime power.
This is joint work with Vladislav Taranchuk.</p>
"
S2,SC2001,1,Beatrice,Meini,Beatrice Meini,2025-06-23 14:00:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Monday,14:00,14:30,102,5,"A combination of cyclic reduction and shift-and-deflate techniques for solving quadratic matrix equations
","<p>We consider the problem of computing the minimal solvent <span
class=""math inline""><em>G</em></span> of a quadratic matrix equation
<span
class=""math inline""><em>A</em><sub>0</sub> + <em>A</em><sub>1</sub><em>X</em> + <em>A</em><sub>2</sub><em>X</em><sup>2</sup> = 0</span>.
If the eigenvalues of the corresponding quadratic matrix polynomial
<span
class=""math inline""><em>P</em>(<em>z</em>) = <em>A</em><sub>0</sub> + <em>A</em><sub>1</sub><em>z</em> + <em>A</em><sub>2</sub><em>z</em><sup>2</sup></span>
have a splitting with respect to the unit circle, Cyclic Reduction (CR)
algorithm converges quadratically to the sought solution <span
class=""math inline""><em>G</em></span>. In this talk we consider the case
where <span class=""math inline""><em>P</em>(<em>z</em>)</span> has some
eigenvalues on the unit circle, therefore convergence of CR is not
generally guaranteed. More specifically, we propose an algorithm based
on a combination of CR and a shift-and-deflate technique. CR is used to
approximate the eigensapce of <span
class=""math inline""><em>G</em></span> corresponding to the eigenvalues
in the open unit disk, while the eigenspace corresponding to the
eigenvalues on the unit circle is computed by solving a reduced
quadratic matrix equation.</p>
<p>Joint work with Xu Li, Lanzhou University of Technology, China.</p>
"
S2,SC2001,2,Bruno,Iannazzo,Bruno Iannazzo,2025-06-23 14:00:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Monday,14:30,15:00,102,5,"The Lambert $W$, the wright $\omega$ and the unwinding number of matrices
","<p>The matrix equations <span
class=""math inline""><em>W</em><em>e</em><sup><em>W</em></sup> = <em>A</em></span>
or <span
class=""math inline""><em>W</em> + log (<em>W</em>) = <em>A</em></span>
are used to define the matrix Lambert <span
class=""math inline""><em>W</em></span> and Wright <span
class=""math inline""><em>ω</em></span> functions, respectively. We
present results on the existence of Lambert <span
class=""math inline""><em>W</em></span> functions with prescribed
eigenvalues or with real elements and we provide a characterization of
the Wright <span class=""math inline""><em>ω</em></span> of a matrix <span
class=""math inline""><em>A</em></span> as the only primary Lambert <span
class=""math inline""><em>W</em></span> of <span
class=""math inline"">exp (<em>A</em>)</span>, together with links to the
matrix equations. By making use of a novel connection between the matrix
unwinding number and the matrix sign function, we present a method for
evaluating the unwinding number of a real matrix using only real
arithmetic.</p>
"
S2,SC2001,3,Massimiliano,Fasi,Massimiliano Fasi,2025-06-23 14:00:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Monday,15:00,15:30,102,5,Mixed-precision algorithms for the Sylvester matrix equation,"<p>Modern supercomputers achieve their remarkable speeds by leveraging
machine-learning hardware accelerators. These accelerators deliver
extraordinary throughput by trading off some degree of accuracy, and, to
fully utilise their potential, we must rely on low-precision
floating-point formats such as binary16, bfloat16, or binary8. These
reduced-precision formats can have a throughput up to two orders of
magnitude higher than binary64, but they lack the precision needed for
traditional scientific simulations, which require higher accuracy to
yield meaningful results. To integrate GPUs effectively into scientific
computing, we must reimagine high-precision computations by
strategically applying lower precision whenever feasible.</p>
<p>We consider techniques to solve the general Sylvester equation <span
class=""math inline""><em>A</em><em>X</em> + <em>X</em><em>B</em> = <em>C</em></span>
in mixed precision. By revisiting a stationary iteration for linear
systems, we derive a new iterative refinement scheme for the
quasi-triangular Sylvester equation. We then leverage this iterative
scheme to solve the general Sylvester equation in mixed precision. The
new algorithms compute the Schur decomposition of the matrix
coefficients in low precision, use the low-precision Schur factors to
obtain an approximate solution to the quasi-triangular equation, and
iteratively refine it to obtain a working-precision solution to the
quasi-triangular equation. However, being only orthonormal to low
precision, the unitary Schur factors of A and B cannot be used to
recover the solution to the original equation. We propose two effective
approaches to address this issue: one is based on re-orthonormalization
in the working precision, and the other on explicit inversion of the
almost-unitary factors.</p>
<p>This is joint work with Andrii Dmytryshyn, Nicholas J. Higham, and
Xiaobo Liu.</p>
"
S2,SC2006,1,Shu-Yung,Liu,Shu-Yung Liu,2025-06-23 14:00:00,MS22,Linear algebra applications in computational geometry,Monday,14:00,14:30,102,22,Spherical volume-preserving parameterization via energy minimization,"<p>For a simplicial <span class=""math inline"">3</span>-manifold, such as
a tetrahedral mesh sampled from a solid brain, a spherical
volume-preserving parameterization is a bijective mapping onto the unit
solid sphere. In this presentation, we introduce a novel energy
functional to measure the volume distortion of such mappings and propose
an associated minimization method to obtain volume-preserving
parameterizations. Our method is theoretically guaranteed to converge
globally and demonstrates improved effectiveness compared to a
state-of-the-art method. Finally, we present its application in brain
imaging, showcasing its real-world utility.</p>
"
S2,SC2006,2,Mei-Heng,Yueh,Mei-Heng Yueh,2025-06-23 14:00:00,MS22,Linear algebra applications in computational geometry,Monday,14:30,15:00,102,22,Authalic energy minimization for area-preserving mappings,"<p>The authalic energy is a functional specifically designed to measure
area distortion in surface mappings, providing a foundation for the
efficient computation of area-preserving mappings of simplicial
surfaces. Such mappings can serve as parameterizations that define a
unified coordinate system, which simplifies various image and geometry
processing tasks, such as surface registration and blending. In this
talk, I will introduce authalic energy minimization for computing
area-preserving simplicial mappings and demonstrate its practical
utility in geometry processing.</p>
"
S2,SC2006,3,Kristian,Sabo,Kristian Sabo,2025-06-23 14:00:00,MS22,Linear algebra applications in computational geometry,Monday,15:00,15:30,102,22,A method for searching for a globally optimal k-partition of higher-dimensional datasets,"<p>Finding a globally optimal <span
class=""math inline""><em>k</em></span>-partition of a set is a highly
complex optimization problem. In general, except for the special case of
one-dimensional data (i.e., data with a single feature), no exact
solution method exists. In the one-dimensional case, efficient methods
leverage the fact that the problem can be reformulated as a global
optimization task for a symmetric Lipschitz-continuous function, which
can be solved using the global optimization algorithm DIRECT. We propose
a method for finding a globally optimal <span
class=""math inline""><em>k</em></span>-partition in the general case
(<span class=""math inline""><em>n</em></span>-dimensional data, <span
class=""math inline""><em>n</em> &gt; 1</span>), extending an approach
originally designed for solving Lipschitz global optimization for
symmetric functions. Our method integrates a global optimization
algorithm with linear constraints and the <span
class=""math inline""><em>k</em></span>-means algorithm. The global
optimization component is used solely to generate a high-quality initial
approximation for <span class=""math inline""><em>k</em></span>-means. We
evaluated our approach on multiple artificial datasets and several
benchmark examples from the UCI Machine Learning Repository. The results
demonstrate that the proposed method is more efficient compared to some
other methods from the literature.</p>
"
S2,SC3001,1,Tzon-Tzer,Lu,Tzon-Tzer Lu,2025-06-23 14:00:00,MS1,Embracing new opportunities in numerical linear algebra,Monday,14:00,14:30,102,1,Uncertainty principle of condition number,"<p>Schaback, in 1995, proved the Uncertainty Principle of radial basis
function interpolation, which states that the condition number and the
error cannot be kept small simultaneously. Hence, it is a trade-off
principle. It seems to violate our cognition about ill/well-conditioned
problems. In this talk, we would like to extend this principle, i.e.,
there is no case where the error and the condition number are both
small, from interpolation matrices to arbitrary linear systems. The
underlying theory behind the conflict between accuracy and stability
flips our misconceptions about condition numbers and gives us a
brand-new understanding of them.</p>
"
S2,SC3001,2,Matthew M.,Lin,Matthew M. Lin,2025-06-23 14:00:00,MS1,Embracing new opportunities in numerical linear algebra,Monday,14:30,15:00,102,1,"A gradient flow method to differentiate between classical and quantum correlations
","<p>In this talk, we aim to quantify measurement disturbance by
minimizing the distinction between input and post-measurement states,
enabling us to determine whether the correlations are classical or
quantum. Theoretically, we employ a complex-valued gradient flow over
Stiefel manifolds for optimization. Our approach applies the well-known
Lojasiewicz gradient inequality, guaranteeing the global convergence of
the flow from any initial point. Experimental results demonstrate that
our method can accurately and reliably classify correlations as
classical or quantum.</p>
"
S2,SC3001,3,Li-Gang,Lin,Li-Gang Lin,2025-06-23 14:00:00,MS1,Embracing new opportunities in numerical linear algebra,Monday,15:00,15:30,102,1,Fast SDDRE-based maneuvering-target interception at prespecified orientation,"<p>This talk considers the 3-D guidance law based on target lead angle
information and the state-dependent differential Riccati equation
(SDDRE) scheme. In an application-oriented manner, it presents theories
to significantly improve critical computational performance and thus
aims at a fast implementation for impact-angle-constrained interception
of agile maneuvering targets. More specifically, regarding the two major
computational burdens using SDDRE, we have replaced the burden in
numerical applicability checking by a simple, equivalent, and
closed-form condition for the entire state space, which is actually the
dominant burden as supported by complexity analysis and extensive
validations. Notably, the proposed analysis not only complements the
early findings of applicability guarantee in literature, but also
promotes the efficiency of the proposed philosophy when compared to the
classic method, where the latter has caused concerns/reservations due to
its feasibility and difficulty. On the other hand, we have largely
mitigated the second major burden of SDDRE by – after exhaustive trials
– selecting the most efficient Riccati-equation solver until the latest
benchmarks. Such evaluations are: 1) in favor of a much-less-known
achievement, rather than the common QR-based benchmark and 2) subject to
both numerical and hardware experiments including, notably,
implementations on microcontrollers and field-programmable gate
arrays.</p>
"
S2,SC4011,1,Guangliang,Chen,Guangliang Chen,2025-06-23 14:00:00,MS20,Manifold learning and statistical applications,Monday,14:00,14:30,102,20,"On parameter tuning for spectral clustering: two simple, fast, and effective criteria","<p>Spectral clustering is a modern, powerful clustering approach with
many successful applications. However, it has faced two major challenges
– high computational complexity and parameter tuning. Since its
introduction, much effort has been devoted to improving the scalability
of spectral clustering, while little research has been conducted on
parameter tuning. In this talk, we address the parameter tuning
challenge of spectral clustering in a general context. Specifically, we
propose two new criteria for tuning the scale parameter used in
similarity functions such as Gaussian and cosine. Experiments
demonstrate the effectiveness of these tuning techniques.</p>
"
S2,SC4011,2,Szu-Han,Lin,Szu-Han Lin,2025-06-23 14:00:00,MS20,Manifold learning and statistical applications,Monday,14:30,15:00,102,20,Distributed $t$-SNE,"<p>The <span class=""math inline""><em>t</em></span>-distributed
stochastic neighbor embedding method (<span
class=""math inline""><em>t</em></span>-SNE, Maaten and Hinton, 2008) has
gained popularity for data exploration, particularly for its highly
effective visualization of high-dimensional data, offering valuable
insights before analysis. However, with a computational complexity of
<span class=""math inline""><em>O</em>(<em>n</em><sup>2</sup>)</span>, its
applicability to large datasets is limited. In practical applications,
the Barnes-Hut <span class=""math inline""><em>t</em></span>-SNE (BH <span
class=""math inline""><em>t</em></span>-SNE, Maaten, 2014), a <span
class=""math inline""><em>t</em></span>-SNE variant with computational
complexity <span
class=""math inline""><em>O</em>(<em>n</em>log <em>n</em>)</span>, is
commonly employed for large datasets due to its high computational
efficiency. In this work, we propose a divide-and-conquer approach that
further reduces the computational complexity to <span
class=""math inline""><em>O</em>(<em>n</em>)</span>, significantly
lowering both computational time and memory usage by processing only
subsets of the data at a time. Implementing the divide-and-conquer
approach requires careful parameter adjustments to ensure asymptotic
equivalence to the original <span
class=""math inline""><em>t</em></span>-SNE. We provide theoretical proof
of this convergence and support our findings with simulation studies on
the MNIST dataset. In summary, this work offers a scalable solution for
applying <span class=""math inline""><em>t</em></span>-SNE to extremely
large datasets, maintaining its consistency and efficiency.</p>
"
S2,SC4011,3,ShengLi,Tzeng,ShengLi Tzeng,2025-06-23 14:00:00,MS20,Manifold learning and statistical applications,Monday,15:00,15:30,102,20,Integrating covariates in learning spatio-temporal patterns,"<p>We consider a dimension reduction approach for spatio-temporal data
analysis of the primary measurements (i.e., the main phenomenon being
studied) while integrating covariates of interest. Unlike traditional
principal component analysis (PCA), our method not only identifies
similarities and distinctions among data points but also investigates
how these relationships are associated with covariates across both
spatial and temporal domains.</p>
<p>We develop data-driven functions that uncover spatial patterns and
temporal trends, while also revealing connections between covariates and
the underlying data structure. Furthermore, we introduce visualization
techniques to illustrate the relationships between extracted geometric
features, covariates, and the spatial and temporal patterns of the
primary measurements. This approach offers a more comprehensive
understanding of the factors driving data similarities and
discrepancies.</p>
<p>The key innovation of our method, in contrast to traditional PCA,
lies in its ability to reveal how these functions relate to covariates,
providing deeper insights into the underlying characteristics of the
data by examining how covariates interact with spatial and temporal
patterns in the primary measurements.</p>
"
S3,SC0008,1,Sweta,Das,Sweta Das,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,Canonical form for pairs of matrices associated with linear-time invariant dissipative Hamiltonian descriptor systems,"<p>We study pairs of complex matrices associated with Linear-Time
Invariant (LTI) dissipative Hamiltonian descriptor systems. These
systems appear in energy-based modeling of dynamical systems and are a
special case of port-Hamiltonian (pH) descriptor systems. We derive the
canonical forms for a pair of <span
class=""math inline""><em>n</em> × <em>n</em></span> complex matrices
<span class=""math inline"">(<em>E</em>, <em>Q</em>)</span> under
transformations <span
class=""math inline"">(<em>E</em>, <em>Q</em>) → (<em>U</em><em>E</em><em>V</em>, <em>U</em><sup>−<em>T</em></sup><em>Q</em><em>V</em>)</span>,
and <span
class=""math inline"">(<em>E</em>, <em>Q</em>) → (<em>U</em><em>E</em><em>V</em>, <em>U</em><sup>−*</sup><em>Q</em><em>V</em>)</span>,
where <span class=""math inline""><em>U</em></span> and <span
class=""math inline""><em>V</em></span> are non-singular complex matrices.
We also consider the special cases of <span
class=""math inline""><em>E</em><sup><em>T</em></sup><em>Q</em></span> and
<span class=""math inline""><em>E</em><sup>*</sup><em>Q</em></span> being
(skew-)symmetric and (skew-)Hermitian, respectively. This is a joint
work with Andrii Dmytryshyn and Volker Mehrmann.</p>
"
S3,SC0008,2,Roksana,Słowik,Roksana Słowik,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,Products of infinite upper triangular matrices that satisfy fixed polynomial equation,"<p>There is plenty of results concerning representation elements of an
algebraic structure, mainly a group, as products of elements possessing
some particular properties. In the matrix groups one of the most famous
one is being an involution. The famous theorem states that every square
matrix with determinant <span class=""math inline"">±1</span> defined over
a field is a product of at most four involutions. Simply by their
definition, the involutions satisfy equation <span
class=""math inline""><em>x</em><sup>2</sup> − 1 = 0</span>, i.e. a
quadratic equation. Hence, it is natural to raise a question does a
similar result hold for matrices that satisfy some other fixed quadratic
equation.</p>
<p>Consider a field <span class=""math inline""><em>F</em></span> and an
algebra <span class=""math inline"">𝒜</span> defined over <span
class=""math inline""><em>F</em></span>. Define polynomial <span
class=""math inline""><em>q</em></span> by the formula <span
class=""math inline""><em>q</em>(<em>x</em>) = <em>a</em><sub>2</sub><em>x</em><sup>2</sup> + <em>a</em><sub>1</sub><em>x</em> + <em>a</em><sub>0</sub></span>,
where <span class=""math inline""><em>a</em><sub>2</sub> ≠ 0</span>. If
element <span class=""math inline""><em>a</em> ∈ 𝒜</span> satisfies <span
class=""math inline""><em>q</em>(<em>a</em>) = 0</span>, then we say that
<span class=""math inline""><em>a</em></span> is quadratic with respect to
<span class=""math inline""><em>q</em>(<em>x</em>)</span>, or shortly that
<span class=""math inline""><em>a</em></span> is <span
class=""math inline""><em>q</em>(<em>x</em>)</span>-quadratic. Recently,
Bien et al. <span class=""citation"" data-cites=""bi_ta_tr_tr""></span>
proved that every <span class=""math inline"">ℕ × ℕ</span> upper
triangular matrix whose diagonal entries are of the form <span
class=""math inline""><em>λ</em><sub>1</sub><sup><em>s</em><sub><em>i</em></sub></sup><em>λ</em><sub>2</sub><sup><em>t</em><sub><em>i</em></sub></sup></span>,
where <span
class=""math inline""><em>s</em><sub><em>i</em></sub> + <em>t</em><sub><em>i</em></sub> = <em>k</em></span>
for every <span class=""math inline""><em>i</em> ∈ ℕ</span>, <span
class=""math inline""><em>λ</em><sub>1</sub></span>, <span
class=""math inline""><em>λ</em><sub>2</sub> ≠ 0</span>, can be expressed
as a product of at most <span class=""math inline""><em>k</em></span>
quadratic matrices with respect to <span
class=""math inline""><em>q</em><sub><em>λ</em><sub>1</sub>, <em>λ</em><sub>2</sub></sub>(<em>x</em>) = (<em>x</em> − <em>λ</em><sub>1</sub>)(<em>x</em> − <em>λ</em><sub>2</sub>)</span>.
This result brings up further questions. Does the same claim holds when
<span
class=""math inline""><em>λ</em><sub>1</sub><em>λ</em><sub>2</sub> = 0</span>?
Does it also hold when we replace the quadratic polynomial by a
polynomial of degree <span class=""math inline""><em>n</em></span> (<span
class=""math inline""> ≱ 3</span>)? During this talk we are going to
discuss these issues.</p>
<div class=""thebibliography"">
<p><span>66</span> M.H. Bien, V.M. Tam, D.C.M. Tri, L.Q. Truong,
Products of infinite upper triangular matrices, Linear Algebra Appl. 699
(2024), 59-71. L.Q. Truong, R. S<span>ł</span>owik, Products of infinite
upper triangular matrices that satisfy fixed polynomial equation, in
preparation.</p>
</div>
"
S3,SC0008,3,Chih-Sheng,Chuang,Chih-Sheng Chuang,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,Algorithms and inertial algorithms for the inverse mixed variational inequality problems in Hilbert spaces,"<p>The inverse mixed variational inequality problem comes from the
classical variational inequality, and it has many applications. In this
paper, we propose new algorithms to study the inverse mixed variational
inequality problems in Hilbert spaces, and these algorithms based on the
generalized projection operator. Next, we establish convergence theorems
under inverse strongly monotonicity conditions. Besides, we also give
inertial-type algorithms for the inverse mixed variational inequality
problems, and the conditions are different from the above convergence
theorems.</p>
"
S3,SC0008,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S3,SC0009,1,Yotsanan,Meemark,Yotsanan Meemark,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,Spectral properties and perfect state transfer in unitary $(t-1)$-matching $t$-Cayley graphs,"<p>We introduce a new family of Cayley graphs arising from a collection
of subsets of a finite group. It is a generalization of a Cayley graph
and a bi-Cayley graphs, so we call it a <span
class=""math inline""><em>t</em></span>-Cayley graph. Let <span
class=""math inline"">ℛ</span> be direct products of finite matrix rings.
We work on unitary <span
class=""math inline"">(<em>t</em> − 1)</span>-matching <span
class=""math inline""><em>t</em></span>-Cayley graph of <span
class=""math inline"">ℛ</span> and its complement graph. We show that the
graphs are hyperenergetic and obtain a criterion on <span
class=""math inline""><em>t</em></span> and the rings <span
class=""math inline"">ℛ</span> for each graph being a Ramanujan graph.
Moreover, we show that the unitary <span
class=""math inline"">(<em>t</em> − 1)</span>-matching <span
class=""math inline""><em>t</em></span>-Cayley graph of <span
class=""math inline"">ℛ</span> is always periodic and also characterize
<span class=""math inline""><em>t</em></span> and the rings <span
class=""math inline"">ℛ</span> such that its corresponding unitary <span
class=""math inline"">(<em>t</em> − 1)</span>-matching <span
class=""math inline""><em>t</em></span>-Cayley graph has perfect state
transfer between vertices.</p>
"
S3,SC0009,2,Koushik,Bhakta,Koushik Bhakta,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,Grover walks on unitary Cayley graphs and integral regular graphs,"<p>Quantum walk on graphs is an important concept that lies at the
intersection of quantum information and graph theory. There are two
types of quantum walk: continuous-time quantum walk and discrete-time
quantum walk. We focus on the Grover walk, a type of discrete-time
quantum walk. The unitary Cayley graph has vertex set <span
class=""math inline"">{0, 1, …, <em>n</em> − 1}</span>, where two vertices
<span class=""math inline""><em>u</em></span> and <span
class=""math inline""><em>v</em></span> are adjacent if <span
class=""math inline"">gcd (<em>u</em> − <em>v</em>, <em>n</em>) = 1</span>.
We study periodicity and perfect state transfer of Grover walks on the
unitary Cayley graphs. We characterize all periodic unitary Cayley
graphs. We prove that periodicity is a necessary condition for the
occurrence of perfect state transfer on a vertex-transitive graph. Also,
we provide a necessary and sufficient condition for the occurrence of
perfect state transfer on circulant graphs. Using these, we prove that
only four graphs in the class of unitary Cayley graphs exhibit perfect
state transfer. Also, we provide a spectral characterization of the
periodicity of Grover walks on integral regular graphs.</p>
"
S3,SC0009,3,Pragati Asutosh,Jena,Pragati Asutosh Jena,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,Brouwer's conjecture for the corona and edge corona of graphs,"<p>Let <span class=""math inline""><em>G</em></span> be a connected graph
on <span class=""math inline""><em>n</em></span> vertices. Let <span
class=""math inline""><em>S</em><sub><em>k</em></sub>(<em>G</em>)</span>
denote the sum of <span class=""math inline""><em>k</em></span> largest
Laplacian eigenvalues of <span class=""math inline""><em>G</em></span> and
<span class=""math inline""><em>e</em>(<em>G</em>)</span> denote the
number of edges in <span class=""math inline""><em>G</em></span>. Brouwer
conjectured that <span class=""math inline"">$S_k(G)\leq
e(G)+\binom{k+1}{2}$</span> for any <span
class=""math inline""><em>k</em> ∈ {1, …, <em>n</em>}</span>. Let <span
class=""math inline""><em>H</em></span> be a connected graph on <span
class=""math inline""><em>m</em> ≥ 2</span> vertices. Here, we show that
if <span class=""math inline""><em>G</em></span> and <span
class=""math inline""><em>H</em></span> satisfy the Brouwer’s conjecture,
then the corona of <span class=""math inline""><em>G</em></span> and <span
class=""math inline""><em>H</em></span> also satisfies the Brouwer’s
conjecture. Furthermore, when <span
class=""math inline""><em>G</em></span> is regular, <span
class=""math inline""><em>n</em> ≥ 4</span>, <span
class=""math inline""><em>m</em> ≥ 3</span> and <span
class=""math inline""><em>e</em>(<em>H</em>) ≥ <em>m</em> + 1</span>, we
prove that if <span class=""math inline""><em>H</em></span> satisfies the
Brouwer’s conjecture, then the edge corona of <span
class=""math inline""><em>G</em></span> and <span
class=""math inline""><em>H</em></span> also satisfies the Brouwer’s
conjecture. This talk is based on joint work with Sasmita Barik.</p>
"
S3,SC0009,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S3,SC0012,1,Divyadevi,T,Divyadevi T,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,Characterizations and interlacing property of Euclidean distance matrices,"<p>Motivated by the inverse formula of the distance matrix of a tree and
the Moore-Penrose inverse of a circum-Euclidean distance matrix (CEDM),
in this talk, we study a general real square matrix <span
class=""math inline""><em>M</em></span> whose Moore-Penrose inverse can be
expressed as the sum of a Laplacian-like matrix <span
class=""math inline""><em>L</em></span> and a rank one matrix. In
particular, for a symmetric hollow matrix <span
class=""math inline""><em>M</em></span>, under an assumption, we show that
<span class=""math inline""><em>M</em></span> is a Euclidean distance
matrix if and only if <span class=""math inline""><em>L</em></span> is
positive semidefinite. Based on this, we obtain a new characterization
for CEDMs involving their Moore-Penrose inverses. As an application, we
show that the distance matrices of block graphs and odd-cycle-clique
graphs are CEDMs. Finally, we establish an interlacing property between
the eigenvalues of a Euclidean distance matrix <span
class=""math inline""><em>M</em></span> (including the singular case) and
its associated Laplacian-like matrix <span
class=""math inline""><em>L</em></span>, which generalizes the interlacing
property proved for the distance matrices of trees.</p>
"
S3,SC0012,2,Kadali,Kranthi Priya,Kadali Kranthi Priya,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,Singular matrices possessing the triangle property - II,"<p>It is known that an invertible real square matrix has the triangle
property, if and only if the inverse is a tridiagonal matrix. This
result has an implicit importance due to the fact that nonsingular
tridiagonal matrices arise in a variety of problems in pure and applied
mathematics and for this reason they have been extensively studied in
the literature. However, the singular case has received comparatively
much lesser attention. In particular, there has been little focus on the
generalized inverses of such matrices. In this paper, we provide a
complete description of those singular matrices possessing the triangle
property to have tridiagonal Moore-Penrose inverse or group inverse.</p>
"
S3,SC0012,3,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,,
S3,SC0012,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S3,SC0014,1,Sophia,Keip,Sophia Keip,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,QCLAB: A MATLAB toolbox for quantum numerical linear algebra,"<p>Quantum numerical linear algebra is about solving numerical linear
algebra problems on quantum computers - a field that has seen exciting
and significant progress in the past few years. Rapid advancements in
quantum hardware continue to drive this momentum forward and highlight
the fast-paced progress of the field. To facilitate quantum algorithm
research, especially as quantum hardware is still maturing, access to
robust computational tools is crucial. We introduce QCLAB (<a
href=""https://github.com/QuantumComputingLab/qclab""
class=""uri"">https://github.com/QuantumComputingLab/qclab</a>), an
object-oriented MATLAB toolbox for creating, representing and simulating
quantum circuits. What sets QCLAB apart is its emphasis on numerical
linear algebra, prioritizing numerical stability, efficiency and
performance, as well as its seamless integration with MATLAB. In this
talk, featuring a MATLAB tutorial on QCLAB, we will showcase the key
features of QCLAB while providing concrete insights into quantum
numerical linear algebra through three landmark quantum algorithms: the
Quantum Fourier Transform (QFT), Quantum Phase Estimation (QPE), and
Quantum Singular Value Estimation (QSVE). This hands-on introduction is
intended to encourage the audience to engage actively with this
promising research area. With both beginners and experts in mind, the
talk is designed for researchers looking for an accessible entry point
into quantum computing and experienced practitioners seeking a tool for
rapid prototyping of quantum algorithms.</p>
<p><em>This is joint work with Daan Camps and Roel Van Beeumen</em></p>
"
S3,SC0014,2,Hareshkumar,Jadav,Hareshkumar Jadav,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,Generalizing Wilf's inequality for strongly regular graphs,"<p>The clique number <span class=""math inline""><em>ω</em></span> is the
size of the largest clique in any graph. Determining the clique number
is an NP-complete problem, which implies that there is no
polynomial-time algorithm to solve it. Wilf’s inequality provides a
spectral bound for the clique number of simple graphs, given by <span
class=""math inline"">$\frac{n}{n - \lambda_{1}} \leq \omega$</span>,
where <span class=""math inline""><em>λ</em><sub>1</sub></span> is the
largest eigenvalue of the adjacency matrix, and <span
class=""math inline""><em>n</em></span> is the number of vertices in the
graph. Strengthening this bound, Elphick and Wocjan proposed a
conjecture in 2018 that is <span class=""math inline"">$\frac{n}{n -
\sqrt{s^{+}}} \leq \omega$</span>, where <span
class=""math inline""><em>s</em><sup>+</sup> = ∑<sub><em>λ</em><sub><em>i</em></sub> &gt; 0</sub><em>λ</em><sub><em>i</em></sub><sup>2</sup></span>
and <span class=""math inline""><em>λ</em><sub><em>i</em></sub></span> are
eigenvalues of the adjacency matrix. In this work, we have settled this
conjecture for seven different classes of graphs: (1) Paley graphs which
are strongly regular graphs with parameters <span
class=""math inline""><em>s</em><em>r</em><em>g</em>(4<em>β</em> + 1, 2<em>β</em>, <em>β</em> − 1, <em>β</em>)</span>,
where <span class=""math inline""><em>q</em></span> is a prime power and
<span class=""math inline""><em>q</em> ≡ 1 (mod  4)</span>; (2) strongly
regular graphs with <span
class=""math inline""><em>α</em> = <em>β</em></span> (i.e., <span
class=""math inline""><em>s</em><em>r</em><em>g</em>(<em>n</em>, <em>d</em>, <em>β</em>, <em>β</em>)</span>);
(3) the line graph of <span
class=""math inline""><em>K</em><sub><em>m</em>, <em>m</em></sub></span>;
(4) the line graph of <span
class=""math inline""><em>K</em><sub><em>n</em></sub></span>; (5) the
Cartesian product of strongly regular graphs <span
class=""math inline""><em>G</em></span> with <span
class=""math inline""><em>G</em></span>, where <span
class=""math inline""><em>G</em></span> is a strongly regular graph; (6)
general Rook’s graphs; and (7) Ramanujan graphs, where the second
largest eigenvalue follows the property <span
class=""math inline"">$\lambda_2 \leq 2\sqrt{d-1}$</span>.</p>
"
S3,SC0014,3,Amrita,Mandal,Amrita Mandal,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,On order $5$ trace zero doubly stochastic matrices and the corresponding eigenvalue region,"<p>A non-negative square matrix is called a doubly stochastic (DS)
matrix if all its row and column sums are exactly equal to <span
class=""math inline"">1.</span> A vast literature is known for such
matrices concerning the eigenvalue region, inverse eigenvalue problem or
entry-wise distribution of the non-negative numbers when matrix size or
order of the matrix is restricted up to <span
class=""math inline"">4,</span> whereas only a little is known for
matrices of order <span class=""math inline"">5</span> or more except for
some sets of doubly structured matrices.</p>
<p>This talk concerns the following questions: What are those trace zero
order <span class=""math inline"">5</span> DS matrices whose <span
class=""math inline""><em>k</em></span>-times multiplications are also
trace zero matrices for some values of <span
class=""math inline""><em>k</em>?</span> What is the eigenvalue region of
the set of trace zero order <span class=""math inline"">5</span> DS
matrices?</p>
<p>We address these questions by proposing a graph theoretic approach to
determine the trace of the product of two permutation matrices through a
weighted digraph representation for a pair of permutation matrices.
Then, we derive the DS matrices of order <span
class=""math inline"">5</span> whose <span
class=""math inline""><em>k</em></span>-th power is also a trace-zero DS
matrix for <span class=""math inline""><em>k</em> ∈ {2, 3, 4, 5}</span>.
Then, we determine necessary conditions for the coefficients of a
generic polynomial of degree <span class=""math inline"">5</span> to be
realizable as the characteristic polynomial of a trace-zero DS matrix of
order <span class=""math inline"">5</span>. Using this, we approximate the
eigenvalue region of trace-zero DS matrices of order <span
class=""math inline"">5.</span></p>
"
S3,SC0014,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S3,SC1001,1,Aditi,Howlader,Aditi Howlader,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,The full P-vertex problem for unicyclic graphs,"<p>Let <span
class=""math inline""><em>A</em> = [<em>a</em><sub><em>i</em><em>j</em></sub>] ∈ ℝ<sup><em>n</em> × <em>n</em></sup></span>
be a real symmetric and nonsingular matrix and <span
class=""math inline""><em>G</em></span> be the underlying graph with the
vertex set <span
class=""math inline"">{<em>v</em><sub>1</sub>, …, <em>v</em><sub><em>n</em></sub>}</span>
and the edge set <span
class=""math inline"">{(<em>v</em><sub><em>i</em></sub>, <em>v</em><sub><em>j</em></sub>): <em>a</em><sub><em>i</em><em>j</em></sub> ≠ 0, <em>i</em> ≠ <em>j</em>}</span>.
Let <span class=""math inline""><em>A</em>(<em>i</em>)</span> be the
principal submatrix obtained by removing the <span
class=""math inline""><em>i</em><sup>th</sup></span> row and the <span
class=""math inline""><em>i</em><sup>th</sup></span> column of <span
class=""math inline""><em>A</em></span>. If the nullity of <span
class=""math inline""><em>A</em>(<em>i</em>)</span> is unity, then the
vertex <span class=""math inline""><em>v</em><sub><em>i</em></sub></span>
is called a P-vertex of the matrix <span
class=""math inline""><em>A</em></span>. The full P-vertex problem is to
determine if there is a nonsingular matrix <span
class=""math inline""><em>A</em></span> such that each vertex of the
corresponding graph <span class=""math inline""><em>G</em></span>, is a
P-vertex of <span class=""math inline""><em>A</em></span>. In this
article, we investigate the full P-vertex problem for unicyclic
graphs.</p>
"
S3,SC1001,2,Kshitij,Sharma,Kshitij Sharma,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,Combinatorial description of the inverse of the adjacency matrix of non-bipartite bicyclic graphs,"<p>Barik et al. [On nonsingular trees and a reciprocal eigenvalue
property, Linear Multilinear Algebra, 54(6)(2006) 453-465] provided a
combinatorial description of the inverse of the adjacency matrix for
bipartite graphs in terms of <span
class=""math inline""><em>m</em><em>m</em></span>-alternating paths,
enabling deeper exploration of bipartite graph properties. However, for
non-bipartite graphs, a similar framework remained an open challenge. In
2022, a combinatorial description was established for non-bipartite
unicyclic graphs. This paper advances the understanding of non-bipartite
graphs by providing a comprehensive combinatorial description of the
inverse of the adjacency matrix for non-bipartite bicyclic graphs,
utilizing <span
class=""math inline""><em>m</em><em>m</em></span>-alternating paths
between vertices. It further determines the conditions under which the
adjacency matrix of a bicyclic graph is unimodular and establishes
criteria for the adjacency matrix of a non-bipartite graph to be
signable. Additionally, it is definitively shown that the inverse graph
of a non-bipartite bicyclic graph remains non-bipartite, reinforcing the
structural properties of such graphs.</p>
"
S3,SC1001,3,Bharat Pratap,Chauhan,Bharat Pratap Chauhan,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,Almost (Strictly) semimonotone matrices,"<p>An almost (strictly) semimonotone matrix <span
class=""math inline""><em>A</em></span> is a real square matrix that is
not (strictly) semimonotone but whose proper principal submatrices are
(strictly) semimonotone. Furthermore, a real square matrix <span
class=""math inline""><em>A</em></span> is a semimonotone matrix if the
operation <span class=""math inline""><em>A</em><em>x</em></span> does not
negate all positive entries of any nonzero, entrywise nonnegative real
vector <span class=""math inline""><em>x</em></span>. Similarly, a real
square matrix <span class=""math inline""><em>A</em></span> is a strictly
semimonotone matrix if the operation <span
class=""math inline""><em>A</em><em>x</em></span> does not negate or turn
to zero all positive entries of any nonzero, entrywise nonnegative real
vector <span class=""math inline""><em>x</em></span>. The class of
(strictly) semimonotone matrices generalizes the class of (strictly)
copositive matrices, which includes (positive) nonnegative matrices.
These matrices play a crucial role in the theory of the linear
complementarity problem (LCP). The LCP is the problem of finding a
complementary pair of nonnegative vectors in a finite-dimensional real
vector space that satisfies a given system of linear inequalities. The
LCP is one of the fundamental problems in optimization theory, providing
a unifying framework for studying mathematical programming problems such
as linear programming, quadratic programming, and bimatrix games.</p>
<p>One of the major challenges with (strictly) semimonotone matrices
lies in their construction and detection. To address these challenges
and further advance our understanding of these matrices, we focus on the
class of almost (strictly) semimonotone matrices, introduced by
Tsatsomeros and Wendler. In [Spec. Matrices 7 (2019) 291–303], Wendler
studied various properties of <span class=""math inline"">2 × 2</span> and
<span class=""math inline"">3 × 3</span> almost (strictly) semimonotone
matrices and proposed a conjecture. In this work, we revisit the class
of almost (strictly) semimonotone matrices and address Wendler’s
conjecture. We conducted a comprehensive study of matrix theoretic
properties of almost (strictly) semimonotone matrices and examined the
structural and sign-reversing properties of matrices. We explore results
concerning the existence and multiplicity of solutions to the linear
complementarity problem associated with these matrices.</p>
"
S3,SC1001,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S3,SC1003,1,Stefano,Sicilia,Stefano Sicilia,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,Minimum-norm solutions of the non-symmetric semidefinite Procrustes problem,"<p>Given two matrices <span
class=""math inline""><em>X</em>, <em>B</em> ∈ ℝ<sup><em>n</em> × <em>m</em></sup></span>
and a set <span
class=""math inline"">𝒜 ⊆ ℝ<sup><em>n</em> × <em>n</em></sup></span>, a
Procrustes problem consists in finding a matrix <span
class=""math inline""><em>A</em> ∈ 𝒜</span> such that the Frobenius norm
of <span class=""math inline""><em>A</em><em>X</em> − <em>B</em></span> is
minimized. When <span class=""math inline"">𝒜</span> is the set of the
matrices whose symmetric part is positive semidefinite, we obtain the
so-called non-symmetric positive semidefinite Procrustes (NSPSDP)
problem. The NSPSDP problem arises in the estimation of compliance or
stiffness matrix in solid and elastic structures. If <span
class=""math inline""><em>X</em></span> has rank <span
class=""math inline""><em>r</em></span>, Baghel et al. in [1] proposed a
three-step semi-analytical approach: (1) construct a reduced NSPSDP
problem in dimension <span
class=""math inline""><em>r</em> × <em>r</em></span>, (2) solve the
reduced problem by means of a fast gradient method with a linear rate of
convergence, and (3) post-process the solution of the reduced problem to
construct a solution of the larger original NSPSDP problem. We revisit
this approach of Baghel et al. and identify an unnecessary assumption
used by the authors leading to cases where their algorithm cannot attain
a minimum and produces solutions with unbounded norm. In fact, revising
the post-processing phase of their semi-analytical approach, we show
that the infimum of the NSPSDP problem is always attained, and we show
how to compute a minimum-norm solution. We also prove that the symmetric
part of the computed solution has minimum rank bounded by <span
class=""math inline""><em>r</em></span>, and that the skew-symmetric part
has rank bounded by <span class=""math inline"">2<em>r</em></span>.
Several numerical examples show the efficiency of this algorithm, both
in terms of computational speed and of finding optimal minimum-norm
solutions.</p>
<div class=""thebibliography"">
<p><span>2</span> Mohit Kumar Baghel, Nicolas Gillis, and Punit Sharma.
On the non-symmetric semidefinite Procrustes problem. Linear Algebra and
its Applications, 648:133–159, 2022. Nicolas Gillis and Stefano Sicilia.
Minimum-norm solutions of the non-symmetric semidefinite procrustes
problem. arXiv preprint arXiv:2406.02203, 2024.</p>
</div>
"
S3,SC1003,2,Manu,Mathew,Manu Mathew,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,Completely positive factorization,"<p>A real symmetric matrix <span class=""math inline""><em>M</em></span>
of size <span class=""math inline""><em>n</em></span> is a completely
positive matrix if there exists a real non-negative(entrywise) matrix
<span class=""math inline""><em>B</em></span> of size <span
class=""math inline""><em>n</em> × <em>m</em></span> such that <span
class=""math inline""><em>M</em> = <em>B</em><em>B</em><sup><em>T</em></sup></span>.
Completely positive matrix has applications in block designs,
complementarity problems and optimization problems. The collection of
all completely positive matrices of size <span
class=""math inline""><em>n</em></span> is a proper cone in the vector
space of all real symmetric matrices of size <span
class=""math inline""><em>n</em></span>. The dual of the completely
positive cone is the copositive cone. These cones are widely studied in
copositive programming. It is well known that a positive semidefinite
matrix <span class=""math inline""><em>M</em></span> of size <span
class=""math inline""><em>n</em></span> can be factorized as <span
class=""math inline""><em>M</em> = <em>A</em><em>A</em><sup><em>T</em></sup></span>
for some real matrix <span class=""math inline""><em>A</em></span> of size
<span class=""math inline""><em>n</em></span>. The membership problem of
the completely positive matrices is proven to be NP-hard. In this talk,
we discuss, a sufficient condition for a symmetric matrix <span
class=""math inline""><em>M</em></span> to be completely positive, when
<span class=""math inline""><em>M</em></span> has initial factorization
<span
class=""math inline""><em>M</em> = <em>A</em><em>A</em><sup><em>T</em></sup></span>.
We also find a completely positive factorization of <span
class=""math inline""><em>M</em></span> when it is completely
positive.</p>
"
S3,SC1003,3,Pinki,Khatun,Pinki Khatun,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,Structured backward errors for special classes of saddle point problems with applications,"<p>Saddle point problems (SPPs) have garnered significant attention in
recent times due to their pervasive occurrence in applications such as
computational fluid dynamics and constrained and weighted least square
estimation. Many numerical algorithms have been developed to find the
efficient solution of the <span>SPP</span> with <span>circulant</span>,
<span>Toeplitz</span>, or <span>symmetric</span>-<span>Toeplitz</span>
block matrices. This prompts a natural inquiry: can an approximate
solution obtained from a numerical algorithm be the exact solution to a
nearly perturbed problem? The concept of backward error
(<span>BE</span>) is used to determine how far a computed solution
stands from the original problem. Recent research efforts have focused
on exploring the BE for SPPs. However, these investigations overlook the
inherent sparsity pattern and <span>circulant</span>,
<span>Toeplitz</span> or symmetric-Toeplitz structures of the
coefficient matrix of the SPP. To overcome these limitations, we
investigate the structured <span>BEs</span> of <span>SPPs</span> when
the perturbation matrices exploit the sparsity pattern as well as
<span>circulant</span>, <span>Toeplitz</span>, and
<span>symmetric</span>-<span>Toeplitz</span> structures. Furthermore, we
construct minimal perturbation matrices that preserve the sparsity
pattern and the aforementioned structures. One application of the
obtained results is discussed in deriving structured <span>BEs</span>
for the weighted regularized least squares problem. Numerical experiment
are performed to validate our findings, showcasing the utility of the
obtained structured <span>BEs</span> in assessing the strong stability
of numerical algorithms.</p>
"
S3,SC1003,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S3,SC1005,1,Sachindranath,Jayaraman,Sachindranath Jayaraman,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,Quaternion matrix polynomials: location of eigenvalues,"<p>A right quaternion matrix polynomial is an expression of the form
<span class=""math inline"">$P(\lambda) = \displaystyle \sum_{i=0}^{m}A_i
\lambda^i$</span>, where <span
class=""math inline""><em>A</em><sub><em>i</em></sub> ∈ <em>M</em><sub><em>n</em></sub>(ℍ)</span>
with <span
class=""math inline""><em>A</em><sub><em>m</em></sub> ≠ 0</span>, where
<span class=""math inline""><em>M</em><sub><em>n</em></sub>(ℍ)</span> is
the set of all square matrices from the ring of quaternions. A
quaternion <span class=""math inline""><em>λ</em><sub>0</sub> ∈ ℍ</span>
is a right eigenvalue of <span
class=""math inline""><em>P</em>(<em>λ</em>)</span> if there exists a
nonzero vector <span
class=""math inline""><em>y</em> ∈ ℍ<sup><em>n</em></sup></span> such that
<span class=""math inline"">$\displaystyle
\sum_{i=0}^{m}A_i  y\lambda_0^i  =0$</span>. The purpose of this talk is
to bring out some recent results about the location of right eigenvalues
of <span class=""math inline""><em>P</em>(<em>λ</em>)</span> relative to
certain subsets of the set of quaternions. The notion of
(hyper)stability of complex matrix polynomials is extended to quaternion
matrix polynomials and results are obtained about right eigenvalues of
<span class=""math inline""><em>P</em>(<em>λ</em>)</span> by <span
class=""math inline"">(1)</span> giving a relation between
(hyper)stability of a quaternion matrix polynomial and its complex
adjoint matrix polynomial, and then by <span
class=""math inline"">(2)</span> proving that <span
class=""math inline""><em>P</em>(<em>λ</em>)</span> is stable with respect
to an open (closed) ball in the set of quaternions, centered at a
complex number if and only if it is stable with respect to its
intersection with the set of complex numbers. We derive as a consequence
of the above that right eigenvalues of <span
class=""math inline""><em>P</em>(<em>λ</em>)</span> lie between two
concentric balls of specific radii in the set of quaternions centered at
the origin. A generalization of the Enestr<span>ö</span>m-Kakeya theorem
to quaternion matrix polynomials is obtained as an application. Finally,
we also identify classes of quaternion matrix polynomials for which
stability and hyperstability are equivalent. This talk is based on the
following paper.</p>
<ul>
<li><p>Pallavi Basavaraju, Shrinath Hadimani and Sachindranath
Jayaraman, <em>Stability of quaternion matrix polynomials</em>, appecped
for publication, <em>Linear Algebra, Matrices and their
Applications</em>, Contemporary Mathematics, AMS, Edited by Surender
Kumar Jain, Manjunatha Prasad Karantha, Steve Kirkland, Vinay
Madhusudanan, Srinivasa Siva Rama Krishna Rao Taduri.</p></li>
</ul>
"
S3,SC1005,2,Thaniporn,Chaysri,Thaniporn Chaysri,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,"(Generic) Eigenvalue algorithms for matrices of quaternions, reduced biquaternions and their dual, and applications","<p>Quaternions are a four-dimensional non-commutative algebra and a
division ring of numbers introduced by Hamilton in 1843. The main
obstacle in deriving eigenvalue algorithms for matrices of quaternions,
due to non-cummutativity, is the efficient implementation of shifts.
Other linear algebra concepts naturally carry over from real or complex
numbers. Reduced biquaternions are a four-dimensional commutative number
algebra, introduced by Segre in 1892. The main obstacles when deriving
algorithms for matrices of reduced biquaternions are the existence of
non-invertible non-zero elements, and the need to consistently define
some basic linear algebra concepts in this setting. We present new
efficient algorithms for the QR factorization and eigenvalue and
singular value decompositions of these types of matrices and their dual,
keeping them as generic as possible. We also present applications to
computation of various types of matrix generalized inverses and image
analysis. The algorithms are efficiently implemented using the
multiple-dispatch feature of the programming language Julia. This is
joint work with Ivan Slapni<span>č</span>ar, Nevena
Jakov<span>č</span>evi<span>ć</span> Stor, and Anita
Carevi<span>ć</span> from the Department of Mathematics and Physics,
FESB, University of Split, Croatia, and Sk. Safique Ahmad, Neha Bhadala,
Pinki Khatun, and Gyan Swarup Nag from the Department of Mathematics,
IIT Indore, India. This work has been partially supported by Croatian
Science Foundation under the project IP-2020-02-2240.</p>
"
S3,SC1005,3,Neha,Bhadala,Neha Bhadala,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,"Generalized inverses of quaternion matrices: theory, computation, and applications","<p>This talk explores the theoretical foundations and computational
techniques for quaternion generalized inverses, with a particular
emphasis on outer inverses and <span
class=""math inline"">{1, 2}</span>-inverses under prescribed range and
null space constraints. Given the non-commutative nature of quaternions,
we provide a structured analysis of left and right range and null spaces
of quaternion matrices. Explicit representations for these inverses are
formulated, including full-rank decomposition-based constructions. To
facilitate efficient computation, we introduce two distinct algorithms:
one utilizing the Quaternion Toolbox for MATLAB (QTFM) and another based
on a complex structure-preserving framework. Additionally, we establish
a novel link between quaternion outer inverses with subspace constraints
and the Moore–Penrose inverse, offering a new perspective on their
interrelation. The effectiveness of our methods is demonstrated through
numerical experiments, and their practical utility is highlighted via a
color image deblurring application. These results underscore the
significance of quaternion generalized inverses in engineering and
applied mathematics.</p>
"
S3,SC1005,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S3,SC2001,1,Samir,Mondal,Samir Mondal,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,$P$-matrix powers,"<p>A <span class=""math inline""><em>P</em></span>-matrix is a matrix all
of whose principal minors are positive. In this talk, we demonstrate
that the fractional powers of a <span
class=""math inline""><em>P</em></span>-matrix are also <span
class=""math inline""><em>P</em></span>-matrices. This insight allows us
to affirmatively address a longstanding conjecture raised in [D.
Hershkowitz and C.R. Johnson, Spectra of matrices with <span
class=""math inline""><em>P</em></span>-matrix powers, <span><em>Linear
Algebra Appl.</em></span>, 80:159–171, 1986]: It is shown that if <span
class=""math inline""><em>A</em><sup><em>k</em></sup></span> is a <span
class=""math inline""><em>P</em></span>-matrix for all positive integers
<span class=""math inline""><em>k</em></span>, then the eigenvalues of
<span class=""math inline""><em>A</em></span> are positive.</p>
"
S3,SC2001,2,Sushmitha,P,Sushmitha P,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,Some extensions of the class of $Q$-matrices,"<p>A real square matrix <span class=""math inline""><em>A</em></span> is
called a <span class=""math inline""><em>Q</em></span>-matrix if LCP<span
class=""math inline"">(<em>A</em>, <em>q</em>)</span> has a solution for
all <span
class=""math inline""><em>q</em> ∈ ℝ<sup><em>n</em></sup></span>, i.e.,
for every vector <span class=""math inline""><em>q</em></span>, there
exists an <span
class=""math inline""><em>x</em> ∈ ℝ<sup><em>n</em></sup></span> such that
<span class=""math inline""><em>x</em> ≥ 0</span>, <span
class=""math inline""><em>A</em><em>x</em> + <em>q</em> ≥ 0</span> and
<span
class=""math inline""><em>x</em><sup><em>T</em></sup>(<em>A</em><em>x</em> + <em>q</em>) = 0</span>.
A well known result states that a <span
class=""math inline""><em>Q</em></span>-matrix with nonpositive
off-diagonal entries is inverse nonnegative. In this talk, we shall look
at properties of two classes of matrices that extend the inverse
nonnegativity of the <span
class=""math inline""><em>Q</em></span>-matrices to the generalized
inverse of a matrix. We shall also look at a new result for the class of
<span class=""math inline""><em>Q</em></span>-matrices.</p>
"
S3,SC2001,3,Falguni,Roy,Falguni Roy,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,Schur and Hurwitz diagonal stability of parametric interval matrices,"<p>Consider the parametric interval matrix <span
class=""math inline"">$A(\mathbf{c})=\Big\{A^{(0)}+\displaystyle
\sum_{k=1}^{l}c_kA^{(k)}\in \mathbb{R}^{n \times
n}:c\in\mathbf{c}\Big\}$</span>, where <span
class=""math inline""><strong>c</strong></span> is an interval vector.
This work focuses primarily on the generalized matrix diagonal
stability, i.e., Schur / Hurwitz diagonal stability relative to the
<span class=""math inline""><em>p</em></span>-norm ( <span
class=""math inline""><em>S</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
/ <span
class=""math inline""><em>H</em><em>D</em><em>S</em><sub><em>p</em></sub></span>)
introduced in [1], for three newly defined subclasses of the parametric
interval matrix <span
class=""math inline""><em>A</em>(<strong>c</strong>)</span>. First, a
necessary and sufficient condition is given for <span
class=""math inline""><em>S</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
and <span
class=""math inline""><em>H</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
of <span class=""math inline""><em>A</em>(<strong>c</strong>)</span> based
on the vertex matrices of <span
class=""math inline""><em>A</em>(<strong>c</strong>)</span>. Next, some
verifiable sufficient conditions for <span
class=""math inline""><em>S</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
and <span
class=""math inline""><em>H</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
of the first subclass <span
class=""math inline"">𝒜<sub>1</sub>(<strong>c</strong>)</span> are given
using majorant matrices. Using majorant matrices, the necessary and
sufficient condition for <span
class=""math inline""><em>S</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
is obtained for the second subclass <span
class=""math inline"">𝒜<sub>2</sub>(<strong>c</strong>)</span> and <span
class=""math inline""><em>H</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
for the third subclass <span
class=""math inline"">𝒜<sub>3</sub>(<strong>c</strong>)</span>,
respectively. From these, it is shown that <span
class=""math inline""><em>S</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
/ <span
class=""math inline""><em>H</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
for complex interval matrices is a special case. Methods for finding a
common diagonal matrix that meets conditions <span
class=""math inline""><em>S</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
/ <span
class=""math inline""><em>H</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
and the robustness analysis of <span
class=""math inline""><em>S</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
/ <span
class=""math inline""><em>H</em><em>D</em><em>S</em><sub><em>p</em></sub></span>
are also discussed.</p>
"
S3,SC2001,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S3,SC2006,1,Manisha,Devi,Manisha Devi,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,On the eigenvalues of the matrix $[f(g(p_i-p_j))]$,"<p>We prove that if <span
class=""math inline""><em>g</em> : ℛ → [0, ∞)</span> is a conditionally
negative definite function and <span
class=""math inline""><em>f</em> : [0, ∞) → [0, ∞)</span> is a Bernstein
function, then the function <span
class=""math inline""><em>f</em> ∘ <em>g</em></span> is conditionally
negative definite. The inertia of the matrix <span
class=""math inline"">[<em>f</em>(<em>g</em>(<em>p</em><sub><em>i</em></sub> − <em>p</em><sub><em>j</em></sub>))]</span>
is <span class=""math inline"">(1, 0, <em>n</em> − 1)</span> if <span
class=""math inline""><em>g</em>(<em>x</em>) = 0</span> only for <span
class=""math inline""><em>x</em> = 0</span> and <span
class=""math inline""><em>f</em></span> is non-linear. A new and easy
proof is also presented to demonstrate that the matrix <span
class=""math inline"">[log (1 − <em>p</em><sub><em>i</em></sub><em>p</em><sub><em>j</em></sub>)]</span>
is negative definite for <span class=""math inline""><em>n</em></span>
distinct positive real numbers <span
class=""math inline""><em>p</em><sub><em>i</em></sub> &lt; 1, ∀ <em>i</em></span>.
Numerous more relevant results are discussed. These results supplements
and unifies previous findings for operator monotone functions
demonstrated by several authors, including Dyn, Goodman and Michelli,
Bhatia and Jain, Garg and Aujla, and Garg and Agarwal.</p>
"
S3,SC2006,2,Sunyo,Moon,Sunyo Moon,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,Edge completion of signed graphs with spectral integral variation,"<p>Spectral variation of two matrices is integral if their spectra
differ by integer quantities. For two signed graphs, where one is
obtained from the other by adding a new edge, we characterize when the
spectral variation of their signed Laplacian matrices becomes integral.
Furthermore, for every fixed signed complete graph, we fully
characterize the class of signed graphs to which one can recursively add
new edges keeping spectral integral variation to make the signed
complete graph.This generalizes Kirkland’s characterization for
integrally completable graphs (Discrete Math., 2005). This is joint work
with Jungho Ahn and Cheolwon Heo.</p>
"
S3,SC2006,3,Piyush,Verma,Piyush Verma,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,Laplacian spectral properties of token graphs,"<p>Let <span class=""math inline""><em>G</em></span> be a graph on <span
class=""math inline""><em>n</em></span> vertices. For a given integer
<span class=""math inline""><em>k</em></span> such that <span
class=""math inline"">1 ≤ <em>k</em> ≤ <em>n</em></span>, the <span
class=""math inline""><em>k</em></span>-token graph <span
class=""math inline""><em>F</em><sub><em>k</em></sub>(<em>G</em>)</span>
of <span class=""math inline""><em>G</em></span> is defined as the graph
whose vertices are the <span
class=""math inline""><em>k</em></span>-subsets of the vertex set of <span
class=""math inline""><em>G</em></span>, and two of them are adjacent
whenever their symmetric difference is a pair of adjacent vertices in
<span class=""math inline""><em>G</em></span>. Token graphs have
applications in coding theory and quantum mechanics. It was conjectured
that for any graph <span class=""math inline""><em>G</em></span>, the
algebraic connectivity of <span
class=""math inline""><em>F</em><sub><em>k</em></sub>(<em>G</em>)</span>
is equal to the algebraic connectivity of <span
class=""math inline""><em>G</em></span>. This result turned out to be a
theorem, as it was proved by using the theory of the continuous Markov
chain of random walks and interchange process. However, proving this
theorem using algebraic and combinatorial methods is still an open and
interesting problem. In this talk, we discuss the algebraic connectivity
and Laplacian spectral radius of token graphs. Moreover, we study the
Laplacian integral token graphs. This talk is based on joint work with
Sasmita Barik.</p>
"
S3,SC2006,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S3,SC3001,1,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,,
S3,SC3001,2,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,,
S3,SC3001,3,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,,
S3,SC3001,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S3,SC4011,1,Alexander,Osinsky,Alexander Osinsky,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:00,16:30,103,200,The existence of close to optimal cross approximations in the Frobenius norm,"<p>It will be shown that there exists a cross <span
class=""math inline""><em>C</em><em>U</em><em>R</em></span> approximation
with relative error of the order <span
class=""math inline"">1 + <em>r</em>/<em>n</em> + <em>o</em>(<em>r</em>/<em>n</em>)</span>,
which improves on the best currently known bound of <span
class=""math inline"">1 + 40<em>r</em>/<em>n</em> + <em>o</em>(<em>r</em>/<em>n</em>)</span>
by Boutsidis and Woodruff. Notably, the generator <span
class=""math inline""><em>U</em></span> in such an approximation is the
pseudoinverse of the rank <span class=""math inline""><em>r</em></span>
projection of the submatrix at the intersection of the selected rows and
columns, similar to how maximum projective volume approximations are
formed. This allows to view any cross approximation algorithm of a
similar form as an approximate projection onto subspace of rank <span
class=""math inline""><em>r</em></span> matrices, and as a faster
alternative to randomized approximate SVD. In particular, projections
with such cross approximations outperform modern matrix completion
algorithms, when the fraction of known elements is high enough.</p>
"
S3,SC4011,2,Dmitry,Zheltkov,Dmitry Zheltkov,2025-06-23 16:00:00,CT,Contributed talks,Monday,16:30,17:00,103,200,TTCrossOrth: a better way to construct tensor train approximation,"<p>The TT-cross method efficiently approximates the tensor with a
logarithmic count of tensor element evaluations, maintaining low
computational complexity by heuristically selecting submatrices of the
TT-unfolding matrices to form an approximation.</p>
<p>TT-cross approximation has certain limitations: the tensor’s
approximation error may be exponentially linked to that of selected
submatrices, and determining ranks poses a challenge.</p>
<p>In this talk we introduce the TTCrossOrth algorithm, which optimizes
the TT-cross method through error orthogonalization to mitigate
exponential error growth and incorporates a novel rank adaptation
strategy.</p>
"
S3,SC4011,3,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:00,17:30,103,200,,
S3,SC4011,4,,,,2025-06-23 16:00:00,CT,Contributed talks,Monday,17:30,18:00,103,200,,
S4,SC0008,1,Olga,Katkova,Olga Katkova,2025-06-24 10:30:00,MS9,Total positivity,Tuesday,10:30,11:00,104,9,,
S4,SC0008,2,Sujit Sakharam,Damase,Sujit Sakharam Damase,2025-06-24 10:30:00,MS9,Total positivity,Tuesday,11:00,11:30,104,9,"Multivariate transforms of totally positive matrices and kernels
","<p>We will discuss recent results on multivariate transforms of totally
positive/nonnegative matrices and kernels, together with some
observations that go into their proofs. This is a joint work with
Apoorva Khare.</p>
"
S4,SC0008,3,Tanvi,Jain,Tanvi Jain,2025-06-24 10:30:00,MS9,Total positivity,Tuesday,11:30,12:00,104,9,,
S4,SC0009,1,Miran,Jeong,Miran Jeong,2025-06-24 10:30:00,MS29,Matrix functions and related topics,Tuesday,10:30,11:00,104,29,New weighted spectral geometric mean and quantum divergence,"<p>A new class of weighted spectral geometric means has recently been
introduced. In this talk, we present its inequalities in terms of the
Löwner order, operator norm, and trace. Moreover, we establish a
log-majorization relationship between the new spectral geometric mean,
and the Rényi relative operator entropy. We also give the quantum
divergence of the quantity, given by the difference of trace values
between the arithmetic mean and new spectral geometric mean. Finally, we
study the barycenter that minimizes the weighted sum of quantum
divergences for given variables.</p>
"
S4,SC0009,2,Shuhei,Wada,Shuhei Wada,2025-06-24 10:30:00,MS29,Matrix functions and related topics,Tuesday,11:00,11:30,104,29,On some multi-variable means of ALM type,"<p>The study of multivariable operator geometric means was pioneered by
Ando, Li, and Mathias (ALM). In recent years, research has primarily
focused on operator means obtained as solutions to operator equations.
Nevertheless, there has been growing interest in operator means of ALM
type, which are obtained by generalizing their approach. ALM-type means
are particularly notable because the approximating sequences are
explicitly given, making it easier to understand their properties. In
this talk, we will introduce an example of an ALM-type mean and discuss
its properties. Additionally, we will touch upon related results.</p>
"
S4,SC0009,3,Takashi,Sano,Takashi Sano,2025-06-24 10:30:00,MS29,Matrix functions and related topics,Tuesday,11:30,12:00,104,29,Convex matrix functions,"<p>I would like to talk about some topics related to convex matrix
functions: Kraus matrices; conditionally negative semidefiniteness;
inertia problems, strongly convex matrix functions, etc.</p>
"
S4,SC0012,1,Dániel,Virosztek,Dániel Virosztek,2025-06-24 10:30:00,MS12,"Preserver problems, I",Tuesday,10:30,11:00,104,12,Isometries and metric properties of quantum Wasserstein distances,"<p>Although the theory of classical optimal transport has been playing
an important role in mathematical physics (especially in fluid dynamics)
and probability since the late 80s, concepts of optimal transportation
in quantum mechanics have emerged only very recently. We briefly review
the most relevant approaches and discuss a non-quadratic generalization
of the quantum mechanical optimal transport problem introduced by De
Palma and Trevisan where quantum channels realize the transport. Relying
on this general machinery, we introduce p-Wasserstein distances and
divergences and study their fundamental geometric properties. Finally,
we demonstrate that the quadratic quantum Wasserstein divergences are
genuine metrics, and summarize our recent results on the isometries of
the qubit state space with respect to Wasserstein distances induced by
distinguished transport cost operators.</p>
"
S4,SC0012,2,Michiya,Mori,Michiya Mori,2025-06-24 10:30:00,MS12,"Preserver problems, I",Tuesday,11:00,11:30,104,12,On the Scottish Book Problem 155 by Mazur and Sternbach,"<p>The Scottish Book was a notebook used by mathematicians of the Lwów
School of Mathematics in Poland to collect unsolved problems in
mathematics. Problem 155 of the Scottish Book asks whether every
bijection <span
class=""math inline""><em>U</em>: <em>X</em> → <em>Y</em></span> between
two Banach spaces <span
class=""math inline""><em>X</em>, <em>Y</em></span> with the property
that, each point of <span class=""math inline""><em>X</em></span> has a
neighborhood on which <span class=""math inline""><em>U</em></span> is
isometric, is globally isometric on <span
class=""math inline""><em>X</em></span>. In this talk, I will explain that
this is true under the additional assumption that <span
class=""math inline""><em>X</em></span> is separable and the weaker
assumption of surjectivity instead of bijectivity.</p>
"
S4,SC0012,3,Osamu,Hatori,Osamu Hatori,2025-06-24 10:30:00,MS12,"Preserver problems, I",Tuesday,11:30,12:00,104,12,Isometries on groups of invertible elements in Fourier-Stieltjes algebras,"<p>If open subgroups of the groups of invertible elements in two
Fourier-Stieltjes algebras are isometric as metric spaces, then the
underlying locally compact groups are topologically isomorphic.</p>
"
S4,SC0014,1,Saifon,Chaturantabut,Saifon Chaturantabut,2025-06-24 10:30:00,MS6,Model reduction,Tuesday,10:30,11:00,104,6,Nonlinear model reduction using machine learning on Grassmann Manifol,"<p>This work explores a parametric model order reduction approach for
nonlinear dynamical systems, integrating machine learning methods on a
Grassmann manifold. Distances between parameters are first calculated
using a metric defined on the Grassmann manifold of solution subspaces.
Then, the K-medoids clustering algorithm is used with these Grassmann
distances to categorize the parameters into classes and form a
dictionary of local bases. Machine learning techniques based on support
vector machines (SVM) and artificial neural networks (ANN) are finally
employed to create classifiers that can automatically determine the most
appropriate local basis for constructing reduced-order models. Numerical
experiments are conducted on nonlinear differential equations, including
the parametrized Burger’s equation, the Sine-Gordon equation, and a
nonlinear flow.</p>
"
S4,SC0014,2,Ralf,Zimmermann,Ralf Zimmermann,2025-06-24 10:30:00,MS6,Model reduction,Tuesday,11:00,11:30,104,6,Maximum volume coordinates for subspace interpolation,"<p>Model reduction of complex nonlinear parametric dynamical systems is
still a challenge. One possible approach to deal with such systems is
via manifold interpolation. In particular, the interpolation of
subspaces, i.e., points on the Grassmann manifold has recently received
more and more attention. Basic manifold interpolation requires working
with local coordinate charts and can be subdivided into three key
steps:<br />
1: <span><em>Preprocessing.</em></span> Map sampled data from manifold
to coordinate domain.<br />
2: <span><em>Interpolation.</em></span> Employ a Euclidean interpolation
method to interpolate the data images in the coordinate domain.<br />
3: <span><em>Postprocessing.</em></span> Map interpolated data from
coordinate domain to manifold.<br />
The gold standard is arguably to work with Riemannian normal
coordinates, since in a sense they exhibite the least possible geometric
distortion. Yet, this may become expensive, especially when derivative
data is involved.<br />
An alternative for the Grassmann manifold are a certain set of local
coordinates, which do not require matrix decompositions. Although these
have been known for three decades, to our knowledge they have not yet
been investigated in detail and have not been used in connection with
model reduction.<br />
In this talk, we investigate their usability for Grassmann
interpolation. We show that this set of coordinates constitutes a
retraction. Moreover, we expose the sources of data processing errors
and their impact on the interpolation errors. A pivot in these
coordinates is an invertible submatrix of an orthogonal projector. We
show how selection of this subblock by volume maximization improves the
condition number of the coordinate charts and eventually reduces the
interpolation errors. The results are illustrated by numerical
experiments.<br />
This is joint work with Rasmus Jensen, IMADA, University of Southern
Denmark.</p>
"
S4,SC0014,3,Zlatko,Drmac,Zlatko Drmac,2025-06-24 10:30:00,MS6,Model reduction,Tuesday,11:30,12:00,104,6,Koopman mode decomposition for nonlinear model reduction,"<p>The Dynamic Mode Decomposition (DMD) is a popular numerical method
for data driven analysis of nonlinear dynamical systems, with a wide
spectrum of applications. It can be used for model order reduction,
analysis of latent structures in the dynamics, and e.g. for forecasting
and control. The theoretical bedrock upon which the more general
Extended DMD framework is built is the Koopman composition operator. DMD
can be described as a data driven Rayleigh-Ritz extraction of spectral
information of a Koopman operator associated with the underlying
dynamical system. The nonlinear data snapshots are represented using the
eigenvectors of the operator resulting in a modal decomposition KMD
(Koopman Mode Decomposition). This becomes a model order reduction tool
that represents the nonlinear dynamics using selected eigenpairs. It can
be used to reveal coherent states and for forecasting.<br />
In some cases, a numerically computed compression of the Koopman
operator exhibits high non-normality, and, as a result, the eigenvectors
are highly ill-conditioned and the KMD becomes numerically unstable. We
address this problem and introduce a new theoretical and computational
framework for data driven Koopman mode analysis of nonlinear dynamics.
The problem of ill-conditioned eigenvectors is solved using a
Koopman-Schur decomposition that is entirely based on unitary
transformations. The analysis in terms of the eigenvectors as modes of a
Koopman operator is replaced with a modal decomposition in terms of a
flag of invariant subspaces that correspond to selected
eigenvalues.<br />
The main computational tool from the numerical linear algebra is the
partial ordered Schur decomposition that provides convenient orthonormal
bases for these subspaces.<br />
This is a joint work with Igor Mezić, University of California at Santa
Barbara.</p>
<p>Reference:<br />
Zlatko Drmač, Igor Mezić A data driven Koopman-Schur decomposition for
computational analysis of nonlinear dynamics, SIAM J. Sci. Comp. (in
review)<br />
https://doi.org/10.48550/arXiv.2312.15837</p>
"
S4,SC1001,1,Miklós,Pálfia,Miklós Pálfia,2025-06-24 10:30:00,MS10,Matrix means and related topics,Tuesday,10:30,11:00,104,10,,
S4,SC1001,2,Huajun,Huang,Huajun Huang,2025-06-24 10:30:00,MS10,Matrix means and related topics,Tuesday,11:00,11:30,104,10,Progress on orders of matrix means,"<p>On the set of positive definite matrices, the Löwner order <span
class=""math inline"">≤</span>, the chaotic order <span
class=""math inline"">≪</span>, the near order <span
class=""math inline"">≼</span>, the eigenvalue entrywise order, and the
weak log-majorization order <span
class=""math inline"">≺<sub><em>w</em>log </sub></span> satisfy: <span
class=""math display""><em>A</em> ≤ <em>B</em> ⇒ <em>A</em> ≪ <em>B</em> ⇒ <em>A</em> ≼ <em>B</em> ⇒ <em>A</em>≤<sub><em>λ</em></sub><em>B</em> ⇒ <em>A</em>≺<sub><em>w</em>log </sub><em>B</em>.</span>
The spectral geometric mean <span
class=""math inline"">♮<sub><em>t</em></sub></span> and the
Bures–Wasserstein mean <span
class=""math inline"">⋄<sub><em>t</em></sub></span> satisfy that for <span
class=""math inline""><em>t</em> ∈ [0, 1]</span>: <span
class=""math display"">$$\begin{aligned}
    A \natural_t B &amp;\preceq A \diamond_t B, \\
    (A^{-1} \diamond_t B^{-1})^{-1} &amp;\preceq A \natural_t B =
(A^{-1} \natural_t B^{-1})^{-1}, \\
    (A^{-1} \diamond_t B^{-1})^{-1} &amp;\preceq A \diamond_t B.
\end{aligned}$$</span> Moreover, the Alpha Procrustes mean is closely
related to the Bures–Wasserstein mean. I will present some recent
results on the order relations among these matrix means. A few
affirmative order relations and a few counterexamples will be
explored.</p>
"
S4,SC1001,3,Trung Dung,Vuong,Trung Dung Vuong,2025-06-24 10:30:00,MS10,Matrix means and related topics,Tuesday,11:30,12:00,104,10,,
S4,SC1003,1,Ilias,Kotsireas,Ilias Kotsireas,2025-06-24 10:30:00,MS26,"Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics",Tuesday,10:30,11:00,104,26,"A low-complexity algorithm to search for Legendre pairs
","<p>Legendre pairs constitute an important combinatorial object that can
be used to construct Hadamard matrices. In our LAA paper, we studied the
matrix equation of Legendre pairs and its properties, focusing on the
spectra of the matrices involved, utilizing Gershgorin circles. Legendre
pairs are characterized by two invariants related to the discrete
Fourier transform (DFT) matrix. We propose a low-complexity fast Fourier
transform (FFT)-like algorithm to compute the product of the DFT matrix
with each sequence of the Legendre pair. By utilizing the FFT-like
algorithm, we present a low-time complexity algorithm to search for
Legendre pairs. We present numerical results from our C implementation
of the FFT-like algorithm, which offers a lower time complexity for
finding Legendre pairs compared to traditional combinatorial
algorithms.<br />
<br />
This is a joint work with Sirani M. Perera.</p>
"
S4,SC1003,2,Sirani,M. Perera,Sirani M. Perera,2025-06-24 10:30:00,MS26,"Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics",Tuesday,11:00,11:30,104,26,A low-complexity structured neural network approach for dynamical systems,"<p>Data-driven learning is advancing rapidly, offering a new perspective
on understanding dynamic systems. On the other hand, traditional methods
for solving chaotic and highly non-linear systems face challenges in
computational efficiency due to their inherent complexity and dynamics.
Fortunately, neural networks excel in solving highly non-linear systems,
showing exceptional performance.<br />
<br />
In this talk, we propose a neural network approach to update the states
of dynamical systems through a structured operator known as a Hankel
operator – an operator characterized by a Hankel structure. Our goal is
to develop an optimal, low-complexity learning algorithm that utilizes
time-delay measurements to forecast future states effectively. By the
conclusion of the talk, we will demonstrate how this operator can be
employed to model state-space dynamical systems, enabling predictions
and insights into future dynamics compared to conventional techniques:
SINDy and HAVOK followed by the feedforward neural networks.<br />
<br />
This is a joint work with Hansaka Aluvihare, Levi Lingsch, and Xianqi
Li. This work was funded by the Division of Mathematical Sciences at the
National Science Foundation with the award numbers 2410676, 2410677,
&amp; 2410678.</p>
"
S4,SC1003,3,,,,2025-06-24 10:30:00,MS26,"Utilizing structure to achieve low-complexity algorithms for data science, engineering, and physics",Tuesday,11:30,12:00,104,26,,
S4,SC1005,1,Franklin,Kenter,Franklin Kenter,2025-06-24 10:30:00,MS15,Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham,Tuesday,10:30,11:00,104,15,A geometric adaptation of the Chung-Lu graph model,"<p>The Chung-Lu graph model specifies the expected degree of each vertex
in a graph and, provided the degree distribution is not excessively
skewed, generates a random graph where the existence of each edge is
determined independently.</p>
<p>A common characteristic of many “real-world” graphs is a degree
distribution that follows an inverse power law. Specifically, the number
of vertices with degree <span class=""math inline""><em>x</em></span> is
proportional to <span
class=""math inline""><em>x</em><sup><em>β</em></sup></span>, where <span
class=""math inline""><em>β</em></span> typically ranges between 1 and 3.
The Chung-Lu model offers a straightforward approach to capturing this
power-law behavior in synthetic networks.</p>
<p>We extend the Chung-Lu model to random geometric graphs. In this
extension, each vertex is assigned both an expected degree and a random
position in Euclidean space according to a probability distribution.
Once the vertices are placed, the realization of each edge occurs
independently of others. We rigorously establish the conditions
necessary to ensure that the assigned degrees align with the expected
degrees. This geometric Chung-Lu model is tested on the connectome of
the <em>Drosophila</em> medulla (fruit fly), where the random model
successfully replicates the graph-theoretical structure of the original
network, including the eigenvalues of various graph-theoretic
matrices.</p>
<p>This is joint work with Susama Agarwala.</p>
"
S4,SC1005,2,Wei-Chia,Chen,Wei-Chia Chen,2025-06-24 10:30:00,MS15,Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham,Tuesday,11:00,11:30,104,15,Curvature on graphs via distance matrix,"<p>Recently, Steinerberger introduced a notion of curvature on graphs
based on solutions to the linear system <span
class=""math inline""><em>D</em><em>x</em> = <strong>1</strong>,</span>
where <span class=""math inline""><em>D</em></span> is the graph distance
matrix and <span class=""math inline""><strong>1</strong></span> is the
all-one vector. They also observed in the Mathematica database that
graphs so that <span
class=""math inline""><em>D</em><em>x</em> = <strong>1</strong></span> has
no solutions seem to be rare. In this talk, we will focus on how
nonnegative solutions to <span
class=""math inline""><em>D</em><em>x</em> = <strong>1</strong></span>
behave when certain graph operations are performed, such as adding an
edge between two graphs. We also provide a way to create an infinite
family of graphs so that <span
class=""math inline""><em>D</em><em>x</em> = <strong>1</strong></span> has
no solutions. This is joint work with Mao-Pei Tsui.</p>
"
S4,SC1005,3,Mark,Kempton,Mark Kempton,2025-06-24 10:30:00,MS15,Graphs and their eigenvalues: Celebrating the work of Fan Chung Graham,Tuesday,11:30,12:00,104,15,"Nonbacktracking random walks: mixing rate, Kemeny's constant, and beyond","<p>Random walks on graphs are ubiquitous in spectral graph theory, both
in helping us understand graphs and for applications in graph
algorithms. Considerable research has been done in the last two decades
around understanding how forbidding backtracking affects the random
walk. We will discuss past and current research on how forbidding
backtracking affects mixing rates, hitting times, Kemeny’s constant, and
other aspects of random walks, and we will discuss some future
directions for exploration.</p>
"
S4,SC2001,1,Rachel,Quinlan,Rachel Quinlan,2025-06-24 10:30:00,MS2,Combinatorial matrix theory,Tuesday,10:30,11:00,104,2,Idempotent alternating sign matrices,"<p>An alternating sign matrix (ASM) is a square <span
class=""math inline"">(0, 1, −1)</span>-matrix in which the nonzero
entries alternate between 1 and <span class=""math inline"">−1</span> and
sum to 1, within each row and column. Permutation matrices are examples
of ASMs, and ASMs generalize permutation matrices in several apparently
natural but unexpected ways. Every multiplicative group of nonsingular
ASMs is a group of permutation matrices, but the set of all <span
class=""math inline""><em>n</em> × <em>n</em></span> ASMs also contains
multiplicative groups of singular matrices. The identity element <span
class=""math inline""><em>E</em></span> of such a group is an idempotent
ASM, it satisfies <span
class=""math inline""><em>E</em><sup>2</sup> = <em>E</em></span>. In this
talk we will discuss some methods for construction of idempotent ASMs,
and identify the minimum rank of an idempotent ASM of specified
size.<br />
This is joint work with Cian O’Brien.</p>
"
S4,SC2001,2,Kevin,Vander Meulen,Kevin Vander Meulen,2025-06-24 10:30:00,MS2,Combinatorial matrix theory,Tuesday,11:00,11:30,104,2,Matrix sign patterns that allow the strong multiplicity property,"<p>Various strong multiplicity properties have been developed to aid
with inverse eigenvalue problems. The nonsymmetric strong multiplicity
property (nSMP) has recently been introduced to provide information
about the possible eigenvalue multiplicities of a matrix based on the
sign pattern of the matrix. The nSMP is useful for the problem of
determining the number of distinct eigenvalues allowed by a pattern. We
provide a characterization of the patterns that allow the nSMP. We also
describe classes of patterns of arbitrary order that require the nSMP.
This presentation includes joint work with Abhilash Saha, Leona Tilis,
and Adam Van Tuyl.</p>
"
S4,SC2001,3,Emanuel Juliano,Morais Silva,Emanuel Juliano Morais Silva,2025-06-24 10:30:00,MS2,Combinatorial matrix theory,Tuesday,11:30,12:00,104,2,Spectral upper bounds for the Grundy number of a graph,"<p>The Grundy number of a graph is the minimum number of colors needed
to properly color the graph using the first-fit greedy algorithm
regardless of the initial vertex ordering. Computing the Grundy number
of a graph is an NP-Hard problem. There is a characterization in terms
of induced subgraphs: a graph has a Grundy number at least k if and only
if it contains a <span class=""math inline""><em>k</em></span>-atom. In
this talk, we focus on a natural quotient matrix of the adjacency matrix
of <span class=""math inline""><em>k</em></span>-atoms and use its
combinatorial properties to derive bounds on the Grundy number in terms
of the largest eigenvalue and the size of the graph. This talk is based
on a joint work with Gabriel Coutinho and Thiago Assis.</p>
"
S4,SC2006,1,Shigeru,Furuichi,Shigeru Furuichi,2025-06-24 10:30:00,MS3,Matrix inequalities with applications,Tuesday,10:30,11:00,104,3,Inequalities on spectral geometric mean and application for relative entropy,"<p>The weighted geometric mean is defined by <span
class=""math inline"">$A\sharp_t
B:=A^{\frac{1}{2}}\left(A^{-\frac{1}{2}}BA^{-\frac{1}{2}}\right)^t
A^{\frac{1}{2}}$</span> for positive invertible operators <span
class=""math inline""><em>A</em>, <em>B</em></span> and <span
class=""math inline"">0 ≤ <em>t</em> ≤ 1.</span> The weighted spectral
geometric mean was defined in <span class=""citation""
data-cites=""Lee1""></span> by <span class=""math display"">$$A{{{\rm
sp}}_{t}}B={{\left( {{A}^{-1}}\sharp B \right)}^{t}}A{{\left(
{{A}^{-1}}\sharp B \right)}^{t}},\quad (0\leq t\leq 1).$$</span>
Operator inequalities between the weighted spectral geometric mean <span
class=""math inline"">$A{\rm sp}_t B$</span> and the weighted geometric
mean <span
class=""math inline""><em>A</em>♯<sub><em>t</em></sub><em>B</em></span>
have compared in <span class=""citation"" data-cites=""MFS2023""></span>
with the generalized Kantorovich constant for <span
class=""math inline"">0 &lt; <em>m</em> &lt; <em>M</em></span> and <span
class=""math inline""><em>t</em> ∈ ℝ</span>: <span
class=""math display"">$$K\left( m,M,t
\right)=\frac{\left(m{{M}^{t}}-M{{m}^{t}}\right)}{\left( t-1
\right)\left( M-m \right)}{{\left(
\frac{t-1}{t}\frac{{{M}^{t}}-{{m}^{t}}}{m{{M}^{t}}-M{{m}^{t}}}
\right)}^{t}}.$$</span></p>
<p>In this talk, we consider the case <span
class=""math inline""><em>t</em> ∉ (0, 1)</span>. We firstly state the
relations of <span class=""math inline"">$A\hat\sharp_t B$</span> and
<span class=""math inline"">$A{{\hat{\rm sp}}_{t}}B$</span> for <span
class=""math inline""><em>t</em> ∉ (0, 1)</span> in Löwner order with the
generalized Kantorovich constant. Norm inequalities are also shown for
them. We also give log–majorization and the bounds for the Tsallis
relative entropy as its application. Our talk is based on the results in
<span class=""citation"" data-cites=""FS2024""></span>.</p>
<div class=""thebibliography"">
<p><span>5</span></p>
<p>H. Lee and Y. Lim, <span><em>Metric and spectral geometric means on
symmetric cones</em></span>, Kyungpook Math. J.,
<span><strong>47</strong></span>(1) (2007), 133–150.</p>
<p>H. R. Moradi, S. Furuichi and M. Sababheh, <span><em>Operator
spectral geometric versus geometric mean</em></span>, Linear Multilinear
Algebra, <span><strong>72</strong></span>(2024), 997–1016.</p>
<p>S. Furuichi and Y. Seo, <span><em>Some inequalities for spectral
geometric mean with applications</em></span>, Linear Multilinear
Algebra, <a href=""doi.org/10.1080/03081087.2024.2433512""
class=""uri"">doi.org/10.1080/03081087.2024.2433512</a>.</p>
</div>
"
S4,SC2006,2,Pattrawut,Chansangiam,Pattrawut Chansangiam,2025-06-24 10:30:00,MS3,Matrix inequalities with applications,Tuesday,11:00,11:30,104,3,Integral inequalities of Kantorovich and Fiedler types for Hadamard products of matrices,"<p>The scalar Kantorovich inequality is a reverse weighted
arithmetic-harmonic mean inequality. In matrix case, this inequality is
also a reverse version of Fiedler’s inequality. In this talk, we discuss
several Kantorovich and Fiedler types integral inequalities involving
Hadamard products of continuous fields of Hilbert space operators.
Kantorovich type inequality in which the product is replaced by an
operator mean is also investigated. Such inequalities include discrete
inequalities as special cases. Moreover, we obtain the monotonicity of
certain maps involving Hadamard products of operators. As special cases,
we get some operator versions of Fiedler matrix inequality.</p>
"
S4,SC2006,3,Yang,Zhang,Yang Zhang,2025-06-24 10:30:00,MS3,Matrix inequalities with applications,Tuesday,11:30,12:00,104,3,"On the third-order quaternion tensors and applications
","<p>In this talk, we first discuss the ranks of the third-order
quaternion tensors and present some inequalities for boundaries. Then we
consider SVD and QR decomposition of this quaternion tensors and
applications in color images and videos processing.</p>
"
S4,SC3001,1,Gilad,Lerman,Gilad Lerman,2025-06-24 10:30:00,MS18,New methods in numerical multilinear algebra,Tuesday,10:30,11:00,104,18,,
S4,SC3001,2,Jing,Niu,Jing Niu,2025-06-24 10:30:00,MS18,New methods in numerical multilinear algebra,Tuesday,11:00,11:30,104,18,A tensor alternating Anderson--Richardson method for solving multilinear systems with $ \mathcal{M} $-tensors,"<p>It is well-known that a multilinear system with a nonsingular <span
class=""math inline"">ℳ</span>-tensor and a positive right-hand side has a
unique positive solution. Tensor splitting methods are efficient because
they do not require computing the Jacobian matrix. Anderson acceleration
is also a Jacobian-free technique. The Alternating Anderson–Richardson
(AAR) method is also a Jacobian-free method for solving linear systems.
Inspired by the AAR method, we propose a tensor AAR method for solving
multilinear systems. Specifically, we first present a tensor Richardson
method, then apply Anderson acceleration and derive a tensor
Anderson–Richardson method, finally, we periodically employ the tensor
Anderson–Richardson method within the tensor Richardson method and
propose a tensor AAR method. Numerical experiments show that the
proposed method outperforms some tensor splitting methods.</p>
"
S4,SC3001,3,Jingmei,Qiu,Jingmei Qiu,2025-06-24 10:30:00,MS18,New methods in numerical multilinear algebra,Tuesday,11:30,12:00,104,18,"Efficient Galerkin interpolative tensor train decomposition of high order tensors
","<p>High-dimensional functions and tensors frequently arise in scientific
computing and data science, yet their low-rank representations are often
obscured by noise and numerical instability. This work addresses the
fundamental challenge of constructing accurate and robust tensor train
(TT) decompositions without incurring the curse of dimensionality (CoD).
We propose an efficient Galerkin interpolative framework that integrates
a randomized range-finding strategy with adaptive pivot selection to
identify low-dimensional structure in high-order tensors. Our method
avoids explicit enumeration of the full tensor and leverages
hierarchical structure to construct the TT format with near-optimal
complexity. Despite its reduced computational cost, the proposed
approach retains competitive accuracy, robustness, and stability
compared to state-of-the-art full complexity algorithms. Numerical
experiments demonstrate its effectiveness in capturing low-rank
structure across a range of high-dimensional benchmark problems.</p>
"
S4,SC4011,1,Sing-Yuan,Yeh,Sing-Yuan Yeh,2025-06-24 10:30:00,MS20,Manifold learning and statistical applications,Tuesday,10:30,11:00,104,20,Landmark diffusion accelerates alternating diffusion maps for multi-sensor fusion,"<p>Alternating Diffusion (AD) is a commonly applied diffusion-based
sensor fusion algorithm. While it has been successfully applied to
various problems, its computational burden remains limited. Inspired by
the landmark diffusion idea considered in the Robust and Scalable
Embedding via Landmark Diffusion (ROSELAND), we propose a variation of
AD, called Landmark AD (LAD), which captures the essence of AD while
offering superior computational efficiency. Through a series of
theoretical analyses, we investigate the sample complexity of LAD within
the manifold setup. We then apply LAD to address the automatic sleep
stage annotation problem using two electroencephalogram channels,
demonstrating its efficacy in practical applications.</p>
"
S4,SC4011,2,Yu-Jie,Huang,Yu-Jie Huang,2025-06-24 10:30:00,MS20,Manifold learning and statistical applications,Tuesday,11:00,11:30,104,20,Application of VoxelMorph and SynthMorph for multitype 3D medical image registration,"<p>In this work, we explore the application of VoxelMorph and SynthMorph
for 3D medical image registration. VoxelMorph provides a deep
learning-based framework that utilizes deformable pairwise registration,
enabling the alignment of complex anatomical structures through
continuous deformation fields. By modeling transformations as smooth
manifolds, VoxelMorph facilitates precise, non-rigid alignment, making
it well-suited for capturing intricate deformations in medical images.
SynthMorph further extends this approach, offering a robust method for
image registration across diverse MRI contrasts, effectively handling
variations in image intensities without relying on acquired imaging
data. We investigate how these deformable models can be integrated into
existing medical imaging workflows to enhance multi-type image
registration, improving the alignment of images with varying anatomical
and contrast properties.</p>
"
S4,SC4011,3,Chih-Wei,Chen,Chih-Wei Chen,2025-06-24 10:30:00,MS20,Manifold learning and statistical applications,Tuesday,11:30,12:00,104,20,Convergence of Hessian estimator from random samples on a manifold with boundary,"<p>A common method for estimating the Hessian operator from random
samples on a submanifold involves locally fitting a quadratic
polynomial. Although widely used, it is unclear if this estimator
introduces bias, especially in manifolds with boundaries and nonuniform
sampling. We show that this estimator asymptotically converges to the
Hessian operator, with nonuniform sampling and curvature effects proving
negligible, even near boundaries. Our analysis framework simplifies the
intensive computations required for direct analysis. This is join work
with Hau-Tieng Wu.</p>
"
S5,SC0008,1,,,,2025-06-24 13:30:00,,,Tuesday,13:30,14:00,105,1000,,
S5,SC0008,2,,,,2025-06-24 13:30:00,,,Tuesday,14:00,14:30,105,1000,,
S5,SC0008,3,,,,2025-06-24 13:30:00,,,Tuesday,14:30,15:00,105,1000,,
S5,SC0008,4,,,,2025-06-24 13:30:00,,,Tuesday,15:00,15:30,105,1000,,
S5,SC0009,1,Yuki,Seo,Yuki Seo,2025-06-24 13:30:00,MS29,Matrix functions and related topics,Tuesday,13:30,14:00,105,29,"Matrix trace inequalities related to quantum Tsallis relative entropies
","<p>Let <span
class=""math inline"">𝕄<sub><em>n</em></sub> = 𝕄<sub><em>n</em></sub>(ℂ)</span>
be the algebra of <span
class=""math inline""><em>n</em> × <em>n</em></span> complex matrices. For
<span class=""math inline""><em>ρ</em> ∈ 𝕄<sub><em>n</em></sub></span>, we
write <span class=""math inline""><em>ρ</em> ≥ 0</span> if <span
class=""math inline""><em>ρ</em></span> is positive semidefinite and <span
class=""math inline""><em>ρ</em> &gt; 0</span> if <span
class=""math inline""><em>ρ</em></span> is positive definite. For two
Hermitian matrices <span class=""math inline""><em>ρ</em></span> and <span
class=""math inline""><em>σ</em></span> in <span
class=""math inline"">𝕄<sub><em>n</em></sub></span>, we write <span
class=""math inline""><em>ρ</em> ≥ <em>σ</em></span> if <span
class=""math inline""><em>ρ</em> − <em>σ</em> ≥ 0</span>, and <span
class=""math inline""><em>ρ</em> &gt; <em>σ</em></span> if <span
class=""math inline""><em>ρ</em> − <em>σ</em> &gt; 0</span>. This is
called the Löwner partial order for Hermitian matrices. Let <span
class=""math inline"">𝕊<sub><em>n</em></sub> = 𝕊<sub><em>n</em></sub>(ℂ)</span>
be the set of all density matrices, which mean positive definite
matrices with trace one. The matrix <span
class=""math inline""><em>α</em></span>-geometric mean of two positive
definite matrices <span class=""math inline""><em>ρ</em></span> and <span
class=""math inline""><em>σ</em></span> is defined by <span
class=""math display""><em>ρ</em> ♯<sub><em>α</em></sub> <em>σ</em> = <em>ρ</em><sup>1/2</sup>(<em>ρ</em><sup>−1/2</sup><em>σ</em><em>ρ</em><sup>−1/2</sup>)<sup><em>α</em></sup><em>ρ</em><sup>1/2</sup>   for
<em>α</em> ∈ [0, 1].</span> We use the notation <span
class=""math inline"">♮<sub><em>α</em></sub></span> for the binary
operation <span
class=""math display""><em>ρ</em> ♮<sub><em>α</em></sub> <em>σ</em> = <em>ρ</em><sup>1/2</sup>(<em>ρ</em><sup>−1/2</sup><em>σ</em><em>ρ</em><sup>−1/2</sup>)<sup><em>α</em></sup><em>ρ</em><sup>1/2</sup>   for
<em>α</em> ∉ [0, 1],</span> that has formula in common with <span
class=""math inline"">♯<sub><em>α</em></sub></span>. Notice that the
geodesic connecting two points on the differentiable manifold <span
class=""math inline"">ℙ<sub><em>n</em></sub></span> of positive definite
matrices is the matrix <span
class=""math inline""><em>α</em></span>-geometric mean.<br />
In this talk, we show matrix trace inequalities related to two quantum
Tsallis relative entropies of all real order: For density matrices <span
class=""math inline""><em>ρ</em></span> and <span
class=""math inline""><em>σ</em></span> in <span
class=""math inline"">𝕊<sub><em>n</em></sub></span>, and each <span
class=""math inline""><em>α</em> ∈ ℝ ∖ {0}</span>, the quantum Tsallis
relative entropy <span class=""math inline"">${\rm
D}_{\alpha}(\rho|\sigma)$</span> due to Abe is defined by <span
class=""math display"">$${\rm D}_{\alpha}(\rho|\sigma)=-{\rm
Tr}\left(\frac{\rho^{1-\alpha}\sigma^{\alpha}-\rho}{\alpha}\right)$$</span>
and <span
class=""math inline""><em>N</em><em>T</em><sub><em>α</em></sub>(<em>ρ</em>|<em>σ</em>)</span>
due to Yanagi, Kuriyama and Furuichi is defined by <span
class=""math display"">$$NT_{\alpha}(\rho|\sigma)=-{\rm
Tr}\left(\frac{\rho\ \natural_{\alpha}\
\sigma-\rho}{\alpha}\right).$$</span> If <span
class=""math inline""><em>ρ</em></span> and <span
class=""math inline""><em>σ</em></span> commute, then we have <span
class=""math inline"">${\rm
D}_{\alpha}(\rho|\sigma)=NT_{\alpha}(\rho|\sigma)$</span>. Then we show
the order relation between two quantum Tsallis relative entropies <span
class=""math inline""><em>D</em><sub><em>α</em></sub></span> and <span
class=""math inline""><em>N</em><em>T</em><sub><em>α</em></sub></span> of
all real order <span class=""math inline""><em>α</em> ∈ ℝ</span> and a
<span class=""math inline"">1</span>-parameter extension of the path
connecting them of all real order.<br />
<span><strong>e-mail:</strong></span> yukis@cc.osaka-kyoiku.ac.jp</p>
"
S5,SC0009,2,Athul,Augustine,Athul Augustine,2025-06-24 13:30:00,MS29,Matrix functions and related topics,Tuesday,14:00,14:30,105,29,Composition operators and convexity of their Berezin range on functional Hilbert spaces,"<p>We discuss the convexity of the range of the Berezin transform.
Berezin range of a bounded linear operator <span
class=""math inline""><em>T</em></span> acting on a reproducing kernel
Hilbert space <span class=""math inline"">ℋ</span> is the set <span
class=""math inline""><em>B</em>(<em>T</em>)</span> := <span
class=""math inline"">{⟨<em>T</em><em>k̂</em><sub><em>x</em></sub>, <em>k̂</em><sub><em>x</em></sub>⟩<sub>ℋ</sub> : <em>x</em> ∈ <em>X</em>}</span>,
where <span class=""math inline""><em>k̂</em><sub><em>x</em></sub></span>
is the normalized reproducing kernel for <span
class=""math inline"">ℋ</span> at <span
class=""math inline""><em>x</em> ∈ <em>X</em></span>. The <em>numerical
range</em> of a bounded linear operator <span
class=""math inline""><em>T</em></span> on a Hilbert space <span
class=""math inline"">ℋ</span> is defined as <span
class=""math inline""><em>W</em>(<em>A</em>) := {⟨<em>T</em><em>u</em>, <em>u</em>⟩ : ∥<em>u</em>∥ = 1}.</span>
By Toeplitz-Hausdorff theorem, the numerical range of a linear operator
on a Hilbert space is always convex. It is easy to observe that the
Berezin range of an operator <span class=""math inline""><em>T</em></span>
is always a subset of the numerical range of <span
class=""math inline""><em>T</em></span>. In general, the Berezin range of
an operator is not convex. Primarily, we focus on characterizing
convexity of the Berezin range for classes of composition operators
acting on some functional Hilbert spaces.</p>
"
S5,SC0009,3,,,,2025-06-24 13:30:00,MS29,Matrix functions and related topics,Tuesday,14:30,15:00,105,29,,
S5,SC0009,4,,,,2025-06-24 13:30:00,MS29,Matrix functions and related topics,Tuesday,15:00,15:30,105,29,,
S5,SC0012,1,,,,2025-06-24 13:30:00,MS12,"Preserver problems, I",Tuesday,13:30,14:00,105,12,,
S5,SC0012,2,Ryotaro,Tanaka,Ryotaro Tanaka,2025-06-24 13:30:00,MS12,"Preserver problems, I",Tuesday,14:00,14:30,105,12,On homeomorphisms between geometric structure spaces of primitive $C^*$-algebras,"<p>The notion of geometric structure spaces of Banach spaces was
introduced for classifying non-smooth Banach spaces under Birkhoff-James
isomorphisms. The geometric structure space <span
class=""math inline"">𝔖(<em>X</em>)</span> of a Banach space <span
class=""math inline""><em>X</em></span> reflects the geometric features of
the unit ball <span
class=""math inline""><em>B</em><sub><em>X</em></sub></span> of <span
class=""math inline""><em>X</em></span>, and is equipped with a closure
operator which does not necessarily induce a topology. There is a
natural notion of homeomorphisms between (generalized) closure spaces.
Banach spaces <span class=""math inline""><em>X</em></span> and <span
class=""math inline""><em>Y</em></span> are said to have homeomorphic
geometric structure spaces, denoted by <span
class=""math inline""><em>X</em>∼<sub>𝔖</sub><em>Y</em></span>, if there
exists a homeomorphism between <span
class=""math inline"">𝔖(<em>X</em>)</span> and <span
class=""math inline"">𝔖(<em>Y</em>)</span>. The classification of Banach
spaces with respect to <span class=""math inline"">∼<sub>𝔖</sub></span> is
strictly coarser (and hence, the results are stronger) than that with
respect to the Birkhoff-James equivalence <span
class=""math inline"">∼<sub><em>B</em><em>J</em></sub></span>.</p>
<p>The purpose of this talk is to present a recent progress on the
theory of geometric structure spaces of <span
class=""math inline""><em>C</em><sup>*</sup></span>-algebras. In
particular, a description of homeomorphisms between the normal parts of
geometric structure spaces of <span
class=""math inline""><em>C</em><sup>*</sup></span>-algebras acting
irreducibly on Hilbert spaces is given.</p>
"
S5,SC0012,3,Shiho,Oi,Shiho Oi,2025-06-24 13:30:00,MS12,"Preserver problems, I",Tuesday,14:30,15:00,105,12,Periodic surjective isometries on Banach algebras,"<p>We study periodic surjective isometries on <span
class=""math inline""><em>C</em><sup>*</sup></span>-algebras. We establish
a relation between the complex spectrum of periodic surjective
isometries on Banach algebras and provide several examples that
illustrate the range of possibilities that can occur for the complex
spectrum of the isometry and classical spectrum of the Jordan <span
class=""math inline"">*</span>-isomorphism.</p>
"
S5,SC0012,4,Takeshi,Miura,Takeshi Miura,2025-06-24 13:30:00,MS12,"Preserver problems, I",Tuesday,15:00,15:30,105,12,Surjective isometries on Banach spaces with derivatives,"<p>We shall give the characterization of surjective, possibly nonlinear,
isometries from Banach spaces with derivatives. This unifies the former
results on isometries on the following Banach spaces:</p>
<ol>
<li><p><span class=""math inline""><em>C</em><sup>1</sup>([0, 1])</span>
of all continuously differentiable complex-valued functions on the
closed interval <span class=""math inline"">[0, 1]</span>.</p></li>
<li><p>The Banach space of all continuous extensions to <span
class=""math inline"">$\overline{\mathbb{D}}$</span>, the closure of the
open unit disc <span class=""math inline"">𝔻</span>, of all analytic
functions on <span class=""math inline"">𝔻</span>, which can be extended
to continuous functions on <span
class=""math inline"">$\overline{\mathbb{D}}$</span>.</p></li>
<li><p>The Banach space of all Gelfand transforms of analytic functions
on <span class=""math inline"">𝔻</span> whose derivatives are bounded on
<span class=""math inline"">𝔻</span>.</p></li>
</ol>
"
S5,SC0014,1,Riccardo,Morandin,Riccardo Morandin,2025-06-24 13:30:00,MS6,Model reduction,Tuesday,13:30,14:00,105,6,Structure-preserving model order reduction of linear time-varying port-Hamiltonian systems,"<p>Many physical processes can be naturally modeled using
port-Hamiltonian (pH) systems, which are inherently passive and stable,
and allow for structure-preserving interconnection, making them
particularly suitable for the modeling of complex networks. Furthermore,
many dedicated numerical methods have been developed to exploit and
preserve the structure of pH systems, e.g. for space- and
time-discretization, and model order reduction (MOR). In our work, we
focus on the structure-preserving MOR of linear time-varying (LTV) pH
systems. LTV systems appear quite naturally in many applications, e.g.
in the linearization of nonlinear systems around non-stationary
reference solutions, or when some of the system parameters are
time-dependent. In this talk we introduce a general approach based on
(Petrov)-Galerkin projection for the structure-preserving MOR of LTV-pH
systems. This includes (but is not limited to) the extension of the
effort constraint method to LTV-pH systems. Furthermore, we combine
balancing and projection to obtain a reduced model that is guaranteed to
be pH. We exhibit numerical experiments to validate our algorithms.</p>
"
S5,SC0014,2,Steffen W. R.,Werner,Steffen W. R. Werner,2025-06-24 13:30:00,MS6,Model reduction,Tuesday,14:00,14:30,105,6,Reduced-order modeling of mechanical systems via structured barycentric forms,"<p>Data-driven reduced-order modeling is an essential tool in
constructing high-fidelity compact models to approximate physical
phenomena when explicit models, such as state-space formulations with
access to internal variables, are not available yet abundant
input/output data are. When deriving models from theoretical principles,
the results typically contain differential structures that lead to
certain system properties. A common example are dynamical systems with
second-order time derivatives like <span class=""math display"">$$M
\ddot{x}(t) + D \dot{x}(t) + K x(t) = B u(t), \quad
  y(t) = C x(t),$$</span> arising in the modeling of mechanical or
electro-mechanical processes. In this case, data are often available in
the frequency domain, where the systems’ input-to-output behavior is
described by rational functions of the form <span
class=""math display""><em>H</em>(<em>s</em>) = <em>C</em>(<em>s</em><sup>2</sup><em>M</em> + <em>s</em><em>D</em> + <em>K</em>)<sup>−1</sup><em>B</em>,</span>
rather than differential equations. Classical frequency domain
approaches like the Loewner framework, vector fitting and AAA are
available and can be used to learn unstructured (first-order) models
from data. However, these models in their original formulation do not
reflect the structure-inherited properties. The key element in the
derivation of frequency domain approaches is the barycentric form of
rational functions. In this work, we present a structured extension of
the barycentric form for the case of mechanical systems. This structured
barycentric form is given by <span class=""math display"">$$\widehat{H}(s)
= \left(\sum_{j = 1}^k\frac{h_{j} w_{j}}{(s - \lambda_{j})
    (s - \sigma_{j})} \right) \left/ \left(1 + \sum_{j = 1}^{k}
    \frac{w_{j}}{(s - \lambda_{j})(s -
\sigma_{j})}\right)\right.;$$</span> see <span class=""citation""
data-cites=""WernerSWR_GosGW24""></span>. Building on this structured
rational function representation, we develop new algorithms for learning
reduced-order models of mechanical phenomena in the frequency domain,
while enforcing the mechanical system structure in the model
description.</p>
<div class=""thebibliography"">
<p><span>10</span> I. V. Gosea, S. Gugercin, and S. W. R. Werner.
Structured barycentric forms for interpolation-based data-driven reduced
modeling of second-order systems. , 50(2):26, 2024.
doi:10.1007/s10444-024-10118-7</p>
</div>
"
S5,SC0014,3,Zoran,Tomljanovic,Zoran Tomljanovic,2025-06-24 13:30:00,MS6,Model reduction,Tuesday,14:30,15:00,105,6,Efficient solution of sequences of parametrized Lyapunov equations with applications,"<p>The solutions of parametrized Lyapunov equations frequently serve as
intermediate steps in a broader procedure aimed at computing <span
class=""math inline""><em>t</em><em>r</em><em>a</em><em>c</em><em>e</em>(<em>E</em><em>X</em>)</span>,
where <span class=""math inline""><em>X</em></span> represents the
solution to the Lyapunov equation and <span
class=""math inline""><em>E</em></span> is a given matrix. Our focus is on
studying problems where the parameter dependence of the coefficient
matrix is encoded as a low-rank modification of a fixed, seed
matrix.<br />
We propose two novel numerical procedures that fully exploit such a
common structure. The first one builds upon the
Sherman-Morrison-Woodbury formula and recycling Krylov techniques, and
it is well-suited for small dimensional problems as it uses dense
numerical linear algebra tools. The second algorithm can instead address
large-scale problems by relying on state-of-the-art projection
techniques based on the extended Krylov subspace. We test the new
algorithms on several problems arising in studying damped vibrational
systems and analyzing output synchronization problems for multi-agent
systems. Our results show that the proposed algorithms are superior to
state-of-the-art techniques as they can remarkably speed up the
computation of accurate solutions.<br />
This is joint work with Davide Palitta, Ivica Nakić and Jens Saak.</p>
"
S5,SC0014,4,Robin,Armstrong,Robin Armstrong,2025-06-24 13:30:00,MS6,Model reduction,Tuesday,15:00,15:30,105,6,Identifying and estimating dynamical covariance matrices with hierarchical rank structure,"<p>Many algorithms in data assimilation and model reduction rely on
sample-based estimates for covariance matrices associated with the
trajectory of a high-dimensional dynamical system. The number of
available samples is often far less than the dimension of the underlying
state space, making it necessary to impose a regularizing structural
assumption such as spatial localization. This talk will examine the use
of hierarchical rank structure as a regularizing assumption for
high-dimensional covariance estimation. Whereas spatial localization
assumes that long-range correlations are near-zero, hierarchical rank
structure corresponds to the situation where long-range correlations
vary more smoothly than short-range ones. We will first examine, from
theoretical and empirical circumstances, the conditions under which this
assumption is appropriate. We will then present algorithms and
experiments which show how to estimate a high-dimensional covariance
matrix from limited samples by imposing hierarchical rank structure.
Covariance matrices associated with turbulent fluid dynamics, numerical
weather prediction models, and Lorenz-type systems will serve as
illustrative examples throughout.</p>
"
S5,SC1001,1,Susana,Furtado,Susana Furtado,2025-06-24 13:30:00,MS21,Linear algebra techniques in graph theory,Tuesday,13:30,14:00,105,21,Approximation of reciprocal matrices by consistent matrices,"<p>An <span class=""math inline""><em>n</em></span>-by-<span
class=""math inline""><em>n</em></span> matrix <span
class=""math inline""><em>A</em> = [<em>a</em><sub><em>i</em><em>j</em></sub>]</span>
is said to be a pairwise comparison matrix (PC matrix) or a reciprocal
matrix if it is positive and <span
class=""math inline"">$a_{ij}=\frac{1}{%
a_{ji}},$</span> for all <span
class=""math inline""><em>i</em>, <em>j</em> = 1, …, <em>n</em>.</span>
If, in addition, <span
class=""math inline""><em>a</em><sub><em>i</em><em>k</em></sub><em>a</em><sub><em>k</em><em>j</em></sub> = <em>a</em><sub><em>i</em><em>j</em></sub></span>
for all <span
class=""math inline""><em>i</em>, <em>j</em>, <em>k</em>,</span> the
matrix is said to be consistent. Such a matrix is of the form <span
class=""math inline""><em>w</em><em>w</em><sup>(−<em>T</em>)</sup></span>
for some positive vector <span class=""math inline""><em>w</em></span>, in
which <span
class=""math inline""><em>w</em><sup>(−<em>T</em>)</sup></span> is the
transpose of the entrywise inverse of <span
class=""math inline""><em>w</em></span>.</p>
<p>PC matrices play an important role in decision making, namely in
models for ranking alternatives, as the Analytic Hierarchy Process,
proposed by Saaty (1977). In these models, a PC matrix represents
independent, pairwise, ratio comparisons among <span
class=""math inline""><em>n</em></span> alternatives and a cardinal
ranking vector should be obtained from it. The consistent matrix
constructed from this vector should be a good approximation of the PC
matrix. So, it is desirable to choose a ranking vector from the set of
efficient vectors, as, otherwise, there would be a positive vector such
that the consistent matrix constructed from it better approximates the
PC matrix in at least one entry and is not worse in all other
entries.</p>
<p>It is known that a positive vector <span
class=""math inline""><em>w</em></span> is efficient for a PC matrix <span
class=""math inline""><em>A</em></span> if and only if a certain directed
graph associated with <span class=""math inline""><em>A</em></span> and
<span class=""math inline""><em>w</em></span> is strongly connected. Based
on this result, here we give a description of the set of efficient
vectors for a PC matrix as a union of a finite number of convex sets and
discuss some of its consequences. In particular, tight lower and upper
bound matrices for the consistent matrix constructed from an efficient
vector are given.</p>
<p>(This is a joint work with Charles Johnson.)</p>
"
S5,SC1001,2,Enide,Andrade,Enide Andrade,2025-06-24 13:30:00,MS21,Linear algebra techniques in graph theory,Tuesday,14:00,14:30,105,21,Doubly stochastic matrices and graphs,"<p>In this talk we present a study about inverses of modified Laplacian
matrices; the modification is by adding the identity matrix which gives
a positive definite matrix. We investigate the relationship between the
underlying graph and the properties of this inverse.</p>
"
S5,SC1001,3,Projesh Nath,Choudhury,Projesh Nath Choudhury,2025-06-24 13:30:00,MS21,Linear algebra techniques in graph theory,Tuesday,14:30,15:00,105,21,"Two invariants of distance matrices of trees, in a unified framework","<p>In 1971, Graham and Pollak showed that if <span
class=""math inline""><em>D</em><sub><em>T</em></sub></span> is the
distance matrix of a tree <span class=""math inline""><em>T</em></span> on
<span class=""math inline""><em>n</em></span> nodes, then <span
class=""math inline"">det (<em>D</em><sub><em>T</em></sub>)</span> depends
only on <span class=""math inline""><em>n</em></span>, not <span
class=""math inline""><em>T</em></span>. This independence from the tree
structure has been verified for many different variants of weighted
bi-directed trees. In my talk (over an arbitrary commutative ring):</p>
<ol>
<li><p>I will present a general setting which strictly subsumes every
known variant, and where we show that <span
class=""math inline"">det (<em>D</em><sub><em>T</em></sub>)</span> - as
well as another graph invariant, the cofactor-sum - depends only on the
edge-data, not the tree-structure.</p></li>
<li><p>More generally - even in the original unweighted setting - we
strengthen the state-of-the-art, by computing the minors of <span
class=""math inline""><em>D</em><sub><em>T</em></sub></span> where one
removes rows and columns indexed by equal-sized sets of pendant nodes.
(In fact, we go beyond pendant nodes.)</p></li>
<li><p>We explain why our result is the “most general possible”, in that
allowing greater freedom in the parameters leads to dependence on the
tree-structure.</p></li>
</ol>
<p>We will discuss related results for arbitrary strongly connected
graphs, including a third, novel invariant. If time permits, a formula
for <span
class=""math inline""><em>D</em><sub><em>T</em></sub><sup>−1</sup></span>
will be presented for trees <span class=""math inline""><em>T</em></span>,
whose special case answers an open problem of Bapat-Lal-Pati (Linear
Alg. Appl. 2006), and which extends to our general setting a result of
Graham-Lovasz (Advances in Math. 1978). (Joint with Apoorva Khare.)</p>
"
S5,SC1001,4,Madhab,Mondal,Madhab Mondal,2025-06-24 13:30:00,MS21,Linear algebra techniques in graph theory,Tuesday,15:00,15:30,105,21,A $q$-analogue of the distance matrix of a tree with matrix weights,"<p>A <span class=""math inline""><em>q</em></span>-analogue of the
distance matrix (called the <span
class=""math inline""><em>q</em></span>-distance matrix) of a tree was
introduced in [Bapat RB, Lal AK, Pati S. A <span
class=""math inline""><em>q</em></span>-analogue of the distance matrix of
a tree. Linear Algebra Appl. 2006;416(2-3):799–814]. It was formed from
the distance matrix <span class=""math inline""><em>D</em></span> by
substituting each entry <span
class=""math inline""><em>d</em>(<em>i</em>, <em>j</em>)</span> of <span
class=""math inline""><em>D</em></span> by <span
class=""math inline"">1 + <em>q</em> + ⋯ + <em>q</em><sup><em>d</em>(<em>i</em>, <em>j</em>) − 1</sup></span>.
In this article, we consider the <span
class=""math inline""><em>q</em></span>-distance matrix of a weighted
tree, where the edge weights are matrices of the same size. We deduce a
formula for the determinant of the <span
class=""math inline""><em>q</em></span>-distance matrix of a tree.
Subsequently, we present a necessary and sufficient condition for the
<span class=""math inline""><em>q</em></span>-distance matrix to be
invertible and derive an expression for the inverse whenever it exists.
The expression for the inverse of the <span
class=""math inline""><em>q</em></span>-distance matrix leads us to
introduce the <span class=""math inline""><em>q</em></span>-analogue of
the Laplacian matrix (named as the <span
class=""math inline""><em>q</em></span>-Laplacian matrix) for a tree with
matrix weights. A formula for the determinant of the <span
class=""math inline""><em>q</em></span>-Laplacian matrix is also provided.
Our results extend the existing results for the <span
class=""math inline""><em>q</em></span>-distance matrix of a weighted tree
when the weights are real numbers, as well as the distance matrix of a
tree with matrix weights (that can be obtained by setting <span
class=""math inline""><em>q</em> = 1</span>).</p>
"
S5,SC1003,1,Valerio,Loi,Valerio Loi,2025-06-24 13:30:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Tuesday,13:30,14:00,105,19,"Spectral analysis, approximation, and preconditioning for block structured matrix-sequences","<p>Large block-structured matrices with Toeplitz-type blocks of
different sizes frequently arise in various applications, but pose
computational issues when solving the associated linear systems. In our
setting, the matrices <span
class=""math inline""><em>A</em><sub><em>n</em></sub></span> are composed
of (block rectangular) Toeplitz blocks defined by rectangular <span
class=""math inline""><em>s</em> × <em>t</em></span> matrix-valued
generating functions, and can be viewed as a generalization of classical
GLT (Generalized Locally Toeplitz) sequences. Under mild assumptions on
the block dimensions, the asymptotic distribution of the singular values
of the associated matrix sequences is recently known. Moreover, when the
singular value symbol is Hermitian, the spectral symbol coincides with
the singular value symbol. Starting from the tools used to determine
this singular value distribution, we develop a general preconditioning
framework to construct simplified block matrices that approximate the
original matrices. These simplified matrices offer two key
advantages:<br />
1. They maintain the same singular value distributions as <span
class=""math inline"">{<em>A</em><sub><em>n</em></sub>}<sub><em>n</em></sub></span>;<br />
2. They enable the solution of linear systems in <span
class=""math inline"">𝒪(<em>n</em>log <em>n</em>)</span> arithmetic
operations.<br />
In this way, we propose a natural preconditioning strategy for linear
systems with coefficient matrix <span
class=""math inline""><em>A</em><sub><em>n</em></sub></span>. We provide
detailed singular value and spectral analyses of the preconditioned
matrix sequences and validate our approach through numerical experiments
concerning the convergence of various (preconditioned) Krylov
solvers.</p>
"
S5,SC1003,2,Sean,Hon,Sean Hon,2025-06-24 13:30:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Tuesday,14:00,14:30,105,19,An optimal preconditioned MINRES method for nonsymmetric multilevel block Toeplitz systems with applications,"<p>In this talk, we introduce a novel preconditioning strategy for
solving multilevel block Toeplitz systems, with applications to nonlocal
evolutionary fractional diffusion equations. We show that the Hermitian
part of certain nonsymmetric systems serves as an ideal preconditioner.
By transforming the nonsymmetric block Toeplitz system into a symmetric
block Hankel system using a symmetrization technique, we propose a
symmetric positive definite block Tau preconditioner that is efficiently
implemented using the discrete sine transform. We prove that this
approach enables mesh-size-independent convergence with eigenvalues of
the preconditioned matrices contained in specific intervals around <span
class=""math inline"">±1</span>. Numerical results will be presented to
demonstrate the method’s efficiency in terms of iterations and
computation time. This is joint work with Grigorios Tachyridis.</p>
"
S5,SC1003,3,Rosita Luisa,Sormani,Rosita Luisa Sormani,2025-06-24 13:30:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Tuesday,14:30,15:00,105,19,GLT-based preconditioning for nonsymmetric Toeplitz systems,"<p>Preconditioning for Toeplitz systems has been a prominent area of
research for several decades, with many efficient preconditioners
available in the real symmetric or Hermitian case. However, the real
nonsymmetric setting remains less explored due to the challenges
associated with analyzing the eigenvalues and, consequently, the
convergence behavior of iterative solvers. To address this, we employ a
symmetrization technique that permutes the coefficient matrix into a
real symmetric Hankel structure, whose eigenvalue distribution is known.
Then, by leveraging Generalized Locally Toeplitz (GLT) theory, we
develop a novel preconditioning strategy that involves centrosymmetric
preconditioners, such as those derived from the <span
class=""math inline""><em>τ</em></span> algebra. This approach constitutes
a general framework, as it relies solely on the generating function of
the Toeplitz matrix, provided that it is defined. We extend all
theoretical results to both the multilevel and block settings and
demonstrate their effectiveness through numerical experiments on
space-fractional diffusion equations, providing several examples to
critically evaluate the performance of the proposed preconditioners.</p>
<div class=""thebibliography"">
<p><span>2</span> C. Garoni, S. Serra-Capizzano, <em>Generalized locally
Toeplitz sequences: theory and applications, vol. II</em>. Springer,
Cham, 2018. S.Y. Hon, C. Li, R.L. Sormani, R. Krause, S.
Serra-Capizzano, <em>Symbol-based multilevel block <span
class=""math inline""><em>τ</em></span> preconditioners for multilevel
block Toeplitz systems: GLT-based analysis and applications</em>. SIAM
J. Matrix Anal. Appl., to appear</p>
</div>
"
S5,SC1003,4,Asim,Ilyas,Asim Ilyas,2025-06-24 13:30:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Tuesday,15:00,15:30,105,19,Quasi-boundary regularization for space-time fractional diffusion equations with variable coefficients,"<p>This work addresses the inverse problem of reconstructing a source
term in a space-time fractional diffusion equation with variable
coefficients, using final time observations and a quasi-boundary value
regularization method. The equation under consideration incorporates a
Caputo fractional derivative in space and a tempered fractional
derivative in time, both of order between 0 and 1. These types of
equations are particularly relevant in various applied fields. To
numerically approximate the regularized problem, we employ a finite
difference scheme, which results in a large-scale two-by-two block
linear system. The study presents theoretical insights into the spectral
properties of both non-preconditioned and preconditioned matrix
sequences, using tools from Toeplitz and Generalized Locally Toeplitz
(GLT) theory. Notably, the preconditioner, derived from the GLT
framework, is introduced and analyzed here for the first time in this
context. Numerical experiments are conducted to validate the theoretical
findings, followed by concluding remarks.</p>
"
S5,SC1005,1,Louis,Deaett,Louis Deaett,2025-06-24 13:30:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Tuesday,13:30,14:00,105,17,I love the triangle number!,"<p>A <em>zero-nonzero pattern</em> is a matrix with entries from the set
<span class=""math inline"">{0, *}</span>. The <em>triangle number</em> of
the pattern is the largest <span class=""math inline""><em>k</em></span>
such that some <span class=""math inline""><em>k</em> × <em>k</em></span>
submatrix is (up to permutation) triangular with only <span
class=""math inline"">*</span> entries on its diagonal.</p>
<p>A <em>realization</em> of the pattern over some field is a matrix
that can be obtained by replacing each <span
class=""math inline"">*</span> entry of the pattern with a nonzero value
from that field. The smallest rank of such a realization is the
<em>minimum rank</em> of the pattern (over that field). The triangle
number provides a natural and simple lower bound on this value.</p>
<p>This talk explores some different combinatorial angles on the
triangle number. For example, we review how the triangle number is
connected with the zero forcing number, both for simple graphs and
directed graphs. In fact, the bound it provides on the minimum rank of a
pattern is closely related to the bound given by the zero forcing number
on the maximum nullity of a graph; we see how, in certain special cases,
the relationship is especially strong. This also motivates the question
of Nordhaus-Gaddum type bounds for the triangle number, and we present
some recent results on this front. We also examine the triangle number
through the lens of lattice theory and matroid theory, where it provides
a lower bound on a related class of minimum rank problems for matroids,
one which can provide insights into the original minimum rank problem
for matrix patterns.</p>
"
S5,SC1005,2,Michael,Tait,Michael Tait,2025-06-24 13:30:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Tuesday,14:00,14:30,105,17,Extremal problems on graphs with $q=2$,"<p>For a graph <span class=""math inline""><em>G</em></span>, let <span
class=""math inline""><em>q</em>(<em>G</em>)</span> denote the minimum
number of distinct eigenvalues over all symmetric matrices with the same
zero/nonzero pattern as <span class=""math inline""><em>G</em></span>,
with the diagonal free (this family of matrices denoted <span
class=""math inline"">𝒮(<em>G</em>)</span>). A graph has <span
class=""math inline""><em>q</em>(<em>G</em>) = 2</span> if and only if
there is an orthogonal matrix in <span
class=""math inline"">𝒮(<em>G</em>)</span>. We discuss extremal problems
on graphs with <span
class=""math inline""><em>q</em>(<em>G</em>) = 2</span>. In particular we
consider how sparse such graphs or their complements can be.</p>
<p>This is joint work with Wayne Barrett, Shaun Fallat, Vera Furst,
Shahla Nasserasr, and Brendan Rooney.</p>
"
S5,SC1005,3,Aida,Abiad,Aida Abiad,2025-06-24 13:30:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Tuesday,14:30,15:00,105,17,Recent developments of switching methods for the construction of cospectral graphs,"<p>Switching is an operation on a graph that does not change the
spectrum of the adjacency matrix, thus producing cospectral graphs. An
important activity in the field of spectral graph theory is the
characterization of graphs by their spectrum. Hence, switching provides
a tool for disproving the existence of such a characterization.</p>
<p>In this talk we will overview recent progress on switching methods
for the construction of cospectral graphs. Work by Wang and Xu (2010)
suggests that most cospectral graphs with cospectral complements can be
constructed using regular orthogonal matrices of level 2, which has
relevance for Haemers’ conjecture. In this direction, we will present
two new switching methods based on regular orthogonal matrices of level
2. We will also show a general framework for counting the number of
graphs that have a non-isomorphic cospectral graph through any of the
existing switching methods for the adjacency matrix, expanding on the
work by Haemers and Spence (2004).</p>
<p>This is joint work with Nils van de Berg and Robin Simoens.</p>
"
S5,SC1005,4,Hermie,Monterde,Hermie Monterde,2025-06-24 13:30:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Tuesday,15:00,15:30,105,17,"Uniform mixing and apportionability
","<p>Let <span class=""math inline""><em>X</em></span> be a graph on <span
class=""math inline""><em>n</em></span> vertices with adjacency matrix
<span class=""math inline""><em>A</em></span>. A <em>quantum walk</em> on
<span class=""math inline""><em>X</em></span> is defined by the matrix
<span
class=""math display""><em>U</em>(<em>t</em>) = exp (i<em>t</em><em>A</em>),  <em>t</em> ∈ ℝ</span>
which is unitary for each <span
class=""math inline""><em>t</em> ∈ ℝ</span>. If we write <span
class=""math inline""><em>A</em> = <em>S</em><sup><em>T</em></sup><em>D</em><em>S</em></span>
where <span
class=""math inline""><em>D</em> = diag (<em>λ</em><sub>1</sub>, …, <em>λ</em><sub><em>n</em></sub>)</span>
is the diagonal matrix of eigenvalues of <span
class=""math inline""><em>A</em></span> and <span
class=""math inline""><em>S</em></span> is an orthogonal matrix, then the
above equation can be written as <span
class=""math display""><em>U</em>(<em>t</em>) = <em>S</em><sup><em>T</em></sup><em>e</em><sup>i<em>t</em><em>D</em></sup><em>S</em>,</span>
where <span
class=""math inline""><em>e</em><sup>i<em>t</em><em>D</em></sup> = diag (<em>e</em><sup>i<em>t</em><em>λ</em><sub>1</sub></sup>, …, <em>e</em><sup>i<em>t</em><em>λ</em><sub><em>n</em></sub></sup>)</span>.
We say that <span class=""math inline""><em>X</em></span> admits
<em>uniform mixing</em> at time <span
class=""math inline""><em>τ</em></span> if all entries of <span
class=""math inline""><em>U</em>(<em>τ</em>)</span> have equal magnitude.
Uniform mixing symbolizes maximal entanglement amongst all qubits in a
graph representing a quantum spin network - a phenomenon that is useful
in the theory of quantum information and computation.</p>
<p>To apportion a complex matrix means to apply a similarity so that all
entries of the resulting matrix have the same magnitude. The study of
matrix apportionment was initiated by Leslie and three of her
collaborators in a 2024 LAA paper. From (<a href=""#1""
data-reference-type=""ref"" data-reference=""1"">[1]</a>), the existence of
uniform mixing at time <span class=""math inline""><em>τ</em></span> is
equivalent to <span class=""math inline""><em>U</em>(<em>τ</em>)</span>
being apportionable.</p>
<p>In this talk, we survey old and new results on uniform mixing, and
explore its connections to matrix apportionment. Some results in this
talk are joint work with Steve Kirkland and Sarah Plosker.</p>
"
S5,SC2001,1,Soichi,Okada,Soichi Okada,2025-06-24 13:30:00,MS25,Enumerative/algebraic combinatorics and matrices,Tuesday,13:30,14:00,105,25,Bounded Littlewood identities for cylindric Schur functions and related combinatorics,"<p>The bounded Littlewood identities are determinant formulas for the
sum of Schur functions indexed by partitions with bounded height. These
have interesting combinatorial consequences involving standard Young
tableaux of bounded height. In this talk, we give affine analogs of the
bounded Littlewood identities, which are determinant formulas for sums
of cylindric Schur functions. As an application, we obtain equinumerous
results between cylindric standard Young tableaux and partial
matchings.</p>
<p>This talk is based on a joint work with JiSun Huh, Jang Soo Kim, and
Christian Krattenthaler.</p>
"
S5,SC2001,2,Harry,Richman,Harry Richman,2025-06-24 13:30:00,MS25,Enumerative/algebraic combinatorics and matrices,Tuesday,14:00,14:30,105,25,Principal minors of tree distance matrices,"<p>Suppose <span class=""math inline""><em>D</em></span> is the distance
matrix of a tree. Graham and Pollack showed that the determinant of
<span class=""math inline""><em>D</em></span> satisfies a surprising
identity that depends only on the number of vertices in the given tree.
We generalize this result to a combinatorial identity for the
determinant of any principal submatrix of <span
class=""math inline""><em>D</em></span>. This new identity involves counts
of spanning forests and is proved by use of potential-theoretic concepts
on graphs.</p>
"
S5,SC2001,3,Tian-Xiao,He,Tian-Xiao He,2025-06-24 13:30:00,MS25,Enumerative/algebraic combinatorics and matrices,Tuesday,14:30,15:00,105,25,High-order eulerian numbers and matrices,"<p>We study the properties of the higher-order Eulerian numbers and the
higher-order Eulerian matrices. The row generating functions and the row
sums of the higher-order Eulerian matrices are given. We also define
higher-order Eulerian fractions and their alternative forms. Some
properties of higher-order Eulerian fractions are expressed using
differentials and integrals. The inversion relationships between
second-order Eulerian numbers and Stirling numbers of the second and
first kinds are given. We also give exact expressions for the entries of
higher-order Eulerian matrices.</p>
"
S5,SC2001,4,Chi Ho,Yuen,Chi Ho Yuen,2025-06-24 13:30:00,MS25,Enumerative/algebraic combinatorics and matrices,Tuesday,15:00,15:30,105,25,The critical groups of hypercubes and beyond,"<p>The critical group of a graph <span
class=""math inline""><em>G</em></span> is the torsion part of the
cokernel of its Laplacian. It refines the number of spanning trees of
<span class=""math inline""><em>G</em></span> in an algebraic way and is
related to the chip-firing game (or abelian sandpile model) on <span
class=""math inline""><em>G</em></span>. In this talk, we survey several
results on the critical groups of the hypercube graphs and their
generalizations, including my works on Cayley graphs (joint with J. Gao,
J. Marx-Kuo, and V. McDonald) and Adinkras (partly joint with K. Iga, C.
Klivans, J. Kostiuk, and with K. Hung), which are decorated graphs
introduced by physicists to encode special supersymmetry algebras. The
emphasis will be on the novel algebraic techniques employed to prove
these results.</p>
"
S5,SC2006,1,Chun-Hao,Yang,Chun-Hao Yang,2025-06-24 13:30:00,MS32,Advances in matrix manifold optimization,Tuesday,13:30,14:00,105,32,Nested Grassmannians for dimensionality reduction with applications,"<p>In the recent past, nested structure of Riemannian manifolds has been
studied in the context of dimensionality reduction as an alternative to
the popular principal geodesic analysis (PGA) technique, for example,
the principal nested spheres. In this paper, we propose a novel
framework for constructing a nested sequence of homogeneous Riemannian
manifolds. Common examples of homogeneous Riemannian manifolds include
the spheres, the Stiefel manifolds, and the Grassmann manifolds. In
particular, we focus on applying the proposed framework to the Grassmann
manifolds, giving rise to the nested Grassmannians (NG). An important
application in which Grassmann manifolds are encountered is planar shape
analysis. Specifically, each planar (2D) shape can be represented as a
point in the complex projective space which is a complex Grassmann
manifold. Some salient features of our framework are: (i) it explicitly
exploits the geometry of the homogeneous Riemannain manifolds and (ii)
the nested lower-dimensional submanifolds need not be geodesic. With the
proposed NG structure, we develop algorithms for the supervised and
unsupervised dimensionality reduction problems respectively. The
proposed algorithms are compared with PGA via simulation studies and
real data experiments and are shown to achieve a higher ratio of
expressed variance compared to PGA.</p>
"
S5,SC2006,2,Anthony Man-Cho,So,Anthony Man-Cho So,2025-06-24 13:30:00,MS32,Advances in matrix manifold optimization,Tuesday,14:00,14:30,105,32,Randomized Riemannian submanifold subgradient method for optimization over Stiefel manifold,"<p>In this talk, we present the randomized Riemannian submanifold
subgradient method (RSSM), a lightweight “block-coordinate”-type
algorithm for weakly convex optimization over the Stiefel manifold. We
show that RSSM finds an <span
class=""math inline""><em>ϵ</em></span>-nearly stationary point in <span
class=""math inline""><em>O</em>(<em>ϵ</em><sup>−4</sup>)</span>
iterations. To the best of our knowledge, this is the first convergence
guarantee of a coordinate-type algorithm for tackling non-convex
non-smooth optimization over the Stiefel manifold.</p>
<p>This is joint work with Andy Yat-Ming Cheung, Jinxin Wang, and
Man-Chung Yue.</p>
"
S5,SC2006,3,Di,Hou,Di Hou,2025-06-24 13:30:00,MS32,Advances in matrix manifold optimization,Tuesday,14:30,15:00,105,32,,
S5,SC2006,4,Xiang,Lu,Xiang Lu,2025-06-24 13:30:00,MS32,Advances in matrix manifold optimization,Tuesday,15:00,15:30,105,32,,
S5,SC3001,1,Joe,Kileel,Joe Kileel,2025-06-24 13:30:00,MS18,New methods in numerical multilinear algebra,Tuesday,13:30,14:00,105,18,"Streaming data tensors efficiently and accurately
","<p>In this talk, I will present a new randomized method for maintaining
low-rank CP decompositions of tensorial data streams. Numerical results
indicate that the approach has acceptable computational costs at scale,
while singificantly improving accuracy and adaptivity to changes in the
data stream over existing methods. Joint work with Yifan Zhang (UT
Austin).</p>
"
S5,SC3001,2,JunJun,Pan,JunJun Pan,2025-06-24 13:30:00,MS18,New methods in numerical multilinear algebra,Tuesday,14:00,14:30,105,18,"The importance of linear algebra
","<p>Linear algebra is a fundamental branch of mathematics that underpins
numerous scientific and technological advancements. It provides
essential tools for solving systems of equations, transforming geometric
spaces, and analyzing data. With applications in engineering, computer
science, physics, economics, and machine learning, linear algebra plays
a crucial role in modern innovations, from image processing to
artificial intelligence.</p>
"
S5,SC3001,3,Longxiu,Huang,Longxiu Huang,2025-06-24 13:30:00,MS18,New methods in numerical multilinear algebra,Tuesday,14:30,15:00,105,18,,
S5,SC3001,4,Souad,Mohaoui,Souad Mohaoui,2025-06-24 13:30:00,MS18,New methods in numerical multilinear algebra,Tuesday,15:00,15:30,105,18,Tucker decomposition with temporal regularization for motion capture data completion,"<p>Tensor decompositions are powerful frameworks for analyzing
high-dimensional data by factorizing multi-way arrays into smaller,
interpretable components. In particular, Tucker decomposition has
emerged as a tool for modeling multi-dimensional data, helping to
uncover underlying patterns, especially in the presence of missing data.
In this study, we leverage Tucker decomposition for the completion of
motion capture (MoCap) data, which is inherently multi-dimensional and
characterized by complex temporal dependencies. MoCap data often suffers
from gaps due to missing markers during the recording process, leading
to the need for efficient and accurate gap-filling methods. We propose
two gap-filling algorithms based on Tucker decomposition: Tucker and
TuckerTNN. These methods exploit the low-rank properties of MoCap
tensors. To address the computational challenges associated with
traditional smoothness regularization, we introduce a temporal nuclear
norm regularization in the TuckerTNN model, which provides a more
efficient solution for large-scale MoCap datasets. We evaluate the
proposed algorithms using the publicly available HDM05 MoCap
dataset.</p>
"
S5,SC4011,1,Michele,Rinelli,Michele Rinelli,2025-06-24 13:30:00,MS23,Advances in Krylov subspace methods and their applications,Tuesday,13:30,14:00,105,23,Krylov techniques for estimating spectral gaps of sparse symmetric matrices,"<p>We propose and analyze an algorithm for identifying spectral gaps of
a real symmetric matrix <span class=""math inline""><em>A</em></span> by
simultaneously approximating the traces of spectral projectors
associated with multiple different spectral slices. Our method utilizes
Hutchinson’s stochastic trace estimator together with the Lanczos
algorithm to approximate quadratic forms involving spectral
projectors.<br />
Instead of focusing on determining the gap between two particular
consecutive eigenvalues of <span class=""math inline""><em>A</em></span>,
we aim to find all gaps that are wider than a specified threshold. By
examining the problem from this perspective, and thoroughly analyzing
both the Hutchinson and the Lanczos components of the algorithm, we
obtain error bounds that allow us to determine the numbers of
Hutchinson’s sample vectors and Lanczos iterations needed to ensure the
detection of all gaps above the target width with high
probability.<br />
We conclude that the most efficient strategy is to always use a single
random sample vector for Hutchinson’s estimator and concentrate all
computational effort in the Lanczos algorithm. Our numerical experiments
demonstrate the efficiency and reliability of this approach.</p>
"
S5,SC4011,2,Mariarosa,Mazza,Mariarosa Mazza,2025-06-24 13:30:00,MS23,Advances in Krylov subspace methods and their applications,Tuesday,14:00,14:30,105,23,Rational approximations of fractional power operators applied to preconditioning,"<p>In this talk, we consider the Riesz operator <span
class=""math inline"">$-(- \Delta)^{\frac{\alpha}{2}}$</span>, <span
class=""math inline""><em>α</em> ∈ (1, 2]</span>, which arises in
fractional models such as anomalous diffusion, and develop effective
preconditioners for its efficient numerical solution. First, we
approximate <span
class=""math inline"">$-(-\Delta)^{\frac{\alpha}{2}}$</span> as the
fractional power of a discretized Laplacian using the Matrix Transfer
Technique and represent the result in integral form via the
Dunford-Taylor integral representation. Various quadrature rules are
then explored to approximate the integral, leading to rational
approximations of the fractional power operator. This approach enables
us to construct preconditioners expressed as a sum of <span
class=""math inline""><em>m</em></span> inverses of shifted Laplacian
matrices, where <span class=""math inline""><em>m</em></span> depends on
the chosen quadrature scheme. For <span
class=""math inline""><em>α</em></span> close to <span
class=""math inline"">2</span>, it is well known that the Laplacian itself
serves as an effective preconditioner with linear computational cost.
However, as <span class=""math inline""><em>α</em></span> decreases toward
1, its performance deteriorates, requiring more specialized approaches.
Using Gauss-Jacobi quadrature, we show that our preconditioner
significantly improves performance for <span
class=""math inline""><em>α</em></span> close to <span
class=""math inline"">1</span>, even with a modest <span
class=""math inline""><em>m</em></span>, while maintaining the same
computational complexity as the Laplacian. To further enhance
efficiency, we investigate the use of exponentially convergent
quadrature rules to minimize the number of required inverses while
achieving optimal preconditioning performance. Specifically, we examine
both sinc and Gauss-Laguerre quadratures and demonstrate that, with
appropriate parameter tuning, both approaches outperform the
Gauss-Jacobi one, ensuring numerical optimality.</p>
"
S5,SC4011,3,Benjamin,Carrel,Benjamin Carrel,2025-06-24 13:30:00,MS23,Advances in Krylov subspace methods and their applications,Tuesday,14:30,15:00,105,23,"Low-rank exponential integrators leveraged by rational Krylov techniques
","<p>The numerical integration of stiff equations is a challenging problem
that needs to be approached by specialized numerical methods.
Exponential integrators form a popular class of such methods since they
are provably robust to stiffness and have been successfully applied to a
variety of problems. On the other hand, the dynamical low-rank
approximation is a recent technique for solving high-dimensional
differential equations by means of low-rank approximations. However, the
domain is lacking numerical methods for stiff equations since existing
methods are either not robust-to-stiffness or have unreasonably large
hidden constants.<br />
In this talk, we focus on solving large-scale stiff matrix differential
equations with a Sylvester-like structure, <span
class=""math display""><em>Ẋ</em>(<em>t</em>) = <em>A</em><em>X</em>(<em>t</em>) + <em>X</em>(<em>t</em>)<em>B</em> + <em>G</em>(<em>t</em>, <em>X</em>(<em>t</em>)),   <em>X</em><sub>0</sub> = <em>X</em>(0),</span>
that admit good low-rank approximations. We propose two new methods that
have good convergence properties, small memory footprints and that are
fast to compute. The theoretical analysis shows that the new methods
have order one and two, respectively. The efficient implementation of
the methods relies on the low-rank structure of the scheme leveraged by
rational Krylov techniques. The approximation error is analyzed, leading
to a priori error bounds and, therefore, a mean for choosing the size of
the Krylov space. Numerical experiments are performed on several
examples, confirming the theory and showing good speedup in comparison
to existing techniques.</p>
"
S5,SC4011,4,Yuwen,Li,Yuwen Li,2025-06-24 13:30:00,MS23,Advances in Krylov subspace methods and their applications,Tuesday,15:00,15:30,105,23,Reduced Krylov basis methods,"<p>The reduced basis method is the dominating numerical solver for a
family of parametrized PDEs. In this talk, I will present our new
reduced basis algorithm based on preconditioned Krylov subspace methods
such as the conjugate gradient method, generalized minimum residual
method, and bi-conjugate gradient method. The proposed methods use a
preconditioned Krylov subspace method for a high-fidelity discretization
of one parameter instance to generate orthogonal basis vectors of the
reduced basis subspace. Then the family of large-scale discrete
parameter-dependent problems are approximately solved in the
low-dimensional Krylov subspace. The material in my talk is based on
joint works with Ludmil Zikatanov and Cheng Zuo.</p>
"
S6,SC0008,1,Richard,Ellard,Richard Ellard,2025-06-24 16:00:00,MS24,Nonnegative and related families of matrices,Tuesday,16:00,16:30,106,24,Connecting the Hermite-Biehler theorem to the nonnegative inverse eigenvalue problem,"<p>The famous Hermite-Biehler Theorem (Hermite, 1856; Biehler, 1879)
states that a real polynomial <span
class=""math inline""><em>f</em>(<em>x</em>) = <em>p</em>(<em>x</em><sup>2</sup>) + <em>x</em><em>q</em>(<em>x</em><sup>2</sup>)</span>
is Hurwitz stable (all of the roots of <span
class=""math inline""><em>f</em></span> lie in the open left half-plane)
if and only if the leading coefficients of <span
class=""math inline""><em>p</em></span> and <span
class=""math inline""><em>q</em></span> have the same sign and all the
roots of <span
class=""math inline""><em>p</em>(−<em>x</em><sup>2</sup>)</span> and <span
class=""math inline""><em>x</em><em>q</em>(−<em>x</em><sup>2</sup>)</span>
are real and interlace. More generally, the number and relative
positions of the nonnegative roots of <span
class=""math inline""><em>p</em>(−<em>x</em>)</span> and <span
class=""math inline""><em>q</em>(−<em>x</em>)</span> determine the number
of roots of <span class=""math inline""><em>f</em></span> which lie in the
left (or right) half-plane. The <em>Nonnegative Inverse Eigenvalue
Problem</em> (NIEP) asks for a characterisation of those lists of
complex numbers which are <em>realisable</em> as the spectrum of some
(entrywise) nonnegative matrix. An important special case arises when
the Perron eigenvalue is the only root of the characteristic polynomial
<span class=""math inline""><em>f</em></span> in the right half-plane,
and, in this special case, a complete characterisation was given by
Laffey and Šmigoc (2006) which employed a rather long and technical
argument. By examining the relationship between the roots of <span
class=""math inline""><em>f</em></span> and those of <span
class=""math inline""><em>p</em></span> and <span
class=""math inline""><em>q</em></span> from a simple algorithmic
perspective, we give a new—and perhaps more elegant—proof of the
Laffey-Šmigoc characterisation which provides a deeper insight into the
result.</p>
"
S6,SC0008,2,Minnie,Catral,Minnie Catral,2025-06-24 16:00:00,MS24,Nonnegative and related families of matrices,Tuesday,16:30,17:00,106,24,Refined inertias of nonnegative patterns with positive off-diagonal entries,"<p>The <span><em>refined inertia</em></span> of an <span
class=""math inline""><em>n</em> × <em>n</em></span> matrix <span
class=""math inline""><em>A</em></span> is the 4-tuple <span
class=""math inline"">ri (<em>A</em>) = (<em>n</em><sub>+</sub>, <em>n</em><sub>−</sub>, <em>n</em><sub><em>z</em></sub>, 2<em>n</em><sub><em>p</em></sub>)</span>
where <span
class=""math inline""><em>n</em><sub>+</sub>, <em>n</em><sub>−</sub></span>
equal the number of eigenvalues of <span
class=""math inline""><em>A</em></span> with positive, negative
(respectively) real parts, <span
class=""math inline""><em>n</em><sub><em>z</em></sub></span> is the number
of eigenvalues of <span class=""math inline""><em>A</em></span> equal to
zero and <span
class=""math inline"">2<em>n</em><sub><em>p</em></sub></span> is the
number of nonzero pure imaginary eigenvalues of <span
class=""math inline""><em>A</em></span> (note that <span
class=""math inline""><em>n</em><sub>+</sub> + <em>n</em><sub>−</sub> + <em>n</em><sub><em>z</em></sub> + 2<em>n</em><sub><em>p</em></sub> = <em>n</em></span>).
We investigate refined inertias of nonnegative patterns with all
off-diagonal entries positive, <span
class=""math inline""><em>k</em> ∈ {0, …, <em>n</em>}</span> diagonal
entries positive and the remaining <span
class=""math inline""><em>n</em> − <em>k</em></span> diagonal entries
<span class=""math inline"">0</span>. The case <span
class=""math inline""><em>k</em> = <em>n</em></span> correspond to the
positive pattern and the case <span
class=""math inline""><em>k</em> = 0</span> correspond to the hollow
positive pattern. For the positive sign pattern, every refined inertia
<span
class=""math inline"">(<em>n</em><sub>+</sub>, <em>n</em><sub>−</sub>, <em>n</em><sub><em>z</em></sub>, 2<em>n</em><sub><em>p</em></sub>)</span>
with <span class=""math inline""><em>n</em><sub>+</sub> ≥ 1</span> can be
realized; for the hollow positive pattern, every refined inertia with
<span class=""math inline""><em>n</em><sub>+</sub> ≥ 1</span> and <span
class=""math inline""><em>n</em><sub>−</sub> ≥ 2</span> can be realized.
For the intermediate nonnegative patterns, that is, for <span
class=""math inline""><em>k</em> ∈ {1, …, <em>n</em> − 1}</span>, we show
that for <span class=""math inline""><em>k</em> ≥ 2</span>, there is no
restriction on <span class=""math inline""><em>n</em><sub>−</sub></span>
for the refined inertia set, but <span
class=""math inline""><em>n</em><sub>−</sub> ≥ 1</span> for <span
class=""math inline""><em>k</em> = 1</span>.</p>
<p>This talk is based on joint work with Adam Berliner, Dale Olesky and
Pauline van den Driessche.</p>
"
S6,SC0008,3,Shivaramakrishna,Pragada,Shivaramakrishna Pragada,2025-06-24 16:00:00,MS24,Nonnegative and related families of matrices,Tuesday,17:00,17:30,106,24,"Triangle counting and Bollob\'{a}s-Nikiforov conjecture.
","<p>Let <span class=""math inline""><em>G</em></span> be a graph with <span
class=""math inline""><em>n</em></span> vertices. Let <span
class=""math inline""><em>A</em>(<em>G</em>)</span> be its adjacency
matrix. Let <span
class=""math inline""><em>λ</em><sub>1</sub>(<em>G</em>), <em>λ</em><sub>2</sub>(<em>G</em>)</span>
denote the largest and second largest eigenvalues of the adjacency
matrix. Bollobás and Nikiforov (2007) conjectured that for any graph
<span
class=""math inline""><em>G</em> ≠ <em>K</em><sub><em>n</em></sub></span>
with <span class=""math inline""><em>m</em></span> edges <span
class=""math display"">$$\lambda_1^2+\lambda_2^2\le \bigg(
1-\frac{1}{\omega(G)}\bigg)2m$$</span> where <span
class=""math inline""><em>ω</em>(<em>G</em>)</span> denotes the clique
number of <span class=""math inline""><em>G</em></span>. In this talk, we
prove this conjecture for graphs with not so many triangles, using the
method of triangle counting. This is a joint work with Hitesh Kumar.</p>
"
S6,SC0008,4,Geir,Dahl,Geir Dahl,2025-06-24 16:00:00,MS24,Nonnegative and related families of matrices,Tuesday,17:30,18:00,106,24,Near-derangements and polytopes,"<p>A derangement is a permutation with no fixed point. This talk deals
with <span><em>near-derangements</em></span>, defined as permutations
with at most one fixed point. We present some properties of the
corresponding set of permutation matrices <span
class=""math inline"">𝒫<sub><em>n</em></sub><sup>( ≤ 1)</sup></span>.
Also, we briefly discuss the polytope determined by <span
class=""math inline"">𝒫<sub><em>n</em></sub><sup>( ≤ 1)</sup></span> and
the related polytope <span class=""math inline"">𝒫<sup>*</sup></span> of
all <span class=""math inline""><em>n</em> × <em>n</em></span> doubly
stochastic matrices with trace at most 1. In particular, all its extreme
points of <span class=""math inline"">𝒫<sup>*</sup></span> are determined.
This is joint work with Richard A. Brualdi.</p>
"
S6,SC0009,1,Davide,Bianchi,Davide Bianchi,2025-06-24 16:00:00,MS4,Linear algebra methods for inverse problems and data assimilation,Tuesday,16:00,16:30,106,4,,
S6,SC0009,2,Matthias,Chung,Matthias Chung,2025-06-24 16:00:00,MS4,Linear algebra methods for inverse problems and data assimilation,Tuesday,16:30,17:00,106,4,"Data-driven inverse problems via autoencoder
","<p>Emerging disciplines such as data analytics, machine learning, and
uncertainty quantification increasingly depend on efficient
computational techniques to address inverse problems. As models grow in
complexity and data volumes expand, existing state-of-the-art inference
methods are reaching their limitations, highlighting the urgent need for
novel approaches. Inverse problems in science and engineering remain
inherently challenging. While likelihood-free methods offer promising
alternatives to traditional inversion techniques, they often face
limitations in generalization and accuracy. In this work, we propose a
novel paired autoencoder framework as a likelihood-free estimator. Our
approach enables efficient solution generation, quality evaluation, and
iterative refinement. We demonstrate the effectiveness of the method
through applications to full waveform inversion and inverse
electromagnetic imaging.</p>
"
S6,SC0009,3,Jonas,Bresch,Jonas Bresch,2025-06-24 16:00:00,MS4,Linear algebra methods for inverse problems and data assimilation,Tuesday,17:00,17:30,106,4,Matrix-free stochastic calculation of operator norms without using adjoint---on the way to compute the adjoint mismatch,"<p>Linear inverse problems are of great interest in the last years. In
this talk, we investigate linear inverse problems where the adjoint of
the forward operator is not know exactly. Therefore, we focus on the
problem of computing the norm of an operator (between finite dimensional
Hilbert spaces), more precisely <span
class=""math inline"">∥<em>A</em>∥</span> respectively <span
class=""math inline"">∥<em>A</em> − <em>V</em>∥</span>, where only
evaluations of the linear map <span
class=""math inline""><em>x</em> ↦ <em>A</em><em>x</em></span>,
respectively and <span
class=""math inline""><em>y</em> ↦ <em>V</em><sup>*</sup><em>y</em></span>
are available with restrictive storage assumptions for the proposed
algorithm. We propose stochastic methods of random search type for the
maximization of the Rayleigh quotient respectively Rayleigh-like
quotient and employ exact line search in the random search directions.
Moreover, we can show that the proposed algorithms converge to the
global maximum (the operator norm) almost surely and illustrate the
performance of the method with numerical experiments. Furthermore, for
the latter problem we can prove a convergence rate.</p>
"
S6,SC0009,4,Tiangang,Cui,Tiangang Cui,2025-06-24 16:00:00,MS4,Linear algebra methods for inverse problems and data assimilation,Tuesday,17:30,18:00,106,4,"Tensor-train methods for sequential state and parameter estimation in state-space models
","<p>Numerous real-world applications require the estimation, forecasting,
and control of dynamic systems using incomplete and indirect
observations. These problems can be formulated as state-space models,
where the challenge lies in learning the model states and parameters
from observed data. We present new tensor-based sequential Bayesian
learning methods that jointly estimate parameters and states. Our
methods provide manageable error analysis and potentially mitigate the
particle degeneracy encountered in many particle-based approaches.
Besides offering new insights into algorithmic design, our methods
naturally incorporate conditional transports, enabling filtering,
smoothing, and parameter estimation within a unified framework.</p>
"
S6,SC0012,1,Man-Duen,Choi,Man-Duen Choi,2025-06-24 16:00:00,MS7,Linear algebra and quantum information science,Tuesday,16:00,16:30,106,7,,
S6,SC0012,2,Bing-Ze,Lu,Bing-Ze Lu,2025-06-24 16:00:00,MS7,Linear algebra and quantum information science,Tuesday,16:30,17:00,106,7,"Dynamic flows and iterative methods for identifying the Choi representation of an unknown quantum channel from partial data
","<p>Identifying quantum channels clarifies how quantum states evolve and
how information propagates. Because exact reconstruction is NP‑hard, we
focus on efficient numerical approximations.</p>
<p>Exploiting the unitary nature of channel dynamics, we cast the
problem on the Stiefel manifold—the intrinsic geometric space of real or
complex unitary matrices—to devise practical reconstruction
algorithms.</p>
<p><strong>Part I – Single-unitary channels</strong><br />
When the channel is generated by a single unitary operator, we combine
polar decomposition with manifold geometry to achieve exact recovery and
delineate the minimal data requirements.</p>
<p><strong>Part II – Multi-unitary channels</strong><br />
For channels expressible as convex mixtures of several unitaries, we
formulate a gradient‑flow scheme on the Stiefel manifold and prove
convergence guarantees, showcasing the method’s accuracy and
flexibility.</p>
"
S6,SC0012,3,Saptak,Bhattacharya,Saptak Bhattacharya,2025-06-24 16:00:00,MS7,Linear algebra and quantum information science,Tuesday,17:00,17:30,106,7,,
S6,SC0012,4,Shao-Hua,Hu,Shao-Hua Hu,2025-06-24 16:00:00,MS7,Linear algebra and quantum information science,Tuesday,17:30,18:00,106,7,,
S6,SC0014,1,Christopher,Beattie,Christopher Beattie,2025-06-24 16:00:00,MS6,Model reduction,Tuesday,16:00,16:30,106,6,Gaussian process regression for the identification of model dynamics,"<p>Standard approximation strategies for Gaussian Process Regression may
be linked with optimal spline approximation within the framework of a
reproducing kernel Hilbert space determined by a given covariance
function associated with a Bayesian prior. We extend this framework to
obtain optimal rational approximants (modeling rational transfer
functions) utilizing intrinsic Gaussian processes and Bayesian priors
that allow for data-driven modeling of dynamical systems with the
management of nonstationary temporal dependence, drift, and observation
errors. I will review elements of a basic framework for Gaussian Process
Regression and a version of “rational kriging” recently introduced by V.
R. Joseph, connecting this to optimal approximation in reproducing
kernel Hilbert spaces with rational kernels, paralleling traditional
Gaussian Process Regression approaches.</p>
"
S6,SC0014,2,,,,2025-06-24 16:00:00,MS6,Model reduction,Tuesday,16:30,17:00,106,6,,
S6,SC0014,3,,,,2025-06-24 16:00:00,MS6,Model reduction,Tuesday,17:00,17:30,106,6,,
S6,SC0014,4,,,,2025-06-24 16:00:00,MS6,Model reduction,Tuesday,17:30,18:00,106,6,,
S6,SC1001,1,Vanni,Noferini,Vanni Noferini,2025-06-24 16:00:00,MS14,"Pencils, polynomial, and rational matrices",Tuesday,16:00,16:30,106,14,Invertible bases and root vectors for analytic matrix-valued functions,"<p>I will revisit the notion of a minimal basis from the viewpoint of
the theory of modules over a commutative ring. I will define the concept
of an invertible basis and link it to the Main Theorem in the famous
paper [G. D. Forney Jr., SIAM J. Control 13, 493-520, 1975]. When the
underlying ring <span class=""math inline""><em>R</em></span> is an
elementary divisor domain, the submodules that have an invertible basis
are precisely the free pure submodules of <span
class=""math inline""><em>R</em><sup><em>n</em></sup></span>. As an
application, I will consider the ring <span class=""math inline"">𝒜</span>
of functions that are analytic on <span
class=""math inline""><em>Ω</em> ⊆ ℂ</span>, where <span
class=""math inline""><em>Ω</em></span> is either a connected compact set
or a connected open set. I will show that, for all matrices <span
class=""math inline""><em>M</em> ∈ 𝒜<sup><em>m</em> × <em>n</em></sup></span>,
<span class=""math inline"">ker <em>M</em> ∩ 𝒜<sup><em>n</em></sup></span>
is a free <span class=""math inline"">𝒜</span>-module that admits an
invertible basis, or equivalently a basis that is full rank upon
evaluation at every <span
class=""math inline""><em>λ</em> ∈ <em>Ω</em></span>. This provides a tool
to define maximal sets of root vectors at <span
class=""math inline""><em>λ</em></span>, and in particular to meaningfully
define eigenvectors also for analytic matrices that do not have full
rank.</p>
"
S6,SC1001,2,Steve,Mackey,Steve Mackey,2025-06-24 16:00:00,MS14,"Pencils, polynomial, and rational matrices",Tuesday,16:30,17:00,106,14,Sign characteristic in the inverse problem for Hermitian matrix polynomials,"<p>The sign characteristic is a structural feature of Hermitian matrix
polynomials that is important for both theory and applications. It
consists of a plus or minus sign associated to each elementary divisor
corresponding to a real or infinite eigenvalue; these <span
class=""math inline"">±</span> signs are invariants under unimodular
congruence. Motivated by the generic eigenstructure problem for
Hermitian matrix polynomials, it is natural to consider the special
scenario when all eigenvalues are simple. In this case these signs can
be naturally ordered to form a <em>sign sequence</em>. For an <span
class=""math inline""><em>n</em> × <em>n</em></span> Hermitian polynomial
of degree <span class=""math inline""><em>d</em></span> with <span
class=""math inline""><em>d</em><em>n</em></span> simple real eigenvalues,
for example, there are <span
class=""math inline"">2<sup><em>d</em><em>n</em></sup></span> possible
sign sequences. However, most of these sign sequences cannot be realized
by any degree <span class=""math inline""><em>d</em></span>  Hermitian
polynomial. Is it possible to characterize exactly which sign sequences
are realizable and which are not? And does the degree play any role in
the story?</p>
<p>This talk completely settles these questions, discussing several new
constraints on signs beyond the well-known signature constraint (1),
clarifying the dichotomy between even and odd degrees in the
characterization, as well as describing an underlying group of
symmetries on the collection of all sign sequences that sheds light on
the characterization question. In addition, this characterization of
realizable sign sequences enables a complete solution of the inverse
problem for Hermitian matrix polynomials of all degrees, albeit only in
the generic scenario when all eigenvalues are simple.</p>
<p>(1)<span>V. Mehrmann, V. Noferini, F. Tisseur, and H. Xu</span>,
<span><em>On the sign characteristics of Hermitian matrix
polynomials</em></span>, Linear Alg. App., 511 (2016), pp. 328–364.</p>
"
S6,SC1001,3,Punit,Sharma,Punit Sharma,2025-06-24 16:00:00,MS14,"Pencils, polynomial, and rational matrices",Tuesday,17:00,17:30,106,14,Eigenvalue backward errors of Rosenbrock systems,"<p>We address the problem of computing the eigenvalue backward error of
the Rosenbrock system matrix under various types of block perturbations.
We establish novel characterizations of these backward errors using a
class of minimization problems involving the Sum of Two generalized
Rayleigh Quotients (SRQ2). For computational purposes and analysis, we
reformulate such optimization problems as minimization of a rational
function over the joint numerical range of three Hermitian matrices.
This reformulation eliminates certain local minimizers of the original
SRQ2 minimization and allows for convenient visualization of the
solution. Furthermore, by exploiting the convexity within the joint
numerical range, we derive a characterization of the optimal solution
using a Nonlinear Eigenvalue Problem with eigenvector dependency (NEPv).
Our numerical experiments demonstrate the benefits and effectiveness of
the NEPv approach for SRQ2 minimization in computing eigenvalue backward
errors of Rosenbrock systems.</p>
"
S6,SC1001,4,Andrii,Dmytryshyn,Andrii Dmytryshyn,2025-06-24 16:00:00,MS14,"Pencils, polynomial, and rational matrices",Tuesday,17:30,18:00,106,14,Minimal indices through perturbation behavior,"<p>Computing the complete eigenstructure of matrix pencils is a
challenging problem. Small perturbations can change both the eigenvalues
with their multiplicities, as well as the minimal indices of a given
pencil. Recently, however, perturbation theory was used to compute
eigenvalues of singular matrix pencils. In this talk, we investigate how
the behavior of a general matrix pencil under small perturbations can
help determine its minimal indices.</p>
"
S6,SC1003,1,Roberto,Cavassi,Roberto Cavassi,2025-06-24 16:00:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Tuesday,16:00,16:30,106,19,Signal processing of spherical data. From real life to mathematical challenges,"<p>In signal processing the time-frequency analysis of nonlinear and
non-stationary processes, as well as the determination of the unknown
number of active sub-signals of a blind-source composite signal are, in
general, challenging inverse problem tasks. If we consider data sampled
on a sphere, things get even more complicated. This is the reason why
just a few techniques have been developed so far to study this kind of
data. However, many real-life data are of this nature, like in
Geophysics and Physics.</p>
<p>The idea is to extend the Iterative Filtering (IF) algorithm to work
on the sphere. IF is a non-stationary signal decomposition method
proposed a decade ago [1] to address the problem of extracting
time-varying oscillatory components from a non-stationary multicomponent
signal. This method proved to be really valuable in many applications,
see [2] and references therein, and it was accelerated in what is known
as Fast Iterative Filtering (FIF) [3] by leveraging the Toeplitz matrix
theory.</p>
<p>In this talk, we introduce the generalization of IF to handle
spherical data and show how we can address the question about its
convergence [4]. We conclude with some examples of application to
geophysical data.</p>
<p>This is joint work with <span><em>Giovanni Barbarino</em></span>,
<span><em>Roberto Cavassi</em></span>, <span><em>Wing S. Li</em></span>,
<span><em>Edward J. Timko</em></span>, <span><em>Haomin
Zhou</em></span>.</p>
<p>[1] L. Lin, Y. Wang, and H. Zhou. “Iterative filtering as an
alternative algorithm for empirical mode decomposition”. Adv. in Adap.
Data An., 2009, 1.04, 543-560.</p>
<p>[2] G. Barbarino, A. Cicone. “Conjectures on spectral properties of
ALIF algorithm”. Linear Algebra and its Applications, 2022, 647,
127–152.</p>
<p>[3] A. Cicone, H. Zhou. “Numerical Analysis for Iterative Filtering
with New Efficient Implementations Based on FFT”. Num. Math., 2021, 147
(1), 1–28.</p>
<p>[4] G. Barbarino, R. Cavassi, A. Cicone. Extension and convergence
analysis of Iterative Filtering to spherical data. Linear Algebra and
its Applications, 2024.</p>
"
S6,SC1003,2,,,,2025-06-24 16:00:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Tuesday,16:30,17:00,106,19,,
S6,SC1003,3,,,,2025-06-24 16:00:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Tuesday,17:00,17:30,106,19,,
S6,SC1003,4,David,Meadon,David Meadon,2025-06-24 16:00:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Tuesday,17:30,18:00,106,19,"Trace approximation using GLT theory and the matrix-less method
","<p>The theory of Generalised Locally Toeplitz (GLT) Sequences, see for
example <span class=""citation"" data-cites=""garoni171""></span>, has been
successfully used to study the spectra of different classes of
Toeplitz(-like) matrix sequences such as Hermitian, non-Hermitian,
block-valued, variable coefficient, etc. Specifically, it is a tool that
allows us to approximate the eigenvalues of Hermitian Toeplitz(-like)
matrices by sampling a function, called the symbol, using an equispaced
grid. GLT theory has also been extended to include the concept of
momentary symbols, that is, symbols which change depending on the size
of the matrix, see <span class=""citation""
data-cites=""Bolten2022""></span>. This is particularly useful in the case
of, for example, PDE discetisations of some operators which may have
some variety of grid size <span class=""math inline""><em>h</em></span> in
the symbol that would change depending on the matrix size, that is, it
would change with refinement. The Matrix-less method, see <span
class=""citation""
data-cites=""ekstrom2018matrix expmathmlm ekstromreal variablecoef""></span>,
aims to use the inherent structure of Toeplitz matrices to accurately
compute the spectrum of a much larger matrix in the sequence using a
number of (much) smaller matrices. It computes so called “higher-order”
symbols, and then using an interpolation-extrapolation scheme allow it
to approximate the eigenvalues with much higher accuracy. We show that
these methods, which approximate the eigenvalues of the operator, are
able to cheaply approximate the trace of different matrix functions
without having to actually construct the (potentially very large) matrix
or do any computations on it. We investigate computing the traces of
matrix functions such as <span
class=""math inline"">Tr(<em>e</em><sup>−<em>β</em><strong>A</strong></sup>), Tr(<strong>A</strong><em>e</em><sup>−<em>β</em><strong>A</strong></sup>),  − Tr(<strong>A</strong>log (<strong>A</strong>))</span>
and others, where <span class=""math inline""><strong>A</strong></span> is
the Toeplitz(-like) linear operator.</p>
"
S6,SC1005,1,Jephian C.-H.,Lin,Jephian C.-H. Lin,2025-06-24 16:00:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Tuesday,16:00,16:30,106,17,"Inverse fiedler vector problem of a graph
","<p>Given a graph and one of its weighted Laplacian matrix, a Fiedler
vector is an eigenvector with respect to the second smallest eigenvalue.
The Fiedler vectors have been used widely for graph partitioning, graph
drawing, spectral clustering, and suggesting the center of a network.
The inverse Fiedler vector problem studies the possible Fiedler vectors
for different weighted Laplacian matrices of a given graph. For a given
tree, we characterize all possible Fiedler vectors among its weighted
Laplacian matrix. As an application, the characteristic set can be
anywhere on a tree, except for the set containing a single leaf. For a
given cycle, we characterize all possible eigenvectors corresponding to
the second or the third smallest eigenvalue.</p>
"
S6,SC1005,2,Chassidy,Bozeman,Chassidy Bozeman,2025-06-24 16:00:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Tuesday,16:30,17:00,106,17,On the tree cover number and the positive semidefinite maximum nullity of a graph,"<p>Let <span
class=""math inline""><em>G</em> = (<em>V</em>, <em>E</em>)</span> be a
simple graph. A tree cover of <span
class=""math inline""><em>G</em></span> is a collection of vertex-disjoint
simple trees occurring as induced subgraphs of <span
class=""math inline""><em>G</em></span> that together cover all the
vertices of <span class=""math inline""><em>G</em></span>. The tree cover
number of <span class=""math inline""><em>G</em></span>, denoted <span
class=""math inline""><em>T</em>(<em>G</em>)</span>, is the minimum
cardinality of a tree cover. We give a characterization of connected
outerplanar graphs whose tree cover number equals the upper bound of
<span class=""math inline"">$\lceil \frac{n}{2} \rceil$</span>. We also
present results on tree cover number of graph with girth at least 5. In
2011, [Barioli et al., Minimum semidefinite rank of outerplanar graphs
and the tree cover number, <span><em>Elec. J. Lin. Alg.,</em></span>
2011] introduced the tree cover number as a tool for studying the
maximum nullity of a family of matrices associated with a graph: Let
<span class=""math inline"">𝒮<sub>+</sub>(<em>G</em>)</span> denote the
set of real positive semidefinite matrices <span
class=""math inline""><em>A</em> = (<em>a</em><sub><em>i</em><em>j</em></sub>)</span>
such that for <span class=""math inline""><em>i</em> ≠ <em>j</em></span>,
<span
class=""math inline""><em>a</em><sub><em>i</em><em>j</em></sub> ≠ 0</span>
if <span
class=""math inline"">{<em>i</em>, <em>j</em>} ∈ <em>E</em></span> and
<span
class=""math inline""><em>a</em><sub><em>i</em><em>j</em></sub> = 0</span>
if <span
class=""math inline"">{<em>i</em>, <em>j</em>} ∉ <em>E</em></span>. The
positive semidefinite maximum nullity of <span
class=""math inline""><em>G</em></span>, denoted <span
class=""math inline""><em>M</em><sub>+</sub>(<em>G</em>),</span> is <span
class=""math inline"">max {null(<em>A</em>)|<em>A</em> ∈ 𝒮<sub>+</sub>(<em>G</em>)}.</span>
It was conjectured in 2011 that <span
class=""math inline""><em>T</em>(<em>G</em>) ≤ M<sub>+</sub>(<em>G</em>)</span>
holds for all graphs, and shown that equality holds when <span
class=""math inline""><em>G</em></span> is outerplanar. Therefore our
bounds on <span class=""math inline""><em>T</em>(<em>G</em>)</span> give
bounds on <span
class=""math inline""><em>M</em><sub>+</sub>(<em>G</em>)</span> for
outerplanar graphs. We show that the conjecture <span
class=""math inline""><em>T</em>(<em>G</em>) ≤ <em>M</em><sub>+</sub>(<em>G</em>)</span>
is true for certain other graph families.</p>
"
S6,SC1005,3,Anzila,Laikhuram,Anzila Laikhuram,2025-06-24 16:00:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Tuesday,17:00,17:30,106,17,Inverse eigenvalue problem for discrete Schrödinger operators of a graph,"<p>The Inverse Eigenvalue Problem of a Graph (IEPG) determines whether a
set of real numbers can be realized as the spectrum of a real symmetric
matrix in <span class=""math inline"">𝒮(<em>G</em>)</span>, where <span
class=""math inline"">𝒮(<em>G</em>)</span> consists of symmetric matrices
associated with a graph <span class=""math inline""><em>G</em></span>,
having non-zero off-diagonal entries only for adjacent vertices.
Extending this, the Inverse Eigenvalue Problem for discrete Schrödinger
operators investigates if a given set of real numbers can be the
spectrum of a matrix in <span
class=""math inline"">$\ddot{\mathcal{S}}(G)$</span>, where off-diagonal
entries are negative for edges and zero otherwise, with unrestricted
diagonal entries. We begin with connected graphs on 4 vertices. For a
list of real numbers <span
class=""math inline""><em>λ</em><sub>1</sub> &lt; <em>λ</em><sub>2</sub> ≤ <em>λ</em><sub>3</sub> ≤ <em>λ</em><sub>4</sub></span>,
we determine if there exists a matrix in <span
class=""math inline"">$\ddot{\mathcal{S}}(G)$</span> with spectrum <span
class=""math inline"">{<em>λ</em><sub>1</sub>, <em>λ</em><sub>2</sub>, <em>λ</em><sub>3</sub>, <em>λ</em><sub>4</sub>}</span>
and the smallest eigenvalue simple. We identify feasible ordered
multiplicity lists, noting that not all are valid. Our investigation
extends to families of graphs such as paths (<span
class=""math inline""><em>P</em><sub><em>n</em></sub></span>), and
complete graphs (<span
class=""math inline""><em>K</em><sub><em>n</em></sub></span>). For <span
class=""math inline""><em>P</em><sub><em>n</em></sub></span>, any set of
<span class=""math inline""><em>n</em></span> distinct real numbers is
realizable as a spectrum in <span
class=""math inline"">$\ddot{\mathcal{S}}(P_n)$</span>. For <span
class=""math inline""><em>K</em><sub><em>n</em></sub></span>, any ordered
list <span
class=""math inline""><em>λ</em><sub>1</sub> &lt; <em>λ</em><sub>2</sub> ≤ … ≤ <em>λ</em><sub><em>n</em></sub></span>
is achievable.</p>
"
S6,SC1005,4,Derek,Young,Derek Young,2025-06-24 16:00:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Tuesday,17:30,18:00,106,17,Relationships between minimum rank problem parameters for cobipartite graphs,"<p>The minimum rank problem for zero-nonzero matrix patterns is to
determine the smallest rank of a matrix whose zero entries occur in
specified positions. Similarly, the minimum rank problem for a simple
graph is to find the smallest rank of a symmetric matrix whose
off-diagonal nonzero entries occur according to the edges of a given
graph. In each case, a fundamental combinatorial lower bound exists; for
the former, it is the triangle number of the pattern, while for the
latter it is the zero forcing number of the graph. For a given
zero-nonzero pattern, there exists an associated cobipartite graph. In
previous work, the minimum rank of the pattern and the maximum nullity
of its associated cobipartite graph were shown to obey a simple
relationship; each is equal to the number of vertices in the graph minus
the other. We show that the corresponding bounds (that of the triangle
number and the zero forcing number) obey this same relationship. This
forms a connection between the goal of understanding when the triangle
number is equal to the minimum rank of a pattern and that of determining
when the zero forcing number of a graph is equal to its maximum
nullity.</p>
"
S6,SC2001,1,Yi-Lin,Lee,Yi-Lin Lee,2025-06-24 16:00:00,MS25,Enumerative/algebraic combinatorics and matrices,Tuesday,16:00,16:30,106,25,"Domino tilings, domino shuffling, and the nabla operator","<p>In this talk, I will present a <span
class=""math inline""><em>q</em>, <em>t</em></span>-generalization of
domino tilings of certain regions <span
class=""math inline""><em>R</em><sub><em>λ</em></sub></span>, indexed by
partitions <span class=""math inline""><em>λ</em></span>, weighted
according to generalized area and dinv statistics. These statistics
arise from the <span
class=""math inline""><em>q</em>, <em>t</em></span>-Catalan combinatorics
and Macdonald polynomials. We present a formula for the generating
polynomial of these domino tilings in terms of the Bergeron–Garsia nabla
operator. When <span
class=""math inline""><em>λ</em> = (<em>n</em><sup><em>n</em></sup>)</span>
is a square shape, domino tilings of <span
class=""math inline""><em>R</em><sub><em>λ</em></sub></span> are
equivalent to those of the Aztec diamond of order <span
class=""math inline""><em>n</em></span>. In this case, we give a new
product formula for the resulting polynomials by domino shuffling and
its connection with alternating sign matrices. In particular, we obtain
a combinatorial proof of the joint symmetry of the generalized area and
dinv statistics. This is based on joint work with Ian Cavey.</p>
"
S6,SC2001,2,Lavanya,Selvaganesh,Lavanya Selvaganesh,2025-06-24 16:00:00,MS25,Enumerative/algebraic combinatorics and matrices,Tuesday,16:30,17:00,106,25,"Exploring graph characterization via specialized matrices
","<p>Combinatorial matrix theory has found applications in various fields,
particularly in spectral graph theory, which has many connections to
areas such as chemistry and network analysis. Some of the well-studied
objects in this context include the adjacency matrix, Laplacian matrix,
signless Laplacian, and distance matrix. More recently, since 2013 and
2021, the eccentricity and neighborhood matrices, respectively, have
garnered significant attention due to several influential articles. A
key aspect of spectral graph theory is identifying graphs that can be
characterized by their matrix spectrum. We will present recent
developments in the study of eccentricity and neighborhood matrices for
special classes of graphs, including products of graphs, regular graphs,
and multipartite graphs, among others.</p>
<p>The eccentricity matrix of a connected graph <span
class=""math inline""><em>G</em></span> is derived from its distance
matrix by retaining only the largest nonzero entries in each row and
column, setting all other entries to zero. This class of matrix was
introduced as an application of graph theory to chemical structures. It
is well known that, unlike the distance and the adjacency matrix, the
eccentricity matrix is not irreducible for all connected graphs, making
it an important problem to identify classes of graphs for which it is
irreducible. In this talk, we investigate various properties of
eccentricity matrix and their spectral characteristics. Expanding the
scope, we delve into the irreducibility and spectrum of eccentricity
matrix for some well-known families of <em>distance-regular
graphs</em>.</p>
<p>The neighborhood matrix <span
class=""math inline"">𝒩ℳ(<em>G</em>)</span> of a graph <span
class=""math inline""><em>G</em></span> is a graph matrix obtained by the
product of adjacency and the Laplacian matrix and is also defined using
the neighborhood sets of vertices of <span
class=""math inline""><em>G</em></span>. We show that the neighborhood
matrix of a connected graph is irreducible. We determine the <span
class=""math inline"">𝒩ℳ</span>-eigenvalues of a complete multipartite
graph and find that they are always real and non-positive. Moreover, the
<span class=""math inline"">𝒩ℳ</span>-energy of a complete multipartite
graph is twice the number of edges. Further, we show that no two
complete multipartite graphs are <span
class=""math inline"">𝒩ℳ</span>-cospectral.</p>
"
S6,SC2001,3,Bit-Shun,Tam,Bit-Shun Tam,2025-06-24 16:00:00,MS25,Enumerative/algebraic combinatorics and matrices,Tuesday,17:00,17:30,106,25,On the maximal $A_\alpha$-index of graphs with a prescribed number of edges,"<p>For any real number <span
class=""math inline""><em>α</em> ∈ [0, 1]</span>, by the <span> <em><span
class=""math inline""><em>A</em><sub><em>α</em></sub></span>-matrix</em></span>
of a graph <span class=""math inline""><em>G</em></span> we mean the
matrix <span
class=""math inline""><em>A</em><sub><em>α</em></sub>(<em>G</em>) = <em>α</em><em>D</em>(<em>G</em>) + (1 − <em>α</em>)<em>A</em>(<em>G</em>)</span>,
where <span class=""math inline""><em>A</em>(<em>G</em>)</span> and <span
class=""math inline""><em>D</em>(<em>G</em>)</span> are the adjacency
matrix and the diagonal matrix of vertex degrees of <span
class=""math inline""><em>G</em></span>, respectively. The largest
eigenvalue of <span
class=""math inline""><em>A</em><sub><em>α</em></sub>(<em>G</em>)</span>
is called the <span
class=""math inline""><em>A</em><sub><em>α</em></sub></span>-index of
<span class=""math inline""><em>G</em></span>. Chang and Tam (2023) have
solved the problem of determining graphs with maximal <span
class=""math inline""><em>A</em><sub><em>α</em></sub></span>-index over
<span class=""math inline"">𝒢(<em>n</em>, <em>m</em>)</span>, the class of
graphs with <span class=""math inline""><em>n</em></span> vertices and
<span class=""math inline""><em>m</em></span> edges, for <span
class=""math inline"">$\alpha \in [\frac{1}{2},1)$</span> and <span
class=""math inline"">1 ≤ <em>m</em> ≤ 2<em>n</em> − 3</span>. In the same
paper, they posed the problem of characterizing graphs in <span
class=""math inline"">𝒢(<em>n</em>, <em>m</em>)</span> that maximize the
<span class=""math inline""><em>A</em><sub><em>α</em></sub></span>-index
for <span class=""math inline"">$0&lt;
\alpha &lt; \frac{1}{2}$</span> and <span
class=""math inline""><em>m</em> ≤ <em>n</em> − 1</span>. In this work, it
is noted that, for any <span
class=""math inline""><em>α</em> ∈ [0, 1)</span>, the problem of
characterizing graphs with maximal <span
class=""math inline""><em>A</em><sub><em>α</em></sub></span>-index over
<span class=""math inline"">𝒢(<em>n</em>, <em>m</em>)</span> with <span
class=""math inline""><em>m</em> ≤ <em>n</em> − 1</span> is equivalent to
the problem of characterizing graphs with maximal <span
class=""math inline""><em>A</em><sub><em>α</em></sub></span>-index over
<span class=""math inline"">𝒮(<em>m</em>)</span>, the class of graphs with
<span class=""math inline""><em>m</em></span> edges. In connection with
the latter problem, we pose the following conjecture: Let <span
class=""math inline""><em>m</em> ≥ 3</span> be a positive integer and
suppose that <span class=""math inline"">$m={\binom{d}{2}}+t$</span> with
<span class=""math inline"">0 ≤ <em>t</em> &lt; <em>d</em></span>. There
exists a real number <span
class=""math inline""><em>α</em><sub>0</sub></span>, <span
class=""math inline"">$\alpha_0=\frac{1}{2}$</span> for <span
class=""math inline""><em>m</em> = 3</span> and <span
class=""math inline"">$\alpha_0\in [0,\frac{1}{2})$</span> for <span
class=""math inline""><em>m</em> ≥ 4</span>, such that for any <span
class=""math inline""><em>α</em> ∈ [0, 1)</span>, <span
class=""math inline""><em>C</em><sub><em>d</em> + 1</sub><sup><em>m</em></sup></span>
(replaced by <span
class=""math inline""><em>K</em><sub><em>d</em></sub></span>, in case
<span class=""math inline""><em>t</em> = 0</span>), where <span
class=""math inline""><em>C</em><sub><em>n</em></sub><sup><em>m</em></sup></span>
denotes the quasi-complete graph with <span
class=""math inline""><em>n</em></span> vertices and <span
class=""math inline""><em>m</em></span> edges, or <span
class=""math inline""><em>K</em><sub>1, <em>m</em></sub></span> is the
unique connected graph with <span class=""math inline""><em>m</em></span>
edges that maximize the <span
class=""math inline""><em>A</em><sub><em>α</em></sub></span>-index over
<span class=""math inline"">𝒮(<em>m</em>)</span>, depending on whether
<span
class=""math inline""><em>α</em> ∈ [0, <em>α</em><sub>0</sub>)</span> or
<span
class=""math inline""><em>α</em> ∈ (<em>α</em><sub>0</sub>, 1)</span>;
when <span
class=""math inline""><em>α</em> = <em>α</em><sub>0</sub></span>, there
are exactly two connected graphs that maximize the <span
class=""math inline""><em>A</em><sub><em>α</em></sub></span>-index over
<span class=""math inline"">𝒮(<em>m</em>)</span>, namely, <span
class=""math inline""><em>C</em><sub><em>d</em> + 1</sub><sup><em>m</em></sup></span>
(or <span class=""math inline""><em>K</em><sub><em>d</em></sub></span>, in
case <span class=""math inline""><em>t</em> = 0</span>) and <span
class=""math inline""><em>K</em><sub>1, <em>m</em></sub></span>. The
conjecture is established when <span
class=""math inline""><em>t</em> = 0</span>.</p>
<p> : Maximal <span
class=""math inline""><em>A</em><sub><em>α</em></sub></span>-index
problem; Maximal graph; Threshold graph; Neighborhood equivalence
classes; Quasi-complete graphs; Quasi-stars.</p>
<p>05C35, 05C50</p>
"
S6,SC2001,4,Yen-Jen,Cheng,Yen-Jen Cheng,2025-06-24 16:00:00,MS25,Enumerative/algebraic combinatorics and matrices,Tuesday,17:30,18:00,106,25,"On the maximal spectral radius of digraphs with a prescribed number of arcs
","<p>The spectral radius of a matrix is the largest magnitude of its
eigenvalues. The spectral radius of a graph is the spectral radius of
its adjacency matrix. It captures important structural information about
the graph and plays a key role in spectral graph theory. In this talk, I
will introduce a new approach to find upper bounds of the spectral
radius of a nonnegative matrix, and use it to identify the unique
digraph whose spectral radius is maximum among all digraphs with a
prescribed number of arcs. This result resolves a problem independently
posed by R. Brualdi and A. Hoffman, as well as F. Friedland, back in
1985.</p>
"
S6,SC2006,1,Jamie,Pommersheim,Jamie Pommersheim,2025-06-24 16:00:00,MS30,"Bohemian matrices: Theory, applications, and explorations",Tuesday,16:00,16:30,106,30,,
S6,SC2006,2,Laureano,Gonzalez-Vega,Laureano Gonzalez-Vega,2025-06-24 16:00:00,MS30,"Bohemian matrices: Theory, applications, and explorations",Tuesday,16:30,17:00,106,30,,
S6,SC2006,3,Eunice,Chan,Eunice Chan,2025-06-24 16:00:00,MS30,"Bohemian matrices: Theory, applications, and explorations",Tuesday,17:00,17:30,106,30,A divide-and-conquer framework for efficient algebraic linearizations of matrix polynomials,"<p>In this talk, we explore the integration of the divide-and-conquer
(dc) technique into the computation of eigenvalues for matrix
polynomials using algebraic linearizations. Algebraic linearizations
reduce a matrix polynomial <span
class=""math inline""><strong>P</strong>(<em>z</em>) ∈ ℂ[<em>z</em>]<sup><em>r</em> × <em>r</em></sup></span>
of degree <span class=""math inline""><em>s</em></span> into a generalized
eigenvalue problem of the form <span
class=""math display"">(<em>z</em><strong>D</strong><sub><strong>L</strong></sub> − <strong>L</strong>)<strong>v</strong> = <strong>0</strong> ,</span>
where <span
class=""math inline""><strong>D</strong><sub><strong>L</strong></sub></span>
is block diagonal, <span class=""math inline""><strong>L</strong></span>
is block upper Hessenberg, and <span
class=""math inline""><strong>P</strong>(<em>z</em>)</span> is
reconstructed through a resolvent representation: <span
class=""math display""><strong>P</strong>(<em>z</em>)<sup>−1</sup> = <strong>X</strong><sub><strong>L</strong></sub>(<em>z</em><strong>D</strong><sub><strong>L</strong></sub> − <strong>L</strong>)<sup>−1</sup><strong>Y</strong><sub><strong>L</strong></sub> .</span>
While algebraic linearizations offer a structured and efficient way to
solve polynomial eigenvalue problems, the resulting linearized systems
can become computationally demanding for large-scale problems. To
overcome this challenge, we incorporate the divide-and-conquer
technique, as outlined by Bini and Pan (1992), leveraging its ability to
break down eigenvalue computation into smaller, independent
subproblems.</p>
<p>We demonstrate how this integration facilitates the efficient
computation of eigenvalues for systems such as <span
class=""math display""><strong>h</strong>(<em>z</em>) = <em>z</em><strong>a</strong>(<em>z</em>)<strong>d</strong><sub>0</sub><strong>b</strong>(<em>z</em>) + <strong>c</strong><sub>0</sub> ,</span>
where <span class=""math inline""><strong>a</strong>(<em>z</em>)</span>
and <span class=""math inline""><strong>b</strong>(<em>z</em>)</span> are
matrix polynomials with their own linearizations. This combined approach
reduces computational complexity while maintaining numerical stability,
making it a scalable and practical solution for large-scale polynomial
eigenvalue problems. This talk will highlight the theoretical framework
and discuss how this integration enhances the efficiency and robustness
of algebraic linearizations.</p>
"
S6,SC2006,4,Geeta,Chowdhry,Geeta Chowdhry,2025-06-24 16:00:00,MS30,"Bohemian matrices: Theory, applications, and explorations",Tuesday,17:30,18:00,106,30,,
S6,SC3001,1,Shih-Feng,Shieh,Shih-Feng Shieh,2025-06-24 16:00:00,MS11,Structured matrix computations and its applications,Tuesday,16:00,16:30,106,11,,
S6,SC3001,2,Ching-Sung,Liu,Ching-Sung Liu,2025-06-24 16:00:00,MS11,Structured matrix computations and its applications,Tuesday,16:30,17:00,106,11,"An index search method for solving nonnegative least squares problems
","<p>We introduce a novel Index Search Method (ISM) for efficiently
solving Nonnegative Least Squares (NNLS) problems. ISM employs a
two-level iterative structure: an outer iteration that updates the
estimated index set of the nonzero components in the solution, and an
inner iteration that solves associated subproblems to refine the
solution within this index set. A key feature of ISM is that the
objective function value decreases monotonically across iterations,
ensuring that the index sets do not repeat and the optimal solution is
reached in finitely many steps. The dominant computational cost lies in
solving normal equations during the inner iterations. We also present
numerical results to demonstrate the efficiency and reliability of the
proposed method, supporting our theoretical findings.</p>
"
S6,SC3001,3,Yung-Ta,Li,Yung-Ta Li,2025-06-24 16:00:00,MS11,Structured matrix computations and its applications,Tuesday,17:00,17:30,106,11,"Factorizations of penalized differentiation matrices
","<p>To solve boundary value problems by pseudospectral methods with
penalty leads to penalized differentiation matrices. We had proposed a
factorization of the inverse of the penalized differentiation matrix in
2020. The factorization contains a tridiagonal matrix and is crucial in
solving Poisson’s equations. However, to solve 2D Poisson’s equations,
we aim to diagonalize the penalized differentiation matrix. Thus, we
propose a new factorization of the penalized differentiation matrix
containing a block diagonal matrix plus low ranks.</p>
"
S6,SC3001,4,Ching Kai,Lin,Ching Kai Lin,2025-06-24 16:00:00,MS11,Structured matrix computations and its applications,Tuesday,17:30,18:00,106,11,,
S6,SC4011,1,Igor,Simunec,Igor Simunec,2025-06-24 16:00:00,MS23,Advances in Krylov subspace methods and their applications,Tuesday,16:00,16:30,106,23,Lanczos with compression for symmetric matrix functions,"<p>In this talk we present a low-memory method for the approximation of
the action of a symmetric matrix function <span
class=""math inline""><em>f</em>(<em>A</em>)</span> on a vector <span
class=""math inline""><em>b</em></span>, where the matrix <span
class=""math inline""><em>A</em></span> is large and sparse. The algorithm
that we propose combines the Lanczos method for <span
class=""math inline""><em>f</em>(<em>A</em>)<em>b</em></span> with a basis
compression procedure involving rational Krylov subspaces, which is
employed whenever the basis grows beyond a certain size in order to
reduce memory usage. This method has essentially the same convergence
behaviour as Lanczos, with the addition of an error term that depends on
rational approximation of the function <span
class=""math inline""><em>f</em></span> and is typically negligible. The
cost of the basis compression procedure is also negligible with respect
to the cost of the Lanczos algorithm. In particular, the rational Krylov
subspaces used for the compression of the Lanczos basis are built using
small projected matrices, so their construction is cheap and does not
require the expensive solution of linear systems with the matrix <span
class=""math inline""><em>A</em></span>. Numerical experiments demonstrate
that our algorithm exhibits competitive performance when compared
against other low-memory methods for <span
class=""math inline""><em>f</em>(<em>A</em>)<em>b</em></span>.</p>
<p>[1] A. A. Casulli and I. Simunec, A low-memory Lanczos method with
rational Krylov compression for matrix functions, arXiv:2403.04390,
2024. To appear in SIAM J. Sci. Comput.</p>
"
S6,SC4011,2,Francesco,Hrobat,Francesco Hrobat,2025-06-24 16:00:00,MS23,Advances in Krylov subspace methods and their applications,Tuesday,16:30,17:00,106,23,Lanczos with compression for symmetric Lyapunov equations,"<p>In this work, we present a low-memory variant of the Lanczos
algorithm for the solution of the Lyapunov equation <span
class=""math display""><em>A</em><em>X</em> + <em>X</em><em>A</em> = <strong>c</strong><strong>c</strong><sup><em>T</em></sup>,</span>
where <span class=""math inline""><em>A</em></span> is a large-scale
symmetric positive-definite matrix and <span
class=""math inline""><strong>c</strong></span> is a vector.</p>
<p>The classical Lanczos method consists in building an orthonormal
basis <span
class=""math inline""><strong>Q</strong><sub><em>M</em></sub></span> for
the polynomial Krylov subspace <span
class=""math display"">𝒦<sub><em>M</em></sub>(<em>A</em>, <strong>c</strong>) = <em>s</em><em>p</em><em>a</em><em>n</em>(<strong>c</strong>, <em>A</em><strong>c</strong>, …, <em>A</em><sup><em>M</em> − 1</sup><strong>c</strong>)</span>
and in approximating the solution <span
class=""math inline""><em>X</em></span> with <span
class=""math inline""><strong>Q</strong><sub><em>M</em></sub><em>X</em><sub><em>M</em></sub><strong>Q</strong><sub><em>M</em></sub><sup><em>T</em></sup></span>,
where <span class=""math inline""><em>X</em><sub><em>M</em></sub></span>
solves the projected equation <span
class=""math display""><strong>Q</strong><sub><em>M</em></sub><sup><em>T</em></sup><em>A</em><strong>Q</strong><sub><em>M</em></sub><em>X</em><sub><em>M</em></sub> + <em>X</em><sub><em>M</em></sub><strong>Q</strong><sub><em>M</em></sub><sup><em>T</em></sup><em>A</em><strong>Q</strong><sub><em>M</em></sub> = ∥<strong>c</strong>∥<sub><em>F</em></sub><sup>2</sup><strong>e</strong><sub>1</sub><strong>e</strong><sub>1</sub><sup><em>T</em></sup>.</span>
The Lanczos algorithm often requires a relatively large <span
class=""math inline""><em>M</em></span> to obtain a good approximation of
the solution, which can lead to memory issues due to the storage demands
of <span
class=""math inline""><strong>Q</strong><sub><em>M</em></sub></span>.
Furthermore, the solution <span class=""math inline""><em>X</em></span>
can be well approximated by a low-rank matrix, whose rank is
significantly smaller than <span class=""math inline""><em>M</em></span>,
i.e. the dimension of the polynomial Krylov subspace.</p>
<p>An alternative approach is to use a rational Krylov subspace instead
of a polynomial one. Using the Zolotarev poles as the poles of the
rational Krylov subspace, it is possible to approximate the solution
<span class=""math inline""><em>X</em></span> by a low-rank matrix with
the guarantee that the residual has norm smaller than a prescribed
quantity [<span class=""math inline"">2</span>]. The rank of the computed
approximate solution is usually close to the numerical rank of the real
solution. The main drawback is that this method requires solving
multiple shifted linear systems involving the matrix <span
class=""math inline""><em>A</em></span>, which is prohibitive if <span
class=""math inline""><em>A</em></span> is large.</p>
<p>Mimicking the approach in [<span class=""math inline"">3</span>], our
method employs a polynomial Krylov subspace to approximate the solution
of <a href=""#eqn:lyap"" data-reference-type=""eqref""
data-reference=""eqn:lyap"">[eqn:lyap]</a> while leveraging rational
Krylov subspaces associated with small matrices to compress the Lanczos
basis. This method accesses <span class=""math inline""><em>A</em></span>
only through matrix-vector products and requires the storage of only a
few vectors from the polynomial Krylov subspace instead of the entire
Lanczos basis, producing an approximate solution whose rank is
independent of the dimension of the involved polynomial Krylov
subspace.</p>
<p>The computational cost of the proposed algorithm is dominated by the
construction of the Lanczos basis, and the compression steps do not
require additional matrix-vector products involving <span
class=""math inline""><em>A</em></span>. Furthermore, theoretical results
demonstrate that the algorithm achieves an approximation error
comparable to that of the standard Lanczos algorithm, with an additional
error term that can be bounded a priori using Zolotarev numbers. In
practice, this additional error is negligible compared to the Lanczos
error.</p>
<p>Numerical experiments show that the behavior of the proposed
algorithm is comparable to that of the Lanczos algorithm without
reorthogonalization, both in terms of matrix-vector products and quality
of the approximated solution. Comparisons with existing low-memory
variants of the Lanczos method demonstrate competitive performance in
terms of accuracy, computational cost, and runtime.</p>
<ul>
<li><p>A. A. Casulli, F. H., D. Kressner, Lanczos with Rational Krylov
compression for symmetric Lyapunov equations, In preparation.</p></li>
<li><p>B. Beckermann, An error analysis for rational Galerkin projection
applied to the Sylvester equation, SIAM J. Numer. Anal., 49 (2011), pp.
2430–2450.</p></li>
<li><p>A. A. Casulli and I. Simunec. A low-memory Lanczos method with
rational Krylov compression for matrix functions, arXiv, 2024.</p></li>
</ul>
"
S6,SC4011,3,Fabio,Durastante,Fabio Durastante,2025-06-24 16:00:00,MS23,Advances in Krylov subspace methods and their applications,Tuesday,17:00,17:30,106,23,"Krylov: better, faster, parallel","<p>Krylov subspace methods are indispensable for addressing a wide array
of challenges in sparse and large-scale linear algebra. They are pivotal
in solving large, sparse linear systems <span
class=""math inline""><em>A</em><strong>x</strong> = <strong>b</strong></span>,
computing select eigenvalues and eigenvectors of expansive sparse
matrices <span
class=""math inline""><em>A</em><strong>v</strong> = <em>λ</em><strong>v</strong></span>,
evaluating matrix-function vector products <span
class=""math inline""><strong>y</strong> = <em>f</em>(<em>A</em>)<strong>x</strong></span>,
and resolving linear matrix equations with low-rank right-hand sides
<span
class=""math inline""><em>A</em><em>X</em> + <em>X</em><em>B</em><sup><em>T</em></sup> = <em>U</em><em>V</em><sup><em>T</em></sup></span>.
In contemporary computational science, “large-scale” denotes problems
involving sparse matrices with millions to billions of unknowns.
Addressing such complexities necessitates leveraging supercomputers and
implementing distributed-memory versions of Krylov-based algorithms. The
Parallel Sparse Computation Toolkit (PSCToolkit) is a comprehensive
software framework designed to tackle these challenges. It offers
modular components for managing distributed sparse matrices and
executing sparse matrix computations across various hybrid
architectures, from small servers to high-end supercomputers equipped
with multicore CPUs and NVIDIA GPUs. PSCToolkit’s design emphasizes
node-level efficiency, flexibility, and usability, supporting
integration with both Fortran and C/C++ applications. In this
presentation, I will delve into the implementation nuances of Krylov
subspace methods within distributed computing environments, focusing on
the capabilities and structure of PSCToolkit. Furthermore, I will
showcase scalability results and performance benchmarks achieved on
supercomputers that integrate multicore processors and GPU accelerators,
demonstrating PSCToolkit’s efficacy in harnessing the computational
power of modern heterogeneous systems.</p>
"
S6,SC4011,4,Stefano,Massei,Stefano Massei,2025-06-24 16:00:00,MS23,Advances in Krylov subspace methods and their applications,Tuesday,17:30,18:00,106,23,Error formulas for block rational Krylov approximations of matrix functions,"<p>We investigate explicit expressions for the error associated with the
block rational Krylov approximation of matrix functions. Two formulas
are proposed, both derived from characterizations of the block FOM
residual. The first formula employs a block generalization of the
residual polynomial, while the second leverages the block collinearity
of the residuals. A posteriori error bounds based on the knowledge of
spectral information of the argument are derived and tested on a set of
examples. Notably, both error formulas and their corresponding upper
bounds do not require the evaluation of contour integrals.</p>
"
S7,SC0008,1,,,,2025-06-25 10:30:00,,,Wednesday,10:30,11:00,107,1000,,
S7,SC0008,2,,,,2025-06-25 10:30:00,,,Wednesday,11:00,11:30,107,1000,,
S7,SC0008,3,,,,2025-06-25 10:30:00,,,Wednesday,11:30,12:00,107,1000,,
S7,SC0009,1,Brooke,Randell,Brooke Randell,2025-06-25 10:30:00,MS33,"Norms of matrices, numerical range, applications of functional analysis to matrix theory",Wednesday,10:30,11:00,107,33,Exploring the numerical range of block Toeplitz operators,"<p>We will discuss the numerical range of a family of Toeplitz operators
with symbol function <span
class=""math inline""><em>ϕ</em>(<em>z</em>) = <em>A</em><sub>0</sub> + <em>z</em><em>A</em><sub>1</sub></span>,
where <span class=""math inline""><em>A</em><sub>0</sub></span> and <span
class=""math inline""><em>A</em><sub>1</sub></span> are <span
class=""math inline"">2 × 2</span> matrices with complex-valued entries. A
special case of a result proved by Bebiano and Spitkovsky in 2011 states
that the closure of the numerical range of the Toeplitz operator <span
class=""math inline""><em>T</em><sub><em>ϕ</em>(<em>z</em>)</sub></span>
is the convex hull of <span
class=""math inline"">{<em>W</em>(<em>ϕ</em>(<em>z</em>)) : <em>z</em> ∈ ∂𝔻}</span>.
Here, <span
class=""math inline""><em>W</em>(<em>ϕ</em>(<em>z</em>))</span> denotes
the numerical range of <span
class=""math inline""><em>ϕ</em>(<em>z</em>)</span>. We combine this
result with the envelope algorithm to describe the boundary of the
convex hull of <span
class=""math inline"">{<em>W</em>(<em>ϕ</em>(<em>z</em>)) : <em>z</em> ∈ ∂𝔻}</span>.
We also place specific conditions on the matrices <span
class=""math inline""><em>A</em><sub>0</sub></span> and <span
class=""math inline""><em>A</em><sub>1</sub></span> so that <span
class=""math inline"">{<em>W</em>(<em>ϕ</em>(<em>z</em>)) : <em>z</em> ∈ ∂𝔻}</span>
is a set of potentially degenerate circular disks. The convex hull of
<span
class=""math inline"">{<em>W</em>(<em>ϕ</em>(<em>z</em>)) : <em>z</em> ∈ ∂𝔻}</span>
takes on a wide variety of shapes, including the convex hull of
limaçons.</p>
"
S7,SC0009,2,Dragana,Cvetkovic Ilic,Dragana Cvetkovic Ilic,2025-06-25 10:30:00,MS33,"Norms of matrices, numerical range, applications of functional analysis to matrix theory",Wednesday,11:00,11:30,107,33,Similarities between the numerical range of an operator and of certain generalized inverses,"<p>In this talk we will consider the different properties of the
numerical range for a bounded linear operator from the point of view of
its similarities to the numerical range of certain generalized inverses
such as the Moore-Penrose inverse, Drazin inverse, DMP-inverse,
MDP-inverse and CMP-inverse. We will discuss the question whether the
numerical ranges of an operator and its certain generalized inverse
simultaneously contain the origin as well as whether this is true in the
case of the closure, boundary, extreme points and sharp points of the
corresponding numerical ranges. To illustrate our results we will
exhibit some numerical examples.</p>
"
S7,SC0009,3,Jani A.,Virtanen,Jani A. Virtanen,2025-06-25 10:30:00,MS33,"Norms of matrices, numerical range, applications of functional analysis to matrix theory",Wednesday,11:30,12:00,107,33,,
S7,SC0012,1,Bojan,Kuzma,Bojan Kuzma,2025-06-25 10:30:00,MS35,"Preserver Problems, II",Wednesday,10:30,11:00,107,35,On bijections which strongly preserve Birkhoff-James orthogonality on finite-dimensional $C^*$-algebras,"<p>We classify bijections which in both directions preserve
Birkhoff-James orthogonality on finite-dimensional <span
class=""math inline""><em>C</em><sup>*</sup></span>-algebras. It turns out
that such maps are real-linear isometries multiplied by a central-valued
(possibly nonlinear) function. The result differs from smooth normed
spaces, where every such preserver is a (conjugate)linear isometry
multiplied by a scalar-valued function. Our main technique is using left
symmetric elements, relative to Birkhoff-James orthogonality, of certain
subspaces.</p>
<p>This is a joint work With Srdjan Stefanović</p>
"
S7,SC0012,2,Daisuke,Hirota,Daisuke Hirota,2025-06-25 10:30:00,MS35,"Preserver Problems, II",Wednesday,11:00,11:30,107,35,Tingley's problem concerning the direct sum of extremely C-regular subspaces with the $\ell^p$-norm.,"<p>Tingley’s problem asks whether every surjective isometry between the
unit spheres of two Banach spaces can be extended to a surjective
real-linear between the whole spaces. Let <span
class=""math inline"">{<em>A</em><sub><em>λ</em></sub>}<sub><em>λ</em> ∈ <em>Λ</em></sub></span>
be a family of uniformly closed, extremely C-regular subspaces, and let
<span class=""math inline""><em>p</em></span> be a real number such that
<span class=""math inline"">1 &lt; <em>p</em> &lt; ∞</span> with <span
class=""math inline""><em>p</em> ≠ 2</span>. We denote by <span
class=""math inline""><em>A</em><sub><em>Λ</em></sub><sup><em>p</em></sup></span>
the Banach space of formed by the direct sum of <span
class=""math inline"">{<em>A</em><sub><em>λ</em></sub>}<sub><em>λ</em> ∈ <em>Λ</em></sub></span>
equipped with the norm <span
class=""math inline"">∥<strong>f</strong>∥<sub><em>p</em></sub> = (∑<sub><em>λ</em> ∈ <em>Λ</em></sub>∥<strong>f</strong><sub><em>λ</em></sub>∥<sub>∞</sub><sup><em>p</em></sup>)<sup>1/<em>p</em></sup></span>
for <span
class=""math inline""><strong>f</strong> ∈ <em>A</em><sub><em>Λ</em></sub><sup><em>p</em></sup></span>.<br />
In this presentation, I will speak on the fact that if <span
class=""math inline""><em>Δ</em></span> is a surjective isometry between
two unit spheres <span
class=""math inline""><em>S</em>(<em>A</em><sub><em>M</em></sub><sup><em>p</em></sup>)</span>
and <span
class=""math inline""><em>S</em>(<em>A</em><sub><em>N</em></sub><sup><em>p</em></sup>)</span>
of the Banach spaces <span
class=""math inline""><em>A</em><sub><em>M</em></sub><sup><em>p</em></sup></span>
and <span
class=""math inline""><em>A</em><sub><em>N</em></sub><sup><em>p</em></sup></span>,
then <span class=""math inline""><em>Δ</em></span> admits an extension to
a surjective real-linear isometry between the whole spaces.</p>
"
S7,SC0012,3,Izuho,Matsuzaki,Izuho Matsuzaki,2025-06-25 10:30:00,MS35,"Preserver Problems, II",Wednesday,11:30,12:00,107,35,,
S7,SC0014,1,Raymond Nung-Sing,Sze,Raymond Nung-Sing Sze,2025-06-25 10:30:00,MS8,Tensor and quantum information science,Wednesday,10:30,11:00,107,8,"Characterizing high Schmidt number witnesses in arbitrary dimensions system
","<p>In this talk, we will present an efficient analytical tool for
characterizing high Schmidt number witnesses for bipartite quantum
states in arbitrary dimensions. Our methods not only offer viable
mathematical methods for constructing high-dimensional Schmidt number
witnesses in theory but also simplify the quantification of entanglement
and dimensionality. Most notably, we develop high-dimensional Schmidt
number witnesses within arbitrary-dimensional systems, with our Schmidt
witness coefficients relying solely on the operator Schmidt
coefficient.</p>
"
S7,SC0014,2,Jeroen,Zuiddam,Jeroen Zuiddam,2025-06-25 10:30:00,MS8,Tensor and quantum information science,Wednesday,11:00,11:30,107,8,,
S7,SC0014,3,Seung-Hyeok,Kye,Seung-Hyeok Kye,2025-06-25 10:30:00,MS8,Tensor and quantum information science,Wednesday,11:30,12:00,107,8,"Global locations of Schmidt number witnesses
","<p>We investigate global locations of Schmidt number witnesses which are
outside of the convex set of all bi-partite states. Their locations are
classified by interiors of faces of the convex set of all states, by
considering the line segments from them to the maximally mixed state. In
this way, a nonpositive Hermitian matrix of trace one is located outside
of one and only one face. Faces of the convex set of all states are
classified by subspaces, which are range spaces of states belonging to
specific faces. For a given subspace, we show that there exist Schmidt
number <span class=""math inline""><em>k</em> + 1</span> witnesses outside
of the face arising from this subspace if and only if every vector in
the orthogonal complement of the subspace has Schmidt rank greater than
<span class=""math inline""><em>k</em></span>. Once we have Schmidt number
<span class=""math inline""><em>k</em> + 1</span> witnesses outside of a
face, we also have Schmidt number <span
class=""math inline"">2, 3, …, <em>k</em></span> witnesses outside of the
face.</p>
"
S7,SC1001,1,Milán,Mosonyi,Milán Mosonyi,2025-06-25 10:30:00,MS10,Matrix means and related topics,Wednesday,10:30,11:00,107,10,,
S7,SC1001,2,Trung Hoa,Dinh,Trung Hoa Dinh,2025-06-25 10:30:00,MS10,Matrix means and related topics,Wednesday,11:00,11:30,107,10,Operator means and quantum divergences,"<p>In this talk, we will explore the use of operator means to construct
new quantum divergences. We will also examine the least squares problem
in the context of various quantum divergences. Additionally, we will
discuss some applications and highlight open questions in this area.</p>
"
S7,SC1001,3,Tin-Yau,Tam,Tin-Yau Tam,2025-06-25 10:30:00,MS10,Matrix means and related topics,Wednesday,11:30,12:00,107,10,,
S7,SC1003,1,Dario,Giandinoto,Dario Giandinoto,2025-06-25 10:30:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Wednesday,10:30,11:00,107,19,"Banded block Toeplitz matrices with real asymptotic spectrum
","<p>k-Toeplitz matrices or block Toeplitz matrices are matrices with
periodic entries on their diagonals. In this sense, they constitute a
generalization of Toeplitz matrices, which have constant (or 1-periodic)
entries on their diagonals. In this talk, we will go over a result by
Shapiro and Štampach which gives a condition for the reality of the
asymptotic spectrum. Then, we will illustrate how to generalize this
result to the block Toeplitz setting. Finally we will formulate a
conjecture which completely characterizes block Toeplitz matrices with
real asymptotic spectrum.</p>
"
S7,SC1003,2,Muhammad Faisal,Khan,Muhammad Faisal Khan,2025-06-25 10:30:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Wednesday,11:00,11:30,107,19,"Geometric means of HPD GLT matrix-sequences: structure, invertibility, and convergence","<p>In this work, we extend our previous analysis on the spectral
distribution of the geometric mean of matrix-sequences formed by
Hermitian Positive Definite (HPD) matrices, under the framework of
Generalized Locally Toeplitz (GLT) <span
class=""math inline"">*</span>-algebra. Building on prior results <span
class=""citation"" data-cites=""ahmad2025matrix""></span>, we now
investigate whether the assumption of invertibility of the GLT symbols
almost everywhere is essential. Motivated by the fact that inversion is
often required due to matrix non-commutativity, we explore the scenario
where the symbols commute, aiming to relax the invertibility condition.
Furthermore, we study the Karcher mean of more than two HPD GLT
matrix-sequences, focusing on how an initial guess that itself belongs
to the GLT algebra influences the convergence of the iterative
computation. Numerical experiments support our theoretical claims and
demonstrate improved convergence behavior under structured
initialization.</p>
<p>Finally, we extend the theoretical results to the multilevel block
case (for <span class=""math inline""><em>r</em> = 1</span>, <span
class=""math inline""><em>d</em> ≥ 1</span>), offering a a broader
generalization and deeper numerical validation.</p>
<div class=""thebibliography"">
<p><span>99</span></p>
<p>Ahmad, D.; Khan, M.F.; Serra-Capizzano, S. <em>Matrix-Sequences of
Geometric Means in the Case of Hidden (Asymptotic) Structures.</em>
Mathematics 2025, 13, 393. <a
href=""https://doi.org/10.3390/math13030393""
class=""uri"">https://doi.org/10.3390/math13030393</a>.</p>
<p>G. Barbarino, C. Garoni, and S. Serra-Capizzano, <em>Block
generalized locally Toeplitz sequences: theory and applications in the
unidimensional case</em>, Electronic Transactions on Numerical Analysis,
53 (2020), pp. 28–112.</p>
<p>G. Barbarino, C. Garoni, and S. Serra-Capizzano, <em>Block
generalized locally Toeplitz sequences: theory and applications in the
multidimensional case</em>, Electronic Transactions on Numerical
Analysis, 53 (2020), pp. 113–216.</p>
<p>C. Garoni and S. Serra-Capizzano, <em>Generalized Locally Toeplitz
Sequences: Theory and Applications, Vol. I</em>, Springer, Cham,
2017.</p>
<p>C. Garoni and S. Serra-Capizzano, <em>Generalized Locally Toeplitz
Sequences: Theory and Applications, Vol. II</em>, Springer, Cham,
2018.</p>
</div>
"
S7,SC1003,3,Sven-Erik,Ekström,Sven-Erik Ekström,2025-06-25 10:30:00,MS19,"Explicit and hidden asymptotic structures, GLT Analysis, and applications",Wednesday,11:30,12:00,107,19,The spectrum of Toeplitz matrices with two off-diagonals,"<p>Consider the Toplitz matrix <span
class=""math inline""><em>T</em><sub><em>n</em></sub>(<em>g</em><sub><em>r</em>, <em>s</em></sub>)</span>
generated by the symbol <span
class=""math inline""><em>g</em><sub><em>r</em>, <em>s</em></sub>(<em>θ</em>) = <em>e</em><sup><em>r</em><strong>i</strong><em>θ</em></sup> + <em>e</em><sup>−<em>s</em><strong>i</strong><em>θ</em></sup></span>
where <span class=""math inline"">0 &lt; <em>r</em> &lt; <em>n</em></span>
and <span class=""math inline"">0 &lt; <em>s</em> &lt; <em>n</em></span>.
The eigenvalues of <span
class=""math inline""><em>T</em><sub><em>n</em></sub>(<em>g</em><sub><em>r</em>, <em>s</em></sub>)</span>
(and eigenvectors) for the case <span
class=""math inline""><em>r</em> = <em>s</em> = 1</span> (tridiagonal
Toeplitz) has been know explicitly for about 100 years. In 2018 the
eigenvalues (and eigenvectors) were given also for the case <span
class=""math inline""><em>r</em> = <em>s</em> &gt; 1</span> by Ekström and
Serra-Capizzano. In the current presentation we discuss the case <span
class=""math inline"">1 ≤ <em>r</em> &lt; <em>s</em></span>, and the
eigenvalues of <span
class=""math inline""><em>T</em><sub><em>n</em></sub>(<em>g</em><sub><em>r</em>, <em>s</em></sub>)</span>.
We present an algorithm to construct matrices, smaller than the original
matrix, that given their eigenvalues we can exactly reconstruct the full
spectrum of <span
class=""math inline""><em>T</em><sub><em>n</em></sub>(<em>g</em><sub><em>r</em>, <em>s</em></sub>)</span>.
A brief discussion on the ideas behind the algorithm will be given as
well as some still unresolved questions.</p>
"
S7,SC1005,1,Fernando,De Terán,Fernando De Terán,2025-06-25 10:30:00,MS27,Linear algebra education,Wednesday,10:30,11:00,107,27,A linear algebra online course experience at UC3M: development and teaching,"<p>I will review my experience with a SPOC (Small Private Online Course)
with flipped classroom that we developed to teach basic Linear Algebra
at UC3M. We used this course for 6 academic years in a first-year Linear
Algebra course for engineers.</p>
"
S7,SC1005,2,Frank,Uhlig,Frank Uhlig,2025-06-25 10:30:00,MS27,Linear algebra education,Wednesday,11:00,11:30,107,27,"What is our most urgent task today in Mathematics?
","<p>This is a talk on modern Linear Algebra teaching and learning and on
our most urgent task in Mathematics as a whole and in Linear Algebra
today, namely that of building Matrix Theory and Matrix Computation
based syllabi. Full semester Lesson Plans for first Linear Algebra
courses are introduced and discussed. To prepare our post Covid students
we need to use interactive teaching methods and inversely taught syllabi
which are slowly creating grass roots fire among students and catching
instructors as well. Such courses follow the Teaching Principles of Jean
Piaget from 80 years ago who established that we only learn deeply and
retain what we need to understand, and not what we are taught to pass a
test. Such a course in elementary Linear Algebra can be designed from
only two mathematical principles : the Row Echelon Form Reduction
teaches us of the value of pivot searches and Krylov Vector Iterations
that allow us an inside look at intrinsic matrix qualities such as
eigenvectors and eigenvalues. Both of these rely on Riesz’s Theorem on
Matrix Representations of Linear Functions in varying vector space
bases. Students should build their own basic codes to perform reliable
algorithms for these essential tasks of modern Linear Algebra as it is
used everywhere in our internet, cell-phone and computer worlds and in
Engineering, Medicine, Shipping, Traveling, Banking and so forth. Such a
course would follow the Piaget Principle of deep learning.</p>
"
S7,SC1005,3,Jephian C.-H.,Lin,Jephian C.-H. Lin,2025-06-25 10:30:00,MS27,Linear algebra education,Wednesday,11:30,12:00,107,27,"Engaging students with collaborative tasks in linear algebra
","<p>The main challenge in teaching linear algebra, or mathematics in
general, in Taiwan is the lack of motivation. Many students have been
conditioned to view learning as solely a means to achieve good exam
scores, while higher education should focus on more than just grades.
Hands-on activities can help spark students’ interest in learning. In
this talk, we will present several collaborative tasks that encourage
students to work and learn together.</p>
"
S7,SC2001,1,Shahla,Nasserasr,Shahla Nasserasr,2025-06-25 10:30:00,MS2,Combinatorial matrix theory,Wednesday,10:30,11:00,107,2,An approach to computing maximum multiplicity of eigenvalues in graphs,"<p>For a simple graph <span class=""math inline""><em>G</em></span>, the
maximum multiplicity of an eigenvalue among all symmetric matrices with
the graph of <span class=""math inline""><em>G</em></span> is denoted by
<span class=""math inline""><em>M</em>(<em>G</em>)</span>. It is known
that for trees, <span class=""math inline""><em>M</em>(<em>G</em>)</span>,
can be computed by removing certain vertices to reduce the tree to
paths. We propose a method to generalize this approach to graphs. Using
this generalized method, we compute the maximum multiplicity for
unicyclic graphs and several other families of graphs. This is joint
work with Charles R. Johnson, António Leal-Duarte and Carlos M.
Saiago.</p>
"
S7,SC2001,2,Helena,Šmigoc,Helena Šmigoc,2025-06-25 10:30:00,MS2,Combinatorial matrix theory,Wednesday,11:00,11:30,107,2,Stochastic matrices with infinitely many stochastic roots,"<p>We introduce and study the class of arbitrarily finely divisible
stochastic matrices (<span
class=""math inline"">AFD<sub>+</sub></span>-matrices): stochastic
matrices that have a stochastic <span
class=""math inline""><em>c</em></span>-th root for infinitely many
natural numbers <span class=""math inline""><em>c</em></span>. This notion
generalises the class of embeddable stochastic matrices. We will explore
the connection between the spectral properties of an <span
class=""math inline"">AFD<sub>+</sub></span>-matrix <span
class=""math inline""><em>A</em></span> and the spectral properties of a
limit point <span class=""math inline""><em>L</em></span> of its
stochastic roots. This connection, which is first formalised in the
broader context of complex and real square matrices, poses restrictions
on <span class=""math inline""><em>A</em></span> assuming <span
class=""math inline""><em>L</em></span> is given. For example, if an <span
class=""math inline"">AFD<sub>+</sub></span>-matrix <span
class=""math inline""><em>A</em></span> has a corresponding irreducible
limit point <span class=""math inline""><em>L</em></span>, then <span
class=""math inline""><em>A</em></span> has to be a circulant matrix. We
close with a complete characterisation of <span
class=""math inline"">AFD<sub>+</sub></span>-matrices of rank-two.</p>
"
S7,SC2001,3,Himanshu,Gupta,Himanshu Gupta,2025-06-25 10:30:00,MS2,Combinatorial matrix theory,Wednesday,11:30,12:00,107,2,Minimum number of distinct eigenvalues of Johnson and Hamming graphs,"<p>This talk focuses on the inverse eigenvalue problem for graphs
(IEPG), which seeks to determine the possible spectra of symmetric
matrices associated with a given graph <span
class=""math inline""><em>G</em></span>. These matrices have off-diagonal
non-zero entries corresponding to the edges of <span
class=""math inline""><em>G</em></span>, while diagonal entries are
unrestricted. A key parameter in IEPG is <span
class=""math inline""><em>q</em>(<em>G</em>)</span>, the minimum number of
distinct eigenvalues among such matrices. The Johnson and Hamming graphs
are well-studied families of graphs with many interesting combinatorial
and algebraic properties. We prove that every Johnson graph admits a
signed adjacency matrix with exactly two distinct eigenvalues,
establishing that its <span class=""math inline""><em>q</em></span>-value
is two. Additionally, we explore the behavior of <span
class=""math inline""><em>q</em>(<em>G</em>)</span> for Hamming graphs.
This is a joint work with Shaun Fallat, Allen Herman, and Johnna
Parenteau.</p>
"
S7,SC2006,1,Rute,Lemos,Rute Lemos,2025-06-25 10:30:00,MS3,Matrix inequalities with applications,Wednesday,10:30,11:00,107,3,$J$-selfadoint matrix means and their indefinite inequalities,"<p>Consider the indefinite inner product induced by a non trivial
involutive Hermitian matrix <span class=""math inline""><em>J</em></span>,
which endows the matrix algebra of <span
class=""math inline""><em>n</em></span>-square complex matrices with a
partial order relation between <span
class=""math inline""><em>J</em></span>-selfadjoint matrices. Indefinite
inequalities are given in this setup, involving the <span
class=""math inline""><em>J</em></span>-selfadjoint <span
class=""math inline""><em>α</em></span>-weighted geometric matrix mean. In
particular, an indefinite version of Ando–Hiai inequality is proved to
be equivalent to Furuta inequality of indefinite type.</p>
<p>This talk is based on a joint work with Natália Bebiano and Graça
Soares.</p>
<p>This work is supported by the Center for Research and Development in
Mathematics and Applications (CIDMA) under the Portuguese Foundation for
Science and Technology (FCT, <a href=""https://ror.org/00snfqn58""
class=""uri"">https://ror.org/00snfqn58</a>) Multi-Annual Financing
Program for R&amp;D Units.</p>
"
S7,SC2006,2,Hiroyuki,Osaka,Hiroyuki Osaka,2025-06-25 10:30:00,MS3,Matrix inequalities with applications,Wednesday,11:00,11:30,107,3,"Generalized Hellinger divergences generated by monotone functions.
","<p>Let <span class=""math inline""><em>p</em></span> and <span
class=""math inline""><em>q</em></span> be two discrete probability
distributions, that is, <span
class=""math inline""><em>p</em> = (<em>p</em><sub>1</sub>, …, <em>p</em><sub><em>n</em></sub>)</span>,
<span
class=""math inline""><em>q</em> = (<em>q</em><sub>1</sub>, …, <em>q</em><sub><em>n</em></sub>)</span>
are <span class=""math inline""><em>n</em></span>-vectors with nonnegative
coordinates such that <span class=""math inline"">$\sum_{i=1}^np_i =
\sum_{i=1}^nq_i = 1$</span>. The Hellinger distance <span
class=""math inline""><em>d</em><sub><em>H</em></sub></span> between <span
class=""math inline""><em>p</em></span> and <span
class=""math inline""><em>q</em></span> is the Euclidean norm of the
difference between the squre roots of <span
class=""math inline""><em>p</em></span> and <span
class=""math inline""><em>q</em></span>; <span
class=""math display"">$$d(p,q) = \|\sqrt{p}-\sqrt{q}\|^2 =
\left[\sum_{i=1}^n(\sqrt{p_i}-\sqrt{q_i})^2\right]^{1/2}
= \left[\sum_{i=1}^n(p_i+q_i)
-2\sum_{i=1}^n\sqrt{p_iq_i}\right]^{1/2}.$$</span> and define <span
class=""math inline"">$d_H(p, q) = \frac{1}{\sqrt{2}}d(p,q) = \sqrt{{\rm
Tr} \mathcal{A}(p,q) - {\rm Tr}\mathcal{G}(p,q)}$</span>, where <span
class=""math inline"">𝒜(<em>p</em>, <em>q</em>)</span> is the arithmetic
mean of the vectors <span
class=""math inline""><em>p</em>, <em>q</em></span>, <span
class=""math inline"">𝒢(<em>p</em>, <em>q</em>)</span> is their geometric
mean.</p>
<p>A matrix version of the Hellinger distance is extended on the set of
<span class=""math inline""><em>n</em> × <em>n</em></span> density
matrices <span class=""math inline""><em>A</em></span> and <span
class=""math inline""><em>B</em></span> such that <span
class=""math inline""><em>A</em>, <em>B</em> &gt; 0</span> and <span
class=""math inline"">${\rm Tr}(A) = {\rm Tr}(B) = 1$</span> as follows:
<span class=""math display"">$$\widetilde{d_H}(A, B) = \left[{\rm
Tr}\left(\frac{A + B}{2}\right) - {\rm Tr}(A\sharp B)\right]^{1/2}
= \left[{\rm Tr}(A\nabla B) - {\rm Tr}(A\sharp B)\right]^{1/2}
,$$</span> where <span
class=""math inline""><em>A</em>♯<em>B</em> = <em>A</em><sup>1/2</sup>(<em>A</em><sup>−1/2</sup><em>B</em><em>A</em><sup>−1/2</sup>)<sup>1/2</sup><em>A</em><sup>1/2</sup></span>
is called the geometric mean of <span
class=""math inline""><em>A</em></span> and <span
class=""math inline""><em>B</em></span>. Note that <span
class=""math inline"">$\widetilde{d_H}$</span> does not satisfy the
triangle inequality in the metric axioms and when <span
class=""math inline""><em>A</em><em>B</em> = <em>B</em><em>A</em></span>,
<span class=""math inline"">${\rm Tr}(A \sharp B) = {\rm
Tr}(A^{1/2}B^{1/2})$</span>. In <span class=""citation""
data-cites=""BGJ 2019""></span> they show that <span
class=""math inline"">$\Phi_H(A, B) = \widetilde{d_H}(A,B)^2$</span> is a
divergence on the set <span
class=""math inline"">𝒫<sub><em>n</em></sub></span> of <span
class=""math inline""><em>n</em> × <em>n</em></span> positive definite
matrices as in <span class=""citation"" data-cites=""SA 2016""></span>.</p>
<p>In this talk we present the extended version of the above divergence
as follows:</p>
<p>Let <span class=""math inline""><em>λ</em> ∈ (0, 1)</span> and <span
class=""math inline""><em>σ</em></span> be an operator mean in the sense
of Kubo-Ando <span class=""citation"" data-cites=""KA 1980""></span> such
that <span
class=""math inline"">!<sub><em>λ</em></sub> ≤ <em>σ</em> &lt; ∇<sub><em>λ</em></sub></span>.
Let <span class=""math inline""><em>g</em> : [0, ∞) → [0, ∞)</span> be
strictly increasing function such that <span
class=""math inline""><em>g</em><sup>−1</sup></span> is operator monotone
function on <span class=""math inline"">(0, ∞)</span>. Then the quantity
<span class=""math inline"">$\Phi_{g,\sigma}(X,Y) = {\rm
Tr}(g(X\nabla_\lambda Y))-g(X\sigma Y))$</span> is a quantum divergence
for <span
class=""math inline""><em>X</em>, <em>Y</em> ∈ 𝒫<sub><em>n</em></sub></span>.</p>
<p>This is a joint work with Trung Hoa Dinh, Anh Vu Le and Ngoc Yen
Phan, and Hiroki Shudo.</p>
<div class=""thebibliography"">
<p><span>99</span></p>
<p>S. Amari, <em>Information Geometry and its Applications</em>,
Springer, Tokyo (2016).</p>
<p>R. Bhatia, S. Gaubert and T. Jain, <em>Matrix versions of the
Hellinger distance</em>, Letters in Mth. Phys. (2019),
109:1777-1804.</p>
<p>T. R. Dinh, A. V. Le, H. Osaka, and N. Y. P, <em>New quantum
dyvergences generated by monotonicity inequality</em>, Math. Ineq. Appl.
28 (2025), no. 1, 143–157.</p>
<p>F. Kubo and T. Ando, <em>Means of positive monotone operators</em>,
Math. Ann. 246 (1980), 205-244.</p>
<p>H. Osaka and H. Shudo, in preparation.</p>
</div>
"
S7,SC2006,3,Zhongshan,Li,Zhongshan Li,2025-06-25 10:30:00,MS3,Matrix inequalities with applications,Wednesday,11:30,12:00,107,3,"The orthogonal equivalence transversality property 
","<p>Let <span class=""math inline""><em>A</em></span> be an <span
class=""math inline""><em>m</em> × <em>n</em></span> real matrix. If the
manifold consisting of all matrices orthogonally equivalent to <span
class=""math inline""><em>A</em></span> and the manifold consisting of all
real matrices having the same sign pattern as <span
class=""math inline""><em>A</em></span> (both considered as embedded
submanifolds of <span
class=""math inline"">ℝ<sup><em>m</em> × <em>n</em></sup></span>),
intersect transversally at <span class=""math inline""><em>A</em></span>,
we say that <span class=""math inline""><em>A</em></span> has the
<em>orthogonal equivalence transversality property</em> (OETP) and that
<span class=""math inline""><em>A</em></span> is an OETP matrix. By
examining the tangent spaces, it can be seen that <span
class=""math inline""><em>A</em></span> has the OETP iff as <span
class=""math inline""><em>S</em></span> and <span
class=""math inline""><em>K</em></span> run over all <span
class=""math inline""><em>m</em> × <em>m</em></span> and <span
class=""math inline""><em>n</em> × <em>n</em></span> skew-symmetric
matrices, the matrices <span
class=""math inline""><em>A</em><em>S</em> + <em>K</em><em>A</em></span>
can attain independent and arbitrary values at the positions where the
corresponding entries of <span class=""math inline""><em>A</em></span> are
equal to zero. Using the normal spaces, it can be shown that <span
class=""math inline""><em>A</em></span> has the OETP iff <span
class=""math inline""><em>X</em> = 0</span> is the only matrix satisfying
the following three conditions <span
class=""math inline""><em>A</em> ∘ <em>X</em> = 0,</span> <span
class=""math inline""><em>A</em><em>X</em><sup><em>T</em></sup></span> is
symmetric, and <span
class=""math inline""><em>X</em><sup><em>T</em></sup><em>A</em></span> is
symmetric. Many fundamental facts about the OETP matrices are presented.
For instance, if <span class=""math inline""><em>A</em></span> is an OETP
matrix, then every superpattern of sgn<span
class=""math inline"">(<em>A</em>)</span> allows a matrix orthogonally
equivalent to <span class=""math inline""><em>A</em></span>. The direct
sum of two square matrices <span class=""math inline""><em>B</em></span>
and <span class=""math inline""><em>C</em></span> has the OETP iff both
<span class=""math inline""><em>B</em></span> and <span
class=""math inline""><em>C</em></span> have the OETP, and <span
class=""math inline""><em>B</em></span> and <span
class=""math inline""><em>C</em></span> do not have any common singular
value. The bidiagonal zero-nonzero pattern with all entries on the
diagonal and the first superdiagonal nonzero requires the OETP. This is
joint work with M. Arav, H. van der Holst, F. Hall, J. Seo, L. Wang, Y.
Xu, and Y. Zhao</p>
"
S7,SC3001,1,Chun-Yueh,Chiang,Chun-Yueh Chiang,2025-06-25 10:30:00,MS11,Structured matrix computations and its applications,Wednesday,10:30,11:00,107,11,"Ten Hermitian solutions of anti-Riccati matrix equation arising in anti-LQR problem
","<p>In this talk, we consider a class of conjugate discrete-time Riccati
equations (CDARE), arising originally from the linear quadratic
regulation problem for discrete-time antilinear systems. Recently, we
have proven the existence of the maximal solution to the CDARE with a
nonsingular control weighting matrix within the framework of a
constructive method. Our contribution to the work is to find another
meaningful Hermitian solution, which has received little attention in
the existing literature. Moreover, we show that certain extremal
solutions cannot be attained simultaneously, and almost
(anti-)stabilizing solutions coincide with some extremal solutions. We
expect that our theoretical results presented in this paper will play an
important role in optimal control problems for discrete-time antilinear
systems.</p>
"
S7,SC3001,2,Homoon,Ryu,Homoon Ryu,2025-06-25 10:30:00,MS11,Structured matrix computations and its applications,Wednesday,11:00,11:30,107,11,Linear-time algorithm for finding the Frobenius normal form of symmetric Toeplitz matrices.,"<p>According to Chu and Ryu (2025), the Frobenius normal form of a
symmetric Toeplitz matrix is a direct sum of irreducible symmetric
Toeplitz matrices. In this talk, we present an algorithm which
determines the blocks of the Frobenius normal form of a symmetric
Toeplitz matrix. This algorithm can be implemented in <span
class=""math inline""><em>O</em>(<em>n</em>)</span>-time where <span
class=""math inline""><em>n</em></span> is the order of given symmetric
Toeplitz matrix.</p>
"
S7,SC3001,3,Hung-Yuan,Fan,Hung-Yuan Fan,2025-06-25 10:30:00,MS11,Structured matrix computations and its applications,Wednesday,11:30,12:00,107,11,Inheritance properties of conjugate discrete-time algebraic Riccati equations,"<p>In this talk we consider a class of conjugate discrete-time Riccati
equations, arising originally from the linear quadratic regulator
problem for discrete-time antilinear systems. Under mild and reasonable
assumptions, the existence of the maximal solution to the conjugate
discrete-time Riccati equation, in which the control weighting matrix is
nonsingular and its constant term is Hermitian, will be inherited to a
transformed discrete-time algebraic Riccati equation. Based on this
inheritance property, an accelerated fixed-point iteration is proposed
for finding the maximal solution via the transformed Riccati equation.
Numerical examples are shown to illustrate the correctness of our
theoretical results and the feasibility of the proposed algorithm.</p>
"
S7,SC4011,1,Etna,Lindy,Etna Lindy,2025-06-25 10:30:00,MS1,Embracing new opportunities in numerical linear algebra,Wednesday,10:30,11:00,107,1,Nonnegative rank-2 approximations -- on choosing a starting point for ANLS,"<p>Given a nonnegative <span
class=""math inline""><em>m</em> × <em>n</em></span> matrix <span
class=""math inline""><em>X</em></span>, its nonnegative rank-<span
class=""math inline""><em>r</em></span> approximation (NMF-<span
class=""math inline""><em>r</em></span>) consists of two nonnegative
matrices, <span class=""math inline""><em>A</em></span> and <span
class=""math inline""><em>B</em></span> of sizes <span
class=""math inline""><em>m</em> × <em>r</em></span> and <span
class=""math inline""><em>n</em> × <em>r</em></span>, such that the
Frobenius norm of <span
class=""math inline""><em>X</em> − <em>A</em><em>B</em><sup>⊤</sup></span>
is minimized. The rank-2 case is special in the sense that while the
problem is NP-hard for general <span
class=""math inline""><em>r</em></span> and somewhat trivial in the case
of <span class=""math inline""><em>r</em> = 1</span>, the complexity of
rank-2 NMF is not known. Furthermore, NMF-2 is equivalent to rank-2
optimization with a non-negativity constraint, which is not true for
larger <span class=""math inline""><em>r</em></span>. NMF-2 is commonly
approached by solving for the components <span
class=""math inline""><em>A</em></span> and <span
class=""math inline""><em>B</em></span> separately in an alternating
fashion (ANLS). This means solving several independent nonnegative least
squares problems, which can be done exactly with relatively low
computational cost in the rank-2 case. The ANLS method is not guaranteed
to converge to the global minimum, and choosing a good starting point is
crucial. Specifically, the ANLS method often seems to converge to a
trivial solution with a column of zeros when the starting point is
chosen carelessly. We suggest using a certain angular coordinate
representation of the matrices <span
class=""math inline""><em>A</em></span> and <span
class=""math inline""><em>B</em></span> and then optimizing over these new
sets of coordinates. This approach has the benefit of introducing only a
few zeros, which is a good property for a starting point for ANLS. The
tests we have implemented suggest that our method gives a better
approximation than other existing methods such as SPA <span
class=""citation"" data-cites=""gillis2014hierarchical""></span> while
maintaining the same level of computational complexity. Ideally the
method could be generalized for <span
class=""math inline""><em>r</em> &gt; 2</span>, but it is still under
consideration how this could be done.</p>
<div class=""thebibliography"">
<p><span>9</span> N. Gillis, D. Kuang, H. Park, ”Hierarchical clustering
of hyperspectral images using rank-two nonnegative matrix
factorization”, <span><em>IEEE Transactions on Geoscience and Remote
Sensing</em></span> (2014)</p>
</div>
"
S7,SC4011,2,Van Su,Giap,Van Su Giap,2025-06-25 10:30:00,MS1,Embracing new opportunities in numerical linear algebra,Wednesday,11:00,11:30,107,1,Spectral properties of stochastic block model,"<p>The stochastic block model (SBM) is an extension of the Erdős-Rényi
graph and has applications in numerous fields, such as data analysis,
recovering community structure in graph data and social networks. In
this paper, we consider the normal central SBM adjacency matrix with
<span class=""math inline""><em>K</em></span> communities of arbitrary
sizes. We derive an explicit formula for the limiting empirical spectral
density function when the size of the matrix tends to infinity. We also
obtain an upper bound for the operator norm of such random matrices by
means of the Stieltjes transform and random matrix theory.</p>
"
S7,SC4011,3,Peter Chang-Yi,Weng,Peter Chang-Yi Weng,2025-06-25 10:30:00,MS1,Embracing new opportunities in numerical linear algebra,Wednesday,11:30,12:00,107,1,Generalized Smith method for large-scale nonsymmetric algebraic Riccati equations,"<p>This paper presents an effective algorithm about a computation of the
numerical low-rank solution to a large-scale nonsymmetric algebraic
Riccati equation with a nonsingular <span
class=""math inline""><em>M</em></span>-matrix. The method first applies
the Newton’s method to compute the nonsymmetric algebraic Riccati
equation, followed by a derivation of generalized Sylvester equations.
By extending the Smith method, the proposed algorithm achieves a
quadratic convergence and has the <span
class=""math inline""><em>O</em>(<em>n</em>)</span> computational
complexity. A detailed convergence, error analysis, truncation and
compression process, and numerical examples will be provided.</p>
"
S8,SC0008,1,Angelo,Galimba,Angelo Galimba,2025-06-26 10:30:00,MS31,Matrix decompositions and applications,Thursday,10:30,11:00,108,31,Reversibility problem for real quaternion matrices,"<p>In a group <span class=""math inline""><em>G</em></span>, we say that
<span class=""math inline""><em>g</em> ∈ <em>G</em></span> is
<em>reversible</em> if there exists <span
class=""math inline""><em>s</em> ∈ <em>G</em></span> such that <span
class=""math inline""><em>s</em><sup>−1</sup><em>g</em><em>s</em> = <em>g</em><sup>−1</sup></span>.
Moreover, such <span class=""math inline""><em>g</em></span> is
<em>strongly reversible</em> if <span
class=""math inline""><em>s</em></span> is an involution, i.e., <span
class=""math inline""><em>s</em><sup>2</sup> = <em>e</em></span> where
<span class=""math inline""><em>e</em></span> is the identity of the group
<span class=""math inline""><em>G</em></span>. In this talk, we study the
reversibility problem in the group of invertible matrices over real
quaternions <span class=""math inline"">ℍ</span>, <span
class=""math inline""><em>G</em><em>L</em>(<em>n</em>, ℍ)</span>. We
completely classify up to standard Jordan form all real quaternion
matrices in <span
class=""math inline""><em>G</em><em>L</em>(<em>n</em>, ℍ)</span> that are
strongly reversible.</p>
"
S8,SC0008,2,Eloise,Misa,Eloise Misa,2025-06-26 10:30:00,MS31,Matrix decompositions and applications,Thursday,11:00,11:30,108,31,The algebra generated by nilpotent elements in a matrix centralizer,"<p>For an arbitrary square matrix <span
class=""math inline""><em>S</em></span>, denote by <span
class=""math inline""><em>C</em>(<em>S</em>)</span> the centralizer of
<span class=""math inline""><em>S</em></span>, and by <span
class=""math inline""><em>C</em>(<em>S</em>)<sub><em>N</em></sub></span>
the set of all nilpotent elements in <span
class=""math inline""><em>C</em>(<em>S</em>)</span>. In this paper, we use
the Weyr canonical form to study the subalgebra <span
class=""math inline"">𝒜(<em>S</em>)</span> of <span
class=""math inline""><em>C</em>(<em>S</em>)</span> generated by <span
class=""math inline""><em>C</em>(<em>S</em>)<sub><em>N</em></sub></span>.
We give a necessary and/or sufficient condition such that <span
class=""math inline""><em>A</em> ∈ <em>C</em>(<em>S</em>)</span> is a sum
or product of nilpotent matrices in <span
class=""math inline""><em>C</em>(<em>S</em>)</span>. We determine
conditions on <span class=""math inline""><em>S</em></span> such that
<span
class=""math inline""><em>C</em>(<em>S</em>)<sub><em>N</em></sub></span>
is a subalgebra of <span
class=""math inline""><em>C</em>(<em>S</em>)</span>, that is, when <span
class=""math inline"">𝒜(<em>S</em>) = <em>C</em>(<em>S</em>)<sub><em>N</em></sub></span>.
We also determine conditions on <span
class=""math inline""><em>S</em></span> such that the subalgebra generated
by <span
class=""math inline""><em>C</em>(<em>S</em>)<sub><em>N</em></sub></span>
is <span class=""math inline""><em>C</em>(<em>S</em>)</span>, that is,
when <span
class=""math inline"">𝒜(<em>S</em>) = <em>C</em>(<em>S</em>)</span>.</p>
"
S8,SC0008,3,Jenny,Salinasan,Jenny Salinasan,2025-06-26 10:30:00,MS31,Matrix decompositions and applications,Thursday,11:30,12:00,108,31,The $\phi_S$ polar decomposition when $S$ is skew-symmetric,"<p>Let <span class=""math inline""><em>F</em></span> be a field with
characteristic not equal to <span class=""math inline"">2</span>, and
<span
class=""math inline""><em>S</em> ∈ <em>M</em><sub>2<em>n</em></sub>(<em>F</em>)</span>
be skew-symmetric <span
class=""math inline"">(<em>S</em><sup>⊤</sup> = −<em>S</em>)</span> and
nonsingular. Let <span
class=""math inline""><em>ϕ</em><sub><em>S</em></sub></span> be the
function defined by <span
class=""math inline""><em>ϕ</em><sub><em>S</em></sub>(<em>A</em>) = <em>S</em><sup>−1</sup><em>A</em><sup>⊤</sup><em>S</em></span>
for all <span
class=""math inline""><em>A</em> ∈ <em>M</em><sub>2<em>n</em></sub>(<em>F</em>)</span>.
Suppose <span
class=""math inline""><em>A</em> ∈ <em>M</em><sub>2<em>n</em></sub>(<em>F</em>)</span>.
We say that <span class=""math inline""><em>A</em></span> is <span
class=""math inline""><em>ϕ</em><sub><em>S</em></sub></span>-orthogonal if
<span class=""math inline""><em>A</em></span> is nonsingular and <span
class=""math inline""><em>ϕ</em><sub><em>S</em></sub>(<em>A</em>) = <em>A</em><sup>−1</sup></span>;
and <span class=""math inline""><em>A</em></span> is <span
class=""math inline""><em>ϕ</em><sub><em>S</em></sub></span>-symmetric if
<span
class=""math inline""><em>ϕ</em><sub><em>S</em></sub>(<em>A</em>) = <em>A</em></span>.
We say that <span class=""math inline""><em>A</em></span> has a <span
class=""math inline""><em>ϕ</em><sub><em>S</em></sub></span> polar
decomposition if <span
class=""math inline""><em>A</em> = <em>X</em><em>Y</em></span> for some
<span
class=""math inline""><em>ϕ</em><sub><em>S</em></sub></span>-orthogonal
<span
class=""math inline""><em>X</em> ∈ <em>M</em><sub>2<em>n</em></sub>(<em>F</em>)</span>
and <span
class=""math inline""><em>ϕ</em><sub><em>S</em></sub></span>-symmetric
<span
class=""math inline""><em>Y</em> ∈ <em>M</em><sub>2<em>n</em></sub>(<em>F</em>)</span>.
We give necessary and sufficient conditions for an <span
class=""math inline""><em>X</em> ∈ <em>M</em><sub>2<em>n</em></sub>(<em>F</em>)</span>
to have a <span
class=""math inline""><em>ϕ</em><sub><em>S</em></sub></span> polar
decomposition.</p>
"
S8,SC0009,1,Ryan,O'Loughlin,Ryan O'Loughlin,2025-06-26 10:30:00,MS33,"Norms of matrices, numerical range, applications of functional analysis to matrix theory",Thursday,10:30,11:00,108,33,,
S8,SC0009,2,Jyoti,Rani,Jyoti Rani,2025-06-26 10:30:00,MS33,"Norms of matrices, numerical range, applications of functional analysis to matrix theory",Thursday,11:00,11:30,108,33,On the generalizations of $q$-numerical range and radius,"<p>Let <span class=""math inline"">ℬ(ℋ)</span> be the <span
class=""math inline""><em>C</em><sup>*</sup></span> algebra of all bounded
linear operators acting on the Hilbert space <span
class=""math inline"">(ℋ, ⟨., .⟩)</span> equipped with the operator norm.
For any <span class=""math inline""><em>T</em> ∈ ℬ(ℋ)</span>, a
generalization of the classical numerical range, namely <span
class=""math inline""><em>q</em></span>-numerical range was introduced by
Marcus and Andresen in 1977 on <span
class=""math inline""><em>n</em></span>- dimensional unitary space. In
1984, the convexity of <span
class=""math inline""><em>q</em></span>-numerical range was proved by
Nam-Kiu Tsing. The <span class=""math inline""><em>q</em></span>-numerical
range of <span class=""math inline""><em>T</em> ∈ ℬ(ℋ)</span> is defined
by <span
class=""math display""><em>W</em><sub><em>q</em></sub>(<em>T</em>) = {⟨<em>T</em><em>x</em>, <em>y</em>⟩ : <em>x</em>, <em>y</em> ∈ <em>H</em>, ∥<em>x</em>∥ = ∥<em>y</em>∥ = 1, ⟨<em>x</em>, <em>y</em>⟩ = <em>q</em>}.</span>
And the <span class=""math inline""><em>q</em></span>-numerical radius of
<span class=""math inline""><em>T</em> ∈ <em>B</em>(ℋ)</span> is of the
form <span
class=""math display""><em>w</em><sub><em>q</em></sub>(<em>T</em>) = sup<sub><em>w</em> ∈ <em>W</em><sub><em>q</em></sub>(<em>T</em>)</sub>|<em>w</em>|.</span>
We introduce and examine the concept of the <span
class=""math inline""><em>q</em></span>-numerical range, namely, <span
class=""math inline""><em>q</em></span>-joint numerical range, for <span
class=""math inline""><em>n</em></span>-tuples of bounded linear operators
in Hilbert spaces. We derive several inequalities related to the <span
class=""math inline""><em>q</em></span>-numerical radius of these operator
tuples. Furthermore, we present a generalization of the <span
class=""math inline""><em>q</em></span>-numerical range of an operator
<span class=""math inline""><em>T</em> ∈ ℬ(ℋ)</span> within the context of
semi-Hilbertian spaces. Initially, we established the convexity
properties of the <span class=""math inline""><em>q</em></span>-numerical
range within semi-Hilbertian space, followed by an examination of its
relationship with the spectrum in the same context. We have derived
several numerical-radius inequalities for the <span
class=""math inline""><em>q</em></span>-numerical radius in
semi-Hilbertian space, which generalize numerous existing inequalities
in the literature.</p>
<p>Some part of this work has been jointly done with Dr. Arnab Patra,
Dr. Kais Feki, Dr. Zakaria Taki.</p>
"
S8,SC0009,3,Kennett,Dela Rosa,Kennett Dela Rosa,2025-06-26 10:30:00,MS33,"Norms of matrices, numerical range, applications of functional analysis to matrix theory",Thursday,11:30,12:00,108,33,Zero-dilation indices and numerical ranges,"<p>The zero-dilation index <span
class=""math inline""><em>d</em>(<em>A</em>)</span> of a matrix <span
class=""math inline""><em>A</em></span> is the largest integer <span
class=""math inline""><em>k</em></span> for which <span
class=""math inline"">$\begin{bmatrix}0_k&amp; *\\ * &amp;
*\end{bmatrix}$</span> is unitarily similar to <span
class=""math inline""><em>A</em></span>. In this study, the zero-dilation
indices of certain block matrices are considered, namely, the block
matrix analogues of companion matrices and upper triangular KMS
matrices, respectively shown as <span
class=""math display"">$$\mathcal{C}=\begin{bmatrix} 0&amp;
\bigoplus_{j=1}^{m-1}A_j \\ B_0&amp; [B_j]_{j=1}^{m-1}\end{bmatrix}\
\textup{and}\ \mathcal{K}=\begin{bmatrix}0&amp; A&amp;
A^2&amp;\cdots&amp; A^{m-1}\\ 0 &amp; 0&amp; A&amp; \ddots&amp; \vdots\\
0&amp; 0 &amp;0 &amp;\ddots&amp; A^2\\ \vdots&amp; \vdots &amp;\vdots
&amp; \ddots&amp; A\\ 0&amp; 0 &amp; 0&amp; \cdots
&amp;0\end{bmatrix}$$</span> where <span class=""math inline"">𝒞</span>
and <span class=""math inline"">𝒦</span> are <span
class=""math inline""><em>m</em><em>n</em></span>-by-<span
class=""math inline""><em>m</em><em>n</em></span> and <span
class=""math inline""><em>A</em><sub><em>j</em></sub>, <em>B</em><sub><em>j</em></sub>, <em>A</em></span>
are <span class=""math inline""><em>n</em></span>-by-<span
class=""math inline""><em>n</em></span>. Provided <span
class=""math inline"">⨁<sub><em>j</em> = 1</sub><sup><em>m</em> − 1</sup><em>A</em><sub><em>j</em></sub></span>
is nonsingular, it is proved that <span
class=""math inline""><em>d</em>(𝒞)</span> satisfies the following: if
<span class=""math inline""><em>m</em> ≥ 3</span> is odd (respectively,
<span class=""math inline""><em>m</em> ≥ 2</span> is even), then <span
class=""math inline"">$\frac{(m-1)n}{2}\leq d(\mathcal{C})\leq
\frac{(m+1)n}{2}$</span> (respectively, <span
class=""math inline"">$d(\mathcal{C})= \frac{mn}{2}$</span>). In the odd
<span class=""math inline""><em>m</em></span> case, examples are given
showing that it is possible to get as zero-dilation index each integer
value between <span class=""math inline"">$\frac{(m-1)n}{2}$</span> and
<span class=""math inline"">$\frac{(m+1)n}{2}$</span>. On the other hand,
<span class=""math inline""><em>d</em>(𝒦)</span> is proved to be equal to
the number of nonnegative eigenvalues of <span
class=""math inline"">(𝒦 + 𝒦<sup>*</sup>)/2</span>. Alternative
characterizations of <span class=""math inline""><em>d</em>(𝒦)</span> are
given. The circularity of the numerical range of <span
class=""math inline"">𝒦</span> is also considered.</p>
"
S8,SC0012,1,Lucijan,Plevnik,Lucijan Plevnik,2025-06-26 10:30:00,MS35,"Preserver Problems, II",Thursday,10:30,11:00,108,35,Linear preservers of rank one projections,"<p>Let <span class=""math inline"">ℋ</span> be a complex Hilbert space and
let <span class=""math inline"">ℱ<sub><em>s</em></sub>(ℋ)</span> be the
real vector space of all self-adjoint finite rank operators on <span
class=""math inline""><em>H</em></span>. We will present the description
of linear maps on <span
class=""math inline"">ℱ<sub><em>s</em></sub>(ℋ)</span> sending rank one
projections to rank one projections. Such maps are either induced by a
linear or conjugate-linear isometry on <span
class=""math inline"">ℋ</span> or constant on the set of rank one
projections.</p>
<p>We will also discuss linear maps <span
class=""math inline"">ℱ<sub><em>s</em></sub>(ℋ) → ℱ<sub><em>s</em></sub>(𝒦)</span>
sending rank one projections to projections of a fixed rank. In the case
<span class=""math inline"">dim ℋ = 2</span>, we will present the
description of such maps, including a new kind of (injective) maps
additionally to the previously mentioned one. In the case <span
class=""math inline"">dim ℋ = 3</span>, we will show by an example that
such maps may be neither injective nor constant on the set of rank one
projections.</p>
"
S8,SC0012,2,Ming-Cheng,Tsai,Ming-Cheng Tsai,2025-06-26 10:30:00,MS35,"Preserver Problems, II",Thursday,11:00,11:30,108,35,"Multiplicative trace and spectrum preservers  on   nonnegative and stochastic matrices
","<p>In this talk, we mainly explore multiplicative trace and spectrum
preservers on the set of nonnegative and stochastic matrices. We will
give concrete description of trace and spectrum preservers on the sets
of nonnegative matrices, doubly stochastics, row stochastic, and column
stochastic, respectively. Some related results and examples are
provieded.</p>
"
S8,SC0012,3,Sushil,Singla,Sushil Singla,2025-06-26 10:30:00,MS35,"Preserver Problems, II",Thursday,11:30,12:00,108,35,Linear maps preserving product of involutions,"<p>Let <span
class=""math inline""><em>M</em><sub><em>n</em></sub>(𝔽)</span> the
algebra of <span class=""math inline""><em>n</em> × <em>n</em></span>
matrices over a field <span class=""math inline"">𝔽</span>. A matrix <span
class=""math inline""><em>A</em> ∈ <em>M</em><sub><em>n</em></sub>(𝔽)</span>
is said to be involution if <span
class=""math inline""><em>A</em><sup>2</sup> = <em>I</em></span> (the
identity matrix in <span
class=""math inline""><em>M</em><sub><em>n</em></sub>(𝔽)</span>). Two
interesting known facts about the product of involutions are as
follows.<br />
<br />
(a) A matrix in <span
class=""math inline""><em>M</em><sub><em>n</em></sub>(𝔽)</span> is similar
to its inverse if and only if it can be written as a product of two
involutions in <span
class=""math inline""><em>M</em><sub><em>n</em></sub>(𝔽)</span>.<br />
<br />
(b) An element <span
class=""math inline""><em>X</em> ∈ <em>M</em><sub><em>n</em></sub>(𝔽)</span>
has <span class=""math inline"">det (<em>X</em>) = ±1</span> if and only
if <span class=""math inline""><em>X</em></span> can be written as a
product of at most four involutions from <span
class=""math inline""><em>M</em><sub><em>n</em></sub>(𝔽)</span>. As a
consequence, any matrix which is products of involutions can be written
as product of at most four involutions.<br />
<br />
In this talk, we will investigate the bijective linear preservers of
matrices in <span
class=""math inline""><em>M</em><sub><em>n</em></sub>(𝔽)</span>, which are
products of at most two, or three, or four involutions. This is a joint
work with Chi-Kwong Li and Tejbir Lohan.</p>
"
S8,SC0014,1,Sooyeong,Kim,Sooyeong Kim,2025-06-26 10:30:00,MS8,Tensor and quantum information science,Thursday,10:30,11:00,108,8,"Quasiorthogonality of commutative algebras
","<p>The notion of quasiorthogonality for operator algebras was introduced
to provide a quantitative measure of the geometric relationships between
algebras. Pivotal to the development and motivation for considering
quasiorthogonality were applications in quantum information theory. We
deepen the theory of quasiorthogonal operator algebras through an
analysis of the commutative algebra case. We give a new approach to
calculate the measure of orthogonality between two such subalgebras of
matrices, based on a matrix-theoretic notion we introduce that has a
connection to complex Hadamard matrices. We also show how this new tool
can yield significant information on the general non-commutative
case.</p>
"
S8,SC0014,2,Albert,Rico,Albert Rico,2025-06-26 10:30:00,MS8,Tensor and quantum information science,Thursday,11:00,11:30,108,8,,
S8,SC0014,3,Zehua,Lai,Zehua Lai,2025-06-26 10:30:00,MS8,Tensor and quantum information science,Thursday,11:30,12:00,108,8,,
S8,SC1001,1,Akihiro,Munemasa,Akihiro Munemasa,2025-06-26 10:30:00,MS34,"Combinatorics, association scheme, and graphs",Thursday,10:30,11:00,108,34,,
S8,SC1001,2,Chia-An,Liu,Chia-An Liu,2025-06-26 10:30:00,MS34,"Combinatorics, association scheme, and graphs",Thursday,11:00,11:30,108,34,"An iteration method for attaining the spectral radius of nonnegative irreducible matrices
","<p>It is well known that the spectral radius of a nonnegative
irreducible matrix <span class=""math inline""><em>A</em></span> is no
more than the maximum row sum of <span
class=""math inline""><em>A</em></span> with equality if and only if <span
class=""math inline""><em>A</em></span> has constant row sum. Let <span
class=""math inline""><em>R</em></span> be the diagonal matrix with row
sums of <span class=""math inline""><em>A</em></span> on the diagonal and
<span
class=""math inline""><em>B</em> = <em>R</em><sup>−1</sup><em>A</em><em>R</em>.</span>
Then, the maximum row sum of <span class=""math inline""><em>B</em></span>
is at most the maximum row sum of <span
class=""math inline""><em>A</em></span>. Do the process repeatedly, and we
obtain a sequence of matrices that are similar to <span
class=""math inline""><em>A</em></span>. Its convergence will be
investigated. This is a joint work with Prof. Yen-Jen Cheng.</p>
"
S8,SC1001,3,Pin-Chieh,Tseng,Pin-Chieh Tseng,2025-06-26 10:30:00,MS34,"Combinatorics, association scheme, and graphs",Thursday,11:30,12:00,108,34,"Semidefinite programming bounds on the size of entanglement-assisted codeword stabilized quantum codes
","<p>The Terwilliger algebra has been used to obtain upper bounds on the
size of classical codes. In this paper, we construct semidefinite
programming constraints for quantum codes. Applying this method, we give
the table of upper bounds of the size of entanglement-assisted codeword
stabilized codes. Moreover, we also give an interpretation of the
Shor-Laflamme weight enumerators <span
class=""math inline"">{<em>A</em><sub><em>j</em></sub>}</span> and quantum
shadow enumerators for codeword stabilized codes. It is a joint work
with Ching-Yi Lai and Wei-Hsuan Yu.</p>
"
S8,SC1003,1,,,,2025-06-26 10:30:00,,,Thursday,10:30,11:00,108,1000,,
S8,SC1003,2,,,,2025-06-26 10:30:00,,,Thursday,11:00,11:30,108,1000,,
S8,SC1003,3,,,,2025-06-26 10:30:00,,,Thursday,11:30,12:00,108,1000,,
S8,SC1005,1,Mike,Michailidis,Mike Michailidis,2025-06-26 10:30:00,MS27,Linear algebra education,Thursday,10:30,11:00,108,27,Computational labs to enhance linear algebra intuition,"<p>Linear algebra is a key topic in mathematics and a core component of
science and engineering education. In this talk, we will explore the
role of programming in enhancing linear algebra education. Specifically,
we will report on a study about a proof-based second course in linear
algebra encompassing various topics, including vector spaces,
finite-dimensional vector spaces, linear maps, polynomials, inner
product spaces, operators on inner product spaces, eigenvalues, and
eigenvectors. The existing course was reorganized to incorporate six
labs and a final project using MATLAB, to help students explore
numerical linear algebra and its applications via programming. 22
mathematics and engineering students were enrolled in this course and 15
agreed to participate in this study, the findings of which we will
report and present during this talk.</p>
"
S8,SC1005,2,Rachel,Quinlan,Rachel Quinlan,2025-06-26 10:30:00,MS27,Linear algebra education,Thursday,11:00,11:30,108,27,Project work in an undergraduate linear algebra course,"<p>This talk will report on the work of some students in a free-form
project that was one component of assessment in an undergraduate linear
algebra course taken by second year students at the University of
Galway. Students were encouraged to connect their linear algebra
knowledge to their other interests and to submit work in any medium of
their choice. Submissions included work connected to education and
lifelong learning, poetry, craftwork and the visual arts, along with
many topics more prominently associated with linear algebra. The talk
will share some highlights, and discuss some of the motivation for the
inclusion of this project element and some of the learning outcomes for
the instructor.</p>
"
S8,SC1005,3,Steve,Mackey,Steve Mackey,2025-06-26 10:30:00,MS27,Linear algebra education,Thursday,11:30,12:00,108,27,Exciting eigenvectors: seeing is believing,"<p>There is a simple, inexpensive, easy-to-build, and easy-to-operate
device (adapted from (1)) that can be used to demonstrate to students
the physical reality of eigenvectors. Steve will begin the talk by
showing you that device, and briefly discussing some of its properties.
Although he has used it primarily in lecture/demonstration mode, there
is considerable scope for adapting this to a more hands-on,
direct-engagement-by-students mode. In the second half of the talk, Raf
will tell you about his recent classroom experience with this device,
used in exactly that way.</p>
<p>(1) <span>H. V. McIntosh</span> <span><em>Matrix Analysis II: Further
Introduction and some Applications to Physical Problems</em></span>,
1952.</p>
"
S8,SC2001,1,Steve,Kirkland,Steve Kirkland,2025-06-26 10:30:00,MS2,Combinatorial matrix theory,Thursday,10:30,11:00,108,2,"A centrality measure for cut edges in undirected graphs
","<p>We consider an edge centrality measure, introduced by Altafini et al,
which is based on Kemeny’s constant for a connected undirected graph. We
revisit that centrality measure for the case of cut edges, providing an
intuitive interpretation for it, and showing how it can be computed
using tools from combinatorial matrix theory. Explicit expressions for
the edge centralities are given for certain types of trees. Joint work
with Dario Bini, Guy Latouche and Beatrice Meini.</p>
"
S8,SC2001,2,Carlos,Hoppen,Carlos Hoppen,2025-06-26 10:30:00,MS2,Combinatorial matrix theory,Thursday,11:00,11:30,108,2,Spectral community detection in geometric random graphs,"<p>This talk is about community detection in graphs defined by the Soft
Geometric Block Model (SGBM). Suppose that <span
class=""math inline""><em>n</em> = <em>k</em><em>ℓ</em></span> points are
classified into <span class=""math inline""><em>k</em> ≥ 2</span>
communities with <span class=""math inline""><em>ℓ</em></span> points in
each community. These <span class=""math inline""><em>n</em></span> points
are embedded independently and with uniform probability as points <span
class=""math inline""><em>X</em><sub>1</sub>, …, <em>X</em><sub><em>n</em></sub></span>
of the <span class=""math inline""><em>d</em></span>-dimensional flat unit
torus <span
class=""math inline""><strong>T</strong><sup><strong>d</strong></sup></span>.
A random graph <span class=""math inline""><em>G</em></span> is generated
so that the edge <span
class=""math inline"">{<em>i</em>, <em>j</em>}</span> appears with
probability <span
class=""math inline""><em>F</em><sub><em>i</em><em>n</em></sub>(||<em>X</em><sub><em>i</em></sub> − <em>X</em><sub><em>j</em></sub>||)</span>
if <span class=""math inline""><em>i</em></span> and <span
class=""math inline""><em>j</em></span> belong to the same community, and
with probability <span
class=""math inline""><em>F</em><sub><em>o</em><em>u</em><em>t</em></sub>(||<em>X</em><sub><em>i</em></sub> − <em>X</em><sub><em>j</em></sub>||)</span>
if <span class=""math inline""><em>i</em></span> and <span
class=""math inline""><em>j</em></span> belong to different communities.
Under some technical conditions about <span
class=""math inline""><em>F</em><sub><em>i</em><em>n</em></sub></span> and
<span
class=""math inline""><em>F</em><sub><em>o</em><em>u</em><em>t</em></sub></span>,
we shall prove that asymptotically almost surely there is a set of <span
class=""math inline""><em>k</em> − 1</span> eigenvalues of the adjacency
matrix <span class=""math inline""><em>A</em>(<em>G</em>)</span> whose
eigenspaces allow us to correctly identify the members of each
community. This strategy gives a spectral algorithm for community
detection in random geometric graphs. The talk is based on joint work
with Konstantin Avrachenkov (INRIA-Sophia Antipolis), Luiz Emilio Allem
(UFRGS), Hariprasad Manjunath (Chanakya University), and Lucas Siviero
Sibemberg (UFRGS), and generalizes a result of Avrachenkov, Bobu and
Dreveton [Avrachenkov, K., Bobu, A., Dreveton, M., <em>Higher-Order
Spectral Clustering for Geometric Graphs</em>, Journal of Fourier
Analysis and Applications <span><strong>27</strong></span> (2021),
article 22.], which deals with the case of <span
class=""math inline""><em>k</em> = 2</span> communities.</p>
"
S8,SC2001,3,,,,2025-06-26 10:30:00,MS2,Combinatorial matrix theory,Thursday,11:30,12:00,108,2,,
S8,SC2006,1,,,,2025-06-26 10:30:00,,,Thursday,10:30,11:00,108,1000,,
S8,SC2006,2,,,,2025-06-26 10:30:00,,,Thursday,11:00,11:30,108,1000,,
S8,SC2006,3,,,,2025-06-26 10:30:00,,,Thursday,11:30,12:00,108,1000,,
S8,SC3001,1,Tomohiro,Sogabe,Tomohiro Sogabe,2025-06-26 10:30:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,10:30,11:00,108,16,"Numerical algorithms for matrix functions using the double exponential formulas
","<p>Matrix functions play a critical role in various scientific fields,
including quantum chromodynamics, large-scale electronic structure
calculations, and quantum information science. In this talk, we present
our recent work on numerical algorithms for computing matrix
functions—specifically, the matrix logarithm, matrix fractional powers,
and matrix exponential—based on the double exponential (DE) formula.</p>
"
S8,SC3001,2,Xiaobo,Liu,Xiaobo Liu,2025-06-26 10:30:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,11:00,11:30,108,16,"Generalizing reduced rank extrapolation to low-rank matrix sequences
","<p>Reduced Rank Extrapolation (RRE) is an acceleration method typically
used to accelerate iterative solutions of nonlinear systems of equations
arising from a fixed-point process, which is usually vector-valued. When
considering the iterative solution of large-scale matrix equations, the
iterates are nevertheless low-rank matrices generated by a fixed-point
process in which, in general, the mapping function changes at each
iteration. To enable acceleration of the iterative solution for such
problems, we propose two novel generalizations of RRE. First, we show
how to effectively compute RRE for sequences of low-rank matrices.
Second, we derive a formulation of RRE that is suitable for fixed-point
processes in which the mapping function changes at each iteration. We
demonstrate the potential of the proposed methods on several numerical
examples involving the iterative solution of large-scale Lyapunov and
Riccati matrix equations.</p>
"
S8,SC3001,3,Michael,Saunders,Michael Saunders,2025-06-26 10:30:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,11:30,12:00,108,16,,
S8,SC4011,1,Eric King-wah,Chu,Eric King-wah Chu,2025-06-26 10:30:00,MS1,Embracing new opportunities in numerical linear algebra,Thursday,10:30,11:00,108,1,"Inverse iteration for Sylvester operators
","<p>We generalize the inverse iteration for matrices to the (generalized)
Sylvester operator <span
class=""math inline"">𝒮(<em>X</em>) ≡ <em>A</em><em>X</em><em>B</em><sup>⊤</sup> − <em>C</em><em>X</em><em>D</em><sup>⊤</sup></span>,
computing the null space or the homogeneous solution to <span
class=""math inline"">𝒮(<em>X</em>) = 0</span>, or the eigen-spaces for
the intersecting subspectrum <span
class=""math inline""><em>Λ</em>(<em>A</em>, <em>C</em>) ∩ <em>Λ</em>(<em>D</em>, <em>B</em>)</span>.
Cases with two small matrix pencils in <span
class=""math inline"">(<em>A</em>, <em>C</em>)</span> and <span
class=""math inline"">(<em>D</em>, <em>B</em>)</span>, a large and a small
pencils, and two large pencils, as well as the special cases for the
Sylvester and Lyapunov equations, and the linear equation with tensor
structures, are considered. When the solution process for the
corresponding Sylvester equation is robust and efficient, the
generalized inverse iteration converges in one or two iterations,
especially for cases of small dimensions or with semi-simple
intersecting eigenvalues. For large examples, especially with derogatory
intersecting eigenvalues, the approach performs less well. Illustrative
numerical experiments are presented.</p>
"
S8,SC4011,2,Haesun,Park,Haesun Park,2025-06-26 10:30:00,MS1,Embracing new opportunities in numerical linear algebra,Thursday,11:00,11:30,108,1,"Integrative co-embedding of multi-view data sets
","<p>An integrative co-embedding method based on constrained low rank
approximation is introduced. The method achieves knowledge fusion of
multi-type data and projects the various types of objects onto a common
lower-dimensional space. This produces a more informed representation
that maintains both in-type and across-type semantic proximity between
objects. The effectiveness of the proposed method is illustrated using
examples of document data clustering where we utilize co-embedding of
papers, authors, key words, and patient profiling in healthcare data
utilizing traditional medical records, as well as patients’ interactions
via browsing and searching on healthcare web portals. One important
feature of the proposed co-embedding method is its ability to compute
embeddings for new, previously unobserved patient data efficiently and
effectively, eliminating the need to revisit the entire data set or
recomputing the embedding.</p>
"
S8,SC4011,3,Pengwen,Chen,Pengwen Chen,2025-06-26 10:30:00,MS1,Embracing new opportunities in numerical linear algebra,Thursday,11:30,12:00,108,1,One-bit diffraction tomography,"<p>A few years ago, we proposed a null initialization as one
initialization scheme for phase retrieval reconstruction. The null
initialization can be regarded as one reconstruction from one-bit
measurements. In this talk, we shall present a noise-robust framework
for 1-bit diffraction tomography, a novel imaging approach that relies
on intensity-only binary measurements obtained through coded apertures.
The proposed reconstruction scheme leverages the shifted inverse power
iteration, to effectively recover 3D object structures under high-noise
conditions. We develop one accurate 3D reconstruction scheme for
tomographic phase retrieval. The inverse X-ray transform is implemented
via solving a Toeplitz system, where FFT based preconditioners can be
employed to improve the convergence speed. A few simulations are reveal
the correlation of dose fractionation.</p>
"
S9,SC0008,1,Juan Paolo,Santos,Juan Paolo Santos,2025-06-26 13:30:00,MS31,Matrix decompositions and applications,Thursday,13:30,14:00,109,31,On commutators of unipotent matrices of index $2$,"<p>A commutator of unipotent matrices of index <span
class=""math inline"">2</span> is a matrix of the form <span
class=""math inline""><em>X</em><em>Y</em><em>X</em><sup>−1</sup><em>Y</em><sup>−1</sup></span>,
where <span class=""math inline""><em>X</em></span> and <span
class=""math inline""><em>Y</em></span> are unipotent matrices of index
<span class=""math inline"">2</span>, that is, <span
class=""math inline""><em>X</em> ≠ <em>I</em><sub><em>n</em></sub></span>,
<span
class=""math inline""><em>Y</em> ≠ <em>I</em><sub><em>n</em></sub></span>,
and <span
class=""math inline"">(<em>X</em> − <em>I</em><sub><em>n</em></sub>)<sup>2</sup> = (<em>Y</em> − <em>I</em><sub><em>n</em></sub>)<sup>2</sup> = 0<sub><em>n</em></sub></span>.
If <span class=""math inline""><em>n</em> &gt; 2</span> and <span
class=""math inline"">𝔽</span> is a field with <span
class=""math inline"">|𝔽| ≥ 4</span>, then it is shown that every <span
class=""math inline""><em>n</em> × <em>n</em></span> matrix over <span
class=""math inline"">𝔽</span> with determinant <span
class=""math inline"">1</span> is a product of at most four commutators of
unipotent matrices of index <span class=""math inline"">2</span>.
Consequently, every <span
class=""math inline""><em>n</em> × <em>n</em></span> matrix over <span
class=""math inline"">𝔽</span> with determinant <span
class=""math inline"">1</span> is a product of at most eight unipotent
matrices of index <span class=""math inline"">2</span>. Conditions on
<span class=""math inline"">𝔽</span> are given that improve the upper
bound on the commutator factors from four to three or two. The situation
for <span class=""math inline""><em>n</em> = 2</span> is also considered.
This study reveals a connection between factorability into commutators
of unipotent matrices and properties of <span
class=""math inline"">𝔽</span> such as its characteristic or its set of
perfect squares.</p>
"
S9,SC0008,2,Jesus Paolo,Joven,Jesus Paolo Joven,2025-06-26 13:30:00,MS31,Matrix decompositions and applications,Thursday,14:00,14:30,109,31,Product of skew-involutions,"<p>We show that every <span
class=""math inline"">2<em>n</em></span>-by-<span
class=""math inline"">2<em>n</em></span> matrix over a field <span
class=""math inline"">𝔽</span> with determinant 1 is a product of (i) four
or fewer skew-involutions (<span
class=""math inline""><em>A</em><sup>2</sup> = −<em>I</em></span>)
provided <span class=""math inline"">𝔽 ≠ ℤ<sub>3</sub></span>, and (ii)
eight or fewer skew-involutions if <span
class=""math inline"">𝔽 = ℤ<sub>3</sub></span> and <span
class=""math inline""><em>n</em> &gt; 1</span>. We also show that every
real symplectic matrix is a product of six real symplectic
skew-involutions.</p>
"
S9,SC0008,3,Tejbir,Lohan,Tejbir Lohan,2025-06-26 13:30:00,MS31,Matrix decompositions and applications,Thursday,14:30,15:00,109,31,Product of two involutions in special linear groups,"<p>An element of a group is called an involution if its square equals
the identity element. Decomposing a group element into a product of
involutions has applications in various areas of mathematics, with a
particular focus on elements that can be expressed as the product of two
involutions, known as <em>strongly reversible</em>, <em>strongly
real</em>, or <em>bireflectional</em> elements. Classifying strongly
reversible elements in a group is a problem of broad interest. It is
known that an element of the general linear group over a field is
strongly reversible if and only if it is similar to its inverse.
However, this result does not hold for special linear groups over a
field or a division ring. In this talk, we will use the notion of
reversibility to classify the strongly reversible elements in the
complex special linear group and the quaternionic special linear group.
This talk is based on joint work with Krishnendu Gongopadhyay and
Chandan Maity.</p>
"
S9,SC0008,4,Daryl,Granario,Daryl Granario,2025-06-26 13:30:00,MS31,Matrix decompositions and applications,Thursday,15:00,15:30,109,31,Some factorizations in the complex symplectic group,"<p>As one of the classical Lie groups, the complex symplectic group is
fundamental not only in mathematics but also in various related fields.
We look at some important matrix decompositions when restricted to the
complex symplectic group. In particular, we look at how we can use
symplectic versions of canonical forms to derive decompositions such as
the one given by Ballantine concerning products of positive definite
matrices, and the one given by Sourour concerning the spectra of factors
in a product of matrices.</p>
"
S9,SC0009,1,Daniela,Calvetti,Daniela Calvetti,2025-06-26 13:30:00,MS4,Linear algebra methods for inverse problems and data assimilation,Thursday,13:30,14:00,109,4,The linear algebra of space-time regularization for time-dependent distributed inverse problems,"<p>In Bayesian dynamic ill-posed inverse problem, the a priori belief
about the solution may have different characteristics in the spatial and
temporal directions. This is the case, for example, for a promoting
sparsity in space and smoothness in the temporal direction. In this talk
we will consider dynamic inverse problems where the prior should promote
group sparsity in the spatial direction and some degree of time
continuity in time, and we will show how linear algebraic techniques can
be used to design robust and computationally efficient algorithms.</p>
"
S9,SC0009,2,Julianne,Chung,Julianne Chung,2025-06-26 13:30:00,MS4,Linear algebra methods for inverse problems and data assimilation,Thursday,14:00,14:30,109,4,,
S9,SC0009,3,Fred,Roosta,Fred Roosta,2025-06-26 13:30:00,MS4,Linear algebra methods for inverse problems and data assimilation,Thursday,14:30,15:00,109,4,"Numerical linear algebra and optimization: the interplay between inner and outer iterations
","<p>Newton-type methods offer key advantages over first-order
optimization, including resilience to ill-conditioning, reduced
sensitivity to hyper-parameters, superior local convergence, improved
communication efficiency in distributed settings, and affine invariance.
However, every iteration of these methods requires solving non-trivial
subproblems–an aspect often overlooked. In this talk, we revisit
examples of Newton-type methods, highlighting the role of iterative
linear algebra subroutines in solving these subproblems, and show how
leveraging their theoretical and empirical properties within the inner
iterations can eliminate unnecessary safeguards and assumptions,
resulting in simpler algorithms and analyses of the outer
iterations.</p>
"
S9,SC0009,4,Colin,Fox,Colin Fox,2025-06-26 13:30:00,MS4,Linear algebra methods for inverse problems and data assimilation,Thursday,15:00,15:30,109,4,,
S9,SC0012,1,Tamas,Titkos,Tamas Titkos,2025-06-26 13:30:00,MS35,"Preserver Problems, II",Thursday,13:30,14:00,109,35,Isometries of Lipschitz free Banach spaces,"<p>In the first part of the talk, I will focus on isometries of <span
class=""math inline"">𝒲<sub><em>p</em></sub>(<em>M</em>)</span> spaces,
mainly in the case when <span class=""math inline""><em>p</em> = 1</span>
– the case which is closely connected to the theory of Lipschitz-free
spaces. It is known that if <span class=""math inline""><em>F</em></span>
is an isometry of M, then its push-forward <span
class=""math inline""><em>F</em><sub>#</sub></span> is an isometry of
<span class=""math inline"">𝒲<sub><em>p</em></sub>(<em>M</em>)</span>. A
natural question arises: is this embedding surjective? We know several
concrete examples where the answer is yes, but the answer, in general,
is no. In the second part of the talk, I will present some new results
about isometries of Lipschitz-free spaces. In particular, I will
describe surjective linear isometries and linear isometry groups of a
large class of Lipschitz-free spaces.</p>
"
S9,SC0012,2,Ya-Shu,Wang,Ya-Shu Wang,2025-06-26 13:30:00,MS35,"Preserver Problems, II",Thursday,14:00,14:30,109,35,"Linear maps preserving disjoint idempotents
","<p>Let <span class=""math inline"">${\bf M}_n(F)$</span> denote the set of
all <span class=""math inline""><em>n</em> × <em>n</em></span> matrices
and <span class=""math inline"">${\bf S}_n(F)$</span> denote the set of
symmetric <span class=""math inline""><em>n</em> × <em>n</em></span>
matrices over a field <span class=""math inline""><em>F</em></span>,
respectively. In this talk, I will present a characterization of linear
maps on <span class=""math inline"">${\bf M}_n(F)$</span> and <span
class=""math inline"">${\bf S}_n(F)$</span> that send disjoint rank one
idempotents to disjoint idempotents. As an application, I will also
characterize linear maps on <span class=""math inline"">${\bf
M}_n(F)$</span> and <span class=""math inline"">${\bf S}_n(F)$</span> that
preserve matrices annihilated by a fixed polynomial under certain
assumptions.</p>
"
S9,SC0012,3,Ngai-Ching,Wong,Ngai-Ching Wong,2025-06-26 13:30:00,MS35,"Preserver Problems, II",Thursday,14:30,15:00,109,35,Tingley's problems for positive spheres of operator algebras,"<p>Let <span
class=""math inline""><em>T</em> : <strong>S</strong><sub><em>E</em></sub> → <strong>S</strong><sub><em>F</em></sub></span>
be a bijective isometry between the unit spheres of two real normed
spaces <span class=""math inline""><em>E</em>, <em>F</em></span>, i.e.,
<span
class=""math display"">∥<em>T</em><em>x</em> − <em>T</em><em>y</em>∥<sub><em>F</em></sub> = ∥<em>x</em> − <em>y</em>∥<sub><em>E</em></sub>,  ∀<em>x</em>, <em>y</em> ∈ <em>E</em>.</span>
Tingley asked in 1987 whether we can extend any such <span
class=""math inline""><em>T</em></span> to a linear isometry from <span
class=""math inline""><em>E</em></span> onto <span
class=""math inline""><em>F</em></span>. We answer, in the affirmative,
Tingley’s problem for positive unit spheres of (complex) von Neumann
algebras.</p>
<p>More precisely, let <span
class=""math inline""><em>Λ</em> : S<sub>𝒜<sup>+</sup></sub> → S<sub>ℬ<sup>+</sup></sub></span>
be a bijective isometry between the sets of positive norm-one elements
of two von Neumann algebras <span class=""math inline"">𝒜</span> and <span
class=""math inline"">ℬ</span>. We show that <span
class=""math inline""><em>T</em></span> extends to a bijective complex
linear Jordan <span class=""math inline""><sup>*</sup></span>-isomorphism
from <span class=""math inline"">𝒜</span> onto <span
class=""math inline"">ℬ</span>. Actually, the above results are proved in
the slightly more general situations that <span
class=""math inline"">𝒜</span> and <span class=""math inline"">ℬ</span> are
<span
class=""math inline""><em>A</em><em>W</em><sup>*</sup></span>-algebras, or
separable <span
class=""math inline""><em>C</em><sup>*</sup></span>-algebras with real
rank zero.</p>
<p>This is a joint work with Chi-Keung Ng (Nankai, Tianjin) and Chi-Wai
Leung (CUHK, Hong Kong).</p>
"
S9,SC0012,4,Manideepa,Saha,Manideepa Saha,2025-06-26 13:30:00,MS35,"Preserver Problems, II",Thursday,15:00,15:30,109,35,On linear preservers of semimonotone matrices,"<p>A real square matrix <span class=""math inline""><em>A</em></span> is
said to be <span><em>semimonotone</em></span> if for any entrywise
nonnegative vector <span class=""math inline""><em>x</em> ≠ 0</span>,
there exists an index <span class=""math inline""><em>i</em></span> such
that <span class=""math inline""><em>x</em><sub><em>i</em></sub></span>,
the <span class=""math inline""><em>i</em></span>-th entry of <span
class=""math inline""><em>x</em></span>, satisfies <span
class=""math inline""><em>x</em><sub><em>i</em></sub> &gt; 0</span> and
<span
class=""math inline"">(<em>A</em><em>x</em>)<sub><em>i</em></sub> ≥ 0</span>,
and <span class=""math inline""><strong>E</strong><sub>0</sub></span>
denotes the class of such matrices. Semimonotone matrices are noteworthy
because of their appearance in studying the linear complementarity
problem (LCP), which plays an significant role in areas of bimatrix
games, linear programming, quadratic programming etc. A linear map <span
class=""math inline"">ℒ : ℝ<sup><em>n</em> × <em>n</em></sup> → ℝ<sup><em>n</em> × <em>n</em></sup></span>
is said to be an <span><em><span
class=""math inline""><em>X</em></span>-(linear) preserver</em></span> if
it preserves certain property <span
class=""math inline""><em>X</em></span>, that is, if <span
class=""math inline""><em>X</em> ⊂ ℝ<sup><em>n</em> × <em>n</em></sup></span>,
then <span class=""math inline"">ℒ(<em>X</em>) ⊆ <em>X</em></span>. In
case, <span class=""math inline"">ℒ(<em>X</em>) = <em>X</em></span>, then
<span class=""math inline"">ℒ</span> is known as an <span><em>onto/strong
<span class=""math inline""><em>X</em></span>-(linear)
preserver</em></span>. In this paper, we study strong/onto linear
preservers of semimonotone and almost semimonotone (all proper principal
submatrices are semimonotone) matrices. In particular, we prove that an
onto <span
class=""math inline""><strong>E</strong><sub>0</sub></span>-preserver can
be written as direct sum of monomial and generalized monominal matrices.
We further characterize all strong/onto <span
class=""math inline""><strong>E</strong><sub>0</sub></span>-preservers in
terms of transposition, permutation similarity and positive diagonal
equivalence transformations. At last, we provide three types of onto
linear preservers that preservers almost semimonotone matrices.</p>
"
S9,SC0014,1,Fernando,De Terán,Fernando De Terán,2025-06-26 13:30:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Thursday,13:30,14:00,109,5,The uniqueness of solution of systems of generalized Sylvester and $\star$-Sylvester equations,"<p>The <span><em>generalized Sylvester equation</em></span> <span
class=""math display""><em>A</em><em>X</em><em>B</em> − <em>C</em><em>X</em><em>D</em> = <em>E</em></span>
has been a subject of interest since, at least, the early 20th century.
More recently, the <span><em><span
class=""math inline"">⋆</span>-generalized Sylvester equation</em></span>
<span
class=""math display""><em>A</em><em>X</em><em>B</em> − <em>C</em><em>X</em><sup>⋆</sup><em>D</em> = <em>E</em>,</span>
with <span class=""math inline"">⋆</span> being either the transpose or
the conjugate transpose, has attracted some attention within the linear
algebra community.</p>
<p>In this talk, we provide necessary and sufficient conditions for the
uniqueness of solution of homogeneous systems of generalized Sylvester
and <span class=""math inline"">⋆</span>-Sylvester equations, namely <span
class=""math display""><em>A</em><sub><em>i</em></sub><em>X</em><sub><em>α</em><sub><em>i</em></sub></sub><sup><em>s</em><sub><em>i</em></sub></sup><em>B</em><sub><em>i</em></sub> − <em>C</em><sub><em>i</em></sub><em>X</em><sub><em>β</em><sub><em>i</em></sub></sub><sup><em>t</em><sub><em>i</em></sub></sup><em>D</em><sub><em>i</em></sub> = 0,   <em>i</em> = 1, …, <em>r</em>,</span>
with <span
class=""math inline""><em>s</em><sub><em>i</em></sub>, <em>t</em><sub><em>i</em></sub> ∈ {1, ⋆}</span>.</p>
<p>We focus on the case where the system has the same number of
equations and unknowns (namely, <span
class=""math inline""><em>r</em></span>), and where all coefficient
matrices (and unknowns) are square and with the same size.</p>
"
S9,SC0014,2,Roberto,Canogar,Roberto Canogar,2025-06-26 13:30:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Thursday,14:00,14:30,109,5,"The matrix equation $X^*AX=I_n$, or how much of sesquilinear form is positive definite
","<p>We will report on our progress to provide necessary and sufficient
conditions for the matrix equation <span
class=""math inline""><em>X</em><sup>*</sup><em>A</em><em>X</em> = <em>I</em><sub><em>n</em></sub></span>
to be consistent where <span class=""math inline""><em>A</em></span> is
any complex <span class=""math inline""><em>m</em> × <em>m</em></span>
matrix (<span class=""math inline""><em>m</em>, <em>n</em></span> might be
different). Note that <span
class=""math inline""><em>X</em> ∈ <em>C</em><sup><em>m</em> × <em>n</em></sup></span>
is an unknown matrix, and <span
class=""math inline""><em>X</em><sup>*</sup></span> denotes its conjugate
transpose. In other words, given any sesquilinear form over <span
class=""math inline""><em>C</em><sup><em>m</em></sup></span>, we want to
determine a subspace of the maximum attainable dimension with the
property that the restriction of the sesquilinear form to this subspace
is positive definite. As we will see this project is near
completion.</p>
"
S9,SC0014,3,Patrick,Kürschner,Patrick Kürschner,2025-06-26 13:30:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Thursday,14:30,15:00,109,5,"Extrapolation for iterative solvers for matrix equations
","<p>Given a convergent vector sequence, the speed to convergence can be
improved by reduced rank extrapolation (RRE) [1,2]. Often, the vector
sequences of interest are generated by an iterative process to solve
algebraic equations. This presentation shows how to generalize this
extrapolation framework to sequences of (low-rank) matrices which are
generated by iterative methods for matrix equations. At first, we will
briefly have a glance at recent developments to incorporate RRE in
low-rank alternating directions implicit methods for Lyapunov and
Riccati equations [3]. After this, the main focus lies in RRE for
stationary and non-stationary iterations [4] for general linear matrix
equations <span
class=""math inline"">$\mathcal{A}(X)=\sum\limits_{k=1}^LA_kXB_k=C$</span>
with <span class=""math inline""><em>L</em> &gt; 2</span>, where the
linear operator <span class=""math inline"">𝒜</span> admits a convergent
additive splitting. We discuss the incorporation of RRE in those
iterations for small to moderately sized problems and also in low-rank
variants for large-scale problems [5].</p>
<ol>
<li><p>R. P. Eddy: Extrapolating to the limit of a vector sequence. In
<em>Information linkage between applied mathematics and industry</em>,
pp. 387–396.Academic Press, Cambridge, MA, 1979.</p></li>
<li><p>A. Sidi: Efficient implementation of minimal polynomial and
reduced rank extrapolation methods, <em>J. Comput. Appl. Math</em>.,
36(3):305–337, 1991.</p></li>
<li><p>P. den Boef, P. Kürschner, X. Liu, J. Maubach, J. Saak, W.
Schilders, J. Schulze, N. van de Wouw: Generalizing Reduced Rank
Extrapolation to Low-Rank Matrix Sequences, <em>Arxiv preprint</em>
2502.09165, 2025.</p></li>
<li><p>T. Damm: Direct methods and ADI-preconditioned Krylov subspace
methods for generalized Lyapunov equations. <em>Numer. Lin. Alg.
Appl</em>., 15(9):853–871, 2008</p></li>
<li><p>S. D. Shank, V. Simoncini and D. B. Szyld: Efficient low-rank
solutions of Generalized Lyapunov equations, <em>Numer. Math.</em>,
134:327–342, 2016</p></li>
</ol>
"
S9,SC0014,4,Davide,Palitta,Davide Palitta,2025-06-26 13:30:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Thursday,15:00,15:30,109,5,"A subspace-conjugate gradient method for linear matrix equations
","<p>The efficient solution of large-scale multiterm linear matrix
equations is a challenging task in numerical linear algebra, and it is a
largely open problem. In this talk, a new iterative scheme for symmetric
and positive definite operators is presented, significantly advancing
methods such as truncated matrix-oriented Conjugate Gradients (CG). The
new algorithm capitalizes on the low-rank matrix format of its iterates
by fully exploiting the subspace information of the factors as
iterations proceed. The approach implicitly relies on orthogonality
conditions imposed over much larger subspaces than in CG, unveiling
insightful connections with subspace projection methods. The new method
is also equipped with memory-saving strategies. In particular, for a
given matrix <span class=""math inline""><em>Y</em></span>, the action
<span class=""math inline"">ℒ(<em>Y</em>)</span> in low rank format may
not be evaluated exactly due to memory constraints. This problem is
often underestimated, though it will eventually produce Out-of-Memory
breakdowns for a sufficiently large number of terms. We propose an
ad-hoc randomized range-finding strategy that appears to fully resolve
this shortcoming. Experimental results with typical application problems
illustrate the potential of our approach over various methods developed
in the recent literature.</p>
<p>This is a joint work with Martina Iannacito and Valeria
Simoncini.</p>
"
S9,SC1001,1,Sho,Suda,Sho Suda,2025-06-26 13:30:00,MS34,"Combinatorics, association scheme, and graphs",Thursday,13:30,14:00,109,34,"On $(2s-1)$-designs with $s$-distances in the Hamming association schemes
","<p>It was shown by Delsarte that a <span
class=""math inline"">(2<em>s</em> − 2)</span>-design with <span
class=""math inline""><em>s</em></span>-distances in a Hamming association
scheme induces an <span class=""math inline""><em>s</em></span>-classes
association scheme. In this talk, we prove that a <span
class=""math inline"">(2<em>s</em> − 1)</span>-design with <span
class=""math inline""><em>s</em></span>-distances gives rise to a <span
class=""math inline"">2<em>s</em></span>- or <span
class=""math inline"">(2<em>s</em> − 1)</span>-classes fission association
scheme. As a corollary, a new necessary condition for the existence of
tight <span class=""math inline"">3</span>-design in the Hamming
association schemes is obtained. This talk is based on joint work with
Alexander Gavrilyuk.</p>
"
S9,SC1001,2,Yen-chi,Lin,Yen-chi Lin,2025-06-26 13:30:00,MS34,"Combinatorics, association scheme, and graphs",Thursday,14:00,14:30,109,34,,
S9,SC1001,3,Wasin,So,Wasin So,2025-06-26 13:30:00,MS34,"Combinatorics, association scheme, and graphs",Thursday,14:30,15:00,109,34,Formal orthogonal systems,"<p>Dreaming of an effective way to generate orthogonal bases in <span
class=""math inline"">${\bf R}^n$</span>, we study formal orthogonal
systems which are collections of nonzero <span
class=""math inline""><em>n</em> × <em>n</em></span> real matrices <span
class=""math display"">{<em>A</em><sub>0</sub> = <em>I</em><sub><em>n</em></sub>, <em>A</em><sub>1</sub>, <em>A</em><sub>2</sub>, …, <em>A</em><sub><em>n</em> − 1</sub>}</span>
such that <span
class=""math inline"">{<em>A</em><sub>0</sub><em>x</em>, <em>A</em><sub>1</sub><em>x</em>, <em>A</em><sub>2</sub><em>x</em>, ⋯, <em>A</em><sub><em>n</em> − 1</sub><em>x</em>}</span>
is an orthogonal set for all <span class=""math inline""><em>x</em></span>
in <span class=""math inline"">${\bf R}^n$</span>. We prove that formal
orthogonal systems of order <span class=""math inline""><em>n</em></span>
exist if and only if <span
class=""math inline""><em>n</em> = 1, 2, 4,</span> or <span
class=""math inline"">8</span>. The proof has an unexpected connection to
the famous results of Adolf Hurwitz on the product of two sums of <span
class=""math inline""><em>n</em></span> squares.</p>
<p>Joint work with Ardak Kapbasov and Shaunak Mashalkar.</p>
"
S9,SC1001,4,Wei-Liang,Sun,Wei-Liang Sun,2025-06-26 13:30:00,MS34,"Combinatorics, association scheme, and graphs",Thursday,15:00,15:30,109,34,Power difference sets and cyclotomic matrices,"<p>A difference set in a finite field is a subset where every nonzero
element can be expressed as the difference of two elements from the
subset, each occurring a fixed number of times. Every difference set
gives rise to a symmetric balanced incomplete block design.</p>
<p>In 1933, R. Paley characterized when a set of squares forms a
difference set. Later, S. Chowla extended this result to fourth powers.
A difference set formed by <span
class=""math inline""><em>ℓ</em></span>-th powers is called a power
difference set. A natural question is whether all <span
class=""math inline""><em>ℓ</em></span>-th power difference sets can be
characterized. However, so far, researchers have only been able to
construct such sets for <span
class=""math inline""><em>ℓ</em> = 2, 4, 8</span> when <span
class=""math inline""><em>ℓ</em> ≤ 24</span>, and it is conjectured that
no other power difference sets exist.</p>
<p>Cyclotomic numbers captures the sizes of certain subsets
intersections in a finite field. These numbers provide crucial
information about the existence of a power difference set. The
cyclotomic matrix is a matrix whose entries are cyclotomic numbers. By
exploring properties of the cyclotomic matrix, we are able to conclude
that if a power difference set exists, and if the size of elements
outside the set is a square, then <span
class=""math inline""><em>ℓ</em></span> is congruent to <span
class=""math inline"">0</span> or <span class=""math inline"">2</span>
modulo <span class=""math inline"">8</span>. This result holds for a power
difference set that forms a finite projective plane. In contrast, our
result allows for discussing an infinite number of <span
class=""math inline""><em>ℓ</em></span> values, extending the scope of
previous finite cases. As far as we know, this may be the first
application of cyclotomic matrices to power difference sets.</p>
"
S9,SC1003,1,Lauri,Nyman,Lauri Nyman,2025-06-26 13:30:00,MS14,"Pencils, polynomial, and rational matrices",Thursday,13:30,14:00,109,14,Nearest $\Omega$-stable pencil with Riemannian optimization,"<p>In this talk, we consider the problem of finding the nearest <span
class=""math inline""><em>Ω</em></span>-stable pencil to a given square
pencil <span
class=""math inline""><em>A</em> + <em>x</em><em>B</em> ∈ ℂ<sup><em>n</em> × <em>n</em></sup></span>,
where a pencil is called <span
class=""math inline""><em>Ω</em></span>-stable if it is regular and all of
its eigenvalues belong to the closed set <span
class=""math inline""><em>Ω</em></span>. We propose a new method, based on
the Schur form of a matrix pair and Riemannian optimization over the
manifold <span
class=""math inline""><em>U</em>(<em>n</em>) × <em>U</em>(<em>n</em>)</span>,
that is, the Cartesian product of the unitary group with itself. While
the developed theory holds for any closed set <span
class=""math inline""><em>Ω</em></span>, we focus on two cases that are
the most common in applications: Hurwitz stability and Schur
stability.</p>
"
S9,SC1003,2,Javier,Perez,Javier Perez,2025-06-26 13:30:00,MS14,"Pencils, polynomial, and rational matrices",Thursday,14:00,14:30,109,14,On the numerical stability of compact Krylov methods,"<p>Computational methods like TOAR, CORK, and their variants help solve
large polynomial, rational, and more generally, nonlinear eigenvalue
problems. These methods apply (rational) Arnoldi to a matrix or pencil
with a special Kronecker structure. In this talk, I will present some
results on the numerical stability of these methods and compare them to
(rational) Arnoldi applied without exploiting the Kronecker
structure.</p>
"
S9,SC1003,3,Antti,Hannukainen,Antti Hannukainen,2025-06-26 13:30:00,MS14,"Pencils, polynomial, and rational matrices",Thursday,14:30,15:00,109,14,A Ritz method for solution of parametric generalized EVPs,"<p>This talk deals with approximate solution of generalized eigenvalue
problem with coefficient matrix that is an affine function of <span
class=""math inline""><em>d</em></span>-parameters. The coefficient matrix
is assumed to be symmetric positive definite and spectrally equivalent
to an average matrix for all parameters in a given set. We develop a
Ritz method for rapidly approximating the eigenvalues on the spectral
interval of interest <span class=""math inline"">(0, <em>Λ</em>)</span>
for given parameter value. The Ritz subspace is the same for all
parameters and it is designed based on the observation that any
eigenvector can be split into two components. The first component
belongs to a subspace spanned by some eigenvectors of the average
matrix. The second component is defined by a correction operator that is
a <span class=""math inline""><em>d</em> + 1</span> dimensional analytic
function. We use this structure and build our Ritz subspace from
eigenvectors of the average matrix and samples of the correction
operator. The samples are evaluated at interpolation points related to a
sparse polynomial interpolation method. We show that the resulting Ritz
subspace can approximate eigenvectors of the original problem related to
the spectral interval of interest with the same accuracy as the sparse
polynomial interpolation approximates the correction operator. Bound for
Ritz eigenvalue error follows from this and known results. Theoretical
results are illustrated by numerical examples. The advantage of our
approach is that the analysis treats multiple eigenvalues and eigenvalue
crossings that typically have posed technical challenges in similar
works.</p>
"
S9,SC1003,4,Froilan M.,Dopico,Froilan M. Dopico,2025-06-26 13:30:00,MS14,"Pencils, polynomial, and rational matrices",Thursday,15:00,15:30,109,14,Polynomial and rational matrices with the invariant rational functions and the four sequences of minimal indices prescribed,"<p>The complete eigenstructure, or structural data, of a rational matrix
<span class=""math inline""><em>R</em>(<em>s</em>)</span> is comprised by
its invariant rational functions, both finite and at infinity, which
determine its finite and infinite pole and zero structures, and by the
minimal indices of its left and right null spaces. These quantities
arise in many applications and have been thoroughly studied in numerous
references. However, <span
class=""math inline""><em>R</em>(<em>s</em>)</span> has other two
fundamental subspaces which, in contrast, have received much less
attention in the literature. They are its column and row spaces, which
also have their associated minimal indices. This work solves the
problems of finding necessary and sufficient conditions for the
existence of rational matrices in two scenarios: (a) when the invariant
rational functions and the minimal indices of the column and row spaces
are prescribed, and (b) when the complete eigenstructure together with
the minimal indices of the column and row spaces are prescribed. The
particular, but extremely important, cases of these problems for
polynomial matrices are solved first and are the main tool for solving
the general problems. The results in this work complete and extend
non-trivially the necessary and sufficient conditions recently developed
in the literature for the existence of polynomial and rational matrices
when only the complete eigenstructure is prescribed.</p>
<p>This is joint work with Itziar Baragaña and Silvia Marcaida
(Universidad del País Vasco UPV/EHU, Spain) and Alicia Roca (Universitat
Politècnica de València, Spain).</p>
"
S9,SC1005,1,Helena,Šmigoc,Helena Šmigoc,2025-06-26 13:30:00,MS27,Linear algebra education,Thursday,13:30,14:00,109,27,Posing a question,"<p>Linear algebra is included in the curriculum for students pursuing
various degrees such as computer science, biology, engineering, and pure
mathematics. When students from different fields are in the same
classroom, it can be challenging to tailor instruction to meet
everyone’s needs. We will explore ways of setting a problem in this
context, with the aim to motivate students with diverse interests, and
develop their understanding of the topic.</p>
"
S9,SC1005,2,Jane,Breen,Jane Breen,2025-06-26 13:30:00,MS27,Linear algebra education,Thursday,14:00,14:30,109,27,"Incorporating data science applications into standard linear algebra courses
","<p>Linear algebra plays a central role in data science, but it can be
hard for students to see that connection in a traditional course, and
instructors do not always have the flexibility in the curriculum to
spend time on these ideas. In this talk, I’ll share practical ways that
I have introduced data science-inspired problems and applications into
standard linear algebra classes in the past.</p>
"
S9,SC1005,3,Mei Q,Chen,Mei Q Chen,2025-06-26 13:30:00,MS27,Linear algebra education,Thursday,14:30,15:00,109,27,New challenges in teaching elementary linear algebra,"<p>Linear Algebra is a required course for the BS degree program in
mathematics and is a major program elective for majors in finance,
computer science, engineering, and physics at The Citadel. To provide
students with opportunities to explore advanced topics in linear
algebra, to gain research experience and to solve open problems in
linear algebra (posted in MAA publications), or to work on real-world
applications in their major fields using linear algebra, we add project
assignments to the course curriculum. In this talk, we will share our
experience in developing course projects, working with students with
different majors to complete their projects and to inspire them for
further studies in linear algebra, and to prepare mathematics majors for
advanced linear algebra.</p>
"
S9,SC1005,4,Sepideh,Stewart,Sepideh Stewart,2025-06-26 13:30:00,MS27,Linear algebra education,Thursday,15:00,15:30,109,27,Bridging abstract and numerical linear algebra,"<p>Linear algebra is a key mathematics topic applicable to many other
fields. Hence, equipping students with knowing linear algebra well with
the ability to tackle problems numerically is an excellent way of
preparing them for the future wo rkforce. In this talk, we will discuss
the importance of teaching both abstract and numerical linear algebra in
our classrooms. We will discuss ways to transform an existing abstract
linear algebra into a course that includes numerical  linear algebra, as
well as create a new course. Deciding to balance the amount of theory
and computation is a challenge we often face in our lectures. We will
address some challenges of creating such courses and ways to combat
them. We welcome your input and invite you to join us as we continue
this work. This is a joint work with Rachel Quinlan and Mike
Michailidis.</p>
"
S9,SC2001,1,Iswar,Mahato,Iswar Mahato,2025-06-26 13:30:00,MS21,Linear algebra techniques in graph theory,Thursday,13:30,14:00,109,21,A generalized class of matrices associated to threshold and chain graphs,"<p>Motivated by the distance matrix <span
class=""math inline""><em>D</em>(<em>G</em>)</span> of a connected graph
<span class=""math inline""><em>G</em></span>, we define a new class of
matrix <span
class=""math inline""><em>D</em><sub><em>α</em>, <em>β</em>, <em>γ</em>, <em>δ</em></sub>(<em>G</em>)</span>
of a connected graph <span class=""math inline""><em>G</em></span> with
diameter at most <span class=""math inline"">3</span>, by substituting the
entries <span class=""math inline"">0, 1, 2</span> and <span
class=""math inline"">3</span> of <span
class=""math inline""><em>D</em>(<em>G</em>)</span> by the real variables
<span class=""math inline""><em>α</em>, <em>β</em>, <em>γ</em></span> and
<span class=""math inline""><em>δ</em></span>, respectively. Clearly, by
putting suitable values of <span
class=""math inline""><em>α</em>, <em>β</em>, <em>γ</em></span> and <span
class=""math inline""><em>δ</em></span>, we get six interesting known
matrices, such as adjacency matrix, Seidel matrix, distance matrix,
squared distance matrix, <span
class=""math inline""><em>q</em></span>-distance matrix and exponential
distance matrix. Therefore, for a graph <span
class=""math inline""><em>G</em></span> with diameter at most <span
class=""math inline"">3</span>, the matrix <span
class=""math inline""><em>D</em><sub><em>α</em>, <em>β</em>, <em>γ</em>, <em>δ</em></sub>(<em>G</em>)</span>
generalizes these six known matrices. In this article, we consider <span
class=""math inline""><em>D</em><sub><em>α</em>, <em>β</em>, <em>γ</em></sub>(<em>G</em>)</span>
of a threshold graph <span class=""math inline""><em>G</em></span> and
determine an eigenvalue free-interval for <span
class=""math inline""><em>D</em><sub><em>α</em>, <em>β</em>, <em>γ</em></sub>(<em>G</em>)</span>.
As a consequence of this result, we recover the known results about the
eigenvalue free-interval of the adjacency matrix, the Seidel matrix and
the distance matrix of a threshold graph, respectively and obtain an
eigenvalue free-interval for the squared distance matrix, the <span
class=""math inline""><em>q</em></span>-distance matrix and the
exponential distance matrix of a threshold graph, respectively.
Moreover, we give an explicit expression for the characteristic
polynomial of <span
class=""math inline""><em>D</em><sub><em>α</em>, <em>β</em>, <em>γ</em></sub>(<em>G</em>)</span>.
Furthermore, we consider <span
class=""math inline""><em>D</em><sub><em>α</em>, <em>β</em>, <em>γ</em>, <em>δ</em></sub>(<em>G</em>)</span>
of a chain graph <span class=""math inline""><em>G</em></span> and find
the characteristic polynomial of <span
class=""math inline""><em>D</em><sub><em>α</em>, <em>β</em>, <em>γ</em>, <em>δ</em></sub>(<em>G</em>)</span>.
As a consequence of these results, we give a determinant formula for the
distance matrix, the squared distance matrix, the <span
class=""math inline""><em>q</em></span>-distance matrix and the
exponential distance matrix of a threshold graph and a chain graph,
respectively.</p>
"
S9,SC2001,2,Sasmita,Barik,Sasmita Barik,2025-06-26 13:30:00,MS21,Linear algebra techniques in graph theory,Thursday,14:00,14:30,109,21,"Limit points of the smallest positive eigenvalues of graphs
","<p>Hoffman initiated the study of limit points of eigenvalues of
nonnegative symmetric integer matrices and posed the question of finding
all limit points of the set of spectral radii of all nonnegative
symmetric integer matrices. In the same article, the author showed that
it is enough to consider the adjacency matrices of simple graphs to
study the limit points of spectral radii. Since then, many researchers
have worked on similar problems, considering various specific
eigenvalues such as the least eigenvalue, the <span
class=""math inline""><em>k</em></span>-th largest eigenvalue, and the
<span class=""math inline""><em>k</em></span>-th smallest eigenvalue,
among others. Motivated by this, we ask the question, “which real
numbers are the limit points of the set of the smallest positive
eigenvalues (respectively, the largest negative eigenvalues) of graphs?”
In this talk, we provide a complete answer to this question by proving
that any nonnegative (respectively, nonpositive) real number is a limit
point of the set of all smallest positive eigenvalues (respectively,
largest negative eigenvalues) of graphs. We also show that the union of
the sets of limit points of the smallest positive eigenvalues and the
largest negative eigenvalues of graphs is dense in <span
class=""math inline"">ℝ</span>.</p>
"
S9,SC2001,3,Krishnan,Sivasubramanian,Krishnan Sivasubramanian,2025-06-26 13:30:00,MS21,Linear algebra techniques in graph theory,Thursday,14:30,15:00,109,21,The $2$-Steiner distance and two other matrices associated to a tree,"<p>Let <span class=""math inline""><em>T</em></span> be a tree with vertex
set <span
class=""math inline""><em>V</em>(<em>T</em>) = {1, 2, …, <em>n</em>}</span>.
The Steiner distance of <span
class=""math inline""><em>S</em> ⊆ <em>V</em>(<em>T</em>)</span> of
vertices of <span class=""math inline""><em>T</em></span> is defined to be
the number of edges in a smallest connected subtree of <span
class=""math inline""><em>T</em></span> that contains all the vertices of
<span class=""math inline""><em>S</em></span>. The 2-Steiner distance
matrix <span
class=""math inline"">𝔇<sub><em>k</em></sub>(<em>T</em>)</span> of <span
class=""math inline""><em>T</em></span> is the <span
class=""math inline"">$\binom{n}{2}\times \binom{n}{2}$</span> matrix
whose rows and columns are indexed by subsets of vertices of size <span
class=""math inline"">2</span>. The entry in the row indexed by <span
class=""math inline""><em>P</em></span> and column indexed by <span
class=""math inline""><em>Q</em></span> is equal to Steiner distance of
<span class=""math inline""><em>P</em> ∪ <em>Q</em></span>.</p>
<p>We show that <span
class=""math inline"">rank(𝔇<sub>2</sub>(<em>T</em>)) = 2<em>n</em> − <em>p</em> − 1</span>
where <span class=""math inline""><em>p</em></span> is the number of
pendant vertices (or leaves) in <span
class=""math inline""><em>T</em></span>. We construct a basis <span
class=""math inline"">𝔅</span> for the row space of <span
class=""math inline"">𝔇<sub>2</sub>(<em>T</em>)</span> and obtain a
formula for the inverse of the nonsingular square submatrix <span
class=""math inline"">𝔇 = 𝔇<sub>2</sub>(<em>T</em>)[𝔅, 𝔅]</span>. We also
compute the determinant of <span class=""math inline"">𝔇</span> and show
that its absolute value is independent of the structure of <span
class=""math inline""><em>T</em></span>.</p>
<p>Two other matrices associated to Buneman’s Four point condition (4PC)
about distances in a tree <span class=""math inline""><em>T</em></span>
are the <span class=""math inline"">Min<sub><em>T</em></sub></span> and
<span class=""math inline"">Max<sub><em>T</em></sub></span>. These are
also <span class=""math inline"">$\binom{n}{2}
\times \binom{n}{2}$</span> matrices. The entry in the row indexed by
<span class=""math inline"">{<em>x</em>, <em>y</em>}</span> and column
<span class=""math inline"">{<em>p</em>, <em>q</em>}</span> equals the
minimum or the maximum of the set <span
class=""math inline""><em>D</em><sub><em>p</em>, <em>q</em>, <em>x</em>, <em>y</em></sub> = {<em>d</em><sub><em>x</em>, <em>y</em></sub> + <em>d</em><sub><em>p</em>, <em>q</em></sub>, <em>d</em><sub><em>x</em>, <em>p</em></sub> + <em>d</em><sub><em>y</em>, <em>q</em></sub>, <em>d</em><sub><em>x</em>, <em>q</em></sub> + <em>d</em><sub><em>y</em>, <em>p</em></sub>}</span>.
We show for all trees <span class=""math inline""><em>T</em></span>, that
<span
class=""math inline"">𝔇<sub>2</sub>(<em>T</em>) = 1/2(Min<sub><em>T</em></sub> + Max<sub><em>T</em></sub>)</span>
and give our results on these three matrices.</p>
"
S9,SC2001,4,Milica,Anđelić,Milica Anđelić,2025-06-26 13:30:00,MS21,Linear algebra techniques in graph theory,Thursday,15:00,15:30,109,21,Laplacian eigenvalues of weighted threshold graphs,"<p>We provide a closed formula to compute the Laplacian spectrum of
weighted threshold graphs. We also show that their Laplacian eigenvalues
are the parts of the conjugate partition of the associated weighted
Ferrers diagrams.<br />
(<span><em>This is a joint work with Zoran Stanić, Faculty of
Mathematics, University of Belgrade, Serbia.</em></span>)</p>
"
S9,SC2006,1,Daniel B.,Szyld,Daniel B. Szyld,2025-06-26 13:30:00,MS13,Advances in QR factorizations,Thursday,13:30,14:00,109,13,,
S9,SC2006,2,Takeshi,Fukaya,Takeshi Fukaya,2025-06-26 13:30:00,MS13,Advances in QR factorizations,Thursday,14:00,14:30,109,13,,
S9,SC2006,3,Mark,Gates,Mark Gates,2025-06-26 13:30:00,MS13,Advances in QR factorizations,Thursday,14:30,15:00,109,13,,
S9,SC2006,4,Sivan,Toledo,Sivan Toledo,2025-06-26 13:30:00,MS13,Advances in QR factorizations,Thursday,15:00,15:30,109,13,"Parallel-in-time Kalman smoothing using orthogonal transformations
","<p>The talk will present a numerically-stable parallel-in-time linear
Kalman smoother. The smoother uses a novel highly parallel QR
factorization for a class of structured sparse matrices for state
estimation, and an adaptation of the SelInv selective-inversion
algorithm to evaluate the covariance matrices of estimated states. Our
implementation of the new algorithm, using the Threading Building Blocks
(TBB) library, scales well on both Intel and ARM multi-core servers,
achieving speedups of up to 47x on 64 cores. The algorithm performs more
arithmetic than sequential smoothers; consequently it is 1.8x to 2.5x
slower on a single core. The new algorithm is faster and scales better
than the parallel Kalman smoother proposed by Särkkä and
García-Fernández in 2021. This is joint work with Shahaf Gargir.</p>
"
S9,SC3001,1,Eda,Oktay,Eda Oktay,2025-06-26 13:30:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,13:30,14:00,109,16,Mixed precision parallel operations for tensor train arithmetic,"<p>Tensor Train (TT) decomposition is a widely used low-rank tensor
factorization technique known for its memory efficiency and scalability
in high-dimensional data. Its advantages have motivated the development
of various TT-based methods and applications across fields, such as
chemistry, quantum physics, and machine learning. However, constructing
low-rank tensors and performing operations in TT arithmetic can be
computationally intensive, often due to challenges on the cost of tensor
construction and the complexity of numerical operations. To address
these issues, high-performance computing (HPC) techniques such as
parallelism and mixed-precision arithmetic have become essential tools
for enhancing computational efficiency and reducing memory and
communication requirements in (multi)linear algebra. In this talk, we
discuss recent advances in HPC for TT arithmetic and introduce parallel
TT operations using mixed-precision arithmetic. We then explore the
potential of these developments to improve large-scale tensor
computations and discuss their implications for future applications in
scientific computing.</p>
"
S9,SC3001,2,Oleg,Balabanov,Oleg Balabanov,2025-06-26 13:30:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,14:00,14:30,109,16,,
S9,SC3001,3,,,,2025-06-26 13:30:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,14:30,15:00,109,16,,
S9,SC3001,4,,,,2025-06-26 13:30:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,15:00,15:30,109,16,,
S9,SC4011,1,Shinya,Miyajima,Shinya Miyajima,2025-06-26 13:30:00,MS1,Embracing new opportunities in numerical linear algebra,Thursday,13:30,14:00,109,1,Some norm bounds on the complimentary error matrix functions,"<p>Let <span
class=""math inline""><em>A</em> ∈ <strong>C</strong><sup><em>n</em> × <em>n</em></sup></span>
be a square matrix such that <span class=""math inline"">${\rm
Re}(\lambda) &gt; |{\rm Im}(\lambda)|$</span>, <span
class=""math inline"">∀<em>λ</em> ∈ <em>σ</em>(<em>A</em>)</span>, where
<span class=""math inline""><em>σ</em>(<em>A</em>)</span> is the spectrum
of <span class=""math inline""><em>A</em></span>. The error matrix
function <span class=""math inline"">${\rm erf}(A)$</span> and
complimentary error matrix function <span class=""math inline"">${\rm
erfc}(A)$</span>, which are introduced in <span class=""citation""
data-cites=""Cortes""></span>, are defined as <span
class=""math display"">$${\rm erf}(A) := \frac{2A}{\sqrt{\pi}}\int_{0}^{1}
e^{-(Av)^{2}} dv \quad \mbox{and} \quad {\rm erfc}(A) :=
\frac{2A}{\sqrt{\pi}}\int_{1}^{\infty} e^{-(Av)^{2}} dv,$$</span>
respectively.</p>
<p>One of the most important application of the complimentary error
matrix function is the solution to systems of partial differential
equation. Let <span
class=""math inline""><em>u</em><sub>0</sub>, <em>u</em>(<em>x</em>, <em>t</em>) ∈ <strong>C</strong><sup><em>n</em></sup></span>.
It is proven in <span class=""citation"" data-cites=""Cortes""></span> that
the solution to semi-finite coupled diffusion problem <span
class=""math display"">$$\begin{aligned}
u_{t} &amp;=&amp; A^2u_{xx}, \ x&gt;0, \ t&gt;0, \\
u(x,0) &amp;=&amp; 0, \ x&gt;0, \quad
u(0,t) = u_{0}, \ t&gt;0, \quad
u(x,t) \to 0, \ \textrm{as} \ x\rightarrow\infty, \ t &gt; 0
\end{aligned}$$</span> can be represented by using the complimentary
error matrix function as follows: <span class=""math display"">$$u(x,t) =
{\rm erfc}\left(\frac{A^{-1}x}{2\sqrt{t}}\right)u_{0}, \quad x&gt;0,
\quad t&gt;0.$$</span></p>
<p>Analogously to the scaler case, the functions <span
class=""math inline"">${\rm erf}(A)$</span> and <span
class=""math inline"">${\rm erfc}(A)$</span> satisfy the property <span
class=""math inline"">${\rm erf}(A) + {\rm erfc}(A) = I$</span>, where
<span class=""math inline""><em>I</em></span> is the <span
class=""math inline""><em>n</em> × <em>n</em></span> identity matrix.
According to the Taylor expansion of <span
class=""math inline""><em>e</em><sup>−(<em>A</em><em>v</em>)<sup>2</sup></sup></span>
where <span class=""math inline""><em>v</em> ∈ [0, 1]</span>, and
integrating term by term, we obtain <span class=""math display"">$${\rm
erf}(A) = \frac{2A}{\sqrt{\pi}}\sum_{k=0}^{\infty}\frac{(-1)^k
A^{2k}}{k! (2k+1)},$$</span> which is the Taylor expansion of <span
class=""math inline"">${\rm erf}(A)$</span> <span class=""citation""
data-cites=""Cortes""></span>. From this expansion and <span
class=""math inline"">${\rm erf}(A) + {\rm erfc}(A) = I$</span>, we obtain
<span class=""math display"">$${\rm erfc}(A) = I -
\frac{2A}{\sqrt{\pi}}\sum_{k=0}^{\infty}\frac{(-1)^k A^{2k}}{k!
(2k+1)}.$$</span> In <span class=""citation"" data-cites=""Cortes""></span>,
an upper bound on <span class=""math inline"">$\|{\rm erfc}(A)\|_2$</span>
under the condition <span class=""math inline"">${\rm Re}(\lambda) &gt;
|{\rm Im}(\lambda)|$</span>, <span
class=""math inline"">∀<em>λ</em> ∈ <em>σ</em>(<em>A</em>)</span> has been
derived as a corollary of the fact that <span class=""math inline"">${\rm
erfc}(A)$</span> is well-defined.</p>
<p>The purpose of this talk is to present the following norm bounds:</p>
<ul>
<li><p>a new upper bound on <span class=""math inline"">$\|{\rm
erfc}(A)\|_2$</span> under a condition which is different from <span
class=""math inline"">${\rm Re}(\lambda) &gt; |{\rm Im}(\lambda)|$</span>,
<span
class=""math inline"">∀<em>λ</em> ∈ <em>σ</em>(<em>A</em>)</span>,</p></li>
<li><p>upper bounds on <span class=""math inline"">$\|{\rm erf}(A) - {\rm
erf}(B)\|_2$</span> and <span class=""math inline"">$\|{\rm erfc}(A) -
{\rm erfc}(B)\|_2$</span>, where <span
class=""math inline""><em>B</em> ∈ <strong>C</strong><sup><em>n</em> × <em>n</em></sup></span>,
under an assumption, and</p></li>
<li><p>upper bounds on <span class=""math display"">$$\left\|{\rm erf}(A)
- \frac{2A}{\sqrt{\pi}}\sum_{k=0}^{m}\frac{(-1)^k A^{2k}}{k!
(2k+1)}\right\|_2 \ \mbox{and} \
\left\|{\rm erfc}(A) - \left(I -
\frac{2A}{\sqrt{\pi}}\sum_{k=0}^{m}\frac{(-1)^kA^{2k}}{k!(2k+1)}\right)\right\|_2,$$</span>
where <span class=""math inline""><em>m</em></span> is a nonnegative
integer, under an assumption.</p></li>
</ul>
<p>We report results of numerical experiments in order to observe how
much larger the presented bounds are compared to the corresponding
norms. This talk is based on the joint work with Prof. Amir Sadeghi in
Islamic Azad University.</p>
<div class=""thebibliography"">
<p><span>5</span> J. Cort<span class=""math inline"">$\acute{{\rm
e}}$</span>s, R. Company, L. J<span class=""math inline"">$\acute{{\rm
o}}$</span>dar, The complementary error matrix function and its role
solving coupled diffusion mathematical models, Math. Comput. Modell,
42(9–10), 1023–1034 (2005).</p>
</div>
"
S9,SC4011,2,Chiu-Yen,Kao,Chiu-Yen Kao,2025-06-26 13:30:00,MS1,Embracing new opportunities in numerical linear algebra,Thursday,14:00,14:30,109,1,A semi-definite optimization method for maximizing the shared band gap of topologicalpPhotonic crystals,"<p>Topological photonic crystals (PCs) can support robust edge modes to
transport electromagnetic energy in an efficient manner. Such edge modes
are the eigenmodes of the PDE operator for a joint optical structure
formed by connecting together two photonic crystals with distinct
topological invariants, and the corresponding eigenfrequencies are
located in the shared band gap of two individual photonic crystals. This
work is concerned with maximizing the shared band gap of two photonic
crystals with different topological features in order to increase the
bandwidth of the edge modes. We develop a semi-definite optimization
framework for the underlying optimal design problem, which enables
efficient update of dielectric functions at each time step while
respecting symmetry constraints and, when necessary, the constraints on
topological invariants. At each iteration, we perform sensitivity
analysis of the band gap function and the topological invariant
constraint function to linearize the optimization problem and solve a
convex semi-definite programming (SDP) problem efficiently. Numerical
examples show that the proposed algorithm is superior in generating
optimized optical structures with robust edge modes. (This is joint work
with Junshan Lin at Auburn University and Braxton Osting at University
of Utah)</p>
"
S9,SC4011,3,Akira,Imakura,Akira Imakura,2025-06-26 13:30:00,MS1,Embracing new opportunities in numerical linear algebra,Thursday,14:30,15:00,109,1,Deflation techniques for matrix function calculations based on double exponential-type numerical integral formula,"<p>This talk focuses on efficient methods for computing matrix
functions, such as matrix exponential and matrix square roots. Recently,
methods based on double exponential (DE)-type numerical integral formula
have been proposed and have attracted much attention. In this talk, we
propose a convergence improvement based on a deflation technique of
splitting eigen-components that adversely affect convergence.</p>
"
S9,SC4011,4,,,,2025-06-26 13:30:00,MS1,Embracing new opportunities in numerical linear algebra,Thursday,15:00,15:30,109,1,,
S10,SC0008,1,Hermie,Monterde,Hermie Monterde,2025-06-26 16:00:00,MS24,Nonnegative and related families of matrices,Thursday,16:00,16:30,110,24,"Nonnegativity in quantum walks
","<p>Let <span class=""math inline""><em>X</em></span> be a connected graph
on <span class=""math inline""><em>n</em></span> vertices and let <span
class=""math inline""><em>H</em></span> be a nonnegative symmetric matrix
associated with <span class=""math inline""><em>X</em></span>. A
<em>quantum walk</em> on <span class=""math inline""><em>X</em></span> is
defined by the matrix <span
class=""math display""><em>U</em>(<em>t</em>) = exp (i<em>t</em><em>H</em>),  <em>t</em> ∈ ℝ</span>
which is unitary for each <span
class=""math inline""><em>t</em> ∈ ℝ</span>. We say that two linearly
independent unit vectors <span
class=""math inline""><strong>x</strong></span> and <span
class=""math inline""><strong>y</strong></span> in <span
class=""math inline"">ℂ<sup><em>n</em></sup></span> admit <em>perfect
state transfer</em> if there exists a time <span
class=""math inline""><em>τ</em></span> and a unit complex number <span
class=""math inline""><em>γ</em></span> such that <span
class=""math display""><em>U</em>(<em>τ</em>)<strong>x</strong> = <em>γ</em><strong>y</strong>.</span>
Perfect state transfer represents accurate transmission of pure quantum
states associated with <span
class=""math inline""><strong>x</strong></span> and <span
class=""math inline""><strong>y</strong></span> – a topic that is of
paramount importance in quantum information processing. In this talk, we
show how techniques from nonnegative matrix theory can be used to derive
fundamental properties of perfect state transfer between nonnegative
vectors. This is joint work with Chris Godsil and Stephen Kirkland.</p>
"
S10,SC0008,2,Hitesh,Kumar,Hitesh Kumar,2025-06-26 16:00:00,MS24,Nonnegative and related families of matrices,Thursday,16:30,17:00,110,24,New results on second eigenvalue extremization,"<p>For an <span class=""math inline""><em>n</em></span>-vertex graph <span
class=""math inline""><em>G</em></span> with adjacency matrix <span
class=""math inline""><em>A</em>(<em>G</em>)</span>, let <span
class=""math inline""><em>λ</em><sub>1</sub></span> and <span
class=""math inline""><em>λ</em><sub>2</sub></span> denote the first and
the second largest eigenvalue of <span
class=""math inline""><em>A</em>(<em>G</em>)</span>. The extremization
problem for <span class=""math inline""><em>λ</em><sub>1</sub></span> has
been extensively investigated in the literature. The second eigenvalue
has been investigated primarily for regular graphs, and there are
relatively fewer results on <span
class=""math inline""><em>λ</em><sub>2</sub></span>-extremization. In this
talk, the speaker will discuss several new results on <span
class=""math inline""><em>λ</em><sub>2</sub></span>-extremization, which
include:</p>
<ol>
<li><p>determining extremal trees of given order and diameter having
maximum/minimum <span
class=""math inline""><em>λ</em><sub>2</sub></span>.</p></li>
<li><p>determining complements of trees with given order and
maximum/minimum <span
class=""math inline""><em>λ</em><sub>2</sub></span>.</p></li>
<li><p>determining extremal trees of given order for the convex
combination of <span class=""math inline""><em>λ</em><sub>1</sub></span>
and <span class=""math inline""><em>λ</em><sub>2</sub></span>, and the
asymptotic behaviour of the convex combination.</p></li>
</ol>
<p>The results are based on joint work with several people: Saieed
Akbari, Bojan Mohar, Shivaramakrishna Pragada, and Hanmeng Zhan.</p>
"
S10,SC0008,3,Sivakumar,K.C.,Sivakumar K.C.,2025-06-26 16:00:00,MS24,Nonnegative and related families of matrices,Thursday,17:00,17:30,110,24,"Inverse $Z$-matrices with the bi-diagonal south-west structure
","<p>Two new matrix classes are introduced; inverse cyclic matrices and
bi-diagonal south-west matrices. An interesting relation is established
between these classes. Applications to two classes of inverse <span
class=""math inline""><em>Z</em></span>-matrices are provided.</p>
"
S10,SC0008,4,Raphael,Loewy,Raphael Loewy,2025-06-26 16:00:00,MS24,Nonnegative and related families of matrices,Thursday,17:30,18:00,110,24,On cones of polynomials preserving nonnegative matrices,"<p>We consider polynomials preserving nonnegative matrices. Let <span
class=""math inline""><em>n</em></span> be a positive integer and</p>
<p><span
class=""math display"">𝒫<sub><em>n</em></sub> = {<em>p</em> ∈ ℝ[<em>x</em>] : <em>p</em>(<em>A</em>) ≥ 0
for
all <em>A</em> ≥ 0, <em>A</em> ∈ ℝ<sup><em>n</em>, <em>n</em></sup>}.</span>
<span class=""math inline"">𝒫<sub><em>n</em></sub></span> was defined by
Loewy and London, motivated by the Nonnegative Inverse Eigenvalue
Problem (NIEP), but is of independent interest. Clearly, <span
class=""math inline"">𝒫<sub><em>n</em></sub></span> is a closed, convex
cone.</p>
<p>Given any polynomial <span class=""math inline""><em>p</em></span>, we
identify <span class=""math inline""><em>p</em></span> with its sequence
of coefficients. In order to consider only finite dimensional vector
spaces, we restrict the degree of the polynomials. Given a positive
integer <span class=""math inline""><em>m</em></span>, define</p>
<p><span
class=""math display"">𝒫<sub><em>n</em>, <em>m</em></sub> = {<em>p</em> ∈ 𝒫<sub><em>n</em></sub> : <em>d</em><em>e</em><em>g</em><em>r</em><em>e</em><em>e</em>(<em>p</em>) ≤ <em>m</em>}.</span>
Then, <span
class=""math inline"">𝒫<sub><em>n</em>, <em>m</em></sub></span> can be
thought as a cone in <span
class=""math inline"">ℝ<sup><em>m</em> + 1</sup></span>.</p>
<p>It is clear that any polynomial with nonnegative coefficients is in
<span class=""math inline"">𝒫<sub><em>n</em></sub></span>. Therefore, the
number, relative size and distribution of the negative coefficients of
polynomials in <span class=""math inline"">𝒫<sub><em>n</em></sub></span>
are of significant interest. Clark and Paparella showed that if <span
class=""math inline""><em>p</em> ∈ 𝒫<sub><em>n</em></sub></span>, then its
first and last <span class=""math inline""><em>n</em></span> coefficients
must be nonnegative. Hence, <span
class=""math inline"">𝒫<sub><em>n</em>, <em>m</em></sub></span> is a
simplicial cone, for any <span
class=""math inline"">0 &lt; <em>m</em> &lt; 2<em>n</em></span>.</p>
<p>Let <span class=""math inline""><em>m</em> ≥ 2<em>n</em></span>. Then,
<span class=""math inline"">𝒫<sub><em>n</em>, <em>m</em></sub></span>
contains polynomials with negative coefficients. For example, there
exists <span class=""math inline""><em>a</em> &gt; 0</span> such that
<span
class=""math inline"">1 + <em>x</em> + <em>x</em><sup>2</sup> + ⋯ + <em>x</em><sup><em>n</em> − 1</sup> − <em>a</em><em>x</em><sup><em>n</em></sup> + <em>x</em><sup><em>n</em> + 1</sup> + ⋯ + <em>x</em><sup>2<em>n</em></sup> ∈ 𝒫<sub><em>n</em>, 2<em>n</em></sub></span>
(the question of the optimal <span class=""math inline""><em>a</em></span>
is of interest). It follows that the structure of <span
class=""math inline"">𝒫<sub><em>n</em>, <em>m</em></sub></span> is
nontrivial. We consider its face structure, and in particular the one
dimensional faces, that is, the extreme rays. Using some information on
the possible coefficients of polynomials in <span
class=""math inline"">𝒫<sub><em>n</em>, <em>m</em></sub></span>, we show
that <span class=""math inline"">𝒫<sub><em>n</em>, <em>m</em></sub></span>
is not polyhedral, that is, contains infinitely many extreme rays.
Additional preliminary results on the faces are obtained.</p>
"
S10,SC0009,1,Srinivas,Eswar,Srinivas Eswar,2025-06-26 16:00:00,MS4,Linear algebra methods for inverse problems and data assimilation,Thursday,16:00,16:30,110,4,"Exchange algorithms for Optimal Experimental Design
","<p>We tackle optimal sensor placement for Bayesian linear inverse
problems by establishing connections to the Column Subset Selection
Problem (CSSP). We build on the Golub-Klema-Stewart (GKS) approach which
involves computing the truncated Singular Value Decomposition (SVD)
followed by a pivoted QR factorization on the right singular vectors. We
study the effects of using the Federov exchange rule, greedily swapping
sensors while improving the objective, after a GKS-style initialization.
Theoretical guarantees on the number of swaps are established. Numerical
experiments on model inverse problems demonstrate the performance of our
approaches.</p>
"
S10,SC0009,2,Vishwas,Rao,Vishwas Rao,2025-06-26 16:00:00,MS4,Linear algebra methods for inverse problems and data assimilation,Thursday,16:30,17:00,110,4,,
S10,SC0009,3,Philip,Dinenis,Philip Dinenis,2025-06-26 16:00:00,MS4,Linear algebra methods for inverse problems and data assimilation,Thursday,17:00,17:30,110,4,Preconditioning for uncertainty quantification of high-dimensional inverse problems,"<p>In variational inverse problems, the Laplace approximation of the
posterior distribution can be estimated by minimizing an objective
function and computing its inverse Hessian at the minimizer. In
high-dimensional problems, computing and storing this inverse Hessian
may be intractable while low-rank approximations may be poor in
ill-conditioned settings. We show that in 4DVar problems, we can
construct effective preconditioners using what we know about the scales
of different sources of uncertainty – such as such as model, background,
and measurement errors. When this is used in combination with the
quasi-Newton method l-BFGS, we can greatly speed up the optimization and
improve the approximation of posterior covariance. Moreover, the form of
this approximation in terms of the symmetric low-rank updates, gives a
way to factorize the covariance matrix and efficiently sample from the
posterior distribution.</p>
"
S10,SC0009,4,Arvind Krishna,Saibaba,Arvind Krishna Saibaba,2025-06-26 16:00:00,MS4,Linear algebra methods for inverse problems and data assimilation,Thursday,17:30,18:00,110,4,"Efficient hyperparameter estimation in Bayesian inverse problems using sample average approximation
","<p>In Bayesian inverse problems, it is common to consider several
hyperparameters that define the prior and the noise model that must be
estimated from the data. In particular, we are interested in linear
inverse problems with additive Gaussian noise and Gaussian priors
defined using Matérn covariance models. In this case, we estimate the
hyperparameters using the maximum a posteriori (MAP) estimate of the
marginalized posterior distribution. However, this is a computationally
intensive task since it involves computing log determinants. To address
this challenge, we consider a stochastic average approximation (SAA) of
the objective function and use the preconditioned Lanczos method to
compute efficient approximations of the function and gradient
evaluations. We propose a new preconditioner that can be updated cheaply
for new values of the hyperparameters and an approach to compute
approximations of the gradient evaluations, by reutilizing information
from the function evaluations. We demonstrate the performance of our
approach on static and dynamic seismic tomography problems.</p>
"
S10,SC0012,1,Chung-Yun,Hsieh,Chung-Yun Hsieh,2025-06-26 16:00:00,MS7,Linear algebra and quantum information science,Thursday,16:00,16:30,110,7,Quantum complementarity: A novel resource for exclusion,"<p>Complementarity is a phenomenon explaining several core features of
quantum theory, such as the well-known uncertainty principle. Roughly
speaking, two objects are said to be <span><em>complementary</em></span>
if being certain about one of them necessarily forbids useful knowledge
about the other. Two quantum measurements that do not commute form an
example of complementary measurements, and this phenomenon can also be
defined for ensembles of states. Although a key quantum feature, it is
unclear whether complementarity can be understood more operationally, as
a necessary resource in some quantum information task. Here we show this
is the case, and relates to a novel task which we term <span><em><span
class=""math inline""><em>η</em></span>-unambiguous exclusion</em></span>.
As well as giving complementarity a clear operational definition, this
also uncovers the foundational underpinning of unambiguous exclusion
tasks for the first time.<br />
<br />
Reference: C.-Y. Hsieh, R. Uola, P. Skrzypczyk, <span><em>Quantum
complementarity: A novel resource for unambiguous exclusion and
encryption</em></span>, arXiv:2309.11968.</p>
"
S10,SC0012,2,Ngoc Muoi,Bui,Ngoc Muoi Bui,2025-06-26 16:00:00,MS7,Linear algebra and quantum information science,Thursday,16:30,17:00,110,7,On entanglement-breaking quantum channels,"<p>Entanglement breaking (EB) channel is a completely positive and
trace-preserving linear operator that disrupts the entanglement between
the input system with any system. Examples of EB channels include
depolarizing channels, quantum-classical channels, etc. We will discuss
some characterizations of the class of EB channels for finite- and
infinite-dimensional quantum systems. In particular, we show some
sufficient conditions for channels to be EB.</p>
"
S10,SC0012,3,Hsien-Yi,Hsieh,Hsien-Yi Hsieh,2025-06-26 16:00:00,MS7,Linear algebra and quantum information science,Thursday,17:00,17:30,110,7,,
S10,SC0012,4,Sang-Gyun,Youn,Sang-Gyun Youn,2025-06-26 16:00:00,MS7,Linear algebra and quantum information science,Thursday,17:30,18:00,110,7,,
S10,SC0014,1,Steffen W. R.,Werner,Steffen W. R. Werner,2025-06-26 16:00:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Thursday,16:00,16:30,110,5,Efficiently solving nonstandard Riccati equations via indefinite factorizations,"<p>The continuous-time symmetric algebraic Riccati equation (CARE) is a
special type of nonlinear matrix-valued equation and an essential
component of many applications, including controller design, model order
reduction and game theory. While there have been many developments in
recent years regarding new solution methods of CAREs in the setting of
large-scale sparse coefficient matrices, these methods are typically
based on semi-definite low-rank factorizations of their solutions and
consider the classical CARE formulation <span
class=""math display""><em>A</em><sup>T</sup><em>X</em><em>E</em> + <em>E</em><sup>T</sup><em>X</em><em>A</em> + <em>C</em><sup>T</sup><em>Q</em><em>C</em> − <em>E</em><sup>T</sup><em>X</em><em>B</em><em>R</em><em>B</em><sup>T</sup><em>X</em><em>E</em> = 0,</span>
with <span class=""math inline""><em>Q</em></span> and <span
class=""math inline""><em>R</em></span> symmetric positive definite. In
this work, we investigate solution methods for large-scale sparse
generalized CAREs of the form <span
class=""math display""><em>A</em><sup>T</sup><em>X</em><em>E</em> + <em>E</em><sup>T</sup><em>X</em><em>A</em> + <em>C</em><sup>T</sup><em>Q</em><em>C</em> − (<em>E</em><sup>T</sup><em>X</em><em>B</em> + <em>S</em>)<em>R</em>(<em>E</em><sup>T</sup><em>X</em><em>B</em> + <em>S</em>)<sup>T</sup> = 0,</span>
where <span class=""math inline""><em>Q</em></span> and <span
class=""math inline""><em>R</em></span> can be symmetric positive
definite, negative definite, or even indefinite. The solutions and
intermediate approximations to such general equations often do not
follow the classical semi-definite structure. Therefore, we are
utilizing low-rank symmetric indefinite <span
class=""math inline""><em>L</em><em>D</em><em>L</em><sup>T</sup></span>
factorizations of the CARE solution in our algorithms, which enable
efficient computations; see, for example, <span class=""citation""
data-cites=""Werner_SaaW24""></span>.</p>
<div class=""thebibliography"">
<p><span>10</span> J. Saak and S. W. R. Werner. Using <span><span
class=""math inline""><em>L</em><em>D</em><em>L</em><sup><em>T</em></sup></span></span>
factorizations in <span>N</span>ewton’s method for solving general
large-scale algebraic <span>R</span>iccati equations. , 62:95–118, 2024.
doi:10.1553/etna_vol62s95</p>
</div>
"
S10,SC0014,2,Rudra,Kamat,Rudra Kamat,2025-06-26 16:00:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Thursday,16:30,17:00,110,5,"Simultaneous symplectic normalisation of quadratic forms
","<p>A fundamental result in symplectic linear algebra states that for a
given positive semi-definite quadratic form on a symplectic space there
exists a symplectic basis in which the quadratic form reduces to a
normal form. The special case of the aforementioned result for positive
definite quadratic forms is known as Williamson’s theorem. In this work,
we establish necessary and sufficient conditions on positive
semi-definite quadratic forms on a symplectic space to be simultaneously
reduced to their normal forms in a common symplectic basis. In
particular, we establish conditions on <span
class=""math inline"">2<em>n</em> × 2<em>n</em></span> real symmetric
positive-definite matrices to be simultaneously diagonalisable by a
symplectic matrix in the sense of Williamson’s theorem. We also discuss
some applications of the main result in quantum information theory and
statistical thermodynamics.</p>
"
S10,SC0014,3,Anjali,Beniwal,Anjali Beniwal,2025-06-26 16:00:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Thursday,17:00,17:30,110,5,Computation of an exact and approximate GCRD of several polynomial matrices using generalized Sylvester matrices,"<p>The computation of an exact and approximate Greatest Common Right
Divisor (GCRD) of polynomial matrices is a fundamental problem in
control theory and signal processing. While extensive research has been
conducted on the Greatest Common Divisors (GCDs) of scalar polynomials,
the study of GCRDs in polynomial matrices remains relatively limited. It
is important to develop fast and reliable ways to compute both exact and
approximate GCRD, especially when dealing with approximate cases where
the data is corrupted by noise.<br />
We address the problem of computing both exact and approximate GCRDs for
a given set of univariate polynomial matrices <span
class=""math inline""><em>B</em><sub>1</sub>(<em>s</em>), …, <em>B</em><sub><em>t</em></sub>(<em>s</em>)</span>.
We establish a key theoretical result—proving that the rank deficiency
of a particular generalized Sylvester matrix associated with <span
class=""math inline""><em>P</em>(<em>s</em>)</span>, where <span
class=""math inline""><em>P</em>(<em>s</em>)</span> is obtained by
stacking <span
class=""math inline""><em>B</em><sub>1</sub>(<em>s</em>), …, <em>B</em><sub><em>t</em></sub>(<em>s</em>)</span>
one below the other, corresponds to the degree of the determinant of
their GCRD. This equivalence enables us to develop efficient algorithms
for computing an exact GCRD using <em>Effectively Eliminating QR</em>
(EEQR) decomposition and <span
class=""math inline""><em>S</em><em>V</em><em>D</em></span> of that
particular generalized Sylvester matrix. <span
class=""math inline""><em>S</em><em>V</em><em>D</em></span> can handle
noise-corrupted data, making it particularly effective for computing an
approximate GCRD. This approach leverages the numerical rank of that
particular generalized Sylvester matrix to estimate the degree of an
approximate GCRD. Both algorithms are simple to develop, easy to
understand, and convenient to implement, ensuring scalability.<br />
We validate our results through various numerical examples,
demonstrating their effectiveness. These findings have significant
implications for applications requiring polynomial matrix factorizations
and simplifications in the presence of noise and uncertainty.</p>
"
S10,SC0014,4,Tanay,Saha,Tanay Saha,2025-06-26 16:00:00,MS5,"Advances in matrix equations: Theory, computations, and applications",Thursday,17:30,18:00,110,5,"Computing the nearest structured non-prime polynomial matrix: theory, algorithms, and numerical approaches","<p>We first address the problem of computing the nearest non-prime
polynomial matrix to a given left-prime polynomial matrix, without
imposing structural constraints. This problem extends the classical task
of finding the nearest non-coprime polynomials to a set of coprime
polynomials. Our approach begins by establishing the equivalence between
the left-primeness property of a polynomial matrix and the rank
deficiency of a specific block Toeplitz matrix derived from the
polynomial matrix. By leveraging this equivalence, we reformulate the
problem as finding the nearest Structured Low-Rank Approximation (SLRA)
to the associated block Toeplitz matrix, with a particular focus on
cases where the leading coefficient matrix of the left-prime polynomial
matrix has full row rank.</p>
<p>We further generalize the problem to compute a non-prime matrix that
is as close as possible to a given left-prime polynomial matrix while
preserving a predefined structural form. In this setting, the problem is
again recast as computing the nearest SLRA of a structured matrix in
case of full rank leading coefficient matrix. For computing SLRA, we
employ numerical techniques such as the STLN method and regularized
factorization, both of which are well-documented in the literature.</p>
<p>Additionally, we prove that it is possible to approximate a
left-prime polynomial matrix with a rank-deficient leading coefficient
matrix by a non-prime polynomial matrix, without adhering to the
underlying structure. For cases involving structured coefficient
matrices, we reformulate the problem as a constrained optimization task.
By applying numerical optimization methods, we solve this optimization
problem effectively.</p>
<p>Finally, we demonstrate the efficacy of our proposed algorithm with
several numerical examples and compare the results with existing
approaches in the literature wherever possible.</p>
"
S10,SC1001,1,Yuan Hsun,Lo,Yuan Hsun Lo,2025-06-26 16:00:00,MS25,Enumerative/algebraic combinatorics and matrices,Thursday,16:00,16:30,110,25,"On cyclic-shift-full-rank matrices
","<p>A binary matrix is said to be cyclic-shift-full-rank (CSFR) if it has
full row rank no matter how its rows are cyclically shifted. In this
talk, we will construct CSFR matrices for any row size and introduce
their applications on collision channels without feedback in which CSFR
matrices are employed as protocol sequences.</p>
"
S10,SC1001,2,Xiao-Nan,Lu,Xiao-Nan Lu,2025-06-26 16:00:00,MS25,Enumerative/algebraic combinatorics and matrices,Thursday,16:30,17:00,110,25,Ternary circulant almost orthogonal arrays with (near) D-optimality and good binary sequence pairs,"<p>Circulant almost orthogonal arrays (CAOAs) are a type of circulant
matrices used in the statistical design of fMRI experiments.
D-optimality, which maximizes the determinant of the information matrix
of a design, plays a key role in ensuring efficiency of experiments.
This talk will focus on ternary CAOAs with strength <span
class=""math inline"">2</span>, emphasizing the characterization of
D-optimal and near D-optimal CAOAs and investigating their relations
with binary sequence pairs with good correlation properties.</p>
"
S10,SC1001,3,Lei,Cao,Lei Cao,2025-06-26 16:00:00,MS25,Enumerative/algebraic combinatorics and matrices,Thursday,17:00,17:30,110,25,"Pattern avoiding and pattern forcing $(0,1)$-matrices for some permutation patterns
","<p>Let <span
class=""math inline""><em>A</em> = [<em>a</em><sub><em>i</em><em>j</em></sub>]</span>
be an <span class=""math inline""><em>n</em> × <em>n</em></span> <span
class=""math inline"">(0, 1)</span>-matrix, <span
class=""math inline""><em>P</em> = [<em>p</em><sub><em>i</em><em>j</em></sub>]</span>
an <span class=""math inline""><em>n</em> × <em>n</em></span> permutation
matrix, and <span class=""math inline""><em>Q</em></span> a <span
class=""math inline""><em>k</em> × <em>k</em></span> permutation matrix
with <span class=""math inline""><em>k</em> ≤ <em>n</em></span>. We write
<span class=""math inline""><em>P</em> ≤ <em>A</em></span> if <span
class=""math inline""><em>p</em><sub><em>i</em><em>j</em></sub> ≤ <em>a</em><sub><em>i</em><em>j</em></sub></span>
for all <span
class=""math inline""><em>i</em>, <em>j</em> = 1, 2, …, <em>n</em></span>.</p>
<ul>
<li><p><span class=""math inline""><em>A</em></span> is <em><span
class=""math inline""><em>Q</em></span>-avoiding</em> if and only if there
does not exist a <span
class=""math inline""><em>k</em> × <em>k</em></span> submatrix <span
class=""math inline""><em>A</em><sub><em>k</em></sub></span> of <span
class=""math inline""><em>A</em></span> such that <span
class=""math inline""><em>Q</em> ≤ <em>A</em><sub><em>k</em></sub></span>
entrywise.</p></li>
<li><p><span class=""math inline""><em>A</em></span> is <em><span
class=""math inline""><em>Q</em></span>-permutation avoiding</em> if and
only if there does not exist an <span
class=""math inline""><em>n</em> × <em>n</em></span> permutation matrix
<span class=""math inline""><em>P</em> ≤ <em>A</em></span> such that <span
class=""math inline""><em>Q</em></span> is a <span
class=""math inline""><em>k</em> × <em>k</em></span> submatrix of <span
class=""math inline""><em>P</em></span>.</p></li>
<li><p><span class=""math inline""><em>A</em></span> is <em><span
class=""math inline""><em>Q</em></span>-forcing</em> if and only if every
<span class=""math inline""><em>n</em> × <em>n</em></span> permutation
matrix <span class=""math inline""><em>P</em> ≤ <em>A</em></span> contains
<span class=""math inline""><em>Q</em></span> as a <span
class=""math inline""><em>k</em> × <em>k</em></span> submatrix.</p></li>
</ul>
<p>In this presentation, I will discuss recent results on <span
class=""math inline""><em>Q</em></span>-avoiding, <span
class=""math inline""><em>Q</em></span>-permutation avoiding, and <span
class=""math inline""><em>Q</em></span>-forcing <span
class=""math inline"">(0, 1)</span>-matrices for certain special
permutation patterns <span class=""math inline""><em>Q</em></span>.
Specifically, we investigate the minimum number of zeros in <span
class=""math inline"">(0, 1)</span>-matrices that avoid or force
particular permutation patterns. Additionally, we examine the polytope
of 123-avoiding doubly stochastic matrices—that is, the convex hull of
all 123-avoiding permutation matrices.</p>
"
S10,SC1001,4,Shen-Fu,Tsai,Shen-Fu Tsai,2025-06-26 16:00:00,MS25,Enumerative/algebraic combinatorics and matrices,Thursday,17:30,18:00,110,25,"Extremal and saturation function of multidimensional 0-1 matrices
","<p>Pattern avoidance is a central topic in combinatorics. With
connection to ordered graph and sequence, extremal theories about
avoidance of 0-1 matrices have had applications on areas like geometry
problems, robot navigation, etc. In recent years, investigation of a
similar extremal function called saturation function has gained
interests in the community although saturation of graph dated long back
to Erdős. For both the original and new extremal functions, we give an
overview of related works that extend 0-1 matrices to multidimensional
0-1 matrices.</p>
"
S10,SC1003,1,Ding,Lu,Ding Lu,2025-06-26 16:00:00,MS14,"Pencils, polynomial, and rational matrices",Thursday,16:00,16:30,110,14,,
S10,SC1003,2,Shreemayee,Bora,Shreemayee Bora,2025-06-26 16:00:00,MS14,"Pencils, polynomial, and rational matrices",Thursday,16:30,17:00,110,14,The distance to bounded realness revisited,"<p>The spectrum of a Hamiltonian matrix is symmetric with respect to the
imaginary axis. Hence its eigenvalues occur in pairs <span
class=""math inline"">(<em>λ</em>, −<em>λ̄</em>)</span> if the matrix is
complex and in quadruples, <span
class=""math inline"">(<em>λ</em>, <em>λ̄</em>, −<em>λ̄</em>, −<em>λ</em>)</span>
if the matrix is real. This pairing breaks down when the eigenvalues are
purely imaginary and this can lead to numerical challenges in
computational methods used in optimal control. The distance from a given
Hamiltonian matrix <span class=""math inline""><em>H</em></span> to a
nearest Hamiltonian matrix <span
class=""math inline""><em>H</em> + <em>Δ</em><em>H</em></span> such that
any further arbitrarily small Hamiltonian perturbation to <span
class=""math inline""><em>H</em> + <em>Δ</em><em>H</em></span> generically
removes all its purely imaginary eigenvalues is called the <em>distance
to bounded realness</em>. Algorithms for finding an upper bound of this
distance have been obtained in the literature. In this talk we will
present upper and lower bounds on the distance to <em>bounded
realness</em> which are often seen to be tight in numerical experiments.
In fact in many cases the bounds are seen to be equal. We identify
conditions under which the equality holds. In particular, we show that
our algorithm computes the distance if the Hamiltonian matrix <span
class=""math inline""><em>H</em></span> has only purely imaginary
eigenvalues with the ones of positive type being separated from those of
negative type. The key to obtaining the results is to convert the
Hamiltonian matrix eigenvalue problem into that of an eigenvalue problem
associated with a closely related Hermitian matrix pencil.</p>
<p>This is joint work with Kannan R. of the Department of Mathematics,
IIT Guwahati.</p>
"
S10,SC1003,3,Miryam,Gnazzo,Miryam Gnazzo,2025-06-26 16:00:00,MS14,"Pencils, polynomial, and rational matrices",Thursday,17:00,17:30,110,14,Stable extraction of eigenpairs from a subspace for generalized eigenvalue problems,"<p>In this talk, we consider generalized eigenvalue problems associated
with pencils in the form <span
class=""math inline""><em>A</em><em>v</em> = <em>λ</em><em>B</em><em>v</em></span>,
with <span
class=""math inline""><em>A</em>, <em>B</em> ∈ ℝ<sup><em>m</em> × <em>m</em></sup></span>.
In several frameworks, we may be interested in the numerical
approximation of a prescribed subset of eigenvectors, possibly coming
from a good approximation of part of the eigenspace. This extraction of
eigenpairs from a subspace can be done employing a class of methods
often called oblique projectors. They consist in solving a different
generalized eigenvalue problem <span
class=""math inline""><em>P</em><sup><em>T</em></sup><em>A</em><em>Q</em><em>v</em> = <em>λ</em><em>P</em><sup><em>T</em></sup><em>B</em><em>Q</em><em>v</em></span>,
for suitable <span
class=""math inline""><em>P</em>, <em>Q</em> ∈ ℝ<sup><em>m</em> × <em>n</em></sup></span>
and <span class=""math inline""><em>n</em> &lt; <em>m</em></span>. A
popular example of oblique projectors is Rayleigh-Ritz. However, it can
be observed that this method is not backward stable. The goal of this
talk consists in proposing alternative methods within the family of
oblique projectors, with the additional property of being backward
stable. Moreover, in settings where <span
class=""math inline""><em>m</em> ≫ <em>n</em></span>, we present a
randomized version of this technique, obtained via the solution a
sketched version of the generalized eigenvalue problem.</p>
"
S10,SC1003,4,Alicia,Roca,Alicia Roca,2025-06-26 16:00:00,MS14,"Pencils, polynomial, and rational matrices",Thursday,17:30,18:00,110,14,Row completion of polynomial and rational matrices and partial prescription of their  structure,"<p>The matrix completion problem consists in characterizing the
existence of a matrix with certain properties when a submatrix is
prescribed. It is an important problem in Matrix Theory. Completion
problems of matrices frequently arise in applications, for instance in
structural changes of the dynamics of a system or in pole placement
problems in control theory. They also appear in solutions of
perturbation problems. This work is devoted to the row completion
problem for polynomial and rational matrices. We characterize the
existence of a polynomial matrix when its complete structural data (the
invariant factors, the invariants orders at infinity, and the column and
row minimal indices) and some of its rows are prescribed, allowing the
completed matrix to increase the degree. The same problem is solved for
rational matrices. We have also solved the corresponding problem of
partial prescription of the complete structural data covering all of the
possibilities. We will show here some cases. Obviously, the results
obtained hold for the corresponding column completion problems.</p>
"
S10,SC1005,1,Mary,Flagg,Mary Flagg,2025-06-26 16:00:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Thursday,16:00,16:30,110,17,Reconfiguring a community,"<p>Reconfiguration is a process of transforming one feasible solution to
a problem into another feasible solution in small incremental steps
while maintaining the property of being a solution at each step. In the
case of graph theory, solutions to problems are often subsets of the
vertex set with a specific property. We refer to these as vertex set
parameters. In this talk I will share a universal approach to vertex set
parameter reconfiguration developed with Leslie Hogben and Bryan Curtis
that is applied to zero forcing variants as well as other common graph
parameters. Zero forcing was developed in this community to be an upper
bound to the nullity of any real symmetric matrix with off-diagonal zero
pattern determined by the adjacency matrix of a given graph.
Understanding zero forcing sets has applications to understanding
eigenvalues and eigenvectors of these matrices. Reconfiguration is also
a description of how Leslie Hogben has helped to change our community
for the better, one step at a time by facilitating community and
research opportunity to graduate students, new researchers and faculty
at undergraduate institutions. I will share my perspective on her
reconfiguration efforts.</p>
"
S10,SC1005,2,Shaun,Fallat,Shaun Fallat,2025-06-26 16:00:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Thursday,16:30,17:00,110,17,Leslie's enduring influence on the IEP-G and zero forcing,"<p>When I think about Leslie’s contributions to the IEP-G and Zero
forcing, it is easy to conjure her impact via: Handbook(s) of LA, AIM
workshops, AIM Squares, AIM ARC, BIRS FRGs, Sessions at ILAS, AMS, and
the “Boca” conferences, not to mention, the very recent IEP-G/Zero
forcing book with Shader and Lin…But Leslie has done SO much more to
steer many recent advances in this area, including her numerous research
team members from students, to postdocs, to collaborators. It is safe to
say, the Leslie has personally opened the door to the IEP-G and Zero
forcing to more people than anyone else (and it is not even close). Her
devotion to this topic and her steadfast support and encouragement to
engage with so many researchers is astonishing…I hope to highlight
several instances of Leslie’s leadership and guidance that has shaped
the direction of both the IEP-G and topics related to Zero forcing. When
you look at the past 25 years her stamp is nearly everywhere on the
IEP-G and Zero forcing. Personally, she was instrumental in supporting
my research and I am truly blessed to have published 15 papers with my
friend Dr. Leslie Hogben!</p>
"
S10,SC1005,3,Tracy,Hall,Tracy Hall,2025-06-26 16:00:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Thursday,17:00,17:30,110,17,,
S10,SC1005,4,Franklin,Kenter,Franklin Kenter,2025-06-26 16:00:00,MS17,Graphs and matrices in honor of Leslie Hogben's retirement,Thursday,17:30,18:00,110,17,Leaky forcing: extending zero forcing results to a fault-tolerant setting,"<p>We study a recent variation of zero forcing called leaky forcing.
Zero forcing is a propagation process on a network whereby some nodes
are initially blue with all others white. Blue vertices can “force” a
white neighbor to become blue if all other neighbors are blue. The goal
is to find the minimum number of initially blue vertices to eventually
force all vertices blue after exhaustively applying the forcing rule
above. Leaky forcing is a fault-tolerant variation of zero forcing where
certain vertices (not necessarily initially blue) cannot force. The goal
in this context is to find the minimum number of initially blue vertices
needed that can eventually force all vertices to be blue,
<span><em>regardless</em></span> of which small number of vertices can’t
force.</p>
<p>This work extends results from zero forcing in terms of leaky
forcing. New results regarding leaky forcing presented here include:</p>
<ul>
<li><p>Complete determination of all leaky forcing numbers for all
unicyclic graphs.</p></li>
<li><p>Robust upper bounds for generalized Petersen graphs.</p></li>
<li><p>Bounds for the effect of both edge removal and vertex
removal.</p></li>
<li><p>A complete characterization for which connected graphs have the
maximum possible <span class=""math inline"">1</span>-leaky forcing number
(i.e., when <span
class=""math inline""><em>Z</em><sub>(1)</sub>(<em>G</em>) = |<em>V</em>(<em>G</em>)|−1</span>).</p></li>
</ul>
<p>This is joint work with Beth Bjorkman, Lei Cao, Ryan Moruzzi, Carolyn
Reinhart and Violeta Vasilevska and is part of the AIM Mathematical
Research Communities.</p>
"
S10,SC2001,1,Joshua,Cooper,Joshua Cooper,2025-06-26 16:00:00,MS21,Linear algebra techniques in graph theory,Thursday,16:00,16:30,110,21,Determinants of Steiner distance hypermatrices,"<p>Generalizing work from the 1970s on the determinants of distance
hypermatrices of trees, we consider the hyperdeterminants of order-<span
class=""math inline""><em>k</em></span> Steiner distance hypermatrices of
trees <span class=""math inline""><em>T</em></span> on <span
class=""math inline""><em>n</em></span> vertices. We show that this
hypermatrix has the same diagonalization as a <span
class=""math inline""><em>k</em></span>-form for any <span
class=""math inline""><em>T</em></span> on <span
class=""math inline""><em>n</em></span> vertices, generalizing of a result
of Graham-Lovász, implying a tensor version of “conditional negative
definiteness”, providing new proofs of previous results of the authors
and Tauscheck, and resolving the conjecture that these hyperdeterminants
depend only on <span class=""math inline""><em>k</em></span> and <span
class=""math inline""><em>n</em></span> – as Graham-Pollak showed for
<span class=""math inline""><em>k</em> = 2</span>.</p>
"
S10,SC2001,2,,,,2025-06-26 16:00:00,MS21,Linear algebra techniques in graph theory,Thursday,16:30,17:00,110,21,,
S10,SC2001,3,Debabrota,Mondal,Debabrota Mondal,2025-06-26 16:00:00,MS21,Linear algebra techniques in graph theory,Thursday,17:00,17:30,110,21,Smallest positive eigenvalue of non-bipartite unicyclic graphs,"<p>Let <span class=""math inline""><em>G</em></span> be a simple graph
with the adjacency matrix <span
class=""math inline""><em>A</em>(<em>G</em>)</span>. By the smallest
positive eigenvalue of <span class=""math inline""><em>G</em></span>, we
mean the smallest positive eigenvalue of <span
class=""math inline""><em>A</em>(<em>G</em>)</span>, and it is denoted by
<span class=""math inline""><em>τ</em>(<em>G</em>)</span>. This spectral
parameter has significant applications in both chemical graph theory and
spectral graph theory. In the literature, the study of the smallest
positive eigenvalue has primarily focused on trees, bipartite unicyclic
graphs, and bipartite graphs. In this talk, we discuss bounds on the
smallest positive eigenvalue of non-bipartite unicyclic graphs and
characterize the extremal graphs. This talk is based on joint work with
Sasmita Barik and Subhasish Behera.</p>
"
S10,SC2001,4,Anirban,Banerjee,Anirban Banerjee,2025-06-26 16:00:00,MS21,Linear algebra techniques in graph theory,Thursday,17:30,18:00,110,21,Structural symmetries in hypergraphs and their spectra,"<p>We investigate how certain connectivity matrices capture the
structural symmetries in hypergraphs. We encode hypergraph symmetries
through two frameworks: (1) equivalence relations on the vertex set and
(2) hypergraph automorphisms. We demonstrate how these two formulations
of symmetry manifest in the spectral properties of those hypergraph
matrices. This study further identifies intriguing structural features,
we term building blocks. Moreover, the spectral patterns induced by
hypergraph symmetries provide insight into various dynamical processes,
including dynamics on networks and random walks on graphs.</p>
"
S10,SC2006,1,Juyoung,Jeong,Juyoung Jeong,2025-06-26 16:00:00,MS28,"From matrix theory to Euclidean Jordan algebras, FTvN systems, and beyond",Thursday,16:00,16:30,110,28,"Generalized convexity for spectral functions on Euclidean Jordan algebras
","<p>In a Euclidean Jordan algebra <span class=""math inline"">𝒱</span>, a
spectral function <span class=""math inline""><em>G</em> : 𝒱 → ℝ</span> is
defined as a function that depends solely on the eigenvalues of its
argument. Formally, such a function takes the form <span
class=""math inline""><em>G</em> = <em>f</em> ∘ <em>λ</em></span>, where
<span class=""math inline""><em>f</em> : ℝ<sup><em>n</em></sup> → ℝ</span>
is a (symmetric) function and <span
class=""math inline""><em>λ</em> : 𝒱 → ℝ<sup><em>n</em></sup></span>
denotes the eigenvalue mapping. It turns out that spectral functions are
invariant under algebra automorphisms of <span
class=""math inline"">𝒱</span>. Due to their simple yet elegant structure
and wide applicability, spectral functions play a crucial role not only
in matrix theory but also in convex analysis, optimization, and beyond.
It has been observed that <span class=""math inline""><em>G</em></span> is
(strictly) convex if and only if so is the associated function <span
class=""math inline""><em>f</em></span>, which we call a transfer
principle for (strict) convexity. In this talk, we will explore
analogous transfer principle for generalized notions of convexity,
including strong convexity, quasi-convexity, pseudo-convexity, and
related concepts.</p>
"
S10,SC2006,2,Muddappa,Gowda,Muddappa Gowda,2025-06-26 16:00:00,MS28,"From matrix theory to Euclidean Jordan algebras, FTvN systems, and beyond",Thursday,16:30,17:00,110,28,Commutativity concepts relative to transformation/matrix groups and semi-FTvN systems,"<p>We introduce the concepts of <span><em>commutativity</em></span>
relative to a transformation/matrix group and <span><em>strong
commutativity</em></span> in the setting of a semi-FTvN system and show
their appearance as optimality conditions in certain optimization
problems. In the setting of a semi-FTvN system (in particular, in an
FTvN system), we show that strong commutativity implies commutativity
and observe that in the special case of Euclidean Jordan algebra,
commutativity and strong commutativity concepts reduce, respectively, to
those of operator and strong operator commutativity. We demonstrate that
every complete hyperbolic polynomial induces a semi-FTvN system. By way
of an application, we describe several commutation principles.</p>
"
S10,SC2006,3,Michael,Orlitzky,Michael Orlitzky,2025-06-26 16:00:00,MS28,"From matrix theory to Euclidean Jordan algebras, FTvN systems, and beyond",Thursday,17:00,17:30,110,28,Jordan and isometric cone automorphisms in Euclidean Jordan algebras,"<p>Every symmetric cone <span class=""math inline""><em>K</em></span>
arises as the cone of squares in a Euclidean Jordan algebra <span
class=""math inline""><em>V</em></span>. As <span
class=""math inline""><em>V</em></span> is a real inner-product space, we
may denote by <span class=""math inline"">Isom (<em>V</em>)</span> its
group of isometries. The groups <span
class=""math inline"">JAut (<em>V</em>)</span> of its Jordan-algebra
automorphisms and <span class=""math inline"">Aut (<em>K</em>)</span> of
the linear cone automorphisms are then related. For certain inner
products, <span
class=""math display"">JAut (<em>V</em>) = Aut (<em>K</em>) ∩ Isom (<em>V</em>).</span>
We characterize the inner products for which this holds.</p>
"
S10,SC2006,4,David,Sossa,David Sossa,2025-06-26 16:00:00,MS28,"From matrix theory to Euclidean Jordan algebras, FTvN systems, and beyond",Thursday,17:30,18:00,110,28,"Commutation principles for optimization problems involving strictly Schur-convex functions in Euclidean Jordan algebras
","<p>In this talk, we present several commutation principles for
optimizers of shifts of spectral functions in the context of Euclidean
Jordan Algebras (EJAs). For instance, we show that under certain
assumptions, if <span class=""math inline""><em>x̄</em></span> is a (local)
optimizer of <span
class=""math inline""><em>F</em>(<em>x</em> − <em>a</em>)</span> for <span
class=""math inline""><em>x</em> ∈ <em>Ω</em></span>, where <span
class=""math inline""><em>Ω</em> ⊂ 𝒱</span> is a spectral set of an EJA
<span class=""math inline"">𝒱</span>, <span
class=""math inline""><em>a</em> ∈ 𝒱</span> and <span
class=""math inline""><em>F</em> : 𝒱 → ℝ</span> is a strictly Schur-convex
spectral function, then <span class=""math inline""><em>a</em></span> and
<span class=""math inline""><em>x̄</em></span> operator commute. We make no
further assumption on the smoothness of <span
class=""math inline""><em>F</em></span>; instead, we take advantage of the
smoothness (Lie structure) of the Automorphism group of <span
class=""math inline"">𝒱</span> and make use of majorization techniques for
the eigenvalues of elements in EJAs. Our approach allows us to deal with
several problems considered in the literature, related to strictly
convex spectral functions and strictly convex spectral norms. In
particular, we use our commutation principles to analyze the problem of
minimizing the condition number in EJAs.</p>
"
S10,SC3001,1,Sofia,Sukmaniuk,Sofia Sukmaniuk,2025-06-26 16:00:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,16:00,16:30,110,16,Generalized minimal residual method with flexible Arnoldi process,"<p>We present an extension of the Arnoldi process for subspaces <span
class=""math inline"">ℒ<sub><em>k</em></sub></span> with a chain <span
class=""math inline"">ℒ<sub><em>i</em> − 1</sub> ⊂ ℒ<sub><em>i</em></sub></span>,
for <span class=""math inline"">$i = \overline{2 \dots k}$</span>. As it
takes place in the Arnoldi process, it produces an orthonormal basis for
<span
class=""math inline"">ℒ<sub><em>k</em></sub> + <em>A</em>ℒ<sub><em>k</em></sub></span>,
where the basis for <span
class=""math inline"">ℒ<sub><em>k</em></sub></span> is formed by its first
<span class=""math inline"">dim ℒ<sub><em>k</em></sub></span> vectors.
Moreover, the basis for <span
class=""math inline"">ℒ<sub><em>i</em></sub></span> is represented using
the first <span class=""math inline"">dim ℒ<sub><em>i</em></sub></span>
vectors of the basis for <span
class=""math inline"">ℒ<sub><em>k</em></sub></span>, for all <span
class=""math inline"">$i = \overline{1 \dots k}$</span>. This enhancement
enables a universal GMRES extension, where <span
class=""math inline"">ℒ<sub><em>k</em></sub></span> and <span
class=""math inline""><em>A</em>ℒ<sub><em>k</em></sub></span> greatly
coincide. The extension is suitable for systems with multiple right-hand
sides, allowing dynamic block size changes and on-the-fly integration of
new right-hand sides. It also supports deflated restarts with any
selected deflation strategy and a flexible preconditioner. Since all
essential bases are compactly represented within a common basis, memory
and computational demands are minimal relative to constructing the
common basis.</p>
"
S10,SC3001,2,,,,2025-06-26 16:00:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,16:30,17:00,110,16,,
S10,SC3001,3,,,,2025-06-26 16:00:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,17:00,17:30,110,16,,
S10,SC3001,4,,,,2025-06-26 16:00:00,MS16,Approximations and errors in Krylov-based solvers,Thursday,17:30,18:00,110,16,,
S10,SC4011,1,Kensuke,Aihara,Kensuke Aihara,2025-06-26 16:00:00,MS23,Advances in Krylov subspace methods and their applications,Thursday,16:00,16:30,110,23,Block cross-interactive residual smoothing for block Lanczos-type iterative solvers,"<p>Block Lanczos-type iterative solvers are effective for large sparse
nonsymmetric linear systems with multiple right-hand sides. However, the
methods often exhibit large oscillations in the residual and
approximation norms. The large oscillations are known to lead to a large
increase in the residual gap (the difference between the recursively
updated residual and the explicitly computed residual) due to rounding
errors. The cross-interactive residual smoothing (CIRS) is a useful
scheme to improve convergence behavior and the residual gap for a single
right-hand side case. This approach ensures that the primary and
smoothed sequences of residuals influence one another, thereby avoiding
the severe propagation of rounding errors. In our previous study, we
have extended CIRS to the global version that can be applicable to
linear matrix equations. In this study, we propose another extension to
the multiple right-hand sides case; that is, a block version of CIRS
(Bl-CIRS). Subsequently, we demonstrate its effectiveness through a
rounding error analysis and numerical experiments. We show that
orthonormalizing the columns of direction matrices in Bl-CIRS is crucial
to reduce the residual gap. This talk is based on our recent preprint
[arXiv:2412.19488] jointly worked on Dr. Akira Imakura and Dr. Keiichi
Morikuni.</p>
"
S10,SC4011,2,Robbe,Vermeiren,Robbe Vermeiren,2025-06-26 16:00:00,MS23,Advances in Krylov subspace methods and their applications,Thursday,16:30,17:00,110,23,"An inverse eigenvalue problem linked to multiple orthogonal polynomials
","<p>Multiple orthogonal polynomials (MOPs) arise in various applications,
including approximation theory, random matrix theory, and numerical
integration. To define MOPs, one needs orthogonality conditions with
respect to multiple measures. In this talk, we restrict our attention to
the case of two measures. These MOPs satisfy recurrence relations, and
we focus specifically on the stepline recurrence relation. We derive an
inverse eigenvalue problem: given some initial spectral data, retrieve
the recurrence matrix associated with the stepline recurrence relation.
Several techniques for solving this inverse problem are proposed, and
numerical illustrations are provided to demonstrate their
correctness.</p>
"
S10,SC4011,3,Amin,Faghih,Amin Faghih,2025-06-26 16:00:00,MS23,Advances in Krylov subspace methods and their applications,Thursday,17:00,17:30,110,23,Krylov subspaces and Sobolev functions,"<p>In this talk, we will discuss how to generate Sobolev rational
functions that are orthonormal with respect to a discrete Sobolev inner
product through a long recurrence relation. The recurrence coefficients
of this relation can be stored in a Hessenberg pencil. Two important
numerical methods are those based on Krylov subspace methods and those
based on restoring matrix structures. The methods are based on the
connection between Sobolev orthonormal rational functions and the
orthonormal bases for rational Krylov subspaces generated by a
Jordan-like matrix.</p>
"
S10,SC4011,4,Stefano,Pozza,Stefano Pozza,2025-06-26 16:00:00,MS23,Advances in Krylov subspace methods and their applications,Thursday,17:30,18:00,110,23,Krylov subspace methods an the $\star$-algebra,"<p>The <span class=""math inline"">⋆</span>-algebra <span class=""citation""
data-cites=""Man24""></span> has been successfully employed to solve a
system of linear ODEs with time-dependent coefficients by transforming
the ODE into a system of linear <span
class=""math inline"">⋆</span>-equations <span class=""citation""
data-cites=""BonPozVan23 GisPoz""></span>. Many classical linear algebra
methods and decomposition can be recovered in the <span
class=""math inline"">⋆</span>-algebra. The recovered methods are a
time-dependent version of the original ones. For example, the <span
class=""math inline"">⋆</span>-Lanczos algorithm <span class=""citation""
data-cites=""GisPoz""></span> generalizes the (classical) non-Hermitian
Lanczos algorithm and extends the well-known connections between matrix
moments, and the Lanczos algorithm <span class=""citation""
data-cites=""GolMeu PozPraStr""></span> to the time-dependent case. The
relation between the classical Krylov subspace methods and their <span
class=""math inline"">⋆</span>-counterparts can be used as a way to
compute the solution of ODEs by the <span
class=""math inline"">⋆</span>-algebra approach and, vice versa, to
analyze classical Krylov subspace methods for time-dependent matrices
with possible applications to perturbed matrices.</p>
<div class=""thebibliography"">
<p><span>99</span> Bonhomme, C., Pozza, P., Van Buggenhout, N.: A new
fast numerical method for the generalized Rosen-Zener model.
arXiv:2311.04144 [math.NA] (2023)</p>
<p>Giscard, P-L., Pozza, S., A Lanczos-like method for non-autonomous
linear ordinary differential equations. Boll. Unione Mat. Ital 16,
81–102 (2023)</p>
<p>Golub, G.H., Meurant, G.: Matrices, Moments and Quadrature with
Applications. Princeton University Press, Princeton (2010)</p>
<p>Pozza, S., Pranić, M.S., Strakoš, Z.: Gauss quadrature for
quasi-definite linear functionals. IMA J. Numer. Anal. 37(3), 1468–1495
(2017)</p>
<p>Ryckebusch, M.: A Fréchet-Lie group on distributions.
arXiv:2307.09037 [math.FA] (2024).</p>
</div>
"
S11,SC0008,1,Hojoon,Lee,Hojoon Lee,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,A new perspective on partial ordering by matrix representation,"<p>In the study of partially ordered sets (posets), various matrix
representations provide useful tools for understanding their structure
and properties. One particularly interesting representation is the
<span><em>poset matrix</em></span>, which encodes the partial order
relations between poset elements. This matrix can also be interpreted as
a <span><em>bit matrix</em></span> whose entries encode the bits of the
binary representation. This perspective offers a new way to explore and
analyze posets by focusing on their binary structure. Viewing poset
matrices as bit matrices provides new insights into the enumeration,
classification, and properties of posets. In this talk, we will discuss
the implications of this approach, explore its potential for enumerating
finite posets, and demonstrate how this framework contributes to the
understanding of order structures in combinatorics and computer science.
This is a joint work with Gi-Sang Cheon, Hong Joon Choi, Gukwon Kwon,
and Yaling Wang.</p>
"
S11,SC0008,2,Partha,Rana,Partha Rana,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,Some symmetric sign patterns requiring unique inertia,"<p>A sign pattern is a matrix whose entries are from the set <span
class=""math inline"">{+, −, 0}</span>. A sign pattern requires unique
inertia if every matrix in its qualitative class has the same inertia.
For symmetric tree sign patterns, several necessary and sufficient
conditions to require unique inertia are known. In this paper,
sufficient conditions for symmetric tree sign patterns to require unique
inertia based on the sign and position of the loops in the underlying
graph are given. Further, some sufficient conditions for a symmetric
sign pattern to require unique inertia if the underlying graph contains
cycles are determined.</p>
"
S11,SC0008,3,Denise Mae,Go,Denise Mae Go,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,Initially positive sign patterns,"<p>A nonsingular <span
class=""math inline""><em>n</em> × <em>n</em></span> matrix <span
class=""math inline""><em>A</em></span> is said to be <em>initially
positive</em> if the first column of <span
class=""math inline""><em>A</em></span> and the first row of <span
class=""math inline""><em>A</em><sup>−1</sup></span> are both positive.
Initially positive matrices are used to construct matrices with negative
entries that still satisfy the Perron-Frobenius property. In this short
talk, we determine sign patterns that allow or require initial
positivity for orders <span class=""math inline""><em>n</em> ≤ 4</span>.
We provide some ways of constructing initially positive matrices for any
order <span class=""math inline""><em>n</em></span>.</p>
"
S11,SC0009,1,Yuki,Nishida,Yuki Nishida,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,Comparison of several schemes for the CSR expansion of max-plus matrices,"<p>Max-plus algebra is a semiring with addition <span
class=""math inline""><em>a</em> ⊕ <em>b</em> := max (<em>a</em>, <em>b</em>)</span>
and <span
class=""math inline""><em>a</em> ⊗ <em>b</em> := <em>a</em> + <em>b</em></span>.
The CSR expansion of a max-plus square matrix <span
class=""math inline""><em>A</em></span> is a decomposition of the matrix
power <span class=""math inline""><em>A</em><sup>⊗<em>t</em></sup></span>
into the sum of matrices of the forms <span
class=""math inline""><em>C</em> ⊗ <em>S</em><sup>⊗<em>t</em></sup> ⊗ <em>R</em></span>,
where <span class=""math inline""><em>S</em></span> is a permutation
matrix. Several schemes for the CSR expansion have been introduced, such
as Nachtigall (1997), Hartmann-Arguelles (1999) and Merlet et
al. (2014). In Nishida (2025), the author proposes a new scheme for the
CSR expansion based on the factorization of the characteristic
polynomial of a max-plus matrix. In this study, we compare the CSR
expansions given by these schemes from the viewpoint of the transient
bound, which is the minimum exponent <span
class=""math inline""><em>t</em></span> such that the expansion is valid,
and the number of terms in the expansion.</p>
"
S11,SC0009,2,Richard,Hollister,Richard Hollister,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,Quasi-triangularization of matrix polynomials in Maple,"<p>Given a regular matrix polynomial over any field, it is possible to
construct a quasi-triangular matrix of the same degree that is
unimodularly equivalent to the given polynomial. The details of this
process can be found in the paper by Anguas et al. In this talk we
present Maple code for this quasi-triangularization process and discuss
some of our future plans for Maple implementations in the realm of
matrix polynomials.</p>
"
S11,SC0009,3,Hamide,Dogan,Hamide Dogan,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,Recursions among and classification of singular $k$-tridiagonal Toeplitz matrices,"<p>We introduce a novel L/N factorization approach, inspired by
Doolittle’s L/U factorization, for <span
class=""math inline""><em>k</em></span>-tridiagonal Toeplitz matrices,
<span
class=""math inline""><em>T</em><sub><em>n</em></sub><sup>(<em>k</em>)</sup></span>,
where <span
class=""math inline""><em>n</em> = <em>k</em><em>m</em> + <em>s</em></span>
and <span
class=""math inline"">det (<em>T</em><sub><em>p</em></sub><sup>(1)</sup>) = 0</span>
for <span class=""math inline""><em>p</em> &lt; <em>m</em></span>. This
factorization allows for the derivation of recursion expressions and
provides a classification of singular Toeplitz matrices.</p>
"
S11,SC0012,1,Luis Miguel,Anguas Márquez,Luis Miguel Anguas Márquez,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,New approaches to the solutions of bispectral problems,"<p>A family of polynomials is a solution to a bispectral problem if it
forms a sequence of eigenfunctions of both a finite-order differential
operator <span class=""math inline""><em>L</em></span> and a difference
operator <span class=""math inline""><em>J</em></span>. In 1929, S.
Bochner studied the case where the differential operator is of order
<span class=""math inline"">2</span>, identifying the sequences of
classical orthogonal polynomials as solutions to the bispectral problem.
Since then, several contributions have been made to the study of the
bispectral problem, but the case of arbitrary order remains open.</p>
<p>The aim of this talk is to present new tools that have helped us
obtain results on whether certain differential operators produce
sequences of eigenpolynomials that solve the bispectral problem. We will
draw examples of such differential operators from the existing
literature on bispectral problems.</p>
"
S11,SC0012,2,Miguel,Rojas Rodríguez,Miguel Rojas Rodríguez,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,Matrix analysis of orthogonal polynomials and uvarov perturbations,"<p>In this talk, we emphasize the decisive role of matrix analysis in
studying orthogonal polynomials. The theory of classical orthogonal
polynomials and matrix analysis naturally arises in the study of
tridiagonal matrices (Jacobi matrices), whose spectrum, under certain
conditions, coincides with the support of a measure associated with a
sequence of orthogonal polynomials. Furthermore, the GaussâBorel
factorization of the moment matrix plays a fundamental role in
characterizing orthogonality and uncovering key structural
properties.<br />
We focus on MMOP, which are orthogonal polynomials with respect to a
matrix of measures. In this case, the associated Jacobi matrix is a
banded matrix, where the number of nonzero diagonals depends on the size
of the measure. Within this framework, we study how orthogonal
polynomials transform when the matrix of measures undergoes matrix
polynomial perturbations. The most general perturbation we consider
follows Uvarovâs form:<br />
<span
class=""math inline"">d<em>μ̃</em>(<em>x</em>)<em>R</em>(<em>x</em>) = <em>L</em>(<em>x</em>)d<em>μ</em>(<em>x</em>),</span><br />
where <span
class=""math inline""><em>R</em>(<em>x</em>), <em>L</em>(<em>x</em>)</span>
are polynomial matrices, <span
class=""math inline"">d<em>μ</em>(<em>x</em>)</span> is the original
measure matrix, and <span
class=""math inline"">d<em>μ̃</em>(<em>x</em>)</span> is the perturbed
measure matrix. By taking <span
class=""math inline""><em>R</em>(<em>x</em>) = <em>I</em></span> or <span
class=""math inline""><em>L</em>(<em>x</em>) = <em>I</em></span>, we
obtain a Christoffel or Geronimus perturbation, respectively.<br />
The main contribution of our work is the generalization of these
perturbations beyond diagonal matrix polynomials, extending the theory
to include cases with non-monic leading matrices. This generalization
leads to an analysis of the spectral properties of the perturbation
matrix polynomials. Furthermore, we reduce the problem of ensuring
orthogonalityâframed as a question of the quasi-definiteness of a matrix
measureâto a linear algebra problem involving the compatibility of
certain systems of linear equations.</p>
"
S11,SC0012,3,Noufal,Asharaf,Noufal Asharaf,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,Banach frame structure for the Szego kernels in the Hardy space,"<p>The rational Blaschke functions are used to create the
Multiresolution analysis on the Hardy space H2(T). We discuss a
decomposition using a non-Blashke sequence, which is analogous to the
Whitney cube decomposition of the unit disc. Our primary goal is to
successfully recreate an analytical function from samples at the
non-Blaschke sequence. We explore the Banach frame structure that was
produced from the non-Blaschke sequences, look at the frame structure of
the reproducing kernel that corresponds to it, and derive a series
representation of any operator in the space in terms of the sampling
sequence.</p>
<div class=""thebibliography"">
<p><span>5</span> Casazza, Peter G., Deguang Han, and David R. Larson.
Frames for Banach spaces, Contemporary Mathematics 247 (1999): 149–182.
O. Christensen, An Introduction to Frames and Riesz basis, Birkhäuser,
2003. Pap, M. Hyperbolic wavelets and multiresolution in H2(T). J.
Fourier Anal. Appl. 17(5), 755–776 (2011).</p>
</div>
"
S11,SC0014,1,Samapti,Pratihar,Samapti Pratihar,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,Inverse $Z$-matrices with the bi-diagonal ramp structure,"<p>In the literature, there are only a handful of articles that are
devoted to listing some classes of matrices for which properties such as
the characteristic equation, eigenvectors, associated determinant and
the inverse, can be found in a relatively simple manner. The number of
matrices for which these properties may be expressed analytically is
surprisingly small. The main purpose of studying these matrix classes is
to provide test matrices for evaluating the accuracy and efficiency of
computational processes. These matrix classes have the advantage that
they may be chosen of arbitrary order, and by appropriately selecting
their elements they may be made singular or nonsingular as desired in
specific instances. This enables, for instance, to draw conclusions on
the efficacy of new numerical methods by comparing computed inverses (or
the Moore-Penrose inverses, as the case may be) with the known exact
expressions for the inverse (or the Moore-Penrose inverse), and other
such processes, that may be necessary in the application problems that
motivate such considerations. In this talk we propose another extension
of these test matrices including some of the more recent
generalizations. Specifically, we are considering those invertible
matrices whose inverses are what we refer to as <span><em>bi-diagonal
ramp matrices</em></span>. We use such matrices to identify some new
classes of inverse <span class=""math inline""><em>Z</em></span>-matrices.
Time permitting, a graph theoretic interpretation will also be
presented.</p>
"
S11,SC0014,2,Geeta,Chowdhry,Geeta Chowdhry,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,Inner and outer Bohemian inverses,"<p>A matrix <span class=""math inline""><em>A</em></span> is known as the
Bohemian matrix with respect to a population <strong>P</strong> if all
its entries are restricted to the set <strong>P</strong>. A matrix <span
class=""math inline""><em>X</em></span> is known as the Inner Bohemian
inverse (resp. Outer Bohemian inverse) of <span
class=""math inline""><em>A</em></span> with respect to a population
<strong>P</strong> if it satisfies <span
class=""math inline""><em>A</em><em>X</em><em>A</em> = <em>A</em></span>
(resp. <span
class=""math inline""><em>X</em><em>A</em><em>X</em> = <em>X</em></span>)
and the entries of <span class=""math inline""><em>X</em></span> are
restricted to the set <strong>P</strong>. Recently, the Inner Bohemian
inverses of some structured matrices have been studied with respect to
the general population <strong>P</strong> containing <span
class=""math inline"">{0, 1, −1}</span> in [1]. We have worked on the
Inner and outer Bohemian inverses of the extended class of Bohemian
matrices. We have characterized some classes of Bohemian matrices with
respect to the population <strong>P</strong><span
class=""math inline""> = {0, 1, −1}</span> and have found results for
their Inner and outer Bohemian inverses along with the cardinalities of
the sets of Inner and outer Bohemian inverses when the population is
fixed to <strong>P</strong><span
class=""math inline""> = {0, 1, −1}</span> which in turn simplifies the
cardinality results obtained in [1]. Additionally, for higher rank
Bohemian matrices with respect to the population <strong>P</strong><span
class=""math inline""> = {0, 1, −1}</span>, we have found Inner and Outer
Bohemian inverses of a specified class of Bohemian matrices.</p>
<p>[1] Eunice Y. S. Chan, Robert M. Corless, Laureano González-Vega, J.
Rafael Sendra, and Juana Sendra. : Inner Bohemian inverses, Applied
Mathematics and Computation, 421:126945, May 2022.</p>
"
S11,SC0014,3,Bibekananda,Sitha,Bibekananda Sitha,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,Dual core-EP generalized inverse and decomposition,"<p>In this work, we introduce a new type of generalized inverse called
dual core-EP generalized inverse (in short DCEPGI) for dual square
matrices. We analyze the existence and uniqueness of the DCEPGI inverse
and its compact formula using dual Drazin and dual MP inverses.
Moreover, some characterizations using core-EP decomposition are
obtained. We present a new dual matrix decomposition named the dual
core-EP decomposition for square dual matrices. In addition, some
relationships with other dual generalized inverses are established.
Solutions to some inconsistent system of linear dual equations are
derived.</p>
"
S11,SC1001,1,Hojin,Chu,Hojin Chu,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,Structural properties of symmetric Toeplitz and Hankel matrices,"<p>In this paper, we investigate properties of a symmetric Toeplitz
matrix and a Hankel matrix by studying the components of its graph. To
this end, we introduce the notion of “weighted Toeplitz graph” and
“weighted Hankel graph”, which are weighted graphs whose adjacency
matrix are a symmetric Toeplitz matrix and a Hankel matrix,
respectively. By studying the components of a weighted Toeplitz graph,
we show that the Frobenius normal form of a symmetric Toeplitz matrix is
a direct sum of symmetric irreducible Toeplitz matrices. Similarly, by
studying the components of a weighted Hankel matrix, we show that the
Frobenius normal form of a Hankel matrix is a direct sum of irreducible
Hankel matrices.</p>
"
S11,SC1001,2,Sirshendu,Pan,Sirshendu Pan,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,Universal winner in trees,"<p>Let <span
class=""math inline""><em>A</em> ∈ <em>M</em><sub><em>n</em></sub></span>
be nonnegative, irreducible and <span
class=""math inline""><em>E</em><sub><em>i</em><em>i</em></sub> = <em>e</em><sub><em>i</em></sub><em>e</em><sub><em>i</em></sub><sup><em>t</em></sup></span>,
where <span class=""math inline""><em>e</em><sub><em>i</em></sub></span>
is the <span class=""math inline""><em>i</em></span>-th standard basis
vector. For a fixed <span
class=""math inline""><em>t</em><sub>0</sub> &gt; 0</span>, an index <span
class=""math inline""><em>p</em> ∈ [<em>n</em>] := 1, 2, …, <em>n</em></span>
is called a winner for <span
class=""math inline""><em>t</em><sub>0</sub></span> if the spectral radius
<span class=""math inline"">$\rho(A+t_0E_{pp})=\max\limits_{i\in
[n]}\rho(A+t_0E_{ii})$</span>. If <span
class=""math inline""><em>p</em></span> remains a winner for each <span
class=""math inline""><em>t</em> &gt; 0</span>, then it is called a
universal winner. The concepts have been introduced in 1996 and studied
in only a few articles till now. When <span
class=""math inline""><em>G</em></span> is a simple connected graph (or a
strongly connected digraph), the nonnegative weighted adjacency matrix
<span class=""math inline""><em>A</em>(<em>G</em>)</span> being
irreducible, one can talk of a universal winner vertex with respect to
<span class=""math inline""><em>A</em>(<em>G</em>)</span>. The universal
winners seem to capture the graph structures well. It is known that the
only connected digraph <span class=""math inline""><em>G</em></span> in
which all vertices are universal winners with respect to all nonnegative
weighted <span class=""math inline""><em>A</em>(<em>G</em>)</span>, is the
directed cycle, thereby characterizing it. Let <span
class=""math inline""><em>U</em> ⊂ [<em>n</em>]</span> be nonempty. In a
recent article, the class of directed connected graphs with vertex set
<span class=""math inline"">[<em>n</em>]</span>, for which only the
vertices in <span class=""math inline""><em>U</em></span> are the
universal winners with respect to all nonnegative weighted <span
class=""math inline""><em>A</em>(<em>G</em>)</span> was characterized,
generalizing the earlier result. Many other combinatorial results
exploiting the graph structure were proved establishing the importance
of the study of universal winner vertices. In this article, we further
the study for the class of undirected graphs, in particular for trees,
with respect to only the adjacency matrix. As expected, we supply a
class of trees in which no universal winner exists. More interestingly,
every tree is a subtree of a tree with a unique universal winner and
also a subtree of a tree without a universal winner. Trees with exactly
<span class=""math inline""><em>k</em> &gt; 1</span> universal winners are
not easy to find. A construction of a class of trees with exactly <span
class=""math inline""><em>k</em></span> universal winners is provided.
Interestingly, it turns out that for any undirected connected graph
<span class=""math inline""><em>G</em></span>, the set of universal
winners of <span class=""math inline""><em>G</em></span> and the corona
<span class=""math inline""><em>G</em> ∘ <em>K</em><sub>1</sub></span> are
the same, where the later is obtained by adding a new pendent vertex to
each vertex of <span class=""math inline""><em>G</em></span>. It is also
shown that if <span
class=""math inline""><em>ρ</em>(<em>A</em>(<em>G</em>)) &gt; 2</span>,
then no vertex of degree one or two can be a universal winner.
Previously, it was known that for a path <span
class=""math inline""><em>P</em></span>, the central vertices are the
universal winners and as a vertex <span
class=""math inline""><em>u</em></span> goes farther from the center, the
spectral radius <span
class=""math inline""><em>ρ</em>(<em>A</em>(<em>P</em>) + <em>t</em><em>E</em><sub><em>u</em><em>u</em></sub>)</span>
decreases. We prove that a similar statement also holds for a grid
graph.</p>
"
S11,SC1001,3,Sriram,Balasubramanian,Sriram Balasubramanian,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,On noncommutative partial convexity,"<p>In this talk, we will discuss the structure of matrix-valued (free)
polynomials in several freely noncommuting variables that enjoy certain
partial convexity properties.</p>
"
S11,SC1003,1,Thomas,Mach,Thomas Mach,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,"Approximate two-sided Grasmann-Reyleigh shifts for QR, Core-Chasing, and pole-swapping algorithms","<p>In each iteration of Francis’s implicitly shifted QR algorithm <span
class=""math inline""><em>m</em></span> shift are chosen to drive the
process toward convergence. The most common choice is the Wilkinson
shift for <span class=""math inline""><em>m</em> = 1</span> or <span
class=""math inline"">2</span>. Rayleigh quotient shifts dominate when
multiple shifts <span class=""math inline""><em>m</em> ≫ 1</span> are
used. We present alternatives to the Rayleigh quotient and the Wilkinson
shift for the single or double shift case. We present novel shift
strategies for QR algorithms and generalize them to pole-swapping
algorithms.</p>
<p>For normal matrices the Wilkinson shift is proven globally convergent
locally with a cubic convergence rate. The local convergence rate is
based on the cubic convergence of the Rayleigh quotient iteration.
Usually for non-normal matrices locally only a quadratic convergence
rate is observed both in Francis’s QR algorithm and in Rayleigh quotient
iteration.</p>
<p>It has been shown by Ostrowski in 1959 that the two-sided Rayleigh
quotient iteration is cubic convergent also for non-normal matrices. We
aim to improved the shift strategy for non-normal matrices by
incorporating ideas from the two-sided Rayleigh quotient following ideas
by Chen and Xu. The two-sided Rayleigh quotient requires an
approximation to the right eigenvector, which is expensive to compute.
Hence, we focus on a heuristic approximation to the right
eigenvector.</p>
<p>The discussions also apply to derivatives of Francis’s algorithm like
the QZ algorithm by Moler and Stewart, the core-chasing, and the
pole-swapping variants.</p>
<p>We present extensive numerical experiments comparing the different
shift strategies. These provide valuable insights for practical
implementations since the typical number of iterations to reach machine
precision is far more important than the convergence rate at
infinity.</p>
<p>This research is joint work with Raf Vandebril (KU Leuven). The
research has been partially funded by the Deutsche
Forschungsgemeinschaft (DFG)—Project-ID 318763901—SFB1294.</p>
"
S11,SC1003,2,Duc-Quoc,Huynh,Duc-Quoc Huynh,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,Nonmonotone diagonal quasi-Newton accelerated gradient descent methods for the nearest correlation matrix problems,"<p>The nearest correlation matrix (NCM) problem poses computational
difficulties with critical implications in finance and actuarial
science. Accurate correlation matrices are essential for effective risk
management and investment strategies. The NCM problem is mathematically
formulated as a constrained optimization problem, often solved using the
alternating projection method (APM) or alternating direction of
multipliers method (ADMM) . However, its slow linear convergence and
required complete eigenvalue decomposition at each iteration render it
computationally expensive and impractical for large-scale problems.
Alternatively, the NCM problem can be reformulated as an unconstrained
optimization task in its dual form, taking advantage of its convex
structure. It allows for a focus on minimizing the dual objective
function by solving for the zeros of its gradient to satisfy first-order
optimality conditions. Our proposed method belongs to the framework of
the generalized linesearch iterative methods, incorporating two basic
elements: search direction and stepsize determination. Additionally, we
introduce two practical mechanisms, including an accelerated step and
nonlinear preconditioning, to improve the method’s robustness and
efficiency. We proposed the quasi-Newton method with diagonal Jacobian
approximation (QN-SDAJ), which is used as a nonlinear preconditioner to
accelerate gradient descent, significantly reducing the number of
iterations and computational time. Numerical results show that our
proposed method outperforms existing alternatives, including accelerated
gradient descent, semismooth inexact Newton, and APM, particularly for
large-scale problems, demonstrating superior efficiency.</p>
"
S11,SC1003,3,Quen-Yi,Lin,Quen-Yi Lin,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,A two-grid spectral deferred correction method for the generalized multi-order fractional differential equations,"<p>The spectral deferred correction (SDC) method is a traditional
deferred and defect correction method for ordinary differential
equations (ODEs). The SDC method constructs numerical methods of
arbitrary order by iteratively applying a lower-order method to an error
function, enabling significant reductions in computational cost while
maintaining strong stability properties. For first-order ODE problems,
many theoretical and numerical results for SDC are available. However,
for fractional differential equations (FDEs), although there are many
numerical results, only a few theoretical studies can be found. FDEs can
be considered a generalization of ODEs, replacing integer orders with
non-integer ones. Since FDEs can describe many natural and artificial
phenomena, they have attracted increasing attention in recent years. In
this talk, we will apply a two-grid SDC method to multi-order FDEs and
present an analysis of their stability and convergence. Numerical
experiments are included to illustrate the theoretical results. This
work is based on joint research with Professor Ming-Cheng Shiue.</p>
"
S11,SC1005,1,Ana,Luzón,Ana Luzón,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,Riordan matrices' structures,"<p>In this talk, I will present how to construct matrices of the Riordan
group by row, column, and diagonal. We will look at some Riordan
matrices in particular, including their bi-infinite expressions. These
constructions will lead to recurrence formulas, numerical identities,
group isomorphisms, special subgroups, Lie groups, commutators,
involutions, etc.</p>
"
S11,SC1005,2,Arunava,Mandal,Arunava Mandal,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,Roots of elements in a matrix groups,"<p>Let <span class=""math inline""><em>F</em><sub><em>r</em></sub></span>
be a free group of <span
class=""math inline""><em>r</em></span>-generators, and <span
class=""math inline""><em>w</em> ∈ <em>F</em><sub><em>r</em></sub>.</span>
For every group <span class=""math inline""><em>G</em></span>, one defines
a “word map” <span
class=""math inline""><em>w</em> : <em>G</em><sup><em>r</em></sup> → <em>G</em></span>.
Let <span class=""math inline""><em>w</em>(<em>G</em>)</span> denote the
image of this map. In recent times, it emerged as one of the potential
research areas, and produced several astonishing results. Though it has
a long history dating back to A. Borel, it has attracted a significant
amount of attention, especially after the settlement of the
long-standing Ore’s conjecture (which states that every element of a
finite non-abelian simple group is a commutator). Note that if <span
class=""math inline""><em>G</em></span> is a field, this is nothing else
than a linear form with integer coefficients in <span
class=""math inline""><em>r</em></span> variables. Thus the study of <span
class=""math inline""><em>w</em>(<em>G</em>)</span> can be thought of as
finding solutions to equations in objects belonging to the category of
groups. For non-abelian <span class=""math inline""><em>G</em></span>,
word maps are more subtle objects and a lot of effort has been required
to unravel some of their properties. Fix an integer <span
class=""math inline""><em>k</em> ≥ 2</span> and consider the word <span
class=""math inline""><em>x</em><sup><em>k</em></sup> ∈ <em>F</em><sub>1</sub></span>.
The corresponding word map is called a power map and it has been studied
for several decades in various contexts. A remarkable result by
McCrudden connects the power map with the exponential map. McCrudden’s
result states that, for a connected Lie group <span
class=""math inline""><em>G</em></span>, <span
class=""math inline""><em>g</em> ∈ <em>G</em></span> has roots of all
orders if and only if <span class=""math inline""><em>g</em></span> is
contained in a one-parameter subgroup (and hence <span
class=""math inline""><em>g</em> = exp (<em>X</em>)</span>). In this talk,
we will discuss the analogous result for a linear algebraic group over
non-Archimedean local field <span class=""math inline""><em>F</em></span>
with any characteristic. We discuss our recent result about when an
element <span
class=""math inline""><em>g</em> ∈ <em>G</em>(<em>F</em>) ⊂ <em>G</em><em>L</em>(<em>V</em>)</span>
admits roots of all orders? Also, we will discuss the above theme in the
context of linear algebraic groups over global fields. This talk is
based on joint work with Parteek Kumar.</p>
"
S11,SC1005,3,Saikat,Mukherjee,Saikat Mukherjee,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,Weaving phase retrieval and weaving norm retrieval in tensor product space,"<p>Phase retrieval and norm retrieval sequences for Hilbert spaces were
introduced by Balan et al. in 2006 and by Bahmanpour et al. in 2015,
respectively. In signal processing, phase retrieval plays a crucial role
in reconstructing a signal from its intensity measurements. Similarly,
norm retrieval restores the norm of a signal from its intensity
measurements. Bemrose et al., in 2016, instigated weaving frames for
Hilbert spaces. Weaving phase and norm retrieval sequences for a Hilbert
space were recently studied by Dowerah et al. In this paper we study
weaving phase and weaving norm retrieval sequences in the tensor product
of Hilbert spaces defined by Folland, in the year 1995, as a space of
bounded antilinear maps between Hilbert spaces. Several
characterizations and methods of construction of weaving phase and norm
retrieval sequences in tensor product spaces are discussed.</p>
"
S11,SC2001,1,Damjana,Kokol Bukovšek,Damjana Kokol Bukovšek,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,Compressed commuting graphs of matrix rings,"<p>In the talk we introduce compressed commuting graph of rings. It can
be seen as a compression of the standard commuting graph (with the
central elements added) where we identify the vertices that generate the
same subring. The compression is chosen in such a way that it induces a
functor from the category of rings to the category of graphs, which
means that our graph takes into account not only the commutativity
relation in the ring, but also the commutativity relation in all of its
homomorphic images.</p>
<p>We show that this compression is best possible for matrix algebras
over finite fields. We consider the compressed commuting graphs of
finite fields, rings of <span class=""math inline"">2 × 2</span> matrices
over finite fields and rings of <span class=""math inline"">3 × 3</span>
matrices over finite prime fields.</p>
<p>(This is a joint work with Ivan-Vanja Boroja, Hamid Reza Dorbidi, and
Nik Stopar.)</p>
"
S11,SC2001,2,Hieu,Ha Van,Hieu Ha Van,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,AMDS symbol-pair constacyclic codes,"<p>Let <span class=""math inline""><em>p</em></span> be an odd prime, and
let <span class=""math inline"">𝔽<sub><em>p</em></sub></span> be the
finite field with <span class=""math inline""><em>p</em></span> elements.
In this talk, I will first construct new AMDS symbol-pair cyclic codes
of length <span class=""math inline"">4<em>p</em></span> by analyzing
their generator polynomials. Then, using the generator polynomial, I
derive a family of AMDS symbol-pair constacyclic codes of the same
length.</p>
"
S11,SC2001,3,Zsigmond,Tarcsay,Zsigmond Tarcsay,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,On the UV limit of Wilsonian renormalization group flows of Feynman measures,"<p>In nonperturbative formulation of Euclidean signature quantum field
theory, the vacuum state is characterized by the Wilsonian
renormalization group flow of Feynman measures. Such a flow is a family
<span
class=""math inline"">(<em>μ</em><sub><em>η</em></sub>)<sub><em>η</em> ∈ 𝒮</sub></span>
of finite measures on Borel sets of the space of Schwartz distributions
<span class=""math inline"">𝒮<sup>′</sup></span>, linked by the Wilsonian
renormalization group equation <span
class=""math inline""><em>μ</em><sub><em>η</em> * <em>ζ</em></sub><sup></sup> = (<em>C</em><sub><em>η</em></sub>)<sub>#</sub><sup></sup><em>μ</em><sub><em>ζ</em></sub><sup></sup></span>,
for every pair Schwartz functions <span
class=""math inline""><em>ζ</em>, <em>η</em> ∈ 𝒮</span>. Here, <span
class=""math inline""><em>C</em><sub><em>η</em></sub><em>ζ</em> := <em>η</em> * <em>ζ</em></span>
stands for the convolution of the Schwartz functions <span
class=""math inline""><em>ζ</em>, <em>η</em> ∈ 𝒮</span>, while <span
class=""math inline"">(<em>C</em><sub><em>η</em></sub>)<sub>#</sub><em>μ</em><sub><em>ζ</em></sub></span>
denotes the corresponding pushforward measure by <span
class=""math inline""><em>C</em><sub><em>η</em></sub></span>. The goal of
this talk is to show the existence of an ultimate Borel measure <span
class=""math inline""><em>μ</em></span> (called the UV limit of the flow),
such that for all <span class=""math inline""><em>η</em> ∈ 𝒮</span> the
factorization identity <span
class=""math inline""><em>μ</em><sub><em>η</em></sub> = (<em>C</em><sub><em>η</em></sub>)<sub>#</sub> <em>μ</em></span>
holds.</p>
"
S11,SC2006,1,Rafik,Bouifden,Rafik Bouifden,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,The expansion of functions by Toeplitz matrices,"<p>The expansion of a real function is a crucial technique for
representing a function as an infinite series of simpler functions. This
method serves as the primary tool for locally approximating functions
that cannot be expressed solely through basic operations—addition,
subtraction, multiplication, and division—using polynomials. To grasp
the significance of this mathematical concept, historical and
epistemological research is essential, as noted by Sierpinska <span
class=""math inline"">[1]</span>. The notion of expansion has evolved
through several stages, reflecting the development of a broad conceptual
framework. R. Kouki <span class=""math inline"">[2]</span> categorizes
these stages into five non-linear steps, which incorporate various
geometric, analytical, and algebraic techniques. The groundwork for this
work was laid in the early seventeenth century by mathematicians such as
Torricelli, Roberval, Fermat, Descartes, and Isaac Barrow, who addressed
tangent problems. This was further articulated by Taylor in 1715 and
later expanded upon by Newton and Leibniz through polynomial methods,
with significant contributions from Cauchy in 1823 and Abel in 1826,
culminating in Poincaré’s work in 1886. Today, calculating the expansion
of a function often requires divisions based on increasing powers, where
approximate reasoning involves neglecting certain terms in this limiting
process. In this context, we propose a novel algorithmic matrix
technique that leverages the fundamental properties of matrix
computations. Specifically, we associate the expansion of a function
<span class=""math inline""><em>f</em></span> to order <span
class=""math inline""><em>n</em></span> near zero with a Toeplitz
triangular matrix, where the first column represents the polynomial
corresponding to the expansion of <span
class=""math inline""><em>f</em></span>. We then outline all calculation
rules for these limited developments. Ultimately, our work gives a quick
algorithm to find, according to Douady <span
class=""math inline"">[3]</span> the object “the expansion” of non-usual
functions, whose Toeplitz matrices we have chosen as a “tool” and vice
versa in some cases. This approach highlights the importance of matrix
techniques in advancing our understanding and application of function
expansions.<br />
References<br />
<span class=""math inline"">[1]</span> A.Sierspinka Quelques idées sur la
méthodologie de la recherche en didactique des mathématiques liées à la
notion d’obstacle épistémologique, Cahier de Didactique des
Mathématiques, 7,85-86, (1989).<br />
<span class=""math inline"">[2]</span> R.Kouki Comparaison entre
l’évolution historique ayant mené aux développements limités et leur
pratique d’enseignement au début de l’université : Entre syntaxe et
sémantique, First conference of International Network for Didactic
Research in University Mathematics, Montpellier, France, (2016)
ffhal-01337899ff<br />
<span class=""math inline"">[3]</span> R.Douady Jeux de cadres et
dialectique outil-objet, Recherches en Didactique des Mathématiques,
7(2) 5-31,(1986).</p>
"
S11,SC2006,2,Nikolai,Krivulin,Nikolai Krivulin,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,An alternating algorithm for tropical best discrete approximation,"<p>We consider a best discrete approximation problem in the setting of
tropical (idempotent) algebra dealing with the theory and application of
semirings and semifields with idempotent operations. Given a set of
input-output pairs of an unknown function defined on a tropical
semifield, the problem is to determine an approximating rational
function formed by two Puiseux polynomials as numerator and denominator
in the function. With specified numbers of monomials in both
polynomials, the approximation aims at evaluating the exponent and
coefficient for each monomial in the polynomials to fit the rational
function to the given data in the sense of a tropical distance function.
To solve the problem, we transform it into approximation of a vector
equation with unknown vectors on both sides with one side answered to
the numerator polynomial and the other side to the denominator. Each
side of the equation involves a matrix with entries dependent on the
unknown exponents, multiplied by the vector of unknown coefficients of
monomials in the corresponding polynomial. We propose an algorithm that
constructs a series of approximate solutions by alternatively fixing one
side of the equation to the already found result and leaving the other
intact. The obtained equation is first approximated with respect to the
vector of coefficients, which results in a vector of coefficients and
approximation error both parameterized by the exponents. Furthermore,
the values of exponents are found by minimization of the approximation
error, using an optimization procedure that is based on an agglomerative
clustering technique. To illustrate applications, we present results for
approximation problems formulated in terms of max-plus algebra (a real
semifield with addition defined as maximum and multiplication as
arithmetic addition), which correspond to ordinary problems of piecewise
linear approximation of real functions. As our numerical experience
shows, the proposed algorithm converges in a finite number of steps and
provides a reasonably good solution to approximation problems
considered.</p>
"
S11,SC2006,3,Deb,Sarkar,Deb Sarkar,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,Results on strong coupled best proximity point with application to non-linear differential equation,"<p>Fixed point theory plays very crucial role in different fields
specially in functional analysis. In this paper, some results on strong
coupled best proximity point using some new inequalities have been
established. A suitable example has also been given supporting the
result. In consequences, a result of strong coupled fixed point has been
given. Also, an application to non-linear differential equation has been
shown.</p>
"
S11,SC3001,1,Francis Joseph,Campena,Francis Joseph Campena,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,On the shadow graph operation: a generalization of double graphs and its spectrum,"<p>In 2007, E. Munarini et al defined the notion of the double of a
graph. The double of a connected graph <span
class=""math inline""><em>G</em></span> denoted <span
class=""math inline"">𝒟<sub>2</sub>(<em>G</em>)</span> is constructed by
taking two copies of <span class=""math inline""><em>G</em></span> say
<span class=""math inline""><em>G</em><sup>′</sup></span> and <span
class=""math inline""><em>G</em><sup>″</sup></span> and joining by an edge
each vertex <span class=""math inline""><em>v</em><sup>′</sup></span> in
<span class=""math inline""><em>G</em><sup>′</sup></span> to the neighbors
of the corresponding vertex <span
class=""math inline""><em>v</em><sup>″</sup></span> in <span
class=""math inline""><em>G</em><sup>″</sup></span>. This was later
generalized by M. Marino and N. Salvi.<br />
 <br />
In this study, we define a graph operation called shadow graph of <span
class=""math inline""><em>G</em></span> and <span
class=""math inline""><em>H</em></span> denoted by <span
class=""math inline"">$G \text{\small$ \blacksquare $} H.$</span> This
naturally generalizes this notion of a double graph in the sense that
the double of a graph is just the shadow graph of <span
class=""math inline""><em>G</em></span> with a path of order 2, <span
class=""math inline"">$G\text{\small$ \blacksquare $} P_2$</span>, and the
generalized double is simply the shadow graph of <span
class=""math inline""><em>G</em></span> with the complete graph on <span
class=""math inline""><em>m</em></span> vertices. <span
class=""math inline"">$G\text{\small$ \blacksquare $} K_m$</span>. We
determine the spectrum of <span class=""math inline"">$G\text{\small$
\blacksquare $} H$</span> in relation to the spectrum of <span
class=""math inline""><em>G</em></span> and <span
class=""math inline""><em>H</em></span>.</p>
"
S11,SC3001,2,Shanmugapriya,A,Shanmugapriya A,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,On proper cones in finite dimensional vector spaces,"<p>Let <span class=""math inline""><em>K</em></span> be a proper cone in
<span class=""math inline"">ℝ<sup><em>n</em></sup></span>, its dual is
defined as <span
class=""math inline""><em>K</em><sup>*</sup> = {<em>y</em> ∈ ℝ<sup><em>n</em></sup>|⟨<em>x</em>, <em>y</em>⟩ ≥ 0, for
all <em>x</em> ∈ <em>K</em>}</span>. Two cones <span
class=""math inline""><em>K</em><sub>1</sub></span> and <span
class=""math inline""><em>K</em><sub>2</sub></span> are said to be
isomorphic if there exists an invertible linear map <span
class=""math inline""><em>L</em> : ℝ<sup><em>n</em></sup> → ℝ<sup><em>n</em></sup></span>
such that <span
class=""math inline""><em>L</em>(<em>K</em><sub>1</sub>) = <em>K</em><sub>2</sub></span>.
For a cone <span class=""math inline""><em>K</em></span>, the
complementarity set is defined as <span
class=""math inline""><em>C</em>(<em>K</em>) = {(<em>x</em>, <em>a</em>)|<em>x</em> ∈ <em>K</em>, <em>a</em> ∈ <em>K</em><sup>*</sup>, ⟨<em>x</em>, <em>a</em>⟩ = 0}</span>.
A linear transformation <span class=""math inline""><em>L</em></span> is
said to be Lyapunov-like transformation on <span
class=""math inline""><em>K</em></span> if <span
class=""math inline"">⟨<em>L</em>(<em>x</em>), <em>a</em>⟩ = 0</span>, for
all <span
class=""math inline"">(<em>x</em>, <em>a</em>) ∈ <em>C</em>(<em>K</em>)</span>.
The set of all Lyapunov-like transformations <span
class=""math inline""><em>L</em><em>L</em>(<em>K</em>)</span> forms a
vector space and its dimension is called the Lyapunov rank <span
class=""math inline""><em>β</em>(<em>K</em>)</span> of a cone <span
class=""math inline""><em>K</em></span>. In one of our recent works, we
constructed non-isomorphic proper polyhedral cones using Lyapunov rank.
Our results used the fact that isomorphic cones have same Lyapunov rank.
We know that the converse of this statement is not true. In this work,
we discuss when the converse of this statement is true.</p>
"
S11,SC3001,3,Smrati,Pandey,Smrati Pandey,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,Spectral properties of the eccentricity matrix of graph products,"<p>Let <span class=""math inline""><em>G</em></span> be a connected and
simple graph. The eccentricity of a vertex <span
class=""math inline""><em>u</em> ∈ <em>G</em></span>, <span
class=""math inline"">(<em>e</em>(<em>u</em>))</span>, is defined as the
maximum distance from <span class=""math inline""><em>u</em></span> to any
other vertex <span class=""math inline""><em>v</em> ∈ <em>G</em></span> in
the graph. The eccentricity matrix, <span
class=""math inline""><em>ϵ</em>(<em>G</em>)</span> is derived from the
distance matrix whose <span
class=""math inline"">(<em>u</em>, <em>v</em>)</span>-th entry is equal to
<span class=""math inline""><em>d</em>(<em>u</em>, <em>v</em>)</span> if
<span class=""math inline""><em>d</em>(<em>u</em>, <em>v</em>)</span> is
the minimum of <span
class=""math inline"">{<em>e</em>(<em>u</em>), <em>e</em>(<em>v</em>)}</span>,
and is zero otherwise. Note that <span
class=""math inline""><em>d</em>(<em>u</em>, <em>v</em>)</span> is the
distance between the vertices <span
class=""math inline""><em>u</em></span> and <span
class=""math inline""><em>v</em></span>. A graph <span
class=""math inline""><em>G</em></span> is said to be self centered if the
eccentricity of each vertex of <span
class=""math inline""><em>G</em></span> is same.</p>
<p>The corona product is a prominent graph operation known for its
distinct structural features and has been the focus of extensive
research. Over the time, several variations of the corona product have
been introduced and analyzed.</p>
<p>Assume that <span class=""math inline""><em>G</em></span> and <span
class=""math inline""><em>H</em></span> are two finite graphs on <span
class=""math inline""><em>m</em></span> and <span
class=""math inline""><em>n</em></span> vertices, respectively. The corona
product <span class=""math inline""><em>G</em> ∘ <em>H</em></span> of two
graphs <span class=""math inline""><em>G</em></span> and <span
class=""math inline""><em>H</em></span>, is constructed by keeping a
single copy of <span class=""math inline""><em>G</em></span> and <span
class=""math inline""><em>m</em></span> copies of <span
class=""math inline""><em>H</em></span>, and then connecting each vertex
of the <span class=""math inline""><em>j</em></span>-th copy of <span
class=""math inline""><em>H</em></span> to the <span
class=""math inline""><em>j</em></span>-th vertex of <span
class=""math inline""><em>G</em></span>. The one-point-corona, denoted as
<span
class=""math inline""><em>G</em>∘<sub><em>z</em></sub><em>H</em></span>,
is constructed similarly by taking one copy of <span
class=""math inline""><em>H</em></span> for each vertex of <span
class=""math inline""><em>G</em></span>, but only the the root vertex
<span class=""math inline""><em>z</em></span> from each copy of <span
class=""math inline""><em>H</em></span> is connected to corresponding
vertex in <span class=""math inline""><em>G</em></span> with an edge.</p>
<p>In this talk, we discuss the irreducibility and spectra of
eccentricity matrices obtained from the corona product and the one point
corona product of graphs <span class=""math inline""><em>G</em></span> and
<span class=""math inline""><em>H</em></span>, where <span
class=""math inline""><em>G</em></span> is a self-centered graph.</p>
"
S11,SC4011,1,Anusree,Sreedharan,Anusree Sreedharan,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:00,08:30,111,200,Hyperbolic wavelets and multiresolution in $A_{\alpha}^{2} (\mathbb{D})$,"<p>We examine rational Blaschke functions that are capable to formulate
a Multiresolution on the weighted Bergman space of the open unit disc
<span
class=""math inline""><em>A</em><sub><em>α</em></sub><sup>2</sup>(𝔻)</span>.
We construct a rational orthogonal wavelet system that generates the
levels of the multiresolution. The levels of the multiresolution are
finite dimensional, which makes it easier to find a basis on each level.
We can approximate any <span
class=""math inline""><em>f</em> ∈ <em>A</em><sub><em>α</em></sub><sup>2</sup>(𝔻)</span>
by the projection operator on the <span
class=""math inline""><em>n</em><sup>th</sup></span> resolution level. The
projection will be an interpolation operator and whose coefficients can
be computed through the evaluation of <span
class=""math inline""><em>f</em></span> on a given set of points in the
unit disc. We extend the results to weighted Bergman space of upper half
plane and we introduce a numerical method to compute the coefficients
when the values of <span class=""math inline""><em>f</em></span> are given
on a set of points in the upper half-plane.</p>
"
S11,SC4011,2,Akash,Kalita,Akash Kalita,2025-06-27 08:00:00,CT,Contributed talks,Friday,08:30,09:00,111,200,Pretty good fractional revival on abelian Cayley graphs,"<p>Let <span class=""math inline""><em>Γ</em></span> be a graph with the
adjacency matrix <span class=""math inline""><em>A</em></span>. The
transition matrix of <span class=""math inline""><em>Γ</em></span>,
denoted <span class=""math inline""><em>H</em>(<em>t</em>)</span>, is
defined as <span
class=""math inline""><em>H</em>(<em>t</em>) := exp (−<strong>i</strong><em>t</em><em>A</em>)</span>,
where <span class=""math inline""><em>t</em> ∈ ℝ</span> and <span
class=""math inline"">$\textbf{i} := \sqrt{-1}$</span>. The graph <span
class=""math inline""><em>Γ</em></span> exhibits pretty good fractional
revival (PGFR) between the vertices <span
class=""math inline""><em>a</em></span> and <span
class=""math inline""><em>b</em></span> if there exists a sequence <span
class=""math inline"">{<em>t</em><sub><em>k</em></sub>}</span> in <span
class=""math inline"">ℝ</span> such that <span
class=""math inline"">lim<sub><em>k</em> → ∞</sub><em>H</em>(<em>t</em><sub><em>k</em></sub>)<strong>e</strong><sub><em>a</em></sub> = <em>α</em><strong>e</strong><sub><em>a</em></sub> + <em>β</em><strong>e</strong><sub><em>b</em></sub></span>,
where <span class=""math inline""><em>α</em>, <em>β</em>( ≠ 0) ∈ ℂ</span>
with <span
class=""math inline"">|<em>α</em>|<sup>2</sup> + |<em>β</em>|<sup>2</sup> = 1</span>.
In particular, if <span class=""math inline""><em>α</em> = 0</span>, then
<span class=""math inline""><em>Γ</em></span> exhibits pretty good state
transfer (PGST) between <span class=""math inline""><em>a</em></span> and
<span class=""math inline""><em>b</em></span>. In this study, we first
present a necessary and sufficient condition for the existence of PGFR
on Cayley graphs over abelian groups. Using that necessary and
sufficient condition, we prove that complement of a cycle on <span
class=""math inline"">2<em>p</em><sup><em>s</em></sup></span> vertices,
where <span class=""math inline""><em>p</em></span> is an odd prime and
<span class=""math inline""><em>s</em></span> is a positive integer,
exhibits PGFR. In the class of unitary Cayley graphs, we prove that an
unitary Cayley graph on <span class=""math inline""><em>n</em></span>
(<span class=""math inline""><em>n</em> ≥ 8</span>) vertices exhibits PGFR
if and only if <span
class=""math inline""><em>n</em> = 2<em>p</em></span>, where <span
class=""math inline""><em>p</em></span> is an odd prime. The preceding two
classes of circulant graphs provide infinitely many circulant graphs
exhibiting PGFR that fails to exhibits PGST. Further we obtain more
circulant graphs exhibiting PGFR. We also obtain some classes of
circulant graphs not exhibiting PGFR. Some of our results generalize the
results of Chan et al. [Pretty good quantum fractional revival in paths
and cycles. <em>Algebr. Comb.</em> 4(6) (2021), 989-1004.] for
cycles.</p>
"
S11,SC4011,3,,,,2025-06-27 08:00:00,CT,Contributed talks,Friday,09:00,09:30,111,200,,
